[{"graph":{"title":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","abstract":"Laboratory accidents pose significant risks to human life and property, underscoring the importance of robust safety protocols. Despite advancements in safety training, laboratory personnel may still unknowingly engage in unsafe practices. With the increasing reliance on large language models (LLMs) for guidance in various fields, including laboratory settings, there is a growing concern about their reliability in critical safety-related decision-making. Unlike trained human researchers, LLMs lack formal lab safety education, raising questions about their ability to provide safe and accurate guidance. Existing research on LLM trustworthiness primarily focuses on issues such as ethical compliance, truthfulness, and fairness but fails to fully cover safety-critical real-world applications, like lab safety. To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols. This benchmark includes 765 multiple-choice questions verified by human experts, assessing LLMs and large vision models (LVMs) performance in lab safety contexts. Our evaluations demonstrate that while GPT-4o outperforms human participants, it is still prone to critical errors, highlighting the risks of relying on LLMs in safety-critical environments. Our findings emphasize the need for specialized benchmarks to accurately assess the trustworthiness of LLMs in real-world safety applications. The code and data are available at https://anonymous.4open.science/r/LabSafetyBench-6363","entities":[{"label":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","type":"title","detail":null,"excerpts":null},{"label":"general machine learning (i.e., none of the above)","type":"primary_area","detail":null,"excerpts":null},{"label":"LLMs","type":"keyword","detail":null,"excerpts":null},{"label":"laboratory safety","type":"keyword","detail":null,"excerpts":null},{"label":"benchmark","type":"keyword","detail":null,"excerpts":null},{"label":"evaluation framework","type":"keyword","detail":null,"excerpts":null},{"label":"OSHA protocols","type":"keyword","detail":null,"excerpts":null},{"label":"hallucination propensity","type":"keyword","detail":null,"excerpts":null},{"label":"domain-specific knowledge","type":"keyword","detail":null,"excerpts":null},{"label":"practical decision-making","type":"keyword","detail":null,"excerpts":null},{"label":"To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols.","type":"tldr","detail":null,"excerpts":null},{"label":"First study to address LLM trustworthiness in lab safety","type":"claim","detail":"This work is the first study to address the trustworthiness of LLMs in high-stakes lab safety environments, extending conventional evaluations to assess operational safety in real-world scenarios.","excerpts":[{"section":"Introduction","text":"-   To our knowledge, this is the first study to address the trustworthiness of LLMs in high-stakes lab safety environments---extending conventional evaluations to assess operational safety in real-world scenarios."},{"section":"Conclusion","text":"In this paper, we introduce the LabSafety Bench, a comprehensive framework designed to evaluate the trustworthiness and reliability of LLMs and VLMs in safety-critical laboratory environments."}]},{"label":"First benchmark for evaluating foundational models on lab safety awareness","type":"claim","detail":"The paper presents the first benchmark for evaluating foundational models on lab safety awareness, a comprehensive framework grounded in OSHA protocols that systematically assesses models across three dimensions: hallucination propensity, domain-specific knowledge, and practical decision-making in dynamic lab scenarios.","excerpts":[{"section":"Introduction","text":"-   We present the first benchmark for evaluating foundational models on lab safety awareness---a comprehensive framework grounded in OSHA protocols that systematically assesses models across three dimensions: hallucination propensity, domain-specific knowledge, and practical decision-making in dynamic lab scenarios."}]},{"label":"Comprehensive evaluations of LLMs and VLMs using LabSafety Bench","type":"claim","detail":"The paper conducts comprehensive evaluations of LLMs and VLMs using LabSafety Bench, revealing that while proprietary models excel in multiple-choice tasks, their open-ended performance remains comparable to open-source models, highlighting the urgent need for improved training and evaluation to address real-world lab safety challenges.","excerpts":[{"section":"Introduction","text":"-   We conduct comprehensive evaluations of LLMs and VLMs using LabSafety Bench. Our findings reveal that while proprietary models excel in multiple-choice tasks, their open-ended performance remains comparable to open-source models, highlighting the urgent need for improved training and evaluation to address real-world lab safety challenges."},{"section":"Conclusion","text":"Our evaluations reveal that while models such as GPT-4o can outperform human participants on standard MCQs, they still exhibit significant limitations in open-ended, real-world scenario assessments---none achieving a 75% score on the Hazards Identification Test."}]},{"label":"LabSafety Bench: A comprehensive evaluation framework","type":"method","detail":"The Laboratory Safety Benchmark (LabSafety Bench) is a comprehensive framework that systematically assesses LLMs’ abilities to identify hazards, evaluate risks, and make informed decisions to prevent lab safety threats. It includes 765 multiple-choice questions (MCQs) and 520 realistic laboratory scenarios.","excerpts":[{"section":"Introduction","text":"To address this challenge, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive framework that systematically assesses LLMs’ abilities to identify hazards, evaluate risks, and make informed decisions to prevent lab safety threats."},{"section":"Introduction","text":"Building on this framework, we introduce the core structure of LabSafety Bench, which integrates a diverse set of evaluation tasks to assess LLM performance in laboratory safety contexts comprehensively."},{"section":"Introduction","text":"First, in alignment with US Occupational Safety and Health Administration (OSHA) protocols [@osha_2011_laboratory], we developed a set of 765 multiple-choice questions (MCQs) designed to comprehensively address a wide range of safety concerns across diverse laboratory domains."},{"section":"Introduction","text":"Second, we curated 520 realistic laboratory scenarios, each incorporating potential lab safety hazards."}]},{"label":"Text-only MCQs evaluation","type":"experiment","detail":"Evaluated open-weight models such as Llama3-8B, Llama3-70B, Vicuna-7B, Vicuna-13B, Mistral-7B, Mistral-8x7B and Deepseek-R1. Selected proprietary models include Gemini-1.5-Flash, Gemini-1.5-Pro, Gemini-2.0-Flash, Claude-3-Haiku, Claude-3.5-Sonnet, o3-mini, GPT-4o-mini, and GPT-4o. Eight experimental settings were established by varying the combination of 3 factors: with or without chain of thought (CoT), with or without external hints, and using either 5-shot or 0-shot learning.","excerpts":[{"section":"Experiments on MCQs","text":"**Evaluated Models.** For text-only MCQs and scenario-based questions, we evaluate open-weight models such as Llama3-8B, Llama3-70B [@dubey2024llama], Vicuna-7B, Vicuna-13B [@vicuna2023], Mistral-7B, Mistral-8x7B [@jiang2023mistral] and Deepseek-R1 [@guo2025deepseek]. Selected proprietary models include Gemini-1.5-Flash, Gemini-1.5-Pro, Gemini-2.0-Flash [@team2023gemini], Claude-3-Haiku, Claude-3.5-Sonnet [@anthropic_2024_the], o3-mini, GPT-4o-mini, and GPT-4o [@achiam2023gpt]."},{"section":"Experiments on MCQs","text":"**Evaluation Settings.** For the text-only MCQs, we establish eight experimental settings by varying the combination of 3 factors: with or without chain of thought (CoT), with or without external hints, and using either 5-shot or 0-shot learning."}]},{"label":"Text-with-image MCQs evaluation","type":"experiment","detail":"Evaluated open-weight models like Qwen-VL-Chat, InstructBlip-7B, InternVL2-8B, and Llama3.2-11B. Proprietary models mentioned for text-only questions also support vision inference, we test these models for text-with-image questions as well. Adopted the setting with or without CoT.","excerpts":[{"section":"Experiments on MCQs","text":"For text-with-image MCQs, we evaluate open-weight models like Qwen-VL-Chat [@bai2023qwen], InstructBlip-7B [@dai2023instructblipgeneralpurposevisionlanguagemodels], InternVL2-8B [@chen2024internvl], and Llama3.2-11B [@dubey2024llama]. Since all of the proprietary models mentioned for text-only questions also support vision inference, we test these models for text-with-image questions as well."},{"section":"Experiments on MCQs","text":"For the text-with-image evaluation, we only adopt the setting with or without CoT, as few-shot may not be supported by all models, and hints may potentially reveal the image content."}]},{"label":"Real-Scenario-Based Open-Ended Questions evaluation","type":"experiment","detail":"The same models used in text-only MCQs were evaluated. For all open-ended questions, o3-mini was used to determine whether the LLM's answer covers the ground truth answer. DA with a 0-shot setting was employed.","excerpts":[{"section":"Experiments on Real-Scenario-Based Open-Ended Questions","text":"**Evaluated Models** are the same as that used in text-only MCQs."},{"section":"Experiments on Real-Scenario-Based Open-Ended Questions","text":"For all open-ended questions, we use o3-mini to determine whether the LLM's answer covers the ground truth answer."},{"section":"Experiments on Real-Scenario-Based Open-Ended Questions","text":"Furthermore, given that CoT reasoning and few-shot learning have shown limited benefits in multiple-choice settings, we employed DA with a 0-shot setting to avoid excessively long examples and potential interference from CoT."}]}],"relationships":[{"source":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","target":"general machine learning (i.e., none of the above)"},{"source":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","target":"LLMs"},{"source":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","target":"laboratory safety"},{"source":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","target":"benchmark"},{"source":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","target":"evaluation framework"},{"source":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","target":"OSHA protocols"},{"source":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","target":"hallucination propensity"},{"source":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","target":"domain-specific knowledge"},{"source":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","target":"practical decision-making"},{"source":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","target":"To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols."},{"source":"To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols.","target":"First study to address LLM trustworthiness in lab safety"},{"source":"To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols.","target":"First benchmark for evaluating foundational models on lab safety awareness"},{"source":"To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols.","target":"Comprehensive evaluations of LLMs and VLMs using LabSafety Bench"},{"source":"First study to address LLM trustworthiness in lab safety","target":"LabSafety Bench: A comprehensive evaluation framework"},{"source":"First benchmark for evaluating foundational models on lab safety awareness","target":"LabSafety Bench: A comprehensive evaluation framework"},{"source":"Comprehensive evaluations of LLMs and VLMs using LabSafety Bench","target":"LabSafety Bench: A comprehensive evaluation framework"},{"source":"LabSafety Bench: A comprehensive evaluation framework","target":"Text-only MCQs evaluation"},{"source":"LabSafety Bench: A comprehensive evaluation framework","target":"Text-with-image MCQs evaluation"},{"source":"LabSafety Bench: A comprehensive evaluation framework","target":"Real-Scenario-Based Open-Ended Questions evaluation"}],"valid_status":"Valid","valid_status_all":["Valid"]},"related":[{"summary":"The Related Paper, SafetyBench, complements the Main Paper by providing a broader context for evaluating the safety of large language models (LLMs) through its extensive benchmark of 11,435 multiple-choice questions across various safety categories. While the Main Paper focuses specifically on lab safety and introduces the LabSafety Bench, SafetyBench's findings on the performance of LLMs, including GPT-4, reinforce the Main Paper's concerns about the reliability of LLMs in safety-critical environments. Together, these papers highlight the urgent need for specialized benchmarks to assess LLMs' trustworthiness in real-world applications.","paper_id":"9b9a4fa3ed510fc6eb1bf831979235f3d9f8b556","title":"SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions","abstract":"With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs. In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns. Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages. Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs. We also demonstrate that the measured safety understanding abilities in SafetyBench are correlated with safety generation abilities. Data and evaluation guidelines are available at \\url{https://github.com/thu-coai/SafetyBench}{https://github.com/thu-coai/SafetyBench}. Submission entrance and leaderboard are available at \\url{https://llmbench.ai/safety}{https://llmbench.ai/safety}.","score":0.6762083768844604,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols. This benchmark includes 765 multiple-choice questions verified by human experts, assessing LLMs and large vision models (LVMs) performance in lab safety contexts. Our evaluations demonstrate that while GPT-4o outperforms human participants, it is still prone to critical errors, highlighting the risks of relying on LLMs in safety-critical environments. Our findings emphasize the need for specialized benchmarks to accurately assess the trustworthiness of LLMs in real-world safety applications. The code and data are available at https://anonymous.4open.science/r/LabSafetyBench-6363."},{"summary":"The Related Paper, SORRY-Bench, complements the Main Paper by addressing the evaluation of LLMs' safety refusal behaviors, which is crucial for safe deployments in laboratory settings. While the Main Paper focuses on benchmarking LLMs in lab safety contexts using a comprehensive evaluation framework, SORRY-Bench enhances this by providing a fine-grained taxonomy of unsafe topics and diverse linguistic augmentations, thus offering a more nuanced understanding of LLMs' capabilities in recognizing and rejecting unsafe requests. Together, these papers underscore the importance of specialized benchmarks for assessing LLM trustworthiness in safety-critical applications.","paper_id":"964da38f24d3a2e65474728eef05f3de9e47666d","title":"SORRY-Bench: Systematically Evaluating Large Language Model Safety Refusal Behaviors","abstract":"Evaluating aligned large language models' (LLMs) ability to recognize and reject unsafe user requests is crucial for safe, policy-compliant deployments. Existing evaluation efforts, however, face three limitations that we address with SORRY-Bench, our proposed benchmark. First, existing methods often use coarse-grained taxonomies of unsafe topics, and are over-representing some fine-grained topics. For example, among the ten existing datasets that we evaluated, tests for refusals of self-harm instructions are over 3x less represented than tests for fraudulent activities. SORRY-Bench improves on this by using a fine-grained taxonomy of 44 potentially unsafe topics, and 440 class-balanced unsafe instructions, compiled through human-in-the-loop methods. Second, linguistic characteristics and formatting of prompts are often overlooked, like different languages, dialects, and more -- which are only implicitly considered in many evaluations. We supplement SORRY-Bench with 20 diverse linguistic augmentations to systematically examine these effects. Third, existing evaluations rely on large LLMs (e.g., GPT-4) for evaluation, which can be computationally expensive. We investigate design choices for creating a fast, accurate automated safety evaluator. By collecting 7K+ human annotations and conducting a meta-evaluation of diverse LLM-as-a-judge designs, we show that fine-tuned 7B LLMs can achieve accuracy comparable to GPT-4 scale LLMs, with lower computational cost. Putting these together, we evaluate over 50 proprietary and open-weight LLMs on SORRY-Bench, analyzing their distinctive safety refusal behaviors. We hope our effort provides a building block for systematic evaluations of LLMs' safety refusal capabilities, in a balanced, granular, and efficient manner. Benchmark demo, data, code, and models are available through https://sorry-bench.github.io.","score":0.6367084383964539,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols. This benchmark includes 765 multiple-choice questions verified by human experts, assessing LLMs and large vision models (LVMs) performance in lab safety contexts. Our evaluations demonstrate that while GPT-4o outperforms human participants, it is still prone to critical errors, highlighting the risks of relying on LLMs in safety-critical environments. Our findings emphasize the need for specialized benchmarks to accurately assess the trustworthiness of LLMs in real-world safety applications. The code and data are available at https://anonymous.4open.science/r/LabSafetyBench-6363."},{"summary":"The Related Paper, 'Can't See the Forest for the Trees,' supports the Main Paper by highlighting the critical challenges in ensuring safety awareness in multimodal large language models (MLLMs), which parallels the Main Paper's focus on safety issues in laboratory settings. Both papers emphasize the inadequacies of current models in providing reliable safety guidance, with the Related Paper's findings on MLLMs' misclassification rates reinforcing the Main Paper's concerns about the trustworthiness of LLMs in safety-critical environments. Together, they underscore the urgent need for specialized benchmarks, like LabSafety Bench and MMSafeAware, to evaluate and improve the safety performance of these models.","paper_id":"3a210fef392b2ac99f28d55115961266edd4f8f1","title":"Can't See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs","abstract":"Multimodal Large Language Models (MLLMs) have expanded the capabilities of traditional language models by enabling interaction through both text and images. However, ensuring the safety of these models remains a significant challenge, particularly in accurately identifying whether multimodal content is safe or unsafe-a capability we term safety awareness. In this paper, we introduce MMSafeAware, the first comprehensive multimodal safety awareness benchmark designed to evaluate MLLMs across 29 safety scenarios with 1500 carefully curated image-prompt pairs. MMSafeAware includes both unsafe and over-safety subsets to assess models abilities to correctly identify unsafe content and avoid over-sensitivity that can hinder helpfulness. Evaluating nine widely used MLLMs using MMSafeAware reveals that current models are not sufficiently safe and often overly sensitive; for example, GPT-4V misclassifies 36.1% of unsafe inputs as safe and 59.9% of benign inputs as unsafe. We further explore three methods to improve safety awareness-prompting-based approaches, visual contrastive decoding, and vision-centric reasoning fine-tuning-but find that none achieve satisfactory performance. Our findings highlight the profound challenges in developing MLLMs with robust safety awareness, underscoring the need for further research in this area. All the code and data will be publicly available to facilitate future research.","score":0.6263474822044373,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols. This benchmark includes 765 multiple-choice questions verified by human experts, assessing LLMs and large vision models (LVMs) performance in lab safety contexts. Our evaluations demonstrate that while GPT-4o outperforms human participants, it is still prone to critical errors, highlighting the risks of relying on LLMs in safety-critical environments. Our findings emphasize the need for specialized benchmarks to accurately assess the trustworthiness of LLMs in real-world safety applications. The code and data are available at https://anonymous.4open.science/r/LabSafetyBench-6363."},{"summary":"The Related Paper, 'SimpleSafetyTests', complements the Main Paper by providing a systematic approach to identifying critical safety risks in LLMs, which aligns with the Main Paper's focus on lab safety. Both papers highlight the vulnerabilities of LLMs in safety-critical contexts, with the Related Paper offering a test suite that reveals significant safety weaknesses across various models. This supports the Main Paper's argument for the necessity of specialized benchmarks like LabSafety Bench to evaluate LLMs' trustworthiness in real-world applications.","paper_id":"c11ac248290acf6bba414cd6d6be25df6c7eacf4","title":"SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models","abstract":"The past year has seen rapid acceleration in the development of large language models (LLMs). However, without proper steering and safeguards, LLMs will readily follow malicious instructions, provide unsafe advice, and generate toxic content. We introduce SimpleSafetyTests (SST) as a new test suite for rapidly and systematically identifying such critical safety risks. The test suite comprises 100 test prompts across five harm areas that LLMs, for the vast majority of applications, should refuse to comply with. We test 11 open-access and open-source LLMs and four closed-source LLMs, and find critical safety weaknesses. While some of the models do not give a single unsafe response, most give unsafe responses to more than 20% of the prompts, with over 50% unsafe responses in the extreme. Prepending a safety-emphasising system prompt substantially reduces the occurrence of unsafe responses, but does not completely stop them from happening. Trained annotators labelled every model response to SST (n = 3,000). We use these annotations to evaluate five AI safety filters (which assess whether a models' response is unsafe given a prompt) as a way of automatically evaluating models' performance on SST. The filters' performance varies considerably. There are also differences across the five harm areas, and on the unsafe versus safe responses. The widely-used Perspective API has 72% accuracy and a newly-created zero-shot prompt to OpenAI's GPT-4 performs best with 89% accuracy. Content Warning: This paper contains prompts and responses that relate to child abuse, suicide, self-harm and eating disorders, scams and fraud, illegal items, and physical harm.","score":0.6238635182380676,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols. This benchmark includes 765 multiple-choice questions verified by human experts, assessing LLMs and large vision models (LVMs) performance in lab safety contexts. Our evaluations demonstrate that while GPT-4o outperforms human participants, it is still prone to critical errors, highlighting the risks of relying on LLMs in safety-critical environments. Our findings emphasize the need for specialized benchmarks to accurately assess the trustworthiness of LLMs in real-world safety applications. The code and data are available at https://anonymous.4open.science/r/LabSafetyBench-6363."},{"summary":"The Related Paper, ALERT, complements the Main Paper by providing a comprehensive benchmark for assessing the safety of large language models (LLMs) through a fine-grained risk taxonomy and red teaming methodologies. Both papers emphasize the critical need for safety evaluations in LLMs, with ALERT focusing on adversarial testing to identify vulnerabilities, while the Main Paper introduces LabSafety Bench to specifically address safety in laboratory contexts. Together, they highlight the importance of specialized benchmarks to ensure LLMs can provide reliable guidance in safety-critical environments.","paper_id":"dfc9bb24627d1dd61c8d495cd86a874a2a1130ad","title":"ALERT: A Comprehensive Benchmark for Assessing Large Language Models' Safety through Red Teaming","abstract":"When building Large Language Models (LLMs), it is paramount to bear safety in mind and protect them with guardrails. Indeed, LLMs should never generate content promoting or normalizing harmful, illegal, or unethical behavior that may contribute to harm to individuals or society. This principle applies to both normal and adversarial use. In response, we introduce ALERT, a large-scale benchmark to assess safety based on a novel fine-grained risk taxonomy. It is designed to evaluate the safety of LLMs through red teaming methodologies and consists of more than 45k instructions categorized using our novel taxonomy. By subjecting LLMs to adversarial testing scenarios, ALERT aims to identify vulnerabilities, inform improvements, and enhance the overall safety of the language models. Furthermore, the fine-grained taxonomy enables researchers to perform an in-depth evaluation that also helps one to assess the alignment with various policies. In our experiments, we extensively evaluate 10 popular open- and closed-source LLMs and demonstrate that many of them still struggle to attain reasonable levels of safety.","score":0.6012942790985107,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols. This benchmark includes 765 multiple-choice questions verified by human experts, assessing LLMs and large vision models (LVMs) performance in lab safety contexts. Our evaluations demonstrate that while GPT-4o outperforms human participants, it is still prone to critical errors, highlighting the risks of relying on LLMs in safety-critical environments. Our findings emphasize the need for specialized benchmarks to accurately assess the trustworthiness of LLMs in real-world safety applications. The code and data are available at https://anonymous.4open.science/r/LabSafetyBench-6363."},{"summary":"The Related Paper contrasts the Main Paper by focusing on the issue of 'exaggerated safety' in LLMs, where safe prompts are misclassified as dangerous, leading to excessive caution that hampers utility. While the Main Paper emphasizes the critical errors LLMs can make in safety contexts and the need for specialized benchmarks, the Related Paper proposes strategies to improve LLMs' decision-making by balancing safety and helpfulness. This highlights a fundamental difference in approach: the Main Paper critiques LLMs' reliability in safety-critical environments, whereas the Related Paper seeks to enhance their performance by mitigating overly cautious behaviors.","paper_id":"d440b5ee74cb9663404f7d4701c063f964b56e7f","title":"Mitigating Exaggerated Safety in Large Language Models","abstract":"As the popularity of Large Language Models (LLMs) grow, combining model safety with utility becomes increasingly important. The challenge is making sure that LLMs can recognize and decline dangerous prompts without sacrificing their ability to be helpful. The problem of\"exaggerated safety\"demonstrates how difficult this can be. To reduce excessive safety behaviours -- which was discovered to be 26.1% of safe prompts being misclassified as dangerous and refused -- we use a combination of XSTest dataset prompts as well as interactive, contextual, and few-shot prompting to examine the decision bounds of LLMs such as Llama2, Gemma Command R+, and Phi-3. We find that few-shot prompting works best for Llama2, interactive prompting works best Gemma, and contextual prompting works best for Command R+ and Phi-3. Using a combination of these prompting strategies, we are able to mitigate exaggerated safety behaviors by an overall 92.9% across all LLMs. Our work presents a multiple prompting strategies to jailbreak LLMs' decision-making processes, allowing them to navigate the tight line between refusing unsafe prompts and remaining helpful.","score":0.7165049314498901,"polarity":"negative","source":"semantic","contexts":null,"background":"Laboratory accidents pose significant risks to human life and property, underscoring the importance of robust safety protocols. Despite advancements in safety training, laboratory personnel may still unknowingly engage in unsafe practices. With the increasing reliance on large language models (LLMs) for guidance in various fields, including laboratory settings, there is a growing concern about their reliability in critical safety-related decision-making. Unlike trained human researchers, LLMs lack formal lab safety education, raising questions about their ability to provide safe and accurate guidance. Existing research on LLM trustworthiness primarily focuses on issues such as ethical compliance, truthfulness, and fairness but fails to fully cover safety-critical real-world applications, like lab safety.","target":null},{"summary":"The Related Paper, 'Chinese SafetyQA', contrasts with the Main Paper by focusing on the factuality and clarity of LLMs in safety-related domains, particularly in law and ethics, rather than the specific context of laboratory safety. While the Main Paper emphasizes the need for a specialized benchmark for lab safety protocols, the Related Paper introduces a benchmark aimed at evaluating LLMs' factuality in a broader safety context, highlighting different aspects of LLM reliability. Additionally, the Related Paper's focus on the Chinese language and regional compliance issues presents a different angle on safety concerns compared to the Main Paper's emphasis on OSHA-aligned safety practices.","paper_id":"2b3bb447db34499cbf18cfc67f368e79c69ea538","title":"Chinese SafetyQA: A Safety Short-form Factuality Benchmark for Large Language Models","abstract":"With the rapid advancement of Large Language Models (LLMs), significant safety concerns have emerged. Fundamentally, the safety of large language models is closely linked to the accuracy, comprehensiveness, and clarity of their understanding of safety knowledge, particularly in domains such as law, policy and ethics. This factuality ability is crucial in determining whether these models can be deployed and applied safely and compliantly within specific regions. To address these challenges and better evaluate the factuality ability of LLMs to answer short questions, we introduce the Chinese SafetyQA benchmark. Chinese SafetyQA has several properties (i.e., Chinese, Diverse, High-quality, Static, Easy-to-evaluate, Safety-related, Harmless). Based on Chinese SafetyQA, we perform a comprehensive evaluation on the factuality abilities of existing LLMs and analyze how these capabilities relate to LLM abilities, e.g., RAG ability and robustness against attacks.","score":0.6951780915260315,"polarity":"negative","source":"semantic","contexts":null,"background":"Laboratory accidents pose significant risks to human life and property, underscoring the importance of robust safety protocols. Despite advancements in safety training, laboratory personnel may still unknowingly engage in unsafe practices. With the increasing reliance on large language models (LLMs) for guidance in various fields, including laboratory settings, there is a growing concern about their reliability in critical safety-related decision-making. Unlike trained human researchers, LLMs lack formal lab safety education, raising questions about their ability to provide safe and accurate guidance. Existing research on LLM trustworthiness primarily focuses on issues such as ethical compliance, truthfulness, and fairness but fails to fully cover safety-critical real-world applications, like lab safety.","target":null},{"summary":"The Related Paper contrasts the Main Paper by emphasizing the lack of uncertainty quantification in LLMs, which the Main Paper does not address. While the Main Paper focuses on the reliability of LLMs in providing safe guidance in laboratory settings, the Related Paper critiques the inherent unpredictability of LLMs and their tendency to generate misinformation without offering confidence metrics. This highlights a gap in the Main Paper's approach, suggesting that even if LLMs perform well in safety contexts, their trustworthiness remains questionable due to the absence of a systematic way to measure uncertainty.","paper_id":"57269ec0822fb0afcb16a53558dbcd8ebe9a0a7d","title":"Semantic Density: Uncertainty Quantification in Semantic Space for Large Language Models","abstract":"With the widespread application of Large Language Models (LLMs) to various domains, concerns regarding the trustworthiness of LLMs in safety-critical scenarios have been raised, due to their unpredictable tendency to hallucinate and generate misinformation. Existing LLMs do not have an inherent functionality to provide the users with an uncertainty/confidence metric for each response it generates, making it difficult to evaluate trustworthiness. Although several studies aim to develop uncertainty quantification methods for LLMs, they have fundamental limitations, such as being restricted to classification tasks, requiring additional training and data, considering only lexical instead of semantic information, and being prompt-wise but not response-wise. A new framework is proposed in this paper to address these issues. Semantic density extracts uncertainty/confidence information for each response from a probability distribution perspective in semantic space. It has no restriction on task types and is\"off-the-shelf\"for new models and tasks. Experiments on seven state-of-the-art LLMs, including the latest Llama 3 and Mixtral-8x22B models, on four free-form question-answering benchmarks demonstrate the superior performance and robustness of semantic density compared to prior approaches.","score":0.6788407564163208,"polarity":"negative","source":"semantic","contexts":null,"background":"Laboratory accidents pose significant risks to human life and property, underscoring the importance of robust safety protocols. Despite advancements in safety training, laboratory personnel may still unknowingly engage in unsafe practices. With the increasing reliance on large language models (LLMs) for guidance in various fields, including laboratory settings, there is a growing concern about their reliability in critical safety-related decision-making. Unlike trained human researchers, LLMs lack formal lab safety education, raising questions about their ability to provide safe and accurate guidance. Existing research on LLM trustworthiness primarily focuses on issues such as ethical compliance, truthfulness, and fairness but fails to fully cover safety-critical real-world applications, like lab safety.","target":null},{"summary":"The Related Paper contrasts the Main Paper by focusing on a proactive approach to aligning LLMs with human values through a structured optimization framework, SACPO, which emphasizes safety constraints and reward maximization. While the Main Paper highlights the limitations of LLMs in providing safe guidance in laboratory settings, the Related Paper presents a method that aims to enhance LLM performance by ensuring safety and helpfulness through systematic policy optimization. This difference underscores a divergence in focus: the Main Paper critiques LLMs' current capabilities, whereas the Related Paper proposes a solution to improve those capabilities.","paper_id":"de17e7ed443e13320694cce3b2f475c694801246","title":"Stepwise Alignment for Constrained Language Model Policy Optimization","abstract":"Safety and trustworthiness are indispensable requirements for real-world applications of AI systems using large language models (LLMs). This paper formulates human value alignment as an optimization problem of the language model policy to maximize reward under a safety constraint, and then proposes an algorithm, Stepwise Alignment for Constrained Policy Optimization (SACPO). One key idea behind SACPO, supported by theory, is that the optimal policy incorporating reward and safety can be directly obtained from a reward-aligned policy. Building on this key idea, SACPO aligns LLMs step-wise with each metric while leveraging simple yet powerful alignment algorithms such as direct preference optimization (DPO). SACPO offers several advantages, including simplicity, stability, computational efficiency, and flexibility of algorithms and datasets. Under mild assumptions, our theoretical analysis provides the upper bounds on optimality and safety constraint violation. Our experimental results show that SACPO can fine-tune Alpaca-7B better than the state-of-the-art method in terms of both helpfulness and harmlessness.","score":0.6773436069488525,"polarity":"negative","source":"semantic","contexts":null,"background":"Laboratory accidents pose significant risks to human life and property, underscoring the importance of robust safety protocols. Despite advancements in safety training, laboratory personnel may still unknowingly engage in unsafe practices. With the increasing reliance on large language models (LLMs) for guidance in various fields, including laboratory settings, there is a growing concern about their reliability in critical safety-related decision-making. Unlike trained human researchers, LLMs lack formal lab safety education, raising questions about their ability to provide safe and accurate guidance. Existing research on LLM trustworthiness primarily focuses on issues such as ethical compliance, truthfulness, and fairness but fails to fully cover safety-critical real-world applications, like lab safety.","target":null},{"summary":"The Related Paper contrasts the Main Paper by highlighting that while the Main Paper focuses on the safety protocols and performance of LLMs in laboratory settings, the Related Paper emphasizes the broader societal implications of LLM safety, particularly regarding marginalized populations. It critiques the effectiveness of safety measures in LLMs, suggesting that these models can still perpetuate biases and create quality-of-service harms, which is a concern not addressed in the Main Paper's evaluation of lab safety. Additionally, the Related Paper discusses the trade-offs between safety and helpfulness, indicating that safety optimizations may lead to reduced model responsiveness, a point that the Main Paper does not explore.","paper_id":"1bffb2aad9d34e5b74de328acd04d01355d4680f","title":"From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards","abstract":"Recent progress in large language models (LLMs) has led to their widespread adoption in various domains. However, these advancements have also introduced additional safety risks and raised concerns regarding their detrimental impact on already marginalized populations. Despite growing mitigation efforts to develop safety safeguards, such as supervised safety-oriented fine-tuning and leveraging safe reinforcement learning from human feedback, multiple concerns regarding the safety and ingrained biases in these models remain. Furthermore, previous work has demonstrated that models optimized for safety often display exaggerated safety behaviors, such as a tendency to refrain from responding to certain requests as a precautionary measure. As such, a clear trade-off between the helpfulness and safety of these models has been documented in the literature. In this paper, we further investigate the effectiveness of safety measures by evaluating models on already mitigated biases. Using the case of Llama 2 as an example, we illustrate how LLMs' safety responses can still encode harmful assumptions. To do so, we create a set of non-toxic prompts, which we then use to evaluate Llama models. Through our new taxonomy of LLMs responses to users, we observe that the safety/helpfulness trade-offs are more pronounced for certain demographic groups which can lead to quality-of-service harms for marginalized populations.","score":0.6715303659439087,"polarity":"negative","source":"semantic","contexts":null,"background":"Laboratory accidents pose significant risks to human life and property, underscoring the importance of robust safety protocols. Despite advancements in safety training, laboratory personnel may still unknowingly engage in unsafe practices. With the increasing reliance on large language models (LLMs) for guidance in various fields, including laboratory settings, there is a growing concern about their reliability in critical safety-related decision-making. Unlike trained human researchers, LLMs lack formal lab safety education, raising questions about their ability to provide safe and accurate guidance. Existing research on LLM trustworthiness primarily focuses on issues such as ethical compliance, truthfulness, and fairness but fails to fully cover safety-critical real-world applications, like lab safety.","target":null},{"summary":"The Related Paper complements the Main Paper by addressing the broader context of safety analysis for LLMs, particularly focusing on online safety during the generation phase. While the Main Paper emphasizes the need for a specialized benchmark for lab safety, the Related Paper introduces a comprehensive evaluation of existing online safety analysis methods, highlighting the importance of quality assurance in LLM outputs. Together, these papers underscore the critical need for robust safety protocols in LLM applications, reinforcing the Main Paper's claims about the risks associated with LLMs in safety-critical environments.","paper_id":"aa3def6c0d6eef8183e9b78894a711ed9e092df6","title":"Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward","abstract":"While Large Language Models (LLMs) have seen widespread applications across numerous fields, their limited interpretability poses concerns regarding their safe operations from multiple aspects, e.g., truthfulness, robustness, and fairness. Recent research has started developing quality assurance methods for LLMs, introducing techniques such as offline detector-based or uncertainty estimation methods. However, these approaches predominantly concentrate on post-generation analysis, leaving the online safety analysis for LLMs during the generation phase an unexplored area. To bridge this gap, we conduct in this work a comprehensive evaluation of the effectiveness of existing online safety analysis methods on LLMs. We begin with a pilot study that validates the feasibility of detecting unsafe outputs in the early generation process. Following this, we establish the first publicly available benchmark of online safety analysis for LLMs, including a broad spectrum of methods, models, tasks, datasets, and evaluation metrics. Utilizing this benchmark, we extensively analyze the performance of state-of-the-art online safety analysis methods on both open-source and closed-source LLMs. This analysis reveals the strengths and weaknesses of individual methods and offers valuable insights into selecting the most appropriate method based on specific application scenarios and task requirements. Furthermore, we also explore the potential of using hybridization methods, i.e., combining multiple methods to derive a collective safety conclusion, to enhance the efficacy of online safety analysis for LLMs. Our findings indicate a promising direction for the development of innovative and trustworthy quality assurance methodologies for LLMs, facilitating their reliable deployments across diverse domains.","score":0.7399051785469055,"polarity":"positive","source":"citations","contexts":[{"sentence":"LLM safety primarily focuses on whether the model generates harmful output, such as responding to harmful queries in the context of jailbreak prompts \\citep{wei2024jailbroken, zou2023universal, zhou2024defending, xie2024sorry, xie2024online}.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper, SciAssess, complements the Main Paper by addressing the evaluation of LLMs in scientific contexts, which includes safety-critical applications like laboratory settings. While LabSafety Bench focuses specifically on safety protocols and the reliability of LLMs in lab environments, SciAssess provides a broader framework for assessing LLM proficiency in scientific literature analysis. Both papers highlight the need for specialized benchmarks to evaluate LLM capabilities, reinforcing the importance of rigorous assessment in ensuring safe and effective use of LLMs in various scientific domains.","paper_id":"95d19f8ede34cd712a09ae3b86bed2b338bd9a48","title":"SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis","abstract":"Recent breakthroughs in Large Language Models (LLMs) have revolutionized scientific literature analysis. However, existing benchmarks fail to adequately evaluate the proficiency of LLMs in this domain, particularly in scenarios requiring higher-level abilities beyond mere memorization and the handling of multimodal data. In response to this gap, we introduce SciAssess, a benchmark specifically designed for the comprehensive evaluation of LLMs in scientific literature analysis. It aims to thoroughly assess the efficacy of LLMs by evaluating their capabilities in Memorization (L1), Comprehension (L2), and Analysis \\&Reasoning (L3). It encompasses a variety of tasks drawn from diverse scientific fields, including biology, chemistry, material, and medicine. To ensure the reliability of SciAssess, rigorous quality control measures have been implemented, ensuring accuracy, anonymization, and compliance with copyright standards. SciAssess evaluates 11 LLMs, highlighting their strengths and areas for improvement. We hope this evaluation supports the ongoing development of LLM applications in scientific literature analysis. SciAssess and its resources are available at \\url{https://github.com/sci-assess/SciAssess}.","score":0.5113096237182617,"polarity":"positive","source":"citations","contexts":[{"sentence":"Numerous benchmarks have been developed to evaluate LLM applications in scientific domains \\citep{guo2025can, guo2025artificial, guo2023can, sun2024scieval, cai2024sciassess, liang2024scemqa, yue2024mmmu}.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper, \"Jailbroken: How Does LLM Safety Training Fail?\", supports the Main Paper by highlighting the vulnerabilities of large language models (LLMs) in safety-critical applications, which aligns with the Main Paper's focus on lab safety. Both papers emphasize the inadequacies of current safety training and the potential risks associated with relying on LLMs for guidance in sensitive environments. The Related Paper's exploration of failure modes in safety training reinforces the Main Paper's call for specialized benchmarks like LabSafety Bench to evaluate LLM performance in real-world safety contexts.","paper_id":"929305892d4ddae575a0fc23227a8139f7681632","title":"Jailbroken: How Does LLM Safety Training Fail?","abstract":"Large language models trained for safety and harmlessness remain susceptible to adversarial misuse, as evidenced by the prevalence of\"jailbreak\"attacks on early releases of ChatGPT that elicit undesired behavior. Going beyond recognition of the issue, we investigate why such attacks succeed and how they can be created. We hypothesize two failure modes of safety training: competing objectives and mismatched generalization. Competing objectives arise when a model's capabilities and safety goals conflict, while mismatched generalization occurs when safety training fails to generalize to a domain for which capabilities exist. We use these failure modes to guide jailbreak design and then evaluate state-of-the-art models, including OpenAI's GPT-4 and Anthropic's Claude v1.3, against both existing and newly designed attacks. We find that vulnerabilities persist despite the extensive red-teaming and safety-training efforts behind these models. Notably, new attacks utilizing our failure modes succeed on every prompt in a collection of unsafe requests from the models' red-teaming evaluation sets and outperform existing ad hoc jailbreaks. Our analysis emphasizes the need for safety-capability parity -- that safety mechanisms should be as sophisticated as the underlying model -- and argues against the idea that scaling alone can resolve these safety failure modes.","score":0.46409836411476135,"polarity":"positive","source":"citations","contexts":[{"sentence":"LLM safety primarily focuses on whether the model generates harmful output, such as responding to harmful queries in the context of jailbreak prompts \\citep{wei2024jailbroken, zou2023universal, zhou2024defending, xie2024sorry, xie2024online}.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper supports the Main Paper by highlighting the importance of optimizing test-time computation in LLMs, which can enhance their performance in safety-critical applications like laboratory settings. By demonstrating that adaptive scaling of inference-time compute can significantly improve LLM outputs, the Related Paper reinforces the Main Paper's assertion that LLMs, despite their potential, require careful evaluation and optimization to ensure reliability in providing safety guidance. This connection underscores the necessity of the LabSafety Bench framework proposed in the Main Paper, as it aims to assess LLMs' performance in safety contexts more rigorously.","paper_id":"8292083dd8f6ae898ea0ee54a6b97997d1a51c9d","title":"Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters","abstract":"Enabling LLMs to improve their outputs by using more test-time computation is a critical step towards building generally self-improving agents that can operate on open-ended natural language. In this paper, we study the scaling of inference-time computation in LLMs, with a focus on answering the question: if an LLM is allowed to use a fixed but non-trivial amount of inference-time compute, how much can it improve its performance on a challenging prompt? Answering this question has implications not only on the achievable performance of LLMs, but also on the future of LLM pretraining and how one should tradeoff inference-time and pre-training compute. Despite its importance, little research attempted to understand the scaling behaviors of various test-time inference methods. Moreover, current work largely provides negative results for a number of these strategies. In this work, we analyze two primary mechanisms to scale test-time computation: (1) searching against dense, process-based verifier reward models; and (2) updating the model's distribution over a response adaptively, given the prompt at test time. We find that in both cases, the effectiveness of different approaches to scaling test-time compute critically varies depending on the difficulty of the prompt. This observation motivates applying a\"compute-optimal\"scaling strategy, which acts to most effectively allocate test-time compute adaptively per prompt. Using this compute-optimal strategy, we can improve the efficiency of test-time compute scaling by more than 4x compared to a best-of-N baseline. Additionally, in a FLOPs-matched evaluation, we find that on problems where a smaller base model attains somewhat non-trivial success rates, test-time compute can be used to outperform a 14x larger model.","score":0.4363376498222351,"polarity":"positive","source":"citations","contexts":[{"sentence":"This could involve increasing test-time computing, such as incorporating search against a verifier or refining the proposal distribution to enhance accuracy \\citep{snell2024scaling}.}","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper supports the Main Paper by demonstrating the capabilities of LLMs, specifically GPT-4, in generating robotic scripts for laboratory automation, which highlights the potential of LLMs in enhancing laboratory efficiency. This aligns with the Main Paper's concerns about the reliability of LLMs in safety-critical environments, as it underscores the need for robust evaluation frameworks like LabSafety Bench to ensure that LLMs can safely assist in laboratory settings. Both papers emphasize the importance of understanding LLM limitations and the necessity for specialized benchmarks to assess their performance in real-world applications.","paper_id":"5ec18c8777e0eaf1411987638040546a22da861e","title":"LLMs can generate robotic scripts from goal-oriented instructions in biological laboratory automation","abstract":"The use of laboratory automation by all researchers may substantially accelerate scientific activities by humans, including those in the life sciences. However, computer programs to operate robots should be written to implement laboratory automation, which requires technical knowledge and skills that may not be part of a researcher's training or expertise. In the last few years, there has been remarkable development in large language models (LLMs) such as GPT-4, which can generate computer codes based on natural language instructions. In this study, we used LLMs, including GPT-4, to generate scripts for robot operations in biological experiments based on ambiguous instructions. GPT-4 successfully generates scripts for OT-2, an automated liquid-handling robot, from simple instructions in natural language without specifying the robotic actions. Conventionally, translating the nuances of biological experiments into low-level robot actions requires researchers to understand both biology and robotics, imagine robot actions, and write robotic scripts. Our results showed that GPT-4 can connect the context of biological experiments with robot operation through simple prompts with expert-level contextual understanding and inherent knowledge. Replacing robot script programming, which is a tedious task for biological researchers, with natural-language LLM instructions that do not consider robot behavior significantly increases the number of researchers who can benefit from automating biological experiments.","score":0.42849284410476685,"polarity":"positive","source":"citations","contexts":[{"sentence":"In \\cite{inagaki2023llms}, GPT-4 shows the ability to bridge the context of biological experiments with robot operation through simple prompts, demonstrating expert-level contextual understanding and knowledge.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper contrasts with the Main Paper by focusing on the familiarity and understanding of laboratory safety knowledge among university students, rather than evaluating the performance of LLMs in safety-critical environments. While the Main Paper emphasizes the limitations of LLMs in providing reliable safety guidance, the Related Paper highlights the educational aspect of safety knowledge among students, suggesting that human understanding and training are crucial for effective safety practices. This difference underscores the Main Paper's concern about the inadequacy of LLMs compared to trained individuals in ensuring laboratory safety.","paper_id":"90263d171cd8e2a96caa8dcd3613d0f255e63ce9","title":"Determining University Students’ Familiarity and Understanding of Laboratory Safety Knowledge—A Case Study","abstract":"This work investigates students’ familiarity and understanding of laboratory safety knowledge among students in the College of Environmental Science and Safety Engineering at Tianjin University of ...","score":0.4813312590122223,"polarity":"negative","source":"citations","contexts":[{"sentence":"In high-stakes laboratory settings, this illusion becomes especially hazardous \\citep{menard2020review, wu_2020_determining, ali_2022_development, camel_2020_open, jonggukim_2023_analysis}.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper emphasizes the importance of accessible educational resources for self-training in chemistry lab safety, contrasting with the Main Paper's focus on the limitations of LLMs in providing reliable safety guidance. While the Main Paper highlights the risks associated with relying on LLMs for safety-critical decision-making, the Related Paper advocates for structured educational tools that can enhance human understanding and adherence to safety protocols, suggesting that human training may be more effective than automated systems.","paper_id":"eb6698288a2ce7c8354116388de57b06b8be9e17","title":"Open Digital Educational Resources for Self-Training Chemistry Lab Safety Rules","abstract":"Educational resources that cover essential knowledge related to chemistry safety rules are openly accessible on the CHIMACTIV website (http://chimactiv.agroparistech.fr/). Organized into two online...","score":0.47845831513404846,"polarity":"negative","source":"citations","contexts":[{"sentence":"In high-stakes laboratory settings, this illusion becomes especially hazardous \\citep{menard2020review, wu_2020_determining, ali_2022_development, camel_2020_open, jonggukim_2023_analysis}.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper contrasts the Main Paper by focusing on privacy implications of LLMs rather than safety issues in laboratory settings. While the Main Paper emphasizes the risks of relying on LLMs for safety-critical decision-making in labs, the Related Paper highlights the privacy risks associated with LLMs in various contexts, revealing that even advanced models can leak private information. This divergence underscores a broader concern about the limitations of LLMs, suggesting that while the Main Paper addresses safety, the Related Paper raises critical questions about privacy, indicating that LLMs may not be reliable in both safety and privacy-sensitive applications.","paper_id":"89512c767e0ca0fe64d12a436c64f15dffdad1e0","title":"Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory","abstract":"The interactive use of large language models (LLMs) in AI assistants (at work, home, etc.) introduces a new set of inference-time privacy risks: LLMs are fed different types of information from multiple sources in their inputs and are expected to reason about what to share in their outputs, for what purpose and with whom, within a given context. In this work, we draw attention to the highly critical yet overlooked notion of contextual privacy by proposing ConfAIde, a benchmark designed to identify critical weaknesses in the privacy reasoning capabilities of instruction-tuned LLMs. Our experiments show that even the most capable models such as GPT-4 and ChatGPT reveal private information in contexts that humans would not, 39% and 57% of the time, respectively. This leakage persists even when we employ privacy-inducing prompts or chain-of-thought reasoning. Our work underscores the immediate need to explore novel inference-time privacy-preserving approaches, based on reasoning and theory of mind.","score":0.32900601625442505,"polarity":"negative","source":"citations","contexts":[{"sentence":"LLM privacy addresses concerns about whether the model may leak sensitive personal information \\citep{mireshghallah2023can, staab2023beyond, dou2023reducing, lang2025beyond}.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper contrasts the Main Paper by emphasizing the potential misuse of AI in scientific contexts, highlighting risks such as the creation of harmful substances and the circumvention of regulations. While the Main Paper focuses on the reliability of LLMs in providing safe guidance in laboratory settings, the Related Paper calls for responsible AI development and risk management strategies, proposing a system (SciGuard) to mitigate misuse risks. Additionally, the Related Paper advocates for a collaborative approach to ensure ethical AI use, whereas the Main Paper primarily addresses the evaluation of LLMs against safety benchmarks.","paper_id":"9bce4959082f9c133d9721bdb177dcb25d1d6b33","title":"Control Risk for Potential Misuse of Artificial Intelligence in Science","abstract":"The expanding application of Artificial Intelligence (AI) in scientific fields presents unprecedented opportunities for discovery and innovation. However, this growth is not without risks. AI models in science, if misused, can amplify risks like creation of harmful substances, or circumvention of established regulations. In this study, we aim to raise awareness of the dangers of AI misuse in science, and call for responsible AI development and use in this domain. We first itemize the risks posed by AI in scientific contexts, then demonstrate the risks by highlighting real-world examples of misuse in chemical science. These instances underscore the need for effective risk management strategies. In response, we propose a system called SciGuard to control misuse risks for AI models in science. We also propose a red-teaming benchmark SciMT-Safety to assess the safety of different systems. Our proposed SciGuard shows the least harmful impact in the assessment without compromising performance in benign tests. Finally, we highlight the need for a multidisciplinary and collaborative effort to ensure the safe and ethical use of AI models in science. We hope that our study can spark productive discussions on using AI ethically in science among researchers, practitioners, policymakers, and the public, to maximize benefits and minimize the risks of misuse.","score":0.3141801357269287,"polarity":"negative","source":"citations","contexts":[{"sentence":"A few works have addressed safety issues in the scientific domain, but they mainly focus on preventing the misuse of LLMs, such as ensuring models do not respond to questions about creating chemical weapons \\citep{he2023control, li2024wmdp}.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper, titled 'The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning,' contrasts with the Main Paper by focusing on the malicious use of LLMs in developing hazardous capabilities, such as biological and chemical weapons, rather than on safety protocols in laboratory settings. While the Main Paper emphasizes the need for evaluating LLMs in terms of safety and their reliability in providing accurate guidance in scientific labs, the Related Paper addresses the risks of LLMs empowering malicious actors and proposes a benchmark for measuring hazardous knowledge. Additionally, the Related Paper introduces unlearning methods to mitigate these risks, highlighting a different approach to LLM evaluation compared to the Main Paper's focus on safety benchmarks.","paper_id":"06b9ad0b52d23231f650be0aeb0b17cc52c8a74b","title":"The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning","abstract":"The White House Executive Order on Artificial Intelligence highlights the risks of large language models (LLMs) empowering malicious actors in developing biological, cyber, and chemical weapons. To measure these risks of malicious use, government institutions and major AI labs are developing evaluations for hazardous capabilities in LLMs. However, current evaluations are private, preventing further research into mitigating risk. Furthermore, they focus on only a few, highly specific pathways for malicious use. To fill these gaps, we publicly release the Weapons of Mass Destruction Proxy (WMDP) benchmark, a dataset of 3,668 multiple-choice questions that serve as a proxy measurement of hazardous knowledge in biosecurity, cybersecurity, and chemical security. WMDP was developed by a consortium of academics and technical consultants, and was stringently filtered to eliminate sensitive information prior to public release. WMDP serves two roles: first, as an evaluation for hazardous knowledge in LLMs, and second, as a benchmark for unlearning methods to remove such hazardous knowledge. To guide progress on unlearning, we develop RMU, a state-of-the-art unlearning method based on controlling model representations. RMU reduces model performance on WMDP while maintaining general capabilities in areas such as biology and computer science, suggesting that unlearning may be a concrete path towards reducing malicious use from LLMs. We release our benchmark and code publicly at https://wmdp.ai","score":0.2743987441062927,"polarity":"negative","source":"citations","contexts":[{"sentence":"A few works have addressed safety issues in the scientific domain, but they mainly focus on preventing the misuse of LLMs, such as ensuring models do not respond to questions about creating chemical weapons \\citep{he2023control, li2024wmdp}.","polarity":"negative"}],"background":null,"target":null}],"paper":{"title":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","abstract":"Laboratory accidents pose significant risks to human life and property, underscoring the importance of robust safety protocols. Despite advancements in safety training, laboratory personnel may still unknowingly engage in unsafe practices. With the increasing reliance on large language models (LLMs) for guidance in various fields, including laboratory settings, there is a growing concern about their reliability in critical safety-related decision-making. Unlike trained human researchers, LLMs lack formal lab safety education, raising questions about their ability to provide safe and accurate guidance. Existing research on LLM trustworthiness primarily focuses on issues such as ethical compliance, truthfulness, and fairness but fails to fully cover safety-critical real-world applications, like lab safety. To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols. This benchmark includes 765 multiple-choice questions verified by human experts, assessing LLMs and large vision models (LVMs) performance in lab safety contexts. Our evaluations demonstrate that while GPT-4o outperforms human participants, it is still prone to critical errors, highlighting the risks of relying on LLMs in safety-critical environments. Our findings emphasize the need for specialized benchmarks to accurately assess the trustworthiness of LLMs in real-world safety applications. The code and data are available at https://anonymous.4open.science/r/LabSafetyBench-6363","authors":["Yujun Zhou","Jingdong Yang","Kehan Guo","Pin-Yu Chen","Tian Gao","Werner Geyer","Nuno Moniz","Nitesh V Chawla","Xiangliang Zhang"],"sections":[{"heading":"Introduction","text":"# Introduction\n\nArtificial Intelligence (AI) is increasingly emerging as a transformative force in science, seamlessly reshaping research across disciplines, with tools like AlphaFold [@jumper2021highly] heralding a new era of discovery and innovation [@callaway2024chemistry; @odonnell_2025_whats]. Despite these promising developments, researchers may inadvertently overestimate AI's capabilities, leading to a dangerous \"illusion of understanding\\\" [@messeri2024artificial]. Scientists often rely on LLM-based suggestions [@a2024_openai; @achiam2023gpt; @touvron2023llama] to enhance productivity or compensate for human limitations, assuming that such tools provide objective insights [@logg2019algorithm]. However, this perceived objectivity can obscure important nuances, causing researchers to believe they grasp complex phenomena more thoroughly than they actually do [@sloman2016your]. In high-stakes laboratory settings, this illusion becomes especially hazardous [@menard2020review; @wu_2020_determining; @ali_2022_development; @camel_2020_open; @jonggukim_2023_analysis]. A relevant example can be seen in LabTwin, which employs LLMs for report writing and data analysis but avoids their use in direct experimental tasks due to concerns over content safety and reliability [@sukanijathillainadarasansuki_2023_realtime].\n\nIn fact, laboratory environments inherently carry significant risks [@menard2020review; @jonggukim_2023_analysis], and reliance on AI could exacerbate such dangers if errors go undetected or are mistakenly trusted. The Chemical Safety Board Accidental Release Events report indicates that, between April 2020 and July 2024, the United States experienced 197 cases of substantial property damage, 227 serious injuries, and 57 fatalities due to accidental releases [@incident]. These incidents underscore the importance of rigorous safety protocols. In scenarios where an LLM might provide flawed recommendations---such as erroneous estimates of chemical reaction conditions or inadequate consideration of environmental hazards---the potential severity of accidents could escalate. A pertinent illustration is the 2023 accident at GMFC Labs in Visakhapatnam, India, where an ethanol pipeline exploded due to static energy buildup, igniting widespread protests over alleged safety violations [@memorial]. While that incident primarily involved conventional risk factors, similar or more severe outcomes could occur if AI-driven decision-making fails to account for critical variables.\n\n![Overview of LabSafety Bench. This figure presents the development pipeline, evaluation methods for both multiple-choice and scenario-based questions, and the overall performance of various models on LabSafety Bench---with Deepseek-R1 achieving the highest overall score.](Figures/Figure1_new.pdf){#fig:1_new width=\"75%\"}\n\nThe rapid integration of LLMs into scientific laboratories---ranging from procedural guidance for novices to autonomous experiment orchestration [@boiko_2023_autonomous; @latif2024physicsassistant; @m2024augmenting]---builds on their demonstrated abilities in tasks like chemical reaction prediction [@guo2023can]. Notably, LLMs have already exceeded human performance in specific fields---for example, in neuroscience [@luo2024large] and by outperforming PhD-level scholars on the Graduate-Level Google-Proof Q&A Benchmark [@jones2024awe]---and they are expected to excel in an even wider array of tasks as they continue to advance [@odonnell_2025_whats]. However, these advanced capabilities also introduce significant risks when hallucinations [@huang2023survey], delayed hazard detection, or protocol misinterpretations intersect with physical lab operations. Failures in adhering to safety protocols or prioritizing research objectives can escalate into critical incidents, underscoring the need for urgent evaluation frameworks. While existing studies have rigorously assessed LLMs' scientific reasoning [@sun2024scieval] and domain knowledge [@cai2024sciassess], they often neglect the operational safety parameters critical in physical experimental contexts. A structured benchmarking framework is therefore essential to rigorously evaluate their reliability in safety-critical tasks, ensuring that their remarkable potential is harnessed responsibly through evidence-based validation for safe deployment in laboratory environments.\n\nThis paper seeks to address these challenges by focusing on evaluating LLMs' performance in laboratory safety contexts. Specifically, we aim to answer key research questions: **Can LLMs effectively identify potential hazards, accurately assess risks, and provide reliable decisions to mitigate laboratory safety threats?**\n\nTo address this challenge, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive framework that systematically assesses LLMs' abilities to identify hazards, evaluate risks, and make informed decisions to prevent lab safety threats. First, the benchmark measures hallucination propensity by introducing distractor options and complex scenarios, quantifying the frequency and severity of fabricated or overlooked risks. Second, it evaluates domain-specific knowledge by comparing model responses to expert-curated answers, revealing gaps in training data and inconsistencies in understanding. Third, it assesses practical decision-making in realistic scenarios, highlighting the risks of over-reliance on AI when outputs deviate from standard safety protocols. In doing so, LabSafety Bench provides a transformative diagnostic tool for the scientific community, promoting transparency and guiding the development of more robust LLMs and enhanced safety training materials.\n\nBuilding on this framework, we introduce the core structure of LabSafety Bench, which integrates a diverse set of evaluation tasks to assess LLM performance in laboratory safety contexts comprehensively. First, in alignment with US Occupational Safety and Health Administration (OSHA) protocols [@osha_2011_laboratory], we developed a set of 765 multiple-choice questions (MCQs) designed to comprehensively address a wide range of safety concerns across diverse laboratory domains. Second, we curated 520 realistic laboratory scenarios, each incorporating potential lab safety hazards. For each scenario, we curated two tasks to evaluate LLM performance. The first task requires the LLM to list all potential lab-safety-related issues, assessing its ability to identify hazards comprehensively and its tendency to hallucinate in complex, real-world contexts. We call it the Hazards Identification Test. The second task introduces multiple decisions or actions that could significantly impact lab safety by potentially introducing or exacerbating hazards, and the LLM is tasked with predicting the consequences of executing these actions. We call it the Consequence Identification Test. This dual-task evaluation enables the identification of hidden or overlooked dangers, offering a more nuanced and practical measure of LLM knowledge and its application in dynamic, high-stakes scenarios.\n\nIn this study, we evaluated eight proprietary models, seven open‐weight LLMs, and four open‐weight VLMs using LabSafety Bench. Across the three tests in the benchmark, Deepseek-R1 achieved the highest overall score, demonstrating its reliability across various lab safety tasks. Although proprietary models generally outperform open‐weight LLMs in MCQs, their performance on open‐ended, real-world scenario responses was comparable to that of open-source models. Moreover, none of the models achieved a 75% score on the Hazards Identification Test. These findings underscore the need for developers of proprietary models to place greater emphasis on addressing real-world laboratory safety challenges.\n\nTo summarize, the key contributions of this work are as follows:\n\n-   To our knowledge, this is the first study to address the trustworthiness of LLMs in high-stakes lab safety environments---extending conventional evaluations to assess operational safety in real-world scenarios.\n\n-   We present the first benchmark for evaluating foundational models on lab safety awareness---a comprehensive framework grounded in OSHA protocols that systematically assesses models across three dimensions: hallucination propensity, domain-specific knowledge, and practical decision-making in dynamic lab scenarios.\n\n-   We conduct comprehensive evaluations of LLMs and VLMs using LabSafety Bench. Our findings reveal that while proprietary models excel in multiple-choice tasks, their open-ended performance remains comparable to open-source models, highlighting the urgent need for improved training and evaluation to address real-world lab safety challenges."},{"heading":"Related Works","text":"# Related Works\n\n**LLM Trustworthiness:** Since the emergence of LLMs, their trustworthiness has garnered significant attention [@huang2025trustworthiness; @sun2024trustllm; @zhang2024benchmarking; @hong2024decoding; @huang2025position]. LLM safety primarily focuses on whether the model generates harmful output, such as responding to harmful queries in the context of jailbreak prompts [@wei2024jailbroken; @zou2023universal; @zhou2024defending; @xie2024sorry; @xie2024online]. LLM fairness assesses whether the model answers questions objectively and without bias [@gupta2023bias; @li2023survey; @esiobu2023robbie]. LLM privacy addresses concerns about whether the model may leak sensitive personal information [@mireshghallah2023can; @staab2023beyond; @dou2023reducing; @lang2025beyond]. LLM truthfulness, on the other hand, evaluates whether the model can provide accurate representations of information, facts, and results [@huang2024social; @xu2023earth; @monea2024glitch; @guan2024hallusionbench; @li2024inference]. In summary, most existing research on LLM trustworthiness focuses on determining whether the model's output is truthful, fair, or violates safety protocols [@sun2024trustllm]. These are generally straightforward to assess using common knowledge [@inan2023llama]. However, in the context of lab safety, the critical issue is not just whether the LLM's output is accurate but whether implementing its generated actions could lead to lab incidents. Evaluating this requires specialized knowledge. Although difficult, ensuring that LLM generation do not cause serious lab accidents is crucial before integrating them into laboratory settings.\n\n**LLMs in Scientific Domains:** Numerous benchmarks have been developed to evaluate LLM applications in scientific domains [@guo2025can; @guo2025artificial; @guo2023can; @sun2024scieval; @cai2024sciassess; @liang2024scemqa; @yue2024mmmu]. While these benchmarks span various disciplines, they primarily assess LLMs' reasoning capabilities in scientific contexts. For example, some studies evaluate LLM on chemical tasks such as molecular property analysis, reaction prediction, and retrosynthesis [@yue2024mmmu; @guo2023can; @ramos2024review], while others focus on enhancing their abilities in these areas [@janakarajan2023language; @chaves2024tx; @taylor2022galactica; @yu2024llasmol]. A few works have addressed safety issues in the scientific domain, but they mainly focus on preventing the misuse of LLMs, such as ensuring models do not respond to questions about creating chemical weapons [@he2023control; @li2024wmdp]. However, there has not yet been a comprehensive evaluation of how well LLMs understand and apply knowledge related to lab safety. Despite this gap, LLMs are already being preliminarily applied in labs [@ramos2024review]. For instance, GPT-4 is used to assist with decision-making in self-driving labs and manage overall lab operations. Coscientist [@boiko_2023_autonomous], a multi-LLM-based intelligent agent, autonomously designs, plans, and conducts complex scientific experiments. In [@inagaki2023llms], GPT-4 shows the ability to bridge the context of biological experiments with robot operation through simple prompts, demonstrating expert-level contextual understanding and knowledge. ORGANA [@darvish2024organa] automates a variety of chemistry experiments by interacting with chemists using LLMs. However, the lack of specialized models for risk control and robust safety evaluations presents a significant challenge in ensuring the safety of LLMs equipped with tool-using capabilities [@ramos2024review]. Thus, our first step should be to establish a thorough and systematic evaluation of LLMs' awareness and proficiency in lab safety to ensure their safe and effective use in laboratory environments."},{"heading":"LabSafety Bench","text":"# LabSafety Bench\n\n![Our proposed new taxonomy of lab safety.](Figures/Figure1.pdf){#fig:1 width=\"75%\"}\n\n![The overall workflow of benchmark question curation.](Figures/Figure2_mod.pdf){#fig:2 width=\"100%\"}\n\nFigure [1](#fig:1_new){reference-type=\"ref\" reference=\"fig:1_new\"} outlines the overall LabSafety Bench curation process. We start by establishing a new taxonomy for lab safety (Figure [2](#fig:1){reference-type=\"ref\" reference=\"fig:1\"}) and collecting an extensive lab safety corpus. Human experts identify key knowledge points, which, through expert-AI collaboration, are used to curate and refine MCQs---each verified to have a single correct answer. Building on these questions, we generate real-world lab safety scenarios via the same collaborative approach and cross-review them for authenticity. For each scenario, experts and AI together produce ground truth answers for lab safety issues, as well as plausible hazardous decisions and their corresponding consequences.\n\n## Benchmark Data Curation Guidelines\n\n[]{#sec:guidelines label=\"sec:guidelines\"} LabSafety Bench aims to provide a comprehensive set of evaluation questions that cover a wide range of potential lab safety scenarios. The curation process follows these key guidelines:\n\n-   All corpora used to generate questions must come from authoritative sources such as textbooks, the World Health Organization (WHO), and OSHA, ensuring comprehensive coverage of lab safety topics.\n\n-   The generated questions must comprehensively cover lab safety, with at least one question addressing each key knowledge point in the corpora.\n\n-   Human experts cross-review all questions to ensure they are relevant to lab safety, contain only one correct answer for MCQs, and remain practical and applicable to current laboratory practices. The incorrect options are designed to be misleading or confusing without sufficient expertise for MCQs.\n\nTo define the scope of LabSafety Bench, we integrated OSHA protocols [@osha_2011_laboratory] and consulted with the Risk Management and Safety team of a large research university in the US. The taxonomy (shown in Fig. [2](#fig:1){reference-type=\"ref\" reference=\"fig:1\"}) is obtained after thorough discussions and used as guidelines for benchmark data curation. The questions are structured under 4 main categories and 10 subcategories (as shown by the distribution in Fig. [\\[fig:4b\\]](#fig:4b){reference-type=\"ref\" reference=\"fig:4b\"}). To ensure a comprehensive and diverse evaluation, we employed both standard four-option MCQs and real-world, scenario-based open-ended questions.\n\n## Corpora Preparation and Benchmark Data Curation \n\n![Text-only and text-with-image question examples in LabSafety Bench.](Figures/Figure3.pdf){#fig:3 width=\"80%\"}\n\n::: wraptable\nr0.4\n\n  **Statistic**                  **Number**\n  ------------------------------ ------------\n  **MCQs**                       \n  **Total**                      765\n  Text-only MCQs                 632\n  Easy                           352\n  Hard                           280\n  Text-with-image MCQs           133\n  Easy                           74\n  Hard                           59\n  Unique Images                  79\n  Unique Scenarios               520\n  **Scenario-based Questions**   \n  Hazards Identification         2,080\n  Consequence Identification     2,010\n  **Total**                      4,090\n  **Grand Total**                4,855\n:::\n\nIn this section, we outline the detailed benchmark data curation process. First, for the collection of corpora, we gather materials exclusively from the authoritative sources mentioned in Section [\\[sec:guidelines\\]](#sec:guidelines){reference-type=\"ref\" reference=\"sec:guidelines\"}. Based on recommendations from the university's Risk Management and Safety team and OSHA's Laboratory Safety Guidance [@osha_2011_laboratory], we first collect the corpora by discipline, including chemistry lab safety [@americanchemicalsocietycommitteeonchemicalsafety_2017_safety], biology lab safety [@edition2003laboratory], and radiology lab safety [@a2003_uw]. Additionally, we collect specific corpora for equipment and hazardous substances that require specialized lab safety training, such as biosafety cabinets [@osha_2011_bsc] and dry ice [@osha_2011_osha]. The complete list of corpora is provided in Table [\\[tab:3\\]](#tab:3){reference-type=\"ref\" reference=\"tab:3\"}.\n\nAs shown in Figure [3](#fig:2){reference-type=\"ref\" reference=\"fig:2\"}, next, human experts extract key knowledge points from each corpus. Experts employ GPT-4o to curate initial questions derived from these knowledge points. To enhance the quality of the questions, remove overly simplistic incorrect options, and make the answer choices more diverse, we follow WizardLM [@xu2023wizardlm] and use GPT-4o to refine the questions without increasing their length. The full prompts are shown in Appendix [7.4](#app:question_prompt){reference-type=\"ref\" reference=\"app:question_prompt\"}. After refinement, some modified options were found to be inaccurately phrased, irrelevant to the question, or transformed incorrect options into correct ones aligned with the question's intent. Additionally, some options ended up testing overlapping knowledge points. To address this, all refined questions were thoroughly cross-referenced by at least two human experts against authoritative guidelines to ensure their accuracy and quality. This rigorous process minimizes bias in question generation and enhances the overall quality of the questions. Through this process, we collect 632 text-only MCQs.\n\nBased on these MCQs, experts employ GPT-4o to construct specific, realistic scenarios that mirror actual laboratory situations and inherently include lab safety hazards. Each scenario is double-checked by experts to ensure authenticity. From these scenarios, we generate two tasks. First, the LLM is provided with a scenario and tasked with identifying all lab safety issues related to a specified aspect---namely, Most Common Hazards, Improper Operation Issues, Negative Lab Environment Impacts, or Most Likely Safety Incidents. For a trustworthy evaluation, experts collaborate with AI to produce comprehensive ground truth answers for these issues, with each issue potentially comprising multiple points; all answers undergo cross-review to ensure completeness and correctness. Second, the LLM is given a scenario along with a specific hazardous action and tasked with predicting the resulting consequence. In this task, experts, together with AI, identify potential hazardous actions that lab researchers might take and establish the corresponding ground truth consequences, which are also cross-reviewed for thoroughness. Through this process, we collect 520 real-world scenarios, yielding 2,080 questions for the first task and 2,010 questions for the second.\n\nThe multimodal questions are prepared from two sources. The first source comes from the university's Risk Management and Safety team, from whom we obtained a selection of multimodal questions from their lab safety training courses. The second source involves adapting text-only questions. For each, we use GPT-4o to identify key hazardous substances, equipment, or specific laboratory conditions. We then use Google Search to find relevant images. If an image clearly depicts a recognizable hazard or piece of equipment, we apply the same method used for generating text-only questions, with the key difference being that the questions do not explicitly mention the content of the image. As with the text-only questions, human experts review and verify the multimodal questions to ensure accuracy and relevance. From these two sources, we compile a total of 132 text-with-image samples. Table [\\[tab:dataset_overview\\]](#tab:dataset_overview){reference-type=\"ref\" reference=\"tab:dataset_overview\"} presents the key statistics of LabSafety Bench. Further detailed statistical discussion can be found in Appendix [8](#app:dataset_analysis){reference-type=\"ref\" reference=\"app:dataset_analysis\"}.\n\n## Further Annotation\n\nTo support a more granular analysis of benchmarking results and aid in identifying specific areas of strength or weakness in the evaluated models, we annotate each multiple-choice question with its difficulty level, topic, and category in taxonomy, and provide detailed explanations for the questions. The detailed explanation is generated by GPT-4o and then reviewed and corrected by human experts. The \"topic\" of each question is identified using GPT-4o to tag whether the question involves hazardous substances, equipment, or a hazardous situation, represented by a single word or phrase. This \"topic\" not only categorizes the question but also serves as the keyword used when searching for relevant images during the multimodal question generation process. Finally, human experts label each question as \"easy\" or \"hard\" based on whether it can be correctly answered using only high school-level knowledge, and annotate the category of each question according to the established taxonomy. Three examples are shown in Figure [4](#fig:3){reference-type=\"ref\" reference=\"fig:3\"}.\n\nFor scenario-based questions, since a single scenario may involve a combination of multiple complex lab safety categories---which complicates difficulty assessment---we annotate each scenario solely with its corresponding topic and subject. The example is shown in Appendix [7.5](#app:examples){reference-type=\"ref\" reference=\"app:examples\"}. Furthermore, some examples of the expert annotation process are shown in Appendix [7.6](#app:annotation){reference-type=\"ref\" reference=\"app:annotation\"}"},{"heading":"Experiments on MCQs","text":"# Experiments on MCQs\n\n## Experimental Setup\n\n**Evaluated Models.** For text-only MCQs and scenario-based questions, we evaluate open-weight models such as Llama3-8B, Llama3-70B [@dubey2024llama], Vicuna-7B, Vicuna-13B [@vicuna2023], Mistral-7B, Mistral-8x7B [@jiang2023mistral] and Deepseek-R1 [@guo2025deepseek]. Selected proprietary models include Gemini-1.5-Flash, Gemini-1.5-Pro, Gemini-2.0-Flash [@team2023gemini], Claude-3-Haiku, Claude-3.5-Sonnet [@anthropic_2024_the], o3-mini, GPT-4o-mini, and GPT-4o [@achiam2023gpt]. For text-with-image MCQs, we evaluate open-weight models like Qwen-VL-Chat [@bai2023qwen], InstructBlip-7B [@dai2023instructblipgeneralpurposevisionlanguagemodels], InternVL2-8B [@chen2024internvl], and Llama3.2-11B [@dubey2024llama]. Since all of the proprietary models mentioned for text-only questions also support vision inference, we test these models for text-with-image questions as well.\n\n**Evaluation Metrics.** We use accuracy as the evaluation metric across all multiple-choice question tests, comparing the selected option and ground-truth. The details of deriving the option of each evaluation model are presented in Appendix [9.1](#app:prompts_in_eval){reference-type=\"ref\" reference=\"app:prompts_in_eval\"}.\n\n**Evaluation Settings.** For the text-only MCQs, we establish eight experimental settings by varying the combination of 3 factors: with or without chain of thought (CoT), with or without external hints, and using either 5-shot or 0-shot learning. When CoT is enabled, we instruct the LLM to analyze each option step by step before providing the final answer. Without CoT, the LLM is asked to give a direct answer. In five-shot setting, we introduce five lab safety-related questions and their answers as examples. These examples, which are not part of the dataset, cover basic lab safety topics. In 0-shot setting, no examples will be provided. If selecting to use external hints, we first use GPT-4o to generate lab safety concerns relevant to the topic of each question. This hint generation is done without reference to the current question, ensuring that the LLM receives general hints without revealing the direct answer. The LLM then uses these hints to answer each question. The few-shot examples, the prompts used for generating hints, one hint example, and system prompts are provided in Appendix [9.1](#app:prompts_in_eval){reference-type=\"ref\" reference=\"app:prompts_in_eval\"}. For the text-with-image evaluation, we only adopt the setting with or without CoT, as few-shot may not be supported by all models, and hints may potentially reveal the image content.\n\n**Human Evaluation Settings.** We construct 4 questionnaires for launching human evaluation in four respective categories: biological hazards, physical hazards (including radiation), chemical hazards, and general lab safety questions (not covered by the previous three categories). Each questionnaire includes 20 text-only MCQs and 5 multiple-choice text-with-image questions and is distributed to undergraduate and graduate students who have receive lab safety training in the relevant discipline. To ensure response validity, each form includes a basic lab safety question, which is used to determine whether a response is serious and valid. In total, we receive 50 valid responses, with the lowest number coming from the physics questionnaire, which has 8 valid responses. \\\"Human accuracy\\\" is reported by taking the average accuracy of participants. More details can be found in Appendix [9.3](#app:human_setting){reference-type=\"ref\" reference=\"app:human_setting\"}.\n\n[]{#tab:1 label=\"tab:1\"}\n\n## Experimental Results\n\nIn Table [\\[tab:1\\]](#tab:1){reference-type=\"ref\" reference=\"tab:1\"}, we report the performance of evaluated LLMs across eight different settings for text-only MCQs and have the following observation.\n\n**Proprietary models are generally better at multiple-choice-question-based lab safety issues compared to open-weight models.** All proprietary models consistently achieve over 70% accuracy across all settings, with GPT-4o delivering the highest accuracy of 86.55% in the CoT, 0-shot setting, highlighting the challenging nature of LabSafety Bench. Llama3-70B achieves the best overall accuracy among open-weight models, with 78.32% accuracy in 0-shot setting without CoT and hints. In contrast, the Vicuna models perform poorly approaching random guess accuracy (25%) when hints are not provided.\n\n**Larger models are generally better than their smaller counterparts within the same series.** For instance, comparisons between Vicuna-7B and Vicuna-13B, Llama3-8B and Llama3-70B, Gemini-1.5-Flash and Gemini-1.5-Pro, as well as GPT-4o and GPT-4o-mini, show that within the same period, larger models tend to outperform smaller ones on LabSafety Bench's text-only MCQs.\n\n**CoT and few-shot learning have minimal impact on performance but hints significantly boost the performance of smaller open-weight models.** For instance, in Llama and Vicuna models, using both CoT and 5-shot learning actually reduces accuracy. This may be because CoT exacerbates hallucination issues [@zhang2023language]. Additionally, since the task itself is not particularly difficult to understand, the few-shot examples may interfere with reasoning rather than aid in solving the questions. However, hints prove highly beneficial for open-weight models, especially for Vicuna. For instance, Vicuna 13B sees a 22.78% accuracy improvement with CoT in 0-shot setting after introducing hints, with even larger gains compared to the weaker-performing Vicuna 7B. This suggests that Vicuna 13B has stronger reasoning abilities, allowing it to utilize the hints generated by GPT-4o. The fact that CoT isn't very effective while hints are highlights the insufficient lab safety training in these open-source models, and their knowledge base is considerably smaller compared to proprietary models. In contrast, hints provide minimal performance gain or even reduce performance for proprietary models, probably indicating that these models already possess such knowledge.\n\n<figure id=\"fig:5\">\n\n<figcaption>(a) Accuracy (%) of different VLMs on text-with-image multiple-choice questions in LabSafety Bench. (b) Accuracy (%) of trained humans on Sampled LabSafety Bench compared to top-performing models.</figcaption>\n</figure>\n\nThe results in Fig. [\\[fig:5a\\]](#fig:5a){reference-type=\"ref\" reference=\"fig:5a\"} show the performance of VLMs on text-with-image MCQs. InstructBlip-7B, based on Vicuna-7B, has the weakest performance. Among the open-source models, the best-performing one is Llama3.2-11B, built on Llama3.1-8B, achieving 73.68% accuracy with CoT. The best proprietary model, GPT-4o, reaches 84.96% accuracy with CoT. Notably, for high-performing models like GPT-4o and GPT-4o-mini, the CoT setting significantly boosts accuracy, indicating that solving text-with-image questions requires reasoning skills to interpret images and combine that understanding with the question to arrive at the correct answer.\n\nIn Fig. [\\[fig:5b\\]](#fig:5b){reference-type=\"ref\" reference=\"fig:5b\"}, we show the accuracy of student evaluators compared to top-performing models on a Sampled LabSafety Bench (the 100 questions in four questionnaires). On average, even with specialized lab safety training, humans achieve only 65.52% accuracy on these questions, with a standard deviation of 10.27%, indicating significant variation in human performance on lab safety issues. The highest human accuracy is 83%, which is comparable to GPT-4o. It is important to note that since some of the questions are partially generated by GPT-4o, there may be inherent biases contributing to its high performance. Therefore, although GPT-4o demonstrates superior performance, this does not mean it can provide safer decisions than human experts.\n\nGenerally, the low human accuracy can be attributed to two factors: first, participants in our tests were unable to refer to external materials and had to rely solely on memory. In real lab environments, however, lab workers typically review relevant safety procedures before conducting experiments, which significantly reduces the risk of accidents. Second, since most of the human evaluators were students, they are considered junior experts, and there is likely room for improvement if more senior experts are involved.\n\n<figure id=\"fig:6\">\n<p><embed src=\"Figures/Figure6a.pdf\" style=\"height:10cm\" /> <embed src=\"Figures/Figure6b.pdf\" style=\"height:10cm\" /></p>\n<figcaption>Examples of common errors made by GPT-4o. Left: An example of misidentifying nonexistent options. Right: An example of misaligning safety priorities.</figcaption>\n</figure>\n\nDue to space constraints, the results on easy/hard questions are presented in Appendix [11.1](#app:level){reference-type=\"ref\" reference=\"app:level\"}.\n\n## Results by Category\n\nWe also examine the performance of various models across different categories of safety issues. Table [\\[tab:2\\]](#tab:2){reference-type=\"ref\" reference=\"tab:2\"} presents the performance of each model across the sub-categories in the 0-shot setting without CoT and hints. We observe that most models struggle with Radiation Hazards, Physical Hazards, Equipment Usage, and Electricity Safety. Except for Equipment Usage, these areas are closely related to physical experiments, indicating that models generally may not have sufficient training in lab safety for physics-related fields. This may be due to a lack of training data in this domain compared to the more extensive corpora available for biology and chemistry. In contrast, the models show relatively consistent performance across other sub-categories, with the highest average accuracy of 68.46% in PPE (Personal Protective Equipment), likely because the scope of knowledge in this area is narrower and more frequently covered during training.\n\nTable [\\[tab:2\\]](#tab:2){reference-type=\"ref\" reference=\"tab:2\"} also shows human performance across categories. We gathered valid responses from 15 undergraduates, 33 graduate students, and 2 postdocs. Since some participants are junior researchers who may not fully represent the true capabilities of experienced experts, we selected the top-3 scorers and calculated their accuracy across each subcategory, shown in the \"Top3-Human\\*\\\" row. The results indicate that humans more familiar with lab safety issues can achieve accuracy comparable to proprietary models. Both the top-3 human experts and proprietary models perform well in chemical hazards and environmental and waste management, but neither excels in radiation hazards. However, in Physical Hazards and Equipment Usage, proprietary models perform poorly, while the top-3 experts show relatively better accuracy.\n\n## Qualitative Study\n\nBased on an analysis of the step-by-step reasoning provided by various models under the CoT, 0-shot, and no hint setting, we identified several inabilities why LLMs like Vicuna struggle to provide correct answers. These issues include a lack of domain-specific knowledge, insufficient reasoning skills, difficulty interpreting visual information, and misaligning safety priorities. The analysis is shown in Appendix [11.2.2](#app:model_wrong_ex){reference-type=\"ref\" reference=\"app:model_wrong_ex\"}. Among these, misaligning safety priorities is the most common issue for all models. Even for top-performing models that do not face some of these challenges, there are still many obstacles that need to be addressed. Specifically, we highlight key reasons why the best-performing model, GPT-4o, makes mistakes when dealing with lab safety issues. GPT-4o occasionally misidentifies nonexistent options and underestimates the need for comprehensive protection. It may also \"hallucinate\" by generating unsupported information, overfit by applying specific scenarios too broadly or misinterpreting the option. Examples of these issues are shown in Fig. [6](#fig:6){reference-type=\"ref\" reference=\"fig:6\"} and Appendix [11.2.1](#app:case){reference-type=\"ref\" reference=\"app:case\"}. These shortcomings illustrate areas for improvement in future models.\n\nDue to space constraints, we delay the section \"Discussion and Open Opportunities\\\" to Appendix [10](#app:discussion){reference-type=\"ref\" reference=\"app:discussion\"}."},{"heading":"Experiments on Real-Scenario-Based Open-Ended Questions","text":"# Experiments on Real-Scenario-Based Open-Ended Questions\n\n## Experimental Setup\n\n**Evaluated Models** are the same as that used in text-only MCQs.\n\n**Evaluation Settings** For all open-ended questions, we use o3-mini to determine whether the LLM's answer covers the ground truth answer. We manually reviewed over 200 o3-mini evaluations and found no instances of incorrect judgments. For ground truth answers that consist of multiple points, we have o3-mini assess each point individually, and the score for the question is calculated as the number of covered points divided by the total number of points. The specific prompt is provided in Appendix [9.2](#app:open-ended-evaluation){reference-type=\"ref\" reference=\"app:open-ended-evaluation\"}. Furthermore, given that CoT reasoning and few-shot learning have shown limited benefits in multiple-choice settings, we employed DA with a 0-shot setting to avoid excessively long examples and potential interference from CoT.\n\n## Experimental Results\n\n![The performance of 15 models on the five subjects of the scenario-based Hazards Identification Test. For each subject, we computed the average score for each model (shown in the last row), and for each model, we calculated the overall average score on the Hazard Identification Test (shown in the last column). In both cases, the highest score is highlighted in **bold** and the second-highest score is [underlined]{.underline}. ](Figures/Figure7.pdf){#fig:8 width=\"100%\"}\n\n![The performance of 15 models on the five subjects of the scenario-based Consequence Identification Test. For each subject, we computed the average score for each model (shown in the last row), and for each model, we calculated the overall average score on the Consequence Identification Test (shown in the last column). In both cases, the highest score is highlighted in **bold** and the second-highest score is [underlined]{.underline}.](Figures/Figure8.pdf){#fig:9 width=\"100%\"}\n\n::: wrapfigure\nr0.47 ![image](Figures/Figure9.pdf){width=\"47%\"}\n\n[]{#fig:7 label=\"fig:7\"}\n:::\n\nIn Figure [\\[fig:7\\]](#fig:7){reference-type=\"ref\" reference=\"fig:7\"}, we present the performance of various models on four lab safety--related issues in the hazards identification task. In Figures [7](#fig:8){reference-type=\"ref\" reference=\"fig:8\"} and [8](#fig:9){reference-type=\"ref\" reference=\"fig:9\"}, we show the performance of different models on the hazards identification and consequence identification tasks across various disciplines. We have the following observations:\n\n**Deepseek-R1 is the most robust model in lab safety overall.** In both text-based MCQs and two scenario-based open-ended questions, Deepseek-R1 consistently ranks among the top three, demonstrating its comprehensive lab safety knowledge and flexible application.\n\n**Unlike most benchmarks evaluating LLM capabilities and the Labsafety Bench on MCQs, in hazards and consequence identification tasks, proprietary models generally perform on par with smaller open-weight models.** This finding is similar to that reported in TrustGen [@huang2025trustworthiness]. Surprisingly, while Vicuna models perform almost at the level of random guessing on Labsafety Bench MCQs, their performance on scenario-based open-ended questions is not the worst. We infer that although the Vicuna models do possess lab safety knowledge, their ability to judge safety priorities when analyzing options is suboptimal---a point also illustrated in the case study in Appendix [11.2.1](#app:case){reference-type=\"ref\" reference=\"app:case\"}. Furthermore, Llama3-8B and Mistral-7B achieved second and third place, respectively, in the Consequence Identification Test, surpassing all proprietary models.\n\n**Larger or newer models do not necessarily perform better on open-ended lab safety questions, and reasoning models do not guarantee improved performance.** In the hazards identification test, the best performance was achieved by the GPT-4o-mini model, which far exceeded the larger GPT-4o model and the newer o3-mini reasoning model. In the consequence identification test, Gemini-2.0-Flash scored significantly lower than Gemini-1.5-Flash. Similar patterns are observed in the Llama3 and Mistral series. However, in the comparisons between Vicuna-7B and Vicuna-13B, as well as Gemini-1.5-Flash and Gemini-1.5-Pro, larger models consistently outperformed their smaller counterparts. We attribute this variability to the fact that most LLMs have been extensively trained on standardized tasks like MCQs, where pattern matching often suffices. However, for open-ended tasks---especially in less-explored domains such as lab safety---systematic training is lacking, resulting in increased performance variability.\n\n**Most models comprehensively identified \\\"Most Common Hazards\\\" and \\\"Negative Lab Environment Impacts,\\\" yet LLMs generally underperformed in covering \\\"Improper Operation Issues\\\" and \\\"Most Likely Safety Incidents.\\\"** As shown in Figure [\\[fig:7\\]](#fig:7){reference-type=\"ref\" reference=\"fig:7\"}, the average scores for the former two were 77.67% and 71.44%, respectively, while the latter two scored 58.5% and 60.46%. Notably, several models scored below 50% for Improper Operation Issues, whereas even the lowest-performing model for Most Common Hazards achieved an accuracy of 66.55%.\n\n**Longer responses generally correlate with more thorough hazard identification and consequence identification.** Statistics of the LLMs' answers on the Hazards Identification and Consequence Identification Tests are shown in Table [\\[tab:hazards_consequence\\]](#tab:hazards_consequence){reference-type=\"ref\" reference=\"tab:hazards_consequence\"}. For instance, Llama3-8B, which produces the longest answers (463.9 tokens on average), also identifies the highest number of hazards (10.2 on average), whereas Gemini-1.5-flash, with the shortest answers (48.2 tokens), recognizes significantly fewer hazards (2.9 on average). Furthermore, models with higher under-detection rates---cases where fewer hazards are identified than the ground truth---tend to have lower overall scores. Notably, Gemini-1.5-flash has the highest under-detection rate (22.60%) and the lowest score (57.85), whereas Llama3-8B's under-detection rate is 0%, indicating it consistently meets or exceeds the ground-truth hazard count. Although the varying token lengths might seem unfair, we impose no constraints on output length to mirror realistic lab scenarios where researchers expect comprehensive answers to mitigate risks effectively. Consequently, this approach is both practical and equitable for evaluating LLM performance in safety-critical contexts."},{"heading":"Conclusion","text":"# Conclusion\n\nIn this paper, we introduce the LabSafety Bench, a comprehensive framework designed to evaluate the trustworthiness and reliability of LLMs and VLMs in safety-critical laboratory environments. Our evaluations reveal that while models such as GPT-4o can outperform human participants on standard MCQs, they still exhibit significant limitations in open-ended, real-world scenario assessments---none achieving a 75% score on the Hazards Identification Test. Notably, Deepseek-R1 achieved the highest overall score, highlighting its reliability across diverse lab safety tasks. These findings underscore the urgent need for specialized benchmarks that not only assess adherence to general safety protocols but also capture the practical challenges inherent in real laboratory settings. As LLMs become increasingly integrated into autonomous scientific workflows, ensuring their outputs adhere to stringent safety standards is essential. Future research should focus on enhancing the models' contextual and domain-specific understanding, refining training methods, and evolving evaluation frameworks to minimize potential risks and ensure the safe deployment of AI in laboratory environments."},{"heading":"Data Collection Details","text":"# Data Collection Details\n\n## Human Expert Selection\n\nHuman experts were selected from a large research university, targeting individuals with extensive experience in lab safety. We selected individuals with advanced educational backgrounds (PhD students or postdoctoral researchers) and at least three years of direct laboratory experience. Their expertise ensured a solid understanding of both theoretical and practical aspects of lab safety. For physics, biology, and chemistry, we selected 3 human experts respectively to review the questions.\n\n## Corpora Collection\n\nAs discussed in Section [\\[sec:guidelines\\]](#sec:guidelines){reference-type=\"ref\" reference=\"sec:guidelines\"}, we collect corpora exclusively from authoritative sources, such as OSHA \\[2\\] and WHO \\[3\\], to ensure both the trustworthiness of the data and comprehensive coverage of lab safety topics. Using these knowledge points, GPT-4o assisted in generating and refining the questions to create a robust and reliable benchmark. A detailed list of the corpora can be found in Table [\\[tab:3\\]](#tab:3){reference-type=\"ref\" reference=\"tab:3\"}.\n\n## Human Review Procedure\n\nAfter refinement, some modified options were found to be inaccurately phrased, irrelevant to the question, or transformed incorrect options into correct ones aligned with the question's intent. Additionally, some options ended up testing overlapping knowledge points. To address this, all refined questions were thoroughly cross-referenced by human experts against authoritative guidelines to ensure their accuracy and quality. This rigorous process minimizes bias in question generation and enhances the overall quality of the questions. Each expert will review all the questions about the corresponding subject individually.\n\nEach question underwent a panel review by three subject-matter experts, who collaboratively evaluated its accuracy, difficulty level, and ability to effectively assess an LLM's understanding of the corresponding knowledge. This process included detailed discussions to ensure consensus on the correct answer and the plausibility of the distractors.\n\n## Prompts for Question Generation and Refining {#app:question_prompt}\n\nHere, we provide the full prompts for both Initial Question Generation and Question Refining, which are shown below.\n\n## Lab Safety Question Examples {#app:examples}\n\nIn this section, we will show some examples from this dataset, ensuring that each sub-category is covered in the examples.\n\n![An example of the human annotation platform about whether the scenario conforms to reality.](Figures/annotation_ex1.png){#fig:annotation1 width=\"40%\"}\n\n![An example of the human annotation platform for Hazards Identification Test](Figures/annotation_ex2.png){#fig:annotation2 width=\"40%\"}\n\n![An example of the human annotation platform for Consequence Identification Test](Figures/annotation_ex3.png){#fig:annotation3 width=\"40%\"}\n\n## Data Annotation Platform {#app:annotation}\n\nWe required human experts to use a Streamlit-based platform for data annotation, with each expert focusing on the categories or subjects in which they specialize. We ensured that each question underwent cross-review by at least two experts. Figure [9](#fig:annotation1){reference-type=\"ref\" reference=\"fig:annotation1\"},[10](#fig:annotation2){reference-type=\"ref\" reference=\"fig:annotation2\"},[11](#fig:annotation3){reference-type=\"ref\" reference=\"fig:annotation3\"} presents an example of the annotation platform; due to space constraints, we only include selected snippets to illustrate the annotation process."},{"heading":"Additional Dataset Statistics","text":"# Additional Dataset Statistics {#app:dataset_analysis}\n\nIn this section, we present a more detailed statistical analysis of MCQs in the LabSafety Bench dataset. Specifically, we analyze the MCQs from three perspectives: Word Count, Number of Categories per Question, and Category Overlap, which examines the common co-occurrence of categories for one question.\n\n## General Statistics of MCQs in LabSafety Bench\n\nFig. [\\[fig:4a\\]](#fig:4a){reference-type=\"ref\" reference=\"fig:4a\"} presents the distribution of easy and hard questions for both text-only and text-with-image MCQs. In both types of questions, the number of easy and hard questions is roughly balanced. Fig. [\\[fig:4b\\]](#fig:4b){reference-type=\"ref\" reference=\"fig:4b\"} shows the distribution of question categories, with the inner ring representing the distribution of the 4 main categories and the outer ring depicting the distribution across the 10 subcategories.\n\n<figure id=\"fig:4\">\n\n<figcaption>MCQs statistics. (a) The distribution of easy and hard questions for both text-only and text-with-image questions. (b) The distribution of questions in different categories.</figcaption>\n</figure>\n\n![Distribution of Question Lengths in LabSafety Bench](Figures/Figure_A1.pdf){#fig:a1 width=\"100%\"}\n\n![Distribution of Option Lengths in LabSafety Bench](Figures/Figure_A2.pdf){#fig:a2 width=\"100%\"}\n\n## The Distribution of Word Count\n\nWe calculate the word count for each question (excluding the options) in the MCQs in the LabSafety Bench, as well as the word count for each option. The results are shown in Fig. [13](#fig:a1){reference-type=\"ref\" reference=\"fig:a1\"} and Fig. [14](#fig:a2){reference-type=\"ref\" reference=\"fig:a2\"}, respectively. The average question length is 112.2 words, while the average option length is 55 words.\n\n![Distribution of Number of Categories per Question in LabSafety Bench](Figures/Figure_A3.pdf){#fig:a3 width=\"50%\"}\n\n## The Distribution of Number of Categories per MCQ.\n\nWe analyzed the number of categories each question is associated with, and the distribution is shown in Fig. [15](#fig:a3){reference-type=\"ref\" reference=\"fig:a3\"}. Approximately 50% of the questions are associated with two categories, around 10% are relevant to three categories, and 40% are assigned with only a single category.\n\n## Category Overlap Statistical Result\n\nFor each category in MCQs in the LabSafety Bench, we calculated the percentage of questions that are also associated with other categories. The results are displayed in Fig. [16](#fig:a4){reference-type=\"ref\" reference=\"fig:a4\"}. This represents the probability of each category appearing alongside others within the same question. For example, \"biological hazards\" most frequently co-occur with \"equipment usage\". Specifically, if a question involves \"biological hazards\" and is associated with another category, there is a 21.1% chance that the additional category will be \"equipment usage\". This analysis reveals which categories most commonly appear together in lab safety issues, suggesting that when strengthening a model's ability to handle one category, we should also focus on the categories that frequently co-occur.\n\n![Category Overlap in LabSafety Bench](Figures/Figure_A4.pdf){#fig:a4 width=\"80%\"}\n\n![t-SNE Visualization of the Embedding of All Questions.](Figures/t-SNE.png){#fig:tsne width=\"70%\"}\n\n## Diversity Analysis Using t-SNE for MCQs in LabSafety Bench\n\nTo evaluate the diversity of our curated MCQs, we analyzed the embeddings generated for each question. Specifically, we utilized the `text-embedding-3-small` model to transform each question into a 1536-dimensional embedding vector. To visualize the high-dimensional embeddings, we used t-SNE [@van2008visualizing] to project them into a lower-dimensional space while preserving local similarities.\n\nFigure [17](#fig:tsne){reference-type=\"ref\" reference=\"fig:tsne\"} illustrates the t-SNE projection of the question embeddings into a two-dimensional space. The visualization reveals a broad and varied distribution of points with distinct clusters and well-separated regions. This suggests that the dataset is highly diverse, with questions spanning multiple themes and exhibiting varied semantic characteristics. Such a diverse representation is crucial for ensuring the generalizability and robustness of models trained on this dataset.\n\n![Distributions of the scores of three IRT parameters](Figures/IRT.pdf){#fig:IRT width=\"100%\"}\n\n## Distribution of Item Response Theory (IRT) Parameters for MCQs in LabSafety Bench\n\nTo demonstrate the high quality of our curated MCQs, we used IRT [@embretson2013item] parameters to analyze the characteristics of test items and the abilities of respondents. Specifically, we used the parameters of discrimination, difficulty, and guessing to characterize each question's ability to distinguish between test-takers, the level of challenge it presents, and the likelihood of success by guessing. Although IRT parameters are not commonly used in machine learning benchmarks, they are particularly well-suited for our scenario, which involves evaluating the awareness of LLMs in laboratory safety---a highly knowledge-intensive domain. This context makes IRT a rational choice, as it provides a detailed measurement of knowledge retention, understanding, and the ability to reason about complex topics, which is crucial for assessing lab safety awareness.\n\nSpecifically, we invited human experts to rate each question in terms of difficulty, discrimination, and guessing parameters, with scores assigned on a scale from 1 to 5. A score of 1 across all parameters indicates the lowest level: for difficulty, it means common knowledge is sufficient; for discrimination, the item does little to differentiate between abilities; and for guessing, numerous effective distractors make guessing very unlikely. A score of 5 across all parameters represents the highest level: for difficulty, it requires knowledge beyond the typical undergraduate level; for discrimination, it effectively distinguishes between high and low abilities; and for guessing, it indicates minimal distractors, allowing even low-ability participants a high chance of guessing correctly.\n\nEach question was rated by at least three human experts, and the final score was calculated as the average of all expert ratings. We plotted the results to visualize the distribution of the IRT parameters (a, b, c), as shown in Figure [18](#fig:IRT){reference-type=\"ref\" reference=\"fig:IRT\"}. This provides several key insights regarding the quality of our question set:\n\n**Discrimination Parameter (a)**: The average discrimination ($a$) is **3.57**, which suggests that most items are effective at distinguishing between test-takers of different abilities. A high discrimination value (typically greater than 2) indicates that the items are very sensitive to differences in test-taker abilities, which is a positive sign for the test's reliability.\n\n**Difficulty Parameter (b)**: The average difficulty ($b$) is **3.13**, suggesting that the items in the dataset tend to be on the challenging side. Most items are of moderate to high difficulty, indicating that the test might be challenging for test-takers with average or below-average ability. Consider adding items with lower $b$ values to balance the test's overall difficulty.\n\n**Guessing Parameter (c)**: The average guessing parameter ($c$) is **2.58**, which suggests that items are designed to minimize the chance of success through guessing. This is a positive indicator of test quality, as it implies well-designed distractors (incorrect options) that prevent easy guessing.\n\nOverall, these findings affirm that our dataset is well-constructed, providing an effective and reliable tool for evaluating test-taker abilities across a broad spectrum.\n\n![Item Characteristic Curve (ICC) of the Questions in LabSafety Bench](Figures/ICC.pdf){#fig:ICC width=\"75%\"}\n\n### Scaling IRT Scores to Estimate Item Characteristic Curve (ICC)\n\nTo effectively evaluate the quality of our dataset, we scaled the IRT scores derived from human expert ratings to a reasonable IRT parameter range, which enabled us to estimate the ICC [@embretson2013item] more precisely. Specifically, the scores initially ranged from 1 to 5, and we mapped these values onto typical IRT ranges: discrimination ($a$) to \\[0.5, 2\\], difficulty ($b$) to \\[-3, 3\\], and guessing ($c$) to \\[0.15, 0.35\\]. This scaling process ensures that the parameters better reflect the realistic attributes of questions, providing a comprehensive understanding of their discriminative power, difficulty, and resistance to guessing. The ICC was then generated based on these scaled parameters to visualize how each question differentiates among test-takers of varying abilities, as shown in Figure [19](#fig:ICC){reference-type=\"ref\" reference=\"fig:ICC\"}.\n\nThe x-axis of the ICC represents the ability level ($\\theta$) of the test-takers, ranging from low to high ability, while the y-axis represents the probability of a correct response for that particular item, ranging from 0 to 1. This curve provides a clear visual representation of how likely a respondent with a given ability level is to answer a question correctly, thereby illustrating the discriminative power of the item.\n\nWe also annotated the estimated accuracy of GPT-4o, the best-performing LLM in our evaluation. With an accuracy of **86.27%**, the corresponding ability level on the ICC was found to be merely **1.24**. This indicates that, even for a top-tier LLM like GPT-4o, there remains significant room for improvement on our benchmark. The relatively modest ability level underscores the challenging nature of the questions in our dataset, which are designed to assess nuanced knowledge and reasoning about laboratory safety."},{"heading":"Additional Experimental Setup Details","text":"# Additional Experimental Setup Details {#app:experimental_setup}\n\nIn this section, we provide a detailed list of all the prompts used in our experimental evaluations, along with additional human evaluation settings.\n\n## Prompts in the Evaluation of MCQs {#app:prompts_in_eval}\n\nThe following \"Answer Extraction System Prompt\" is used to derive answers for each question. This is necessary because not all evaluated models can directly report answers in the format of option A, B, C, or D. To address this, we employ the LLM-as-a-judge approach [@zheng2023judging] to help determine the selected option. Specifically, we use GPT-4o-mini to extract the chosen option from each response and calculate accuracy based on that selection. If a response does not provide clear information pointing to a specific option, selects multiple options, or claims that all options are incorrect, we consider the answer wrong. The detailed prompt is shown below. In our initial test on 632 samples, we found that GPT-4o-mini achieved 99.8% accuracy in answer extraction.\n\n## Prompts in the Evaluation of Open-Ended Questions {#app:open-ended-evaluation}\n\n## Detailed Human Evaluation Setting {#app:human_setting}\n\nIn this section, we outline the human evaluation settings. Since lab safety knowledge is typically taught by discipline, we structured the sampled LabSafety Bench into subject-specific sections for evaluation. We created 4 Google Forms, each containing 25 questions, corresponding to the three disciplines---physics, biology, and chemistry---as well as a general set of questions outside these specific fields.\n\nThe forms for biology, physics, and chemistry were distributed to undergraduate and graduate students who had received lab safety training in their respective fields. The general questionnaire was sent to students across all the mentioned disciplines with lab safety training. The survey was approved by the Institutional Review Board (IRB) committee at the university, ensuring that all research involving human participants adheres to ethical guidelines and standards for privacy, consent, and safety.\n\nTo ensure response validity, each form included a basic lab safety question, which was used to determine whether a response was serious and valid. In total, we received 50 valid responses, with 15 from undergraduate students, 33 from graduate students, and 2 from postdocs. For the physics, chemistry, biology, and general questionnaires, we received 8, 10, 17, and 15 valid responses, respectively."},{"heading":"Discussion and Open Opportunities","text":"# Discussion and Open Opportunities {#app:discussion}\n\nOur evaluation demonstrates that current LLMs/VLMs are still not fully reliable when engaged in scenarios that may be critical to lab safety. The identified key shortcomings and common errors reported in our work highlight several open opportunities for future research and improvement.\n\nFirst, additional evaluation settings could be explored. In this work, we primarily use CoT and few-shot learning, but other reasoning-enhancement techniques during inference, such as Reflection [@shinn2024reflexion], Tree of Thought [@yao2024tree], Plan and Solve [@wang2023plan], and Self-Consistency [@wang2022self], are worth investigating to see if they can improve the ability of open-weight models to address lab safety-related issues.\n\nSecond, an area worth exploring is whether scaling up inference computing could improve model performance on the LabSafety Bench. This could involve increasing test-time computing, such as incorporating search against a verifier or refining the proposal distribution to enhance accuracy [@snell2024scaling].\n\nThird, we observe that open-weight models, particularly Vicuna, often see significant improvement with the help of GPT-4o-generated hints. Could more refined prompt-based knowledge distillation [@mcdonald2024trace] further enhance the capabilities of these open-weight models? Similarly, could various RAG methods [@gao2023retrieval] also help boost their performance?\n\nFourth, beyond improving inference, models should be aligned and fine-tuned on lab safety knowledge to enhance safety performance. With many authoritative statements available on lab safety, the Constitutional AI framework [@bai2022constitutional] offers a promising approach to further improve safety alignment.\n\nFifth, despite these limitations, GPT-4o's relatively strong performance across most subcategories compared to other LLMs makes it a potential candidate for assisting with lab safety in a supervised and controlled manner. In our case studies, we observed that while GPT-4o may misjudge the priority of certain hazards, its CoT analysis reveals an understanding of which options are dangerous. Furthermore, GPT-4o performed significantly better in identifying the safest option rather than simply determining which options are hazardous. This suggests that GPT-4o could be effectively utilized for tasks focused on identifying the safest course of action. For example, instead of being used directly by experimenters, it would be safer and more effective for a lab manager---who possesses robust safety awareness---to query the LLM for relevant safety details before an experiment. The lab manager could then validate and relay this information to experimenters, ensuring safety while saving time on manual research.\n\nLast, while our work highlights the unreliability of current models in lab safety, similar challenges exist in other high-stakes LLM application scenarios that require precise decision-making and adherence to safety standards. For example, when LLMs are involved in household robotics, medical device operations, or industrial machinery control."},{"heading":"Additional Experimental Results","text":"# Additional Experimental Results\n\n## Results on different difficulty levels {#app:level}\n\nIn this section, we explore the impact of difficulty levels on model accuracy. For humans, \"easy\\\" level questions require only high school-level knowledge to identify the correct answer, whereas \"hard\\\" level questions demand college-level or more specialized knowledge. In Table [1](#tab:level){reference-type=\"ref\" reference=\"tab:level\"}, we present the accuracy of different models when tackling both easy and hard level MCQs.\n\n::: {#tab:level}\n  Model                                                Easy    Hard\n  --------------------------------------------------- ------- -------\n  **LLM on Text-only Questions**                              \n  Llama3-8B                                            69.8    59.79\n  Llama3-70B                                           78.63   77.94\n  Vicuna-7B                                            35.9    36.65\n  Vicuna-13B                                           50.43   41.99\n  Mistral-7B                                           64.1    51.25\n  Mistral-8x7B                                         66.67   58.01\n  Galactica-6.7B                                       35.33   31.32\n  **VLM on Text-with-image Questions**                        \n  InstructBlip-7B                                      21.62   32.2\n  Qwen-VL-Chat                                         67.57   61.02\n  InternVL2-8B                                         82.43   59.32\n  Llama3.2-11B                                         75.68   67.8\n  **Proprietary models on both types of questions**           \n  Gemini-1.5-Flash                                     78.35   70.29\n  Gemini-1.5-Pro                                       82.59   77.35\n  Claude-3-Haiku                                       78.35   76.76\n  Claude-3.5-Sonnet                                    86.59   78.24\n  GPT-4o-mini                                          80.71   78.24\n  GPT-4o                                               86.82   82.35\n  **Average**                                          67.15   61.21\n\n  : Accuracy (%) of different models on easy and hard question sets\n:::\n\nOverall, most models exhibit higher accuracy on easy questions, with the difference being particularly pronounced in InternVL2. However, for most models, the gap between easy and hard question accuracy is not very large. Notably, models with weaker lab safety capabilities, such as Vicuna and InstructBlip, do not follow this trend, likely due to their insufficient knowledge of lab safety overall. In contrast, larger models like GPT-4o and Llama3-70B show smaller differences in accuracy between easy and hard questions. This may be because these larger models can store more rare and specialized knowledge, resulting in improved performance on hard-level questions.\n\n## Additional Qualitative Study\n\n### Additional GPT-4o Error Analysis {#app:case}\n\nIn this section, we provide additional analysis on why GPT-4o often makes incorrect choices in the CoT, 0-shot, no hint setting in MCQs.\n\n### Comparison of answers from different models {#app:model_wrong_ex}\n\nIn this section, we analyze the reasons behind incorrect decisions made by different models by comparing their responses to various examples on 0-shot and CoT setting. Unless otherwise specified, we use the no-hints setting throughout.\n\n**Overall Analysis**: The primary reason for Vicuna-13B's incorrect response is its lack of domain knowledge regarding laboratory safety related to dry ice. After being given a hint, it recognized the potential suffocation risk from dry ice sublimation, but it failed to prioritize this danger, leading to an incorrect answer. Llama3-8B, although aware of the hazard, did not consider the possibility that the lab might already have a high concentration of carbon dioxide and that indiscriminately ventilating the area could pose further risks. As a result, it also made an error in prioritization.\n\n**Overall Analysis**: All the models mentioned lack domain knowledge regarding the synergistic effects of alcohol and chlorinated solvents or the lack of synergy between benzene and carbon tetrachloride. Except for Llama3-8B, the other models incorrectly hallucinated that the wrong combinations would exhibit synergistic effects.\n\n**Overall analysis**: Vicuna-13B initially misaligned safety priorities when no hints were provided. However, after receiving hints, it correctly adjusted and provided the right answer.\n\n**Overall analysis**: All the models underestimated the risks associated with sharp objects, mistakenly considering removing them with gloves as the correct approach. Additionally, GPT-4o incorrectly attributed error A to the item being left for too long.\n\n**Overall analysis**: Except for GPT-4o, the other models failed to recognize that the image depicted a broken thermometer with spilled mercury, even though they provided the correct response."}],"approval":false,"conference":"iclr","rating":2,"year":2025,"id":"6a9290792e9a9889cdd14cf03432d29d4c9568159d1ee728c4abb0443e00c852","y_true":0,"y_pred":0,"rationale_true":"Summary: This paper argues that although there is much previous work on safety, trustworthiness, truthfulness, fairness and privacy for LLMs, no previous work has investigated lab safety specifically, which involves a different aspect of trustworthiness. The paper develops a benchmark to evaluate LLMs in terms of lab safety where they develop a taxonomy based on OSHA protocols, curate a set of questions based on the taxonomy, and then evaluate a set of foundation models and humans for their accuracy in selecting the correct answer to the questions.\n\nStrengths: The problem is well motivated and justified, and seems important considering the use of LLMs in many safety-critical areas. The lab safety taxonomy based on various OSHA requirements seems helpful and useful for benchmarking. The evaluation has good diversity of LLM models, with 17 foundation models, including both open source, proprietary and scientific models and different prompting techniques. Finally, I appreciate that the code is released open source.\n\nWeaknesses: I have some issues with the evaluation. Starting with the human evaluation (see question 1): the paper mentions they used individuals who had undergone lab safety training but what exactly does that entail? I am wondering if this was a sufficiently fair comparison-- it may be the case that the humans were being tested on very specific lab safety questions that they had not encountered or been trained for (e.g., lab safety training was for a broad range of biology wet lab safety questions when an individual only works in or is only trained in a specific sub field of biology safety or vice versa). Moreover, I would argue the LLM in this scenario should be considered an expert, and therefore should be compared to only human \"experts\" (i.e., not junior scientists like undergraduates).\n\nIn addition, the authors mention the goal is to determine whether or not LLMs can be trusted to be more reliable than humans in decision making and planning for lab safety. Can the authors comment on the applicability of using the benchmark multiple-choice question & answer as a proxy for evaluating this (see question 2)? In practice, the way a user engages with the LLM for these types of decisions is very different (i.e., they are probably not going to ask it a multiple choice question with the answers listed.) I am wondering if this is really a fair methodology in order to evaluate how well LLMs follow lab safety protocols.\n\nQuestions: (1a) For the human evaluation, how were the human participants selected and to what extent did they have direct experience or training related to the specific questions being asked in the evaluation? \n(1b) Why did you include junior scientists in the comparison?\n\n(2a) Why were multiple choice questions chosen as the evaluation technique?\n(2b) Can the authors comment on the applicability of using the benchmark multiple-choice question & answer as a proxy for evaluating this?","rationale_pred":"Paper Summary: The paper introduces LabSafety Bench, a new benchmark for evaluating LLMs on safety issues in scientific labs. It addresses a gap in existing LLM trustworthiness research, which doesn't fully cover safety-critical real-world applications like lab safety. The benchmark includes 765 multiple-choice questions aligned with OSHA protocols and assesses LLMs' hallucination propensity, domain-specific knowledge, and practical decision-making. The evaluations show that even advanced models like GPT-4o are prone to critical errors, highlighting the risks of relying on LLMs in safety-critical environments.\n\nSupporting Evidence:\n- Several supporting papers highlight the need for specialized benchmarks to assess LLM trustworthiness in safety-critical applications, reinforcing the importance of LabSafety Bench.\n- Papers like 'Can't See the Forest for the Trees' and 'Jailbroken' emphasize the inadequacies of current models in providing reliable safety guidance, supporting the paper's argument for specialized benchmarks like LabSafety Bench.\n- The paper 'LLMs can generate robotic scripts from goal-oriented instructions in biological laboratory automation' highlights the potential of LLMs in enhancing laboratory efficiency, which aligns with the Main Paper's concerns about the reliability of LLMs in safety-critical environments, as it underscores the need for robust evaluation frameworks like LabSafety Bench to ensure that LLMs can safely assist in laboratory settings.\n\nContradictory Evidence:\n- The paper 'Chinese SafetyQA' introduces a benchmark aimed at evaluating LLMs' factuality in a broader safety context, highlighting different aspects of LLM reliability, which contrasts with the Main Paper's focus on OSHA-aligned safety practices.\n- The paper 'Semantic Density' emphasizes the lack of uncertainty quantification in LLMs, which the Main Paper does not address, suggesting that even if LLMs perform well in safety contexts, their trustworthiness remains questionable due to the absence of a systematic way to measure uncertainty.\n- The paper 'Control Risk for Potential Misuse of Artificial Intelligence in Science' emphasizes the potential misuse of AI in scientific contexts, highlighting risks such as the creation of harmful substances and the circumvention of regulations, which contrasts with the Main Paper's focus on the reliability of LLMs in providing safe guidance in laboratory settings.\n\nConclusion: While the paper introduces a valuable benchmark for evaluating LLMs in lab safety, several related papers address similar aspects of LLM safety and trustworthiness in different contexts. The existence of these related works suggests that the paper's novelty is limited, as the general idea of benchmarking LLMs for safety is not entirely new. The specific focus on lab safety and OSHA protocols adds some uniqueness, but the core concept is present in other works.","structured_evaluation":{"paper_summary":"The paper introduces LabSafety Bench, a new benchmark for evaluating LLMs on safety issues in scientific labs. It addresses a gap in existing LLM trustworthiness research, which doesn't fully cover safety-critical real-world applications like lab safety. The benchmark includes 765 multiple-choice questions aligned with OSHA protocols and assesses LLMs' hallucination propensity, domain-specific knowledge, and practical decision-making. The evaluations show that even advanced models like GPT-4o are prone to critical errors, highlighting the risks of relying on LLMs in safety-critical environments.","supporting_evidence":["Several supporting papers highlight the need for specialized benchmarks to assess LLM trustworthiness in safety-critical applications, reinforcing the importance of LabSafety Bench.","Papers like 'Can't See the Forest for the Trees' and 'Jailbroken' emphasize the inadequacies of current models in providing reliable safety guidance, supporting the paper's argument for specialized benchmarks like LabSafety Bench.","The paper 'LLMs can generate robotic scripts from goal-oriented instructions in biological laboratory automation' highlights the potential of LLMs in enhancing laboratory efficiency, which aligns with the Main Paper's concerns about the reliability of LLMs in safety-critical environments, as it underscores the need for robust evaluation frameworks like LabSafety Bench to ensure that LLMs can safely assist in laboratory settings."],"contradictory_evidence":["The paper 'Chinese SafetyQA' introduces a benchmark aimed at evaluating LLMs' factuality in a broader safety context, highlighting different aspects of LLM reliability, which contrasts with the Main Paper's focus on OSHA-aligned safety practices.","The paper 'Semantic Density' emphasizes the lack of uncertainty quantification in LLMs, which the Main Paper does not address, suggesting that even if LLMs perform well in safety contexts, their trustworthiness remains questionable due to the absence of a systematic way to measure uncertainty.","The paper 'Control Risk for Potential Misuse of Artificial Intelligence in Science' emphasizes the potential misuse of AI in scientific contexts, highlighting risks such as the creation of harmful substances and the circumvention of regulations, which contrasts with the Main Paper's focus on the reliability of LLMs in providing safe guidance in laboratory settings."],"conclusion":"While the paper introduces a valuable benchmark for evaluating LLMs in lab safety, several related papers address similar aspects of LLM safety and trustworthiness in different contexts. The existence of these related works suggests that the paper's novelty is limited, as the general idea of benchmarking LLMs for safety is not entirely new. The specific focus on lab safety and OSHA protocols adds some uniqueness, but the core concept is present in other works.","label":0,"rationale":"Paper Summary: The paper introduces LabSafety Bench, a new benchmark for evaluating LLMs on safety issues in scientific labs. It addresses a gap in existing LLM trustworthiness research, which doesn't fully cover safety-critical real-world applications like lab safety. The benchmark includes 765 multiple-choice questions aligned with OSHA protocols and assesses LLMs' hallucination propensity, domain-specific knowledge, and practical decision-making. The evaluations show that even advanced models like GPT-4o are prone to critical errors, highlighting the risks of relying on LLMs in safety-critical environments.\n\nSupporting Evidence:\n- Several supporting papers highlight the need for specialized benchmarks to assess LLM trustworthiness in safety-critical applications, reinforcing the importance of LabSafety Bench.\n- Papers like 'Can't See the Forest for the Trees' and 'Jailbroken' emphasize the inadequacies of current models in providing reliable safety guidance, supporting the paper's argument for specialized benchmarks like LabSafety Bench.\n- The paper 'LLMs can generate robotic scripts from goal-oriented instructions in biological laboratory automation' highlights the potential of LLMs in enhancing laboratory efficiency, which aligns with the Main Paper's concerns about the reliability of LLMs in safety-critical environments, as it underscores the need for robust evaluation frameworks like LabSafety Bench to ensure that LLMs can safely assist in laboratory settings.\n\nContradictory Evidence:\n- The paper 'Chinese SafetyQA' introduces a benchmark aimed at evaluating LLMs' factuality in a broader safety context, highlighting different aspects of LLM reliability, which contrasts with the Main Paper's focus on OSHA-aligned safety practices.\n- The paper 'Semantic Density' emphasizes the lack of uncertainty quantification in LLMs, which the Main Paper does not address, suggesting that even if LLMs perform well in safety contexts, their trustworthiness remains questionable due to the absence of a systematic way to measure uncertainty.\n- The paper 'Control Risk for Potential Misuse of Artificial Intelligence in Science' emphasizes the potential misuse of AI in scientific contexts, highlighting risks such as the creation of harmful substances and the circumvention of regulations, which contrasts with the Main Paper's focus on the reliability of LLMs in providing safe guidance in laboratory settings.\n\nConclusion: While the paper introduces a valuable benchmark for evaluating LLMs in lab safety, several related papers address similar aspects of LLM safety and trustworthiness in different contexts. The existence of these related works suggests that the paper's novelty is limited, as the general idea of benchmarking LLMs for safety is not entirely new. The specific focus on lab safety and OSHA protocols adds some uniqueness, but the core concept is present in other works."},"arxiv_id":"2410.14182"},"terms":{"tasks":["laboratory safety","safety-critical decision-making","evaluation of large language models in lab safety contexts","trustworthiness of large language models in real-world safety applications"],"methods":["Laboratory Safety Benchmark"],"metrics":["performance"],"resources":["Laboratory Safety Benchmark","765 multiple-choice questions","Occupational Safety and Health Administration protocols","code and data"],"relations":[{"head":"Laboratory Safety Benchmark","tail":"evaluation of large language models in lab safety contexts"},{"head":"Laboratory Safety Benchmark","tail":"trustworthiness of large language models in real-world safety applications"},{"head":"performance","tail":"evaluation of large language models in lab safety contexts"},{"head":"765 multiple-choice questions","tail":"evaluation of large language models in lab safety contexts"},{"head":"Occupational Safety and Health Administration protocols","tail":"laboratory safety"},{"head":"code and data","tail":"trustworthiness of large language models in real-world safety applications"}]},"background":"Laboratory accidents pose significant risks to human life and property, underscoring the importance of robust safety protocols. Despite advancements in safety training, laboratory personnel may still unknowingly engage in unsafe practices. With the increasing reliance on large language models (LLMs) for guidance in various fields, including laboratory settings, there is a growing concern about their reliability in critical safety-related decision-making. Unlike trained human researchers, LLMs lack formal lab safety education, raising questions about their ability to provide safe and accurate guidance. Existing research on LLM trustworthiness primarily focuses on issues such as ethical compliance, truthfulness, and fairness but fails to fully cover safety-critical real-world applications, like lab safety.","target":"To address this gap, we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive evaluation framework based on a new taxonomy aligned with Occupational Safety and Health Administration (OSHA) protocols. This benchmark includes 765 multiple-choice questions verified by human experts, assessing LLMs and large vision models (LVMs) performance in lab safety contexts. Our evaluations demonstrate that while GPT-4o outperforms human participants, it is still prone to critical errors, highlighting the risks of relying on LLMs in safety-critical environments. Our findings emphasize the need for specialized benchmarks to accurately assess the trustworthiness of LLMs in real-world safety applications. The code and data are available at https://anonymous.4open.science/r/LabSafetyBench-6363."},{"graph":{"title":"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems","abstract":"While forward reasoning (i.e., find the answer given the question) has been explored extensively in the recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information? \n\nIn this paper, we formally define the backward reasoning task on math word problems and modify three datasets to evaluate this task: GSM8k, SVAMP and MultiArith. Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa). Utilizing the specific format of this task, we propose three novel techniques that improve performance: Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps. Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over these base methods aided by a verifier to further boost the accuracy by a significant margin. Extensive experimentation demonstrates that our techniques successively improve the performance of LLMs on the backward reasoning task, with the final ensemble-based method resulting in a substantial performance gain compared to the raw LLMs with standard prompting techniques such as chain-of-thought.","entities":[{"label":"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems","type":"title","detail":null,"excerpts":null},{"label":"general machine learning (i.e., none of the above)","type":"primary_area","detail":null,"excerpts":null},{"label":"backward reasoning","type":"keyword","detail":null,"excerpts":null},{"label":"math word problems","type":"keyword","detail":null,"excerpts":null},{"label":"large language models","type":"keyword","detail":null,"excerpts":null},{"label":"fill-in-the-blank","type":"keyword","detail":null,"excerpts":null},{"label":"ensemble methods","type":"keyword","detail":null,"excerpts":null},{"label":"We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?","type":"tldr","detail":null,"excerpts":null},{"label":"Backward reasoning in MWPs is more challenging for LLMs compared to forward reasoning.","type":"claim","detail":"The paper demonstrates a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa) on modified datasets GSM8k, SVAMP and MultiArith.","excerpts":[{"section":"Abstract","text":"Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa)."},{"section":"Introduction","text":"Interestingly, we observe a significant drop in the LLM accuracy across multiple datasets when working with backward reasoning (refer Table\t[\\[tab:model_perf\\]](#tab:model_perf){reference-type=\"ref\" reference=\"tab:model_perf\"})."},{"section":"Base Strategies","text":"A significant drop in backward reasoning accuracy compared to forward reasoning accuracy across all models proves the difficulty of this task for LLMs."}]},{"label":"Novel techniques improve LLM performance on backward reasoning.","type":"claim","detail":"The paper proposes three novel techniques that improve performance: Rephrase, PAL-Tools, and Check your Work. It also proposes a novel Bayesian formulation for creating an ensemble over these base methods aided by a verifier to further boost the accuracy by a significant margin.","excerpts":[{"section":"Abstract","text":"Utilizing the specific format of this task, we propose three novel techniques that improve performance: Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps."},{"section":"Abstract","text":"Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over these base methods aided by a verifier to further boost the accuracy by a significant margin."},{"section":"Introduction","text":"We take three different existing forward reasoning strategies and modify them appropriately to make them work effectively for backward reasoning, resulting in (a) Rephrase, based on [@SelfVerify] (b) PAL-Tools, based on [@PAL] and [@Tools], and (c) Check your work, based on [@SelfRefine]."},{"section":"Introduction","text":"As our final technique, we propose a novel ensemble-based approach combining these base strategies using a Bayesian framework and making use of a *forward verifier* whose accuracy is estimated using a hold-out set."}]},{"label":"Ensemble-based method results in substantial performance gain.","type":"claim","detail":"The paper demonstrates that the final ensemble-based method results in a substantial performance gain compared to the raw LLMs with standard prompting techniques such as chain-of-thought.","excerpts":[{"section":"Abstract","text":"Extensive experimentation demonstrates that our techniques successively improve the performance of LLMs on the backward reasoning task, with the final ensemble-based method resulting in a substantial performance gain compared to the raw LLMs with standard prompting techniques such as chain-of-thought."},{"section":"Introduction","text":"Experiments on several benchmark datasets show that we get successive performance improvement using our strategies, with the Bayesian ensemble based approach performing the best, providing 20-30% points gains compared to SOTA techniques for forward reasoning."},{"section":"Ensembling","text":"Clearly, we see that our ensembling technique results in significant gains ($10$-$20\\%$) on all the datasets, compared to the best-performing PAL-Tools which is the best-performing base model (ref. Table\t[\\[tab:base-methods\\]](#tab:base-methods){reference-type=\"ref\" reference=\"tab:base-methods\"})."}]},{"label":"8-shot chain of thought prompts","type":"method","detail":"The experiments were conducted using the chain of thought prompts defined in @CoT. The few-shot examples used in the chain of thought prompts were modified for the backward reasoning task following the procedure described above.","excerpts":[{"section":"Base Strategies","text":"The experiments were conducted using the chain of thought prompts defined in @CoT. The few-shot examples used in the chain of thought prompts were modified for the backward reasoning task following the procedure described above."}]},{"label":"Rephrase","type":"method","detail":"Transforms the backward reasoning problem into a forward reasoning problem by incorporating the forward answer into the question and changing the objective to finding the value of the blank.","excerpts":[{"section":"Base Strategies","text":"Our first modified SOTA method to tackle the challenging backward reasoning problem involves a problem transformation through rephrasing. This transformation effectively converts the complex backward reasoning task into a more manageable forward reasoning problem."},{"section":"Base Strategies","text":"Given a backward MWP $(Q, A_f)$, we ask the language model to produce a rephrased question $R$, which incorporates the forward answer $A_f$ into the question $Q$ and changes the objective of the question from finding the answer $A_f$ to finding the value of the blank."}]},{"label":"PAL-Tools","type":"method","detail":"Modifies the Program-aided language model (PAL) to write a Python program to solve the MWP and integrates it with Tools which uses the techniques of framing equations in natural language and calls SymPy to solve them.","excerpts":[{"section":"Base Strategies","text":"We modify the Program-aided language model (PAL) [@PAL] which writes a Python program to solve the MWP and integrate it with Tools\t[@Tools] which uses the techniques of framing equations in natural language and calls SymPy to solve them."}]},{"label":"Check your Work (CYW)","type":"method","detail":"Inspired from the iterative prompting technique [Self-Refine], this approach generates the answer, forms a forward problem by substituting the blank, and checks the correctness by comparing the answer to the gold answer.","excerpts":[{"section":"Base Strategies","text":"Inspired from the iterative prompting technique [Self-Refine]{.smallcaps}\t[@SelfRefine], that cycles between refinement and feedback until a stopping criteria is met, our approach has the following steps: (1) Generate the answer of $Q$ say $a$. (2) Form a forward problem obtained by substituting the blank with the obtained answer $a$. (3) Check the correctness of $a$ by checking whether the answer to the forward problem matches with the gold answer $A_f$."}]},{"label":"Bayesian Ensemble","type":"method","detail":"Ensembles the base strategies using a Bayesian framework and a forward verifier whose accuracy is estimated using a hold-out set.","excerpts":[{"section":"Introduction","text":"As our final technique, we propose a novel ensemble-based approach combining these base strategies using a Bayesian framework and making use of a *forward verifier* whose accuracy is estimated using a hold-out set."},{"section":"A Novel Approach of Ensembling","text":"We propose a way of ensembling these methods as illustrated by an example in Figure [2](#fig:ensemble-overview){reference-type=\"ref\" reference=\"fig:ensemble-overview\"}."}]},{"label":"Experiments on GSM8k, SVAMP, and MultiArith datasets","type":"experiment","detail":"The paper transforms examples in GSM8k, MultiArith, and SVAMP datasets into backward tasks, creating GSM8kB, SVAMPB, and MultiArithB. It experiments with GPT-4, GPT-3.5-Turbo, PaLM-2 and LLaMa-2.","excerpts":[{"section":"Experiments","text":"We start with three forward reasoning datasets: GSM8k\t[@GSM8k], MultiArith\t[@MultiArith], and SVAMP\t[@SVAMP], and transform the examples in these datasets into backward tasks, resulting in the creation of three modified datasets: GSM8k$_\\text{B}$, SVAMP$_\\text{B}$, and MultiArith$_\\text{B}$ (ref. Appendix [11](#sec:dataset){reference-type=\"ref\" reference=\"sec:dataset\"} for modification details). We have experimented with four SOTA LLMs: GPT-4, GPT-3.5-Turbo [@GPT4], PaLM-2 [@Palm2] and LLaMa-2 [@LLaMa2]."}]}],"relationships":[{"source":"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems","target":"general machine learning (i.e., none of the above)"},{"source":"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems","target":"backward reasoning"},{"source":"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems","target":"math word problems"},{"source":"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems","target":"large language models"},{"source":"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems","target":"fill-in-the-blank"},{"source":"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems","target":"ensemble methods"},{"source":"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems","target":"We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?"},{"source":"We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?","target":"Backward reasoning in MWPs is more challenging for LLMs compared to forward reasoning."},{"source":"We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?","target":"Novel techniques improve LLM performance on backward reasoning."},{"source":"We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?","target":"Ensemble-based method results in substantial performance gain."},{"source":"Backward reasoning in MWPs is more challenging for LLMs compared to forward reasoning.","target":"8-shot chain of thought prompts"},{"source":"Novel techniques improve LLM performance on backward reasoning.","target":"Rephrase"},{"source":"Novel techniques improve LLM performance on backward reasoning.","target":"PAL-Tools"},{"source":"Novel techniques improve LLM performance on backward reasoning.","target":"Check your Work (CYW)"},{"source":"Novel techniques improve LLM performance on backward reasoning.","target":"Bayesian Ensemble"},{"source":"Ensemble-based method results in substantial performance gain.","target":"Bayesian Ensemble"},{"source":"8-shot chain of thought prompts","target":"Experiments on GSM8k, SVAMP, and MultiArith datasets"},{"source":"Rephrase","target":"Experiments on GSM8k, SVAMP, and MultiArith datasets"},{"source":"PAL-Tools","target":"Experiments on GSM8k, SVAMP, and MultiArith datasets"},{"source":"Check your Work (CYW)","target":"Experiments on GSM8k, SVAMP, and MultiArith datasets"},{"source":"Bayesian Ensemble","target":"Experiments on GSM8k, SVAMP, and MultiArith datasets"}],"valid_status":"Valid","valid_status_all":["Valid"]},"related":[{"summary":"The Related Paper, 'ReasonAgain: Using Extractable Symbolic Programs to Evaluate Mathematical Reasoning,' supports the Main Paper by highlighting the limitations of existing evaluation methods for LLMs in math reasoning, which aligns with the Main Paper's focus on backward reasoning. Both papers utilize the GSM8K dataset, and the Related Paper's findings on the fragility of LLMs' reasoning abilities reinforce the Main Paper's claims about the significant accuracy drop in backward reasoning tasks. Additionally, the Related Paper's approach of using symbolic programs complements the Main Paper's proposed techniques, suggesting a broader context for improving LLM performance in mathematical reasoning.","paper_id":"1176de467f5f6fca504e7b98da7fe6fb4414fcd3","title":"ReasonAgain: Using Extractable Symbolic Programs to Evaluate Mathematical Reasoning","abstract":"Existing math datasets evaluate the reasoning abilities of large language models (LLMs) by either using the final answer or the intermediate reasoning steps derived from static examples. However, the former approach fails to surface model's uses of shortcuts and wrong reasoning while the later poses challenges in accommodating alternative solutions. In this work, we seek to use symbolic programs as a means for automated evaluation if a model can consistently produce correct final answers across various inputs to the program. We begin by extracting programs for popular math datasets (GSM8K and MATH) using GPT4-o. For those executable programs verified using the original input-output pairs, they are found to encapsulate the proper reasoning required to solve the original text questions. We then prompt GPT4-o to generate new questions using alternative input-output pairs based the extracted program. We apply the resulting datasets to evaluate a collection of LLMs. In our experiments, we observe significant accuracy drops using our proposed evaluation compared with original static examples, suggesting the fragility of math reasoning in state-of-the-art LLMs.","score":0.7076916098594666,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"In this paper, we formally define the backward reasoning task on math word problems and modify three datasets to evaluate this task: GSM8k, SVAMP and MultiArith. Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa). Utilizing the specific format of this task, we propose three novel techniques that improve performance: Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps. Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over these base methods aided by a verifier to further boost the accuracy by a significant margin. Extensive experimentation demonstrates that our techniques successively improve the performance of LLMs on the backward reasoning task, with the final ensemble-based method resulting in a substantial performance gain compared to the raw LLMs with standard prompting techniques such as chain-of-thought."},{"summary":"The Related Paper supports the Main Paper by addressing the limitations of LLMs in reasoning tasks, particularly in mathematical contexts. It emphasizes the importance of verification and error detection, which aligns with the Main Paper's focus on enhancing backward reasoning capabilities. Both papers propose innovative techniques to improve LLM performance, with the Related Paper's collaborative verification approach complementing the Main Paper's ensemble methods. Together, they highlight the necessity of integrating multiple reasoning strategies and verification mechanisms to achieve significant performance gains in complex reasoning tasks.","paper_id":"03c3737116ec11828fd63b182723ec54fc2985da","title":"Improving LLM Reasoning through Scaling Inference Computation with Collaborative Verification","abstract":"Despite significant advancements in the general capability of large language models (LLMs), they continue to struggle with consistent and accurate reasoning, especially in complex tasks such as mathematical and code reasoning. One key limitation is that LLMs are trained primarily on correct solutions, reducing their ability to detect and learn from errors, which hampers their ability to reliably verify and rank outputs. To address this, we scale up the inference-time computation by generating multiple reasoning paths and employing verifiers to assess and rank the generated outputs by correctness. To facilitate this, we introduce a comprehensive dataset consisting of correct and incorrect solutions for math and code tasks, generated by multiple LLMs. This diverse set of solutions enables verifiers to more effectively distinguish and rank correct answers from erroneous outputs. The training methods for building verifiers were selected based on an extensive comparison of existing approaches. Moreover, to leverage the unique strengths of different reasoning strategies, we propose a novel collaborative method integrating Chain-of-Thought (CoT) and Program-of-Thought (PoT) solutions for verification. CoT provides a clear, step-by-step reasoning process that enhances interpretability, while PoT, being executable, offers a precise and error-sensitive validation mechanism. By taking both of their strengths, our approach significantly improves the accuracy and reliability of reasoning verification. Our verifiers, Math-Rev and Code-Rev, demonstrate substantial performance gains to existing LLMs, achieving state-of-the-art results on benchmarks such as GSM8k and MATH and even outperforming GPT-4o with Qwen-72B-Instruct as the reasoner.","score":0.6932452321052551,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"In this paper, we formally define the backward reasoning task on math word problems and modify three datasets to evaluate this task: GSM8k, SVAMP and MultiArith. Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa). Utilizing the specific format of this task, we propose three novel techniques that improve performance: Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps. Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over these base methods aided by a verifier to further boost the accuracy by a significant margin. Extensive experimentation demonstrates that our techniques successively improve the performance of LLMs on the backward reasoning task, with the final ensemble-based method resulting in a substantial performance gain compared to the raw LLMs with standard prompting techniques such as chain-of-thought."},{"summary":"The Related Paper, 'MathScale: Scaling Instruction Tuning for Mathematical Reasoning,' supports the Main Paper by providing a scalable method for generating high-quality mathematical reasoning data, which can enhance the training of LLMs. While the Main Paper focuses on backward reasoning in math word problems and proposes novel techniques to improve LLM performance, the Related Paper contributes by creating a comprehensive benchmark (MwpBench) and a large dataset (MathScaleQA) that can be utilized to evaluate and fine-tune LLMs, thereby addressing the inadequacies in mathematical problem-solving capabilities highlighted in the Main Paper.","paper_id":"3352782f94354d3f3a170f497dd1888e9cd39d8a","title":"MathScale: Scaling Instruction Tuning for Mathematical Reasoning","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities in problem-solving. However, their proficiency in solving mathematical problems remains inadequate. We propose MathScale, a simple and scalable method to create high-quality mathematical reasoning data using frontier LLMs (e.g., {\\tt GPT-3.5}). Inspired by the cognitive mechanism in human mathematical learning, it first extracts topics and knowledge points from seed math questions and then build a concept graph, which is subsequently used to generate new math questions. MathScale exhibits effective scalability along the size axis of the math dataset that we generate. As a result, we create a mathematical reasoning dataset (MathScaleQA) containing two million math question-answer pairs. To evaluate mathematical reasoning abilities of LLMs comprehensively, we construct {\\sc MwpBench}, a benchmark of Math Word Problems, which is a collection of ten datasets (including GSM8K and MATH) covering K-12, college, and competition level math problems. We apply MathScaleQA to fine-tune open-source LLMs (e.g., LLaMA-2 and Mistral), resulting in significantly improved capabilities in mathematical reasoning. Evaluated on {\\sc MwpBench}, MathScale-7B achieves state-of-the-art performance across all datasets, surpassing its best peers of equivalent size by 42.9\\% in micro average accuracy and 43.7\\% in macro average accuracy, respectively.","score":0.6814575791358948,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"In this paper, we formally define the backward reasoning task on math word problems and modify three datasets to evaluate this task: GSM8k, SVAMP and MultiArith. Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa). Utilizing the specific format of this task, we propose three novel techniques that improve performance: Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps. Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over these base methods aided by a verifier to further boost the accuracy by a significant margin. Extensive experimentation demonstrates that our techniques successively improve the performance of LLMs on the backward reasoning task, with the final ensemble-based method resulting in a substantial performance gain compared to the raw LLMs with standard prompting techniques such as chain-of-thought."},{"summary":"The Related Paper introduces generative verifiers (GenRM) that enhance the reasoning performance of LLMs, which aligns with the Main Paper's focus on improving backward reasoning in math word problems. Both papers emphasize the importance of verification in boosting model accuracy, with the Main Paper proposing a novel Bayesian ensemble method that incorporates verification steps. The success of GenRM in outperforming traditional verifiers, particularly on datasets like GSM8K, supports the Main Paper's findings by demonstrating that effective verification techniques can significantly enhance LLM performance in reasoning tasks.","paper_id":"3707939a856655fcabf0acd5cba1a1009987b439","title":"Generative Verifiers: Reward Modeling as Next-Token Prediction","abstract":"Verifiers or reward models are often used to enhance the reasoning performance of large language models (LLMs). A common approach is the Best-of-N method, where N candidate solutions generated by the LLM are ranked by a verifier, and the best one is selected. While LLM-based verifiers are typically trained as discriminative classifiers to score solutions, they do not utilize the text generation capabilities of pretrained LLMs. To overcome this limitation, we instead propose training verifiers using the ubiquitous next-token prediction objective, jointly on verification and solution generation. Compared to standard verifiers, such generative verifiers (GenRM) can benefit from several advantages of LLMs: they integrate seamlessly with instruction tuning, enable chain-of-thought reasoning, and can utilize additional test-time compute via majority voting for better verification. We demonstrate that GenRM outperforms discriminative, DPO verifiers, and LLM-as-a-Judge, resulting in large performance gains with Best-of-N, namely 5% $\\rightarrow$ 45.3% on algorithmic tasks and 73% $\\rightarrow$ 93.4% on GSM8K. In easy-to-hard generalization settings, we observe improvements of 28% $\\rightarrow$ 44.6% on MATH, and 37.9% $\\rightarrow$ 53.5% on MMLU abstract algebra. Furthermore, we find that training GenRM with synthetic verification rationales is sufficient to pick out subtle errors on math problems. Finally, we demonstrate that GenRM scales favorably with model size and test-time compute.","score":0.6795799136161804,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"In this paper, we formally define the backward reasoning task on math word problems and modify three datasets to evaluate this task: GSM8k, SVAMP and MultiArith. Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa). Utilizing the specific format of this task, we propose three novel techniques that improve performance: Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps. Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over these base methods aided by a verifier to further boost the accuracy by a significant margin. Extensive experimentation demonstrates that our techniques successively improve the performance of LLMs on the backward reasoning task, with the final ensemble-based method resulting in a substantial performance gain compared to the raw LLMs with standard prompting techniques such as chain-of-thought."},{"summary":"The Related Paper, 'Dipper: Diversity in Prompts for Producing Large Language Model Ensembles in Reasoning tasks', supports the Main Paper by demonstrating the effectiveness of ensemble methods in enhancing reasoning capabilities of LLMs, particularly in math tasks. While the Main Paper focuses on backward reasoning and proposes novel techniques to improve performance, the Related Paper provides empirical evidence that diverse prompting strategies can also lead to significant performance gains in reasoning tasks. Together, these works highlight complementary approaches to improving LLM reasoning, with the Related Paper reinforcing the potential of ensemble methods as a viable strategy for enhancing the backward reasoning capabilities explored in the Main Paper.","paper_id":"3e95793c68c22a7b891973588cf66ce61c503e30","title":"Dipper: Diversity in Prompts for Producing Large Language Model Ensembles in Reasoning tasks","abstract":"Large Language Models still encounter substantial challenges in reasoning tasks, especially for smaller models, which many users may be restricted to due to resource constraints (e.g. GPU memory restrictions). Inference-time methods to boost LLM performance, such as prompting methods to invoke certain reasoning pathways in responses, have been shown effective in past works, though they largely rely on sequential queries. The ensemble method, which consists of multiple constituent models running in parallel, is a promising approach to achieving better inference-time performance, especially given recent developments that enabled significant speed-ups in LLM batch inference. In this work, we propose a novel, training-free LLM ensemble framework where a single LLM model is fed an optimized, diverse set of prompts in parallel, effectively producing an ensemble at inference time to achieve performance improvement in reasoning tasks. We empirically demonstrate that our method leads to significant gains on math reasoning tasks, e.g., on MATH, where our ensemble consisting of a few small models (e.g., three Qwen2-MATH-1.5B-it models) can outperform a larger model (e.g., Qwen2-MATH-7B-it).","score":0.679425060749054,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"In this paper, we formally define the backward reasoning task on math word problems and modify three datasets to evaluate this task: GSM8k, SVAMP and MultiArith. Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa). Utilizing the specific format of this task, we propose three novel techniques that improve performance: Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps. Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over these base methods aided by a verifier to further boost the accuracy by a significant margin. Extensive experimentation demonstrates that our techniques successively improve the performance of LLMs on the backward reasoning task, with the final ensemble-based method resulting in a substantial performance gain compared to the raw LLMs with standard prompting techniques such as chain-of-thought."},{"summary":"The Related Paper contrasts the Main Paper by emphasizing the importance of evaluating LLMs' reasoning capabilities through a focus on end-to-end correctness rather than backward reasoning. While the Main Paper explores backward reasoning in math word problems and proposes techniques to enhance performance, the Related Paper highlights that LLMs often arrive at correct answers through flawed reasoning steps, suggesting that backward reasoning may not be the only or most effective approach to assess mathematical reasoning. Additionally, the Related Paper introduces a dataset that includes hints and concepts, indicating that LLMs can benefit from additional contextual information, which is not addressed in the Main Paper's backward reasoning framework.","paper_id":"bc8e76e9541dd07a094540d262a864b65505cab7","title":"CHAMP: A Competition-level Dataset for Fine-Grained Analyses of LLMs' Mathematical Reasoning Capabilities","abstract":"Recent large language models (LLMs) have shown indications of mathematical reasoning ability on challenging competition-level problems, especially with self-generated verbalizations of intermediate reasoning steps (i.e., chain-of-thought prompting). However, current evaluations mainly focus on the end-to-end final answer correctness, and it is unclear whether LLMs can make use of helpful side information such as problem-specific hints. In this paper, we propose a challenging benchmark dataset for enabling such analyses. The Concept and Hint-Annotated Math Problems (CHAMP) consists of high school math competition problems, annotated with concepts, or general math facts, and hints, or problem-specific tricks. These annotations allow us to explore the effects of additional information, such as relevant hints, misleading concepts, or related problems. This benchmark is difficult, with the best model only scoring 58.1% in standard settings. With concepts and hints, performance sometimes improves, indicating that some models can make use of such side information. Furthermore, we annotate model-generated solutions for their correctness. Using this corpus, we find that models often arrive at the correct final answer through wrong reasoning steps. In addition, we test whether models are able to verify these solutions, and find that most models struggle.","score":0.6633108854293823,"polarity":"negative","source":"semantic","contexts":null,"background":"While forward reasoning (i.e., find the answer given the question) has been explored extensively in the recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?","target":null},{"summary":"The Related Paper contrasts the Main Paper by focusing on the issue of irrelevant conditions in Math Word Problems (MWPs), which the Main Paper does not address. While the Main Paper emphasizes enhancing backward reasoning capabilities of LLMs, the Related Paper introduces the I^3C approach to help LLMs identify and ignore irrelevant information, thereby improving reasoning paths. This highlights a different aspect of MWP solving, suggesting that the challenges faced by LLMs in backward reasoning may stem from their inability to filter out distractions, rather than solely from the backward reasoning process itself.","paper_id":"3455e135151b8026d8e68b1363b212982697a65c","title":"Instructing Large Language Models to Identify and Ignore Irrelevant Conditions","abstract":"Math word problem (MWP) solving requires generating a reasoning path based on a given problem description that often contains irrelevant conditions.Existing chain-of-thought (CoT) prompting methods elicited multi-step reasoning abilities of large language models (LLMs) to solve MWPs.However, they were seriously confused by the irrelevant conditions, resulting in low accuracy.In this paper, we propose a novel approach named I^3C that instructs LLMs to identify and ignore irrelevant conditions.It identifies a set of irrelevant condition candidates that have a weak semantic relevance with the question.Then it prompts LLMs to verify the irrelevant conditions.Lastly it instructs the LLMs with the verification on relevant and irrelevant conditions to avoid confusion and improve reasoning paths.Moreover, we propose to select (problem, reasoning paths) pairs as demonstrations to enhance I^3C with few-shot reasoning. We develop I^3C-Select that selects the most confusing problems based on the semantic relevance measurement.We conduct extensive experiments on eight MWP datasets.I^3C can be combined with any CoT prompting methods to improve the performance of solving MWPs.Notably, with GPT-3.5-Turbo and I^3C-Select, we achieve an accuracy of 96.0 and 94.1 on GSM-IC2-1K and GSM-ICM-1K, respectively, significantly outperforming the state-of-the-art few-shot prompting method Complex-CoT by +11.7 and +11.1.Our implementation is made publicly available at https://wzy6642.github.io/I3C.github.io/.","score":0.6507721543312073,"polarity":"negative","source":"semantic","contexts":null,"background":"While forward reasoning (i.e., find the answer given the question) has been explored extensively in the recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?","target":null},{"summary":"The Related Paper contrasts the Main Paper by highlighting that while the Main Paper focuses on enhancing backward reasoning capabilities in LLMs for math word problems, the Related Paper critiques the overall logical integrity of LLMs, suggesting they often act as 'Blind Solvers' rather than 'Logical Thinkers.' It emphasizes that LLMs struggle to identify logical inconsistencies in mathematical problems, which is a fundamental aspect of reasoning that the Main Paper does not address. Thus, while the Main Paper proposes methods to improve backward reasoning, the Related Paper questions the foundational reasoning abilities of LLMs, indicating a broader issue in their logical processing.","paper_id":"d64487c1b772a8b3aa20cead0e0006c85ce6e4c0","title":"From Blind Solvers to Logical Thinkers: Benchmarking LLMs' Logical Integrity on Faulty Mathematical Problems","abstract":"Consider the math problem:\"Lily received 3 cookies from her best friend yesterday and ate 5 for breakfast. Today, her friend gave her 3 more cookies. How many cookies does Lily have now?\"Many large language models (LLMs) in previous research approach this problem by calculating the answer\"1\"using the equation\"3 - 5 + 3.\"However, from a human perspective, we recognize the inherent flaw in this problem: Lily cannot eat 5 cookies if she initially only had 3. This discrepancy prompts a key question: Are current LLMs merely Blind Solver that apply mathematical operations without deeper reasoning, or can they function as Logical Thinker capable of identifying logical inconsistencies? To explore this question, we propose a benchmark dataset, FaultyMath, which includes faulty math problems of rich diversity: i) multiple mathematical categories, e.g., algebra, geometry, number theory, etc., ii) varying levels of difficulty, and iii) different origins of faultiness -- ranging from violations of common sense and ambiguous statements to mathematical contradictions and more. We evaluate a broad spectrum of LLMs, including open-source, closed-source, and math-specialized models, using FaultyMath across three dimensions: (i) How accurately can the models detect faulty math problems without being explicitly prompted to do so? (ii) When provided with hints -- either correct or misleading -- about the validity of the problems, to what extent do LLMs adapt to become reliable Logical Thinker? (iii) How trustworthy are the explanations generated by LLMs when they recognize a math problem as flawed? Through extensive experimentation and detailed analysis, our results demonstrate that existing LLMs largely function as Blind Solver and fall short of the reasoning capabilities required to perform as Logical Thinker.","score":0.6485277414321899,"polarity":"negative","source":"semantic","contexts":null,"background":"While forward reasoning (i.e., find the answer given the question) has been explored extensively in the recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?","target":null},{"summary":"The Related Paper contrasts the Main Paper by focusing on the impact of longer context lengths on the performance of LLMs in solving Math Word Problems (MWPs), while the Main Paper emphasizes backward reasoning capabilities. The Related Paper introduces the concept of Context Length Generalizability (CoLeG) and highlights deficiencies in LLMs when faced with extended narratives, proposing tailored approaches to improve performance. In contrast, the Main Paper presents novel techniques aimed at enhancing backward reasoning accuracy, revealing a significant drop in performance compared to forward reasoning, thus showcasing different aspects of LLM limitations and potential improvements.","paper_id":"28808dc21b4321b85cacac7ccc2d974632a2980e","title":"Can LLMs Solve longer Math Word Problems Better?","abstract":"Math Word Problems (MWPs) play a vital role in assessing the capabilities of Large Language Models (LLMs), yet current research primarily focuses on questions with concise contexts. The impact of longer contexts on mathematical reasoning remains under-explored. This study pioneers the investigation of Context Length Generalizability (CoLeG), which refers to the ability of LLMs to solve MWPs with extended narratives. We introduce Extended Grade-School Math (E-GSM), a collection of MWPs featuring lengthy narratives, and propose two novel metrics to evaluate the efficacy and resilience of LLMs in tackling these problems. Our analysis of existing zero-shot prompting techniques with proprietary LLMs along with open-source LLMs reveals a general deficiency in CoLeG. To alleviate these issues, we propose tailored approaches for different categories of LLMs. For proprietary LLMs, we introduce a new instructional prompt designed to mitigate the impact of long contexts. For open-source LLMs, we develop a novel auxiliary task for fine-tuning to enhance CoLeG. Our comprehensive results demonstrate the effectiveness of our proposed methods, showing improved performance on E-GSM. Additionally, we conduct an in-depth analysis to differentiate the effects of semantic understanding and reasoning efficacy, showing that our methods improves the latter. We also establish the generalizability of our methods across several other MWP benchmarks. Our findings highlight the limitations of current LLMs and offer practical solutions correspondingly, paving the way for further exploration of model generalizability and training methodologies.","score":0.6478741765022278,"polarity":"negative","source":"semantic","contexts":null,"background":"While forward reasoning (i.e., find the answer given the question) has been explored extensively in the recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?","target":null},{"summary":"The Related Paper contrasts the Main Paper by emphasizing the limitations of programmatic representations in LLMs for constraint solving tasks, which require more sophisticated reasoning than what backward reasoning can provide. While the Main Paper focuses on enhancing backward reasoning capabilities through novel techniques and ensemble methods, the Related Paper introduces a satisfiability-aided approach that leverages automated theorem proving to ensure correctness and improve reasoning accuracy. This highlights a fundamental difference in methodology, with the Related Paper suggesting that the declarative approach may be more effective for complex reasoning tasks than the backward reasoning techniques proposed in the Main Paper.","paper_id":"f27f6d1d521d189e78f5623098ced0deea613d33","title":"Satisfiability-Aided Language Models Using Declarative Prompting","abstract":"Prior work has combined chain-of-thought prompting in large language models (LLMs) with programmatic representations to perform effective and transparent reasoning. While such an approach works well for tasks that only require forward reasoning (e.g., straightforward arithmetic), it is less effective for constraint solving problems that require more sophisticated planning and search. In this paper, we propose a new satisfiability-aided language modeling (SatLM) approach for improving the reasoning capabilities of LLMs. We use an LLM to generate a declarative task specification rather than an imperative program and leverage an off-the-shelf automated theorem prover to derive the final answer. This approach has two key advantages. The declarative specification is closer to the problem description than the reasoning steps are, so the LLM can parse it out of the description more accurately. Furthermore, by offloading the actual reasoning task to an automated theorem prover, our approach can guarantee the correctness of the answer with respect to the parsed specification and avoid planning errors in the solving process. We evaluate SATLM on 8 different datasets and show that it consistently outperforms program-aided LMs in the imperative paradigm. In particular, SATLM outperforms program-aided LMs by 23% on a challenging subset of the GSM arithmetic reasoning dataset; SATLM also achieves a new SoTA on LSAT and BoardgameQA, surpassing previous models that are trained on the respective training sets.","score":0.6416689157485962,"polarity":"negative","source":"semantic","contexts":null,"background":"While forward reasoning (i.e., find the answer given the question) has been explored extensively in the recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?","target":null},{"summary":"The Related Paper supports the Main Paper by providing a foundational dataset (GSM8K) that highlights the challenges LLMs face in multi-step mathematical reasoning, which aligns with the Main Paper's focus on backward reasoning in math word problems. Both papers emphasize the importance of verification in improving model performance, with the Related Paper demonstrating that training verifiers can enhance accuracy, a concept that is echoed in the Main Paper's proposed techniques, particularly the 'Check your Work' method. This connection reinforces the Main Paper's claims about the necessity of innovative approaches to enhance LLM capabilities in reasoning tasks.","paper_id":"d6045d2ccc9c09ca1671348de86d07da6bc28eea","title":"Training Verifiers to Solve Math Word Problems","abstract":"State-of-the-art language models can match human performance on many tasks, but they still struggle to robustly perform multi-step mathematical reasoning. To diagnose the failures of current models and support research, we introduce GSM8K, a dataset of 8.5K high quality linguistically diverse grade school math word problems. We find that even the largest transformer models fail to achieve high test performance, despite the conceptual simplicity of this problem distribution. To increase performance, we propose training verifiers to judge the correctness of model completions. At test time, we generate many candidate solutions and select the one ranked highest by the verifier. We demonstrate that verification significantly improves performance on GSM8K, and we provide strong empirical evidence that verification scales more effectively with increased data than a finetuning baseline.","score":0.6514456272125244,"polarity":"positive","source":"citations","contexts":[{"sentence":"This problem has received significant attention in the recent literature~\\citep{lu2022survey}, and specific datasets~\\citep{GSM8k,MultiArith,SVAMP} have been proposed as a benchmark for this task.","polarity":"positive"},{"sentence":"We start with three forward reasoning datasets: GSM8k~\\citep{GSM8k}, MultiArith~\\citep{MultiArith}, and SVAMP~\\citep{SVAMP}, and transform the examples in these datasets into backward tasks, resulting in the creation of three modified datasets: GSM8k MATH_","polarity":"positive"},{"sentence":"We consider three datasets of interest: GSM8K \\citep{GSM8k}, MultiArith \\citep{MultiArith}, and SVAMP \\citep{SVAMP}.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper supports the Main Paper by demonstrating the effectiveness of combining LLMs with external symbolic solvers for solving math word problems, which aligns with the Main Paper's exploration of enhancing backward reasoning capabilities in LLMs. Both papers emphasize the importance of innovative techniques to improve reasoning accuracy, with the Related Paper providing evidence that incremental formalization and declarative representations can significantly enhance performance on complex problems. This synergy reinforces the Main Paper's findings on the limitations of LLMs in backward reasoning and the potential of novel approaches to address these challenges.","paper_id":"57100e39d0413ee585b381ba9ab366e8a6cf2866","title":"Solving Math Word Problems by Combining Language Models With Symbolic Solvers","abstract":"Automatically generating high-quality step-by-step solutions to math word problems has many applications in education. Recently, combining large language models (LLMs) with external tools to perform complex reasoning and calculation has emerged as a promising direction for solving math word problems, but prior approaches such as Program-Aided Language model (PAL) are biased towards simple procedural problems and less effective for problems that require declarative reasoning. We propose an approach that combines an LLM that can incrementally formalize word problems as a set of variables and equations with an external symbolic solver that can solve the equations. Our approach achieves comparable accuracy to the original PAL on the GSM8K benchmark of math word problems and outperforms PAL by an absolute 20% on ALGEBRA, a new dataset of more challenging word problems extracted from Algebra textbooks. Our work highlights the benefits of using declarative and incremental representations when interfacing with an external tool for solving complex math word problems. Our data and prompts are publicly available at https://github.com/joyheyueya/declarative-math-word-problem.","score":0.6190042495727539,"polarity":"positive","source":"citations","contexts":[{"sentence":"We take three different existing forward reasoning strategies and modify them appropriately to make them work effectively for backward reasoning, resulting in (a) Rephrase, based on \\cite{SelfVerify} (b) PAL-Tools, based on \\cite{PAL} and \\cite{Tools}, and","polarity":"positive"},{"sentence":"We modify the Program-aided language model (PAL) \\citep{PAL} which writes a Python program to solve the MWP and integrate it with Tools~\\cite{Tools} which uses the techniques of framing equations in natural language and calls SymPy to solve them.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper presents a novel approach for solving algebra word problems by constructing systems of linear equations, which aligns with the Main Paper's focus on backward reasoning in math word problems. Both papers emphasize the importance of reasoning capabilities in LLMs, with the Related Paper providing empirical evidence of effective problem-solving strategies that could enhance the backward reasoning techniques proposed in the Main Paper. Additionally, the methodologies in the Related Paper, such as variable alignment and varied supervision, may offer complementary insights that could further improve the performance of LLMs on the backward reasoning task outlined in the Main Paper.","paper_id":"3a395daf6c97c084cf9c3827384c53caf6502921","title":"Learning to Automatically Solve Algebra Word Problems","abstract":"We present an approach for automatically learning to solve algebra word problems. Our algorithm reasons across sentence boundaries to construct and solve a system of linear equations, while simultaneously recovering an alignment of the variables and numbers in these equations to the problem text. The learning algorithm uses varied supervision, including either full equations or just the final answers. We evaluate performance on a newly gathered corpus of algebra word problems, demonstrating that the system can correctly answer almost 70% of the questions in the dataset. This is, to our knowledge, the first learning result for this task.","score":0.61846923828125,"polarity":"positive","source":"citations","contexts":[{"sentence":"They have been successfully applied to mathematical reasoning, specifically in solving { Math Word Problems} (MWPs) ~\\citep{kushman2014learning, roy2018mapping}, where the goal is to produce the answer given an elementary school-level mathematics question.","polarity":"positive"},{"sentence":"Initial works~\\citep{kushman2014learning, koncel2015parsing, roy2018mapping} to solve MWPs involve parsing the natural language description and utilizing statistical learning techniques to identify suitable templates for generating answers.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper supports the Main Paper by emphasizing the importance of declarative knowledge in solving math word problems, which aligns with the Main Paper's exploration of backward reasoning capabilities in LLMs. Both papers highlight the challenges of understanding and interpreting mathematical concepts within word problems. The Related Paper's framework for mapping natural language to mathematical expressions complements the Main Paper's proposed techniques for enhancing backward reasoning, suggesting that integrating declarative knowledge could further improve LLM performance in this area.","paper_id":"83cc0d20275fdc3a97cceacdc41fbb19953fa901","title":"Mapping to Declarative Knowledge for Word Problem Solving","abstract":"Math word problems form a natural abstraction to a range of quantitative reasoning problems, such as understanding financial news, sports results, and casualties of war. Solving such problems requires the understanding of several mathematical concepts such as dimensional analysis, subset relationships, etc. In this paper, we develop declarative rules which govern the translation of natural language description of these concepts to math expressions. We then present a framework for incorporating such declarative knowledge into word problem solving. Our method learns to map arithmetic word problem text to math expressions, by learning to select the relevant declarative knowledge for each operation of the solution expression. This provides a way to handle multiple concepts in the same problem while, at the same time, supporting interpretability of the answer expression. Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations. Experimental evaluation suggests that our domain knowledge based solver outperforms all other systems, and that it generalizes better in the realistic case where the training data it is exposed to is biased in a different way than the test data.","score":0.5844964981079102,"polarity":"positive","source":"citations","contexts":[{"sentence":"They have been successfully applied to mathematical reasoning, specifically in solving { Math Word Problems} (MWPs) ~\\citep{kushman2014learning, roy2018mapping}, where the goal is to produce the answer given an elementary school-level mathematics question.","polarity":"positive"},{"sentence":"Initial works~\\citep{kushman2014learning, koncel2015parsing, roy2018mapping} to solve MWPs involve parsing the natural language description and utilizing statistical learning techniques to identify suitable templates for generating answers.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper supports the Main Paper by demonstrating advanced methodologies for solving math word problems, which aligns with the Main Paper's exploration of backward reasoning in LLMs. While the Main Paper focuses on enhancing backward reasoning capabilities through novel techniques and ensemble methods, the Related Paper's deep neural solver and hybrid model provide a complementary approach that emphasizes direct translation of problems into equation templates. Together, these works highlight the potential for improved performance in math problem-solving through innovative model architectures.","paper_id":"678fd7c48efe21434148b4b3482c2b8b3ee618fc","title":"Deep Neural Solver for Math Word Problems","abstract":"This paper presents a deep neural solver to automatically solve math word problems. In contrast to previous statistical learning approaches, we directly translate math word problems to equation templates using a recurrent neural network (RNN) model, without sophisticated feature engineering. We further design a hybrid model that combines the RNN model and a similarity-based retrieval model to achieve additional performance improvement. Experiments conducted on a large dataset show that the RNN model and the hybrid model significantly outperform state-of-the-art statistical learning methods for math word problem solving.","score":0.5791916847229004,"polarity":"positive","source":"citations","contexts":[{"sentence":"Subsequently, following the triumph of sequence-to-sequence (Seq2Seq) neural models~\\citep{sutskever2014sequence} in machine translation and other NLP tasks, the encoder-decoder framework~\\citep{wang2017deep, ling2017program, li2020graph, shen2021generate,","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper contrasts with the Main Paper by focusing on the effectiveness of chain-of-thought prompting and a new decoding strategy called self-consistency, which enhances performance on reasoning tasks. While the Main Paper highlights the challenges and limitations of backward reasoning in LLMs, demonstrating a significant drop in accuracy compared to forward reasoning, the Related Paper emphasizes improvements in reasoning through diverse sampling and consistency checks. This suggests that the approaches to enhancing LLM capabilities differ fundamentally, with the Related Paper advocating for a method that builds on existing forward reasoning techniques rather than addressing backward reasoning directly.","paper_id":"5f19ae1135a9500940978104ec15a5b8751bc7d2","title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models","abstract":"Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and ARC-challenge (+3.9%).","score":0.3668587803840637,"polarity":"negative","source":"citations","contexts":[{"sentence":"Iterative prompting techniques like \\citep{SelfConsistency} do not use a verifier; instead, they sample multiple hypotheses from the model and select the answer using majority voting.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper contrasts the Main Paper by focusing on the calibration of language models (LMs) in question answering, highlighting that LMs often fail to provide accurate answers despite their capabilities. While the Main Paper emphasizes enhancing backward reasoning in LLMs for math word problems, the Related Paper critiques the reliability of LMs' confidence in their answers, showing that their predicted probabilities do not correlate well with actual correctness. This suggests that improvements in backward reasoning may not address underlying issues of model reliability and calibration.","paper_id":"33422275fbb9958f55419620697faf531482699b","title":"How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering","abstract":"Abstract Recent works have shown that language models (LM) capture different types of knowledge regarding facts or common sense. However, because no model is perfect, they still fail to provide appropriate answers in many cases. In this paper, we ask the question, “How can we know when language models know, with confidence, the answer to a particular query?” We examine this question from the point of view of calibration, the property of a probabilistic model’s predicted probabilities actually being well correlated with the probabilities of correctness. We examine three strong generative models—T5, BART, and GPT-2—and study whether their probabilities on QA tasks are well calibrated, finding the answer is a relatively emphatic no. We then examine methods to calibrate such models to make their confidence scores correlate better with the likelihood of correctness through fine-tuning, post-hoc probability modification, or adjustment of the predicted outputs or inputs. Experiments on a diverse range of datasets demonstrate the effectiveness of our methods. We also perform analysis to study the strengths and limitations of these methods, shedding light on further improvements that may be made in methods for calibrating LMs. We have released the code at https://github.com/jzbjyb/lm-calibration.","score":0.3339669704437256,"polarity":"negative","source":"citations","contexts":[{"sentence":"Note that we could also use the verifier's internal model to estimate MATH_PLACEHOLDER , % provided by the verifier internal model, but this may not be well calibrated~\\citep{jiang2021can, zhao2021calibrate}, i.e., the model's probability estimates may not","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper contrasts the Main Paper by highlighting the instability of few-shot learning in language models, suggesting that the performance of LLMs can vary significantly based on prompt format and example order, which is not addressed in the Main Paper's focus on backward reasoning. While the Main Paper emphasizes enhancing backward reasoning capabilities through specific techniques and ensemble methods, the Related Paper points out that the inherent biases in LLMs can lead to unpredictable outcomes, thus questioning the reliability of the improvements claimed in the Main Paper.","paper_id":"56fa0b9cba4d9aee5ccc327365b3b3a721031c69","title":"Calibrate Before Use: Improving Few-Shot Performance of Language Models","abstract":"GPT-3 can perform numerous tasks when provided a natural language prompt that contains a few training examples. We show that this type of few-shot learning can be unstable: the choice of prompt format, training examples, and even the order of the training examples can cause accuracy to vary from near chance to near state-of-the-art. We demonstrate that this instability arises from the bias of language models towards predicting certain answers, e.g., those that are placed near the end of the prompt or are common in the pre-training data. To mitigate this, we first estimate the model's bias towards each answer by asking for its prediction when given the training prompt and a content-free test input such as \"N/A\". We then fit calibration parameters that cause the prediction for this input to be uniform across answers. On a diverse set of tasks, this contextual calibration procedure substantially improves GPT-3 and GPT-2's average accuracy (up to 30.0% absolute) and reduces variance across different choices of the prompt.","score":0.21506938338279724,"polarity":"negative","source":"citations","contexts":[{"sentence":"Note that we could also use the verifier's internal model to estimate MATH_PLACEHOLDER , % provided by the verifier internal model, but this may not be well calibrated~\\citep{jiang2021can, zhao2021calibrate}, i.e., the model's probability estimates may not","polarity":"negative"}],"background":null,"target":null}],"paper":{"title":"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems","abstract":"While forward reasoning (i.e., find the answer given the question) has been explored extensively in the recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information? \n\nIn this paper, we formally define the backward reasoning task on math word problems and modify three datasets to evaluate this task: GSM8k, SVAMP and MultiArith. Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa). Utilizing the specific format of this task, we propose three novel techniques that improve performance: Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps. Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over these base methods aided by a verifier to further boost the accuracy by a significant margin. Extensive experimentation demonstrates that our techniques successively improve the performance of LLMs on the backward reasoning task, with the final ensemble-based method resulting in a substantial performance gain compared to the raw LLMs with standard prompting techniques such as chain-of-thought.","authors":["Aniruddha Deb","Neeva Hareshbhai Oza","Sarthak Singla","Dinesh Khandelwal","Dinesh Garg","Parag Singla"],"sections":[{"heading":"Introduction","text":"# Introduction\n\nLarge language models (LLMs) [@GPT3; @GPT4; @Palm2] have shown remarkable versatility, excelling in various tasks like sentence completion, question answering, and summarization. They have been successfully applied to mathematical reasoning, specifically in solving *Math Word Problems* (MWPs)  [@kushman2014learning; @roy2018mapping], where the goal is to produce the answer given an elementary school-level mathematics question. We refer to this task as *Forward Reasoning*. This problem has received significant attention in the recent literature [@lu2022survey], and specific datasets [@GSM8k; @MultiArith; @SVAMP] have been proposed as a benchmark for this task. The performance of powerful LLMs such as GPT-4 [@GPT4] with techniques such as Chain-of-Thought [@CoT] and Self-Verification [@CodeSelfVerify] on some of these datasets is more than $90\\%$ [@lu2022survey].\n\nWe would like to solve a slightly different problem: given an MWP, with one of the numerical quantities omitted from the question, and the answer to the original question, what is the value of the omitted numerical quantity? Yu et al.  refer to this as the problem of *Backward Reasoning Problem*, and we would like to examine how effective are LLMs on this task. While this problem of backward reasoning has been studied in the literature in the context of improving the performance of forward reasoning [@SelfVerify], to the best of our knowledge, there is no existing work that explicitly aims to solve this problem analyzing its hardness and providing solutions thereof. We believe this is an interesting problem because (1) It is a matter of study that even for humans, whether forward reasoning and backward reasoning have different complexities [@ramful2008reversibility; @rivera2008pitfalls], and we would like to ask the same question in the context of LLMs (2) Assuming we establish that backward reasoning is a harder problem, how can we design techniques to improve performance on this task, that specifically exploit the problem structure of backward reasoning and the availability of the forward direction answer? (3) The backward reasoning problem can be seen as a special case of abduction, with a unique answer, and it is interesting to explore this connection since LLMs have not been explored as much for this important class of abductive reasoning problems [@ACR; @DeLorean; @COLD]. (4) Enhancing the backward reasoning capabilities of large language models (LLMs) can be highly beneficial in domains such as automated theorem proving [@bibel2013automated; @yang2024leandojo], where solutions are already known and where backward reasoning is essential for automatically generating mathematical proofs.\n\nAs an initial analysis, we modify existing benchmark MWP datasets for backward reasoning, and experiment with existing forward reasoning strategies. Interestingly, we observe a significant drop in the LLM accuracy across multiple datasets when working with backward reasoning (refer Table [\\[tab:model_perf\\]](#tab:model_perf){reference-type=\"ref\" reference=\"tab:model_perf\"}). We hypothesize this may be due to the specific nature of the task, which makes it harder to solve, or the lack of sufficient data that LLMs have seen during their training compared to forward reasoning.\n\nWe take three different existing forward reasoning strategies and modify them appropriately to make them work effectively for backward reasoning, resulting in (a) Rephrase, based on [@SelfVerify] (b) PAL-Tools, based on [@PAL] and [@Tools], and (c) Check your work, based on [@SelfRefine]. As our final technique, we propose a novel ensemble-based approach combining these base strategies using a Bayesian framework and making use of a *forward verifier* whose accuracy is estimated using a hold-out set. Experiments on several benchmark datasets show that we get successive performance improvement using our strategies, with the Bayesian ensemble based approach performing the best, providing 20-30% points gains compared to SOTA techniques for forward reasoning. We perform additional analysis on the models to explain our results.\n\nOur contributions can be summarized as: (1) we explicitly handle the problem of backward reasoning and identify the performance gap using existing LLM strategies for this task (2) we propose variations of three different existing forward reasoning strategies and a Bayesian ensemble based approach (3) we perform extensive experimentation to demonstrate the efficacy of our models for backward reasoning via LLMs. (4) We perform additional analysis, giving further insights into the performance of the proposed models. We publicly release our code and data[^2]."},{"heading":"Related Work","text":"# Related Work\n\nA mathematical word problem (MWP) [@lu2022survey] consists of a description in natural language that expresses the relation between various entities and quantities, followed by a query for an unknown quantity, as shown in Figure [1](#fig:techniques-overview){reference-type=\"ref\" reference=\"fig:techniques-overview\"}. One can answer the question by representing the relationship between the entities and quantities through a set of equations and then solving these equations. Solving MWPs necessitates a semantic understanding of the natural language description. Initial works [@kushman2014learning; @koncel2015parsing; @roy2018mapping] to solve MWPs involve parsing the natural language description and utilizing statistical learning techniques to identify suitable templates for generating answers. Subsequently, following the triumph of sequence-to-sequence (Seq2Seq) neural models [@sutskever2014sequence] in machine translation and other NLP tasks, the encoder-decoder framework [@wang2017deep; @ling2017program; @li2020graph; @shen2021generate; @jie2022learning] is employed to directly translate the natural language description in MWPs into equations.\n\n<figure id=\"fig:techniques-overview\">\n<div class=\"minipage\">\n<embed src=\"figures/fig1.pdf\" />\n</div>\n<figcaption>A summary of the prompting techniques we adapt</figcaption>\n</figure>\n\n**MWPs:** Recently, the strongest performance on MWPs has been given by large pre-trained language models like GPT-4 [@GPT4] and PaLM [@Palm2]. These models leverage the power of few-shot in-context examples and employ prompting methods like CoT [@CoT], all without requiring any modifications to their parameters.\n\n**Answer Verification:** One class of techniques [@SelfRefine; @SelfCorrect] using LLMs involves verifying the answer provided by the Language Model, either using the model itself or external verifiers such as compilers or proof checkers. If the answer is incorrect, the model is re-prompted, optionally with suggestions on improving its output. Other techniques, such as Progressive Hint Prompting [@PHP] iteratively pass the model's previous answers to itself as hints. Iterative prompting techniques like [@SelfConsistency] do not use a verifier; instead, they sample multiple hypotheses from the model and select the answer using majority voting.\n\n**Backward Reasoning:** Our work can be seen as a special case of abductive reasoning with a unique answer. Abductive reasoning [@ACR; @DeLorean; @COLD] involves inferring the most plausible out of the several explanations. Prior work on abductive reasoning has focused mostly on text-based reasoning under constraints. In the context of arithmetic reasoning tasks, @SelfVerify has utilized backward reasoning to enhance forward reasoning accuracy. In contrast, our work addresses backward reasoning as an independent problem. Our primary interest lies in analyzing the inherent complexities of backward reasoning and devising more effective solutions to tackle it."},{"heading":"Task Definition","text":"# Task Definition {#sec:task}\n\n::: table*\n                                GSM8k                    SVAMP               MultiArith \n  ------------------------- --------- ---------- ------------- ---------- ------------- ----------\n  2-3(lr)4-5(lr)6-7 Model     forward   backward       forward   backward       forward   backward\n  GPT-4                          92.8       38.6   90.5$^\\dag$       43.9   97.8$^\\dag$       54.8\n  GPT-3.5-turbo                  58.4       10.8          79.1       20.4          97.0       14.5\n  PaLM-2                         60.5       15.2          73.7       11.2          95.7        6.3\n  LLaMa-2-70B                    37.0        6.8          70.3       20.3          89.2       11.0\n\n[]{#tab:model_perf label=\"tab:model_perf\"}\n:::\n\nA forward or the typical Mathematical Word Problem (MWP) consists of a question text $Q_f$, which we call a forward question, and its corresponding answer $A_f$. The forward question is a textual representation of the MWP. It is typically composed of one or more sentences and encompasses various elements, including numbers, operations, and textual information, all represented by tokens within the question. A backward MWP is defined as a tuple $(Q, A_f)$, where $Q$ is obtained from the forward question $Q_f$ by replacing one numerical quantity such as $5$, $3.7$, or 'half' with a blank. The goal of solving the backward MWP is to find out the unique value of the numerical quantity that was blanked out using backward reasoning. By backward reasoning, we mean the process of using the provided answer $A_f$ and the context provided by the question $Q$ to deduce the missing numerical quantity to arrive at the given answer. Since there is a unique answer for every question, we measure accuracy on this task by the number of questions on which the model is able to provide the correct numeric value of the blank."},{"heading":"Base Strategies","text":"# Base Strategies {#sec:approaches}\n\nTable [\\[tab:model_perf\\]](#tab:model_perf){reference-type=\"ref\" reference=\"tab:model_perf\"} compares the performance of four state-of-the-art (SOTA) language models on forward and backward reasoning tasks by using the 8-shot chain of thought [@CoT] prompts. The experiments were conducted using the chain of thought prompts defined in @CoT. The few-shot examples used in the chain of thought prompts were modified for the backward reasoning task following the procedure described above. A significant drop in backward reasoning accuracy compared to forward reasoning accuracy across all models proves the difficulty of this task for LLMs. Next, we adopt three base approaches for the backward reasoning task, as described below:\n\n#### Rephrase:\n\nOur first modified SOTA method to tackle the challenging backward reasoning problem involves a problem transformation through rephrasing. This transformation effectively converts the complex backward reasoning task into a more manageable forward reasoning problem. Consequently, we employ the LLM to solve this transformed forward reasoning problem instead of the original and inherently more difficult backward reasoning challenge. Given a backward MWP $(Q, A_f)$, we ask the language model to produce a rephrased question $R$, which incorporates the forward answer $A_f$ into the question $Q$ and changes the objective of the question from finding the answer $A_f$ to finding the value of the blank. We then ask the language model to solve the rephrased problem $R$ instead of the original backward problem. The verification method used by [@SelfVerify] works similarly to this, and they use this task only to improve the accuracy of the forward reasoner. In this prompting strategy, to rephrase the question, the LLM is given in-context examples where the blank is replaced by 'x', $A_f$ is used to change the interrogative part of the question to assertive and the value of 'x' is asked to be found. We define it as *algebraic prompt* and have used this for all experiments that include rephrasing the question before solving it. (see the first part of Analysis [7](#sec:other-analysis){reference-type=\"ref\" reference=\"sec:other-analysis\"} for more details).\n\n#### PAL-Tools:\n\nWe modify the Program-aided language model (PAL) [@PAL] which writes a Python program to solve the MWP and integrate it with Tools [@Tools] which uses the techniques of framing equations in natural language and calls SymPy to solve them. Neither of the two techniques, i.e., PAL or Tools, does well independently, as shown by our experiments.\n\n#### Check your Work (CYW):\n\nInspired from the iterative prompting technique [Self-Refine]{.smallcaps} [@SelfRefine], that cycles between refinement and feedback until a stopping criteria is met, our approach has the following steps: (1) Generate the answer of $Q$ say $a$. (2) Form a forward problem obtained by substituting the blank with the obtained answer $a$. (3) Check the correctness of $a$ by checking whether the answer to the forward problem matches with the gold answer $A_f$. We repeat this if $a$ is found to be incorrect. Comparing Self-Refine (that we modified to solve the backward task) with Check your Work, Self-Refine uses the LLM's assessment on the backward task as a stopping criteria, whereas in Check your Work, we use the easier problem of forward verification, for deciding when to stop (ref. Appendix [13](#sec:prompts){reference-type=\"ref\" reference=\"sec:prompts\"} for prompts).\n\n::: {#tab:base-methods}\n  Strategy           Shots   GSM8k$_\\text{B}$   SVAMP$_\\text{B}$   MultiArith$_\\text{B}$\n  ----------------- ------- ------------------ ------------------ -----------------------\n  CoT                  8          10.77              20.40                 14.50\n  PAL                  4           9.27              20.90                 18.17\n  Tools                3          31.45              43.50                 71.83\n  PAL-Tools            4          37.11              42.70                 80.50\n  CoT (R)              8          36.12              37.80                 71.67\n  PAL (R)              4          21.38               37.0                 55.50\n  Tools (R)            3          41.43               48.5                 73.00\n  Self-Refine (R)      2          40.17              49.70                 77.50\n  CYW (R)              8          41.82              47.40               **84.83**\n  PAL-Tools (R)        4        **48.74**          **51.10**               84.50\n\n  : Performance of base strategies. LLM is GPT-3.5-Turbo. R: Rephrase. CYW: Check Your Work\n:::\n\n[]{#tab:base-methods label=\"tab:base-methods\"}"},{"heading":"A Novel Approach of Ensembling","text":"# A Novel Approach of Ensembling\n\nWe propose a way of ensembling these methods as illustrated by an example in Figure [2](#fig:ensemble-overview){reference-type=\"ref\" reference=\"fig:ensemble-overview\"}. Assume that we are given a set of models $\\{M_1,M_2,\\cdots,M_k\\}$. Given a model $M_i$, we run the model $M_i$ on the question $Q$ $r$ times, to get a multi-set of answers $\\{A_{ij}\\}_{j=1}^{r}$. For each unique answer $A$ in this multi-set, we want to estimate the probability of it being correct. We do so by using an LLM as a verifier $V$ in the forward direction, i.e., by substituting the answer in the original question in place of the missing numerical quantity; and solving the forward problem. Given a question $Q$ and an answer $A$, $V$ gives a Boolean output $Z$, which is equal to $1$ if $A$ is the correct answer to the question according to the verifier, and $0$ otherwise. If $A^{*}$ is the gold answer to $Q$, we want the probability of $A$ being correct conditioned on the output of the verifier. From Bayes' rule,\n\n$$P(A = A^*\\ |\\ Z, Q) = \\frac{X}{X + Y} \\label{eq:final}$$ where $X$ and $Y$ are defined as follows: $$\\begin{aligned}\n    X &= {P(Z\\ |\\ A = A^*, Q)\\ P(A = A^*\\ |\\ Q)}\\\\\n    Y &=  P(Z\\ |\\ A \\neq A^*, Q)\\ P(A \\neq A^*\\ |\\ Q)\n\\end{aligned}$$\n\nWe compute the prior $P(A = A^*\\ |\\ Q)$ as the fraction of times $A$ appears as the answers in the union of the multiset of answers produced by each model for the question $Q:P(A = A^*\\ |\\ Q)=\\sum_{i,j} \\mathbbm{1}[A_{ij} \\mkern 1.5mu{=}\\mkern 1.5mua]/kr$.\n\nNow, let $P(Z\\ |\\ A \\mkern 1.5mu{=}\\mkern 1.5muA^*, Q)$ denote the distribution over $V$'s outputs when $A \\mkern 1.5mu{=}\\mkern 1.5muA^*$. Similarly, let $P(Z\\ |\\ A \\mkern 1.5mu{\\ne}\\mkern 1.5muA^*, Q)$ denote the distribution over $V$'s outputs when $A \\mkern 1.5mu{\\ne}\\mkern 1.5muA^*$. We estimate these distributions by computing the accuracy of the verifier on the holdout set $S'$, and supplying a set of answers produced by the $k$ models, each run $r$ times on each $Q \\in S'$, along with the gold answer. Thus, we obtain values for Equation ([\\[eq:final\\]](#eq:final){reference-type=\"ref\" reference=\"eq:final\"}) and select the answer having the highest probability.\n\n![An illustrative example of how the ensembling of base models works together with a verifier.](figures/fig2_final.pdf){#fig:ensemble-overview width=\"\\\\textwidth\"}\n\n![Overlap between problems in GSM8k$_\\text{B}$ that different base techniques can solve](figures/venn.pdf){#fig:ana-venn width=\"\\\\columnwidth\"}\n\nNote that we could also use the verifier's internal model to estimate $P(Z\\ |\\ A \\mkern 1.5mu{=}\\mkern 1.5muA^*, Q)$, but this may not be well calibrated [@jiang2021can; @zhao2021calibrate], i.e., the model's probability estimates may not accurately reflect the true likelihood of the answer being correct. Therefore, we instead use a holdout set to estimate these probabilities."},{"heading":"Experiments","text":"# Experiments\n\n## Setup\n\nWe start with three forward reasoning datasets: GSM8k [@GSM8k], MultiArith [@MultiArith], and SVAMP [@SVAMP], and transform the examples in these datasets into backward tasks, resulting in the creation of three modified datasets: GSM8k$_\\text{B}$, SVAMP$_\\text{B}$, and MultiArith$_\\text{B}$ (ref. Appendix [11](#sec:dataset){reference-type=\"ref\" reference=\"sec:dataset\"} for modification details). We have experimented with four SOTA LLMs: GPT-4, GPT-3.5-Turbo [@GPT4], PaLM-2 [@Palm2] and LLaMa-2 [@LLaMa2]. Further details are in Appendix [12](#sec:exp-details){reference-type=\"ref\" reference=\"sec:exp-details\"}. Prompts and in-context examples for the prompting techniques are taken from their original works. The in-context examples are modified for the backward setting as discussed in Section [4](#sec:approaches){reference-type=\"ref\" reference=\"sec:approaches\"}. Examples of the prompts used are given in Appendix [13](#sec:prompts){reference-type=\"ref\" reference=\"sec:prompts\"}.\n\n## Results of Base Strategies\n\nTable [1](#tab:base-methods){reference-type=\"ref\" reference=\"tab:base-methods\"} presents the results comparing standard forward reasoning strategies, with their variants that we introduced for backward reasoning [^3]. Surprisingly, PAL does quite badly on this task, likely because the LLM is not able to construct good programs for the backward reasoning task. For rephrasing, we find that models perform better when the rephrased problem has the blank replaced with $x$ compared to the baseline prompt. This is because the relationship between the missing value and the equations that models need to frame in order to solve the forward problem is explicit. Also, for the baseline prompt, the model requires inferring the relationship between the forward answer and the equations they need to frame to obtain it, which may introduce ambiguity and reduce accuracy. We see that Rephrase also helps the other standard techniques in all cases, and we use that along with our remaining models.\n\nCYW does better than Self-Refine on two of the datasets, gaining significantly on MultiArith$_\\text{B}$. This points to the efficacy of using LLM as a forward verifier. The best-performing model is PAL+Tools, significantly improving accuracy over both PAL and Tools when run independently. We hypothesize the combination allows the model to retain the advantages of the programmatic way of formulation, while the backward reasoning is handled effectively by calling the external solver as in Tools.\n\n::: {#tab:ensembling}\n                     GSM8k$_\\text{B}^\\dag$   SVAMP$_\\text{B}^\\dag$   MultiArith$_\\text{B}^\\dag$\n  ----------------- ----------------------- ----------------------- ----------------------------\n  CoT (R)                    35.67                   37.78                     69.60\n  Tools (R)                  41.81                   48.11                     72.00\n  PAL-Tools (R)              48.55                   45.00                     81.50\n  Majority Voting            58.28                   59.07                     92.00\n  Ensemble                 **65.33**               **66.67**                 **92.60**\n\n  : Ensembling results. LLM: GPT-3.5-Turbo\n:::\n\n[]{#tab:ensembling label=\"tab:ensembling\"}\n\n## Ensembling\n\nThe models we included in the ensemble are rephrased versions of three of our strongest single-prompt models: CoT, Tools, and PAL-Tools. We use a temperature of $0.5$ for sampling to generate $3$ answers per question with each model. With $3$ different models, we generate a total of $9$ answers per question. The verifier is the LLM used in each of these base strategies. We select $100$ examples from the datasets as holdout sets to compute an estimate of the verifier accuracy. We evaluate all the models on the non-holdout set, which is denoted with a $^\\dag$ symbol in Table [2](#tab:ensembling){reference-type=\"ref\" reference=\"tab:ensembling\"} to show the results. Clearly, we see that our ensembling technique results in significant gains ($10$-$20\\%$) on all the datasets, compared to the best-performing PAL-Tools which is the best-performing base model (ref. Table [1](#tab:base-methods){reference-type=\"ref\" reference=\"tab:base-methods\"}). We also compare our ensemble-based method with plain majority voting. Our approach results in close to $7\\%$ gain compared to vanilla majority voting pointing on two of the datasets to the efficacy of our Bayesian ensembling via a forward verifier. We observe that the accuracy on backward MWP via ensembling surpasses the forward accuracy of CoT by up to $6\\%$. We also show that ensembling improves performance compared to majority voting, it shows the significance of using a verifier for selecting the correct answer compared to generating multiple answers via LLM.\n\nOn analyzing the base methods, as shown in figure [3](#fig:ana-venn){reference-type=\"ref\" reference=\"fig:ana-venn\"}, we find that there are a significant number of problems that are solved correctly by one of the models but not by others. This shows how ensembling exploits the strenghts of individual models to provide significant boost in overall performance. Ensembling exploits the fact that the task of verifying is easier for LLMs than solving the backward MWP."},{"heading":"Analysis","text":"# Analysis {#sec:other-analysis}\n\n:::::::: description\nSince rephrasing is a strategy that can be applied across multiple techniques, we analyze the extent of accuracy gains obtained via rephrasing by applying it independently to the base techniques: CoT, PAL, and Tools. The results are shown in Table [1](#tab:base-methods){reference-type=\"ref\" reference=\"tab:base-methods\"}. Rephrasing improves the accuracy of every technique that it is applied to. We see larger gains with rephrasing in weaker methods, such as CoT. We also see that rephrasing has higher gains in datasets where the problems are harder, such as in GSM8k compared to SVAMP. We also tried to check whether the nature of the prompt affected the performance of rephrasing. We tried using a prompt where unlike the *algebraic prompt*, instead of introducing an 'x' and asking to find its value, we gave in-context examples that convert the problem to be worded similar to a forward reasoning task MWP. We call this a *linguistic prompt* In the experiment of table [\\[tab:rephrasing\\]](#tab:rephrasing){reference-type=\"ref\" reference=\"tab:rephrasing\"}, we show how our specific prompts improve the performance of CoT. And we demonstrate the advantage of explicitly naming the value to be found as 'x'.\n\n::: {#tab:rephrase-versions}\n  Strategy   Shots    GSM8k$_\\text{B}$   SVAMP$_\\text{B}$   MultiArith$_\\text{B}$  \n  ---------- ------- ------------------ ------------------ ----------------------- --\n  CoT        8             10.77              20.40                 14.50          \n  CoT (LR)   8             19.65              32.60                 40.50          \n  CoT (AR)   8             36.12              37.80                 71.67          \n\n  : Improvements in accuracy with rephrasing strategies. LP: Linguistic prompt rephrase. AP: Algebraic prompt rephrase\n:::\n\n[]{#tab:rephrase-versions label=\"tab:rephrase-versions\"}\n\nIn the third step of the ensembling method, we try to verify whether the blank provided is correct by solving the resulting forward problem after substituting the blank. There are two settings in which we can verify this: 1) We ask the model to solve this new question and compare whether the answer obtained is the same as the original answer $a$. 2) We give the original answer $a$ to the model and ask it to check whether it is the answer obtained for the new question.\n\nTo find which method is better at correctly verifying the blank, we check the accuracy of GPT-3.5-turbo on GSM8k in setting 2. In the first pass, we provide the correct blank and in the second pass, we provide an incorrect blank formed by multiplying $z \\in \\{2 \\ldots 10\\}$ with the correct blank. The confusion matrix obtained is shown in Table [\\[tab:verif_conf_mat\\]](#tab:verif_conf_mat){reference-type=\"ref\" reference=\"tab:verif_conf_mat\"}. It is observed that the accuracy of setting 2 is higher than the forward reasoning accuracy of GPT-3.5-turbo. Hence, we use that as the verification method for ensembling.\n\n:::: minipage\n::: {#fig:pal_tools_2_vs_4}\n                    model \n  ------------ ---------- ----------\n  2-3 actual     positive   negative\n  positive          75.94      24.05\n  negative           7.39      92.61\n\n  : Relative performance increase rephrasing brings to PAL-tools when 4 shots are used compared to 2.\n:::\n::::\n\n::: minipage\n![image](figures/pal_tools_2_vs_4.pdf){width=\"\\\\columnwidth\"}\n:::\n\nWe compare the accuracies obtained by using majority voting with and without the verifier. We find that using a verifier improves the accuracy on GSM8k$_\\text{B}^\\dag$ and SVAMP$_\\text{B}^\\dag$ by 7% and on MultiArith$_\\text{B}^\\dag$ by 0.6%. Since the verifier has a higher accuracy than any of the models we consider, its inclusion inevitably increases the accuracy of any set of methods we choose. Even if we use a noisy verifier, updating our priors based on its results using Bayes' rule ensures that the priors are not changed significantly.\n\nLet prompts $M_1, M_2, M_3$ be able to solve problems $\\mathcal{D}_1, \\mathcal{D}_2, \\mathcal{D}_3$ respectively, where $\\mathcal{D}_i \\subseteq D$. If we choose to ensemble these prompts together, then $|\\bigcup_j \\mathcal{D}_j| > |\\mathcal{D}_i|$ for the ensemble to do better. Figure [3](#fig:ana-venn){reference-type=\"ref\" reference=\"fig:ana-venn\"} gives an overview of the subsets of GSM8k that the three prompts, namely Rephrased Chain of Thought, Rephrased PAL-Tools, and Rephrased Tools can solve in a single try. We see that even though there is significant overlap between the prompts, the probability of any one of them giving the right answer is $66.9\\%$, provided we sample from each prompt once. The Venn diagram also shows the subsets of problems different prompts cover are quite disjoint in nature. No prompt can solve all the problems that another prompt can solve.\n\nThere may be cases where the blank does not directly contribute to the answer or is irrelevant. In such a case, inferring the value of the blank is not possible given the answer. Even though [@GSM8k] claim that less than two percent of problems have breaking errors, We sample 50 random examples from GSM8k$_\\text{B}$that our strongest model solves incorrectly and find that no such problems in the sample we analyse, leading us to believe that the probability of such problems existing in our dataset is little to none.\n\nIn the 50 examples we analyse above, there are 10 examples where the value of the blank can be obtained simply from reading the question, as the question makes implicit assumptions or provides further information that can be used to fill in the blank. Two examples are presented in table [5](#fig:bad_examples){reference-type=\"ref\" reference=\"fig:bad_examples\"}. It is surprising that even our strongest model is unable to find the answer to such questions, either as a consequence of its poor reasoning abilities or because we make the dependency between requiring the answer to fill in the blank explicit.\n\n::: {#fig:bad_examples}\n  Carla just gave birth to identical octuplets. She dresses 3/4 of them in purple and \\_\\_\\_\\_\\_ in blue. If all the blue wearers and 1/3 of the purple wearers also wear bows, what is the percentage chance a baby wearing a bow is wearing purple?\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n  Ian has a board that is 40 feet long. He decides to make a cut so he can have \\_\\_\\_\\_\\_ pieces. The longer piece is 4 times longer than the shorter piece. How long is the longer piece?\n\n  :  Examples of questions in GSM8k$_\\text{B}$ that don't require the answer to find the value of the blank\n:::\n\n[]{#fig:bad_examples label=\"fig:bad_examples\"}\n::::::::"},{"heading":"Going beyond masking of a single numeric quantity","text":"# Going beyond masking of a single numeric quantity {#sec:phrase-mask}\n\nAs a preliminary study, we aim to extend the task by forming tuples $(Q, A_f)$ by masking a phrase instead of a numeric quantity. A phrase is defined as the contiguous set of words between two connectives such as \\['and', ',' , '.'\\], and from the forward question $Q_f$, we replace the phrase containing the second occurrence of any numeric quantity with a blank. This choice is made to make the task similar to abductive reasoning [@ACR; @DeLorean; @COLD] for story completion . We define this as a phrase-masked backward reasoning task. Note that in this setting, there can be multiple correct answers, which may differ from the originally masked phrase. To verify the correctness of the generated phrases, the task requires hand-evaluation of the results produced by various techniques.\n\nAs a baseline, we prompt the LLM to fill in the masked phrase given the rest of the question and the final answer to the original question using CoT. We observed experimentally that asking LLM to divide the task to first guessing the missing phrase with an 'x' in it and then solving it similar to a single numeric quantity masked backward reasoning task, performed better than finding the entire phrase altogether. We modified our methods to include a prior step to guess in this manner. For the hand-evaluation of the method, we replace the blank phrase in $Q$ with the predicted phrase and replace the value of 'x' in it with the value generated by the respective method. We then manually solve the resulting question and if its answer is the same as $A_f$, we mark that generation as correct. We performed the experiments on a $100$-sized subset of the GSM8k dataset. We used GPT-3.5-Turbo with the same experimental setup as before. As it can be seen in table [6](#tab:phrase-masked){reference-type=\"ref\" reference=\"tab:phrase-masked\"}, our methods improve performance for this extension of the task.\n\n::: {#tab:phrase-masked}\n  Strategy               Shots  Accuracy\n  --------------------- ------- -----------\n  CoT                      8    22\n  Check Your Work          8    27\n  CoT Rephrase             8    37\n  Rephrased Tools          3    34\n  Rephrased PAL-Tools      4    38\n  Ensembling              \\*    **61.16**\n\n  : Performance on 100 examples for phrase-masked backward reasoning task. Note: The accuracy of CoT on the forward task of these 100 examples is 80%. Ensembling uses 3 rephrased methods: CoT, Tools, and PAL-Tools \\*The number of shots for each strategy used in ensembling matches the number used when the strategy is applied individually.\n:::\n\n[]{#tab:phrase-masked label=\"tab:phrase-masked\"}\n\n::::: description\nAs the multiset of answers for ensembling consists of phrases instead of numbers, almost all answers have minor differences in wording, capitalization, etc. Thus, as we use exact phrase matching to count the frequency of an answer, even semantically identical answers get counted as different. Additionally, the probability of the verifier giving output $1$ for a correct answer is independent of the question and answer. When these factors are applied in Equation [\\[eq:final\\]](#eq:final){reference-type=\"ref\" reference=\"eq:final\"}, they result in a set $S_m$ where each answer marked as correct by the verifier, has an equal probability of being correct. This differs from number masking, where typically only a single answer has the highest probability of being correct. Therefore, we hand-evaluate all the answers in $S_m$, and use the fraction of correct answers in $S_m$ as the probability that an answer sampled from $S_m$ is correct.\n\nOn analyzing, we found that for a few generations, the predicted phrase trivially requires the LLM to directly guess the quantity $A_f$ as 'x' and then it solves for 'x' (for now, we have marked it correct in our evaluation); thus making it technically correct without actually solving the backward reasoning task. An example of such generation is depicted in table [7](#tab:trivial_phrase){reference-type=\"ref\" reference=\"tab:trivial_phrase\"}. Tricky MWPs include questions with extra information, which creates a spectrum depending on how many lines of questions are needed to find the answer. The phrases generated by the LLM achieve their goal but may simplify MWPs to be solved with just one line of information. Table [8](#tab:number_trivial_phrase){reference-type=\"ref\" reference=\"tab:number_trivial_phrase\"} shows the counts of such correctly generated phrases. For Ensembling, in case of multiple correct answers, we report the fraction of answers that are trivially correct as described above. We will try other methods in the future to improve on this aspect.\n\n::: {#tab:trivial_phrase}\n  ---------------------------------------------------------------------------------------------------------------------------\n  **Phrase-masked question:**\n  $Q$: A football team played 22 games. \\_\\_\\_\\_\\_. How many did they win?\n  $A_f$: 15\n  **The phrase that was masked:**\n  They won 8 more than they lost\n  **LLM generation (by CoT rephrase method):**\n  Guess: They won x games\n  Rephrased: A football team played 22 games. They won x games. They won 15 games. Find the value of x.\n  Answer: The football team played 22 games. If they won x games, then they won x out of 22 games. So the answer is x = 15.\n  **Phrase that was finally extracted from LLM:**\n  They won 15 games\n  ---------------------------------------------------------------------------------------------------------------------------\n\n  : Example of an LLM generation that frames the phrase as a guess of $A_f$\n:::\n\n[]{#tab:trivial_phrase label=\"tab:trivial_phrase\"}\n\n::: {#tab:number_trivial_phrase}\n  Strategy                Number of questions\n  --------------------- ---------------------\n  CoT                                   14.00\n  Check Your Work                        9.00\n  CoT Rephrase                           6.00\n  Rephrased Tools                        2.00\n  Rephrased PAL-Tools                    1.00\n  Ensembling                             5.28\n\n  : Number of questions in the 100-sized subset that are like the example in table [7](#tab:trivial_phrase){reference-type=\"ref\" reference=\"tab:trivial_phrase\"}.\n:::\n\n[]{#tab:number_trivial_phrase label=\"tab:number_trivial_phrase\"}\n:::::"},{"heading":"Conclusion and Future Work","text":"# Conclusion and Future Work\n\nWe consider the problem of backward reasoning in MWPs. We show that existing forward reasoning strategies do not work well off-the-shelf for the forward problem, and propose 3 different variations of existing techniques for the backward task. We also propose a novel Bayesian ensemble based approach to further improve the accuracy. Experiments demonstrate the efficacy of our approach compared to forward reasoning strategies. Finally, we analyze the fallacies and pitfalls of each of these techniques and show areas for future improvements. Our method of Bayesian ensembling can also be extended to other tasks of backward reasoning. If there is a setting where the verification or the forward reasoning task is easier compared to the backward, and there is an existing set of methods to solve the backward task in different ways; our method can potentially be used in such settings. Our future work includes extending our technique to other backward reasoning datasets, including those derived from explicit abductive reasoning tasks."},{"heading":"Limitations","text":"# Limitations\n\nLimitations of our approach include (a) It has only been tested on the MWPs. (b) It requires a (small) hold-out set to estimate the accuracy of the verifier in the ensemble."},{"heading":"Acknowledgements","text":"# Acknowledgements {#acknowledgements .unnumbered}\n\nThis work was supported by an IBM AI Horizons Network (AIHN) grant and IBM SUR Awards. We thank IIT Delhi HPC facility[^4], IBM cloud facility, and IBM Cognitive Computing Cluster (CCC) for computational resources. We thank anonymous reviewers for their insightful comments that helped in further improving our paper. Any opinions, findings, conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views or official policies, either expressed or implied, of the funding agencies."},{"heading":"Dataset","text":"# Dataset {#sec:dataset}\n\nWe consider three datasets of interest: GSM8K [@GSM8k], MultiArith [@MultiArith], and SVAMP [@SVAMP]. All these datasets consist of grade-school arithmetic word problems along with their answers.\n\n## Generation Methodology\n\nGiven a source forward dataset $$D = \\{ (Q_i, A_i)_{i=1}^n\\ |\\ Q_i \\in \\Sigma^*, A_i \\in \\mathbb{R} \\}$$ we present a method to create a backward dataset $$\\begin{aligned}\nD'_k &= \\{ (Q_i', A_i, (B_i^0, \\ldots, B_i^k))_{i=1}^{n} \\ | \\ Q'_i \\in \\Sigma^*, A_i, B_i^j \\in \\mathbb{R} \\}\n\\end{aligned}$$ To convert $Q_i$ (Source question) to $Q_i'$ (blanked out question) and extract blanks $B_i^0 \\ldots B_i^k$, we split $Q_i$ into its constituent tokens based on a delimiter, usually space. We then consider all numeric tokens, which are defined as tokens that encode a number. Numeric tokens may be alphanumeric, such as \\$42, 80% or 3.14, or they may be alphabetic, such as three, twice, or half. Using this heuristic for numeric tokens, we ignore the first numeric token and extract the next $k$ tokens sequentially. If we are unable to extract $k$ tokens, then we skip that question and answer pair. It is worth noting that for the datasets we use, $k = 1$, that is we only consider the problem of backwardly inferring one missing number in the question, given the answer. Solving the $n > 1$ case would require first checking if a unique solution exists and is a topic for future work.\n\nThe reason we choose to blank out only numeric tokens rather than an entire phrase or sentence is to make the task of validation easier. An alternative that was explored was phrase masking. However, phrase masking would lead to generations that would not be verifiable with perfect accuracy, and multiple possible generations for each question. The benefit of number masking is that quantities can be compared to each other without loss of accuracy, and every question-answer pair has a unique blank.\n\n## Generation Results\n\nUsing the above method, we were able to convert 1272 of the 1319 question and answer pairs in GSM8k to backward reasoning problems, and all 1000 and 600 pairs in SVAMP and MultiArith respectively. All of these are obtained from the respective test splits of the original datasets.\n\n## Dataset Examples\n\nSome examples of the datasets under consideration are shown in Table [9](#tab:dataset_examples){reference-type=\"ref\" reference=\"tab:dataset_examples\"}. Note that for GSM8k, the original dataset contains 1319 sample problems but our dataset generation method for the backward task filters out 47 of them. For comparability with the backward task, we have used the 1272 common examples of this dataset.\n\n::: {#tab:dataset_examples}\n  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n  Dataset                 *N*    Example\n  ----------------------- ------ ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n  GSM8k                   1272   Kylar went to the store to buy glasses for his new apartment. One glass costs \\$5, but every second glass costs only 60% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?\n\n  GSM8k$_\\text{B}$        1272   Q : Kylar went to the store to buy glasses for his new apartment. One glass costs \\$5, but every second glass costs only \\_\\_\\_\\_\\_% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?\n\n                                 A : 64\n\n  SVAMP                   1000   28 children were riding on the bus. At the bus stop 82 children got on the bus while some got off the bus. Then there were 30 children altogether on the bus. How many more children got on the bus than those that got off?\n\n  SVAMP$_\\text{B}$        1000   Q : 28 children were riding on the bus. At the bus stop, \\_\\_\\_\\_\\_ children got on the bus while some got off the bus. Then there were 30 children altogether on the bus. How many more children got on the bus than those that got off?\\\"\n\n                                 A : 2\n\n  MultiArith              600    Lana picked 36 tulips and 37 roses to make flower bouquets. If she only used 70 of the flowers though, how many extra flowers did Lana pick?\n\n  MultiArith$_\\text{B}$   600    Q : Lana picked 36 tulips and \\_\\_\\_\\_\\_ roses to make flower bouquets. If she only used 70 of the flowers though, how many extra flowers did Lana pick?\n\n                                 A : 3\n  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\n  : Sample questions from the datasets we consider\n:::"},{"heading":"Experiment Reproducibility Details","text":"# Experiment Reproducibility Details {#sec:exp-details}\n\nFor all experiments involving closed-source LLMs, (i.e. GPT-4, GPT-3.5-turbo, and PaLM-2), we utilized the respective model APIs (OpenAI, Google Bard). For experiments using LLaMa-2, we use the 70-billion-parameter model quantized to 4-bit using GPTQ [@GPTQ]. Inference was performed on two 40GB NVIDIA A100 GPUs, on a High Performance Computing cluster node with 8 cores and 16 GB of RAM allocated to the job. For all models, the temperature was set to 0.5 and the maximum number of tokens to generate was limited to 1024. In all the tables showing results, the accuracy values are obtained by taking the mean across all examples of the dataset, *in a single run of the mentioned method*."},{"heading":"Prompts","text":"# Prompts {#sec:prompts}\n\nWe construct prompts by changing the original examples of the papers we consider to solve the backward task. We show one to two in-context examples of each prompt. The remaining examples may be seen in our code.\n\n<figure id=\"prompt:rephrase-linguistic\">\n<div class=\"minipage\">\n<pre><code>Rephrase the given blanked question and answer pairs and then find the solution to the rephrased question. Give your answer as either a number or a decimal (no fractions). Follow the format specified in the examples below:\n\nQ: There are 15 trees in the grove. Grove workers will plant _____ trees in the grove today. After they are done, how many trees would be there?\nA: 21 \nRephrased: There are 15 trees in the grove. Grove workers will plant some trees in the grove today. After they are done, there would be 21 trees. Find the number of trees planted.\nAnswer: There are 15 trees originally, Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6 trees. The answer is 6.\n\nQ: If there are 3 cars in the parking lot and _____ more cars arrive, how many cars are in the parking lot?\nA: 5\nRephrased: If there are 3 cars in the parking lot and some more cars arrive, there are 5 cars in the parking lot. Find the number of cars that arrived.\nAnswer: There are originally 3 cars. There are 5 cars after some more cars arrive. 5 - 3 = 2, so 2 cars arrived. The answer is 2.\n\n...\n\nQ: {{question}}\nA: {{answer}}\nRephrased:\n</code></pre>\n</div>\n<figcaption>Rephrasing with Linguistic prompt</figcaption>\n</figure>\n\n<figure id=\"prompt:rephrase\">\n<div class=\"minipage\">\n<pre><code>Rephrase the given blanked question and answer pairs and then find the solution to the rephrased question. Give your answer as either a number or a decimal (no fractions). Follow the format specified in the examples below:\n\nQ: There are 15 trees in the grove. Grove workers will plant _____ trees in the grove today. After they are done, how many trees would be there?\nA: 21 \nRephrased: There are 15 trees in the grove. Grove workers will plant x trees in the grove today. After they are done, there would be 21 trees. Find the value of x.\nAnswer: There are 15 trees originally, Then there were 21 trees after some more were planted. So there must have been x = 21 - 15 = 6 trees. The answer is 6.\n\nQ: If there are 3 cars in the parking lot and _____ more cars arrive, how many cars are in the parking lot?\nA: 5\nRephrased: If there are 3 cars in the parking lot and x more cars arrive, there are 5 cars in the parking lot. Find the value of x.\nAnswer: There are originally 3 cars. x more cars arrive. 3 + x = 5, so x = 5 - 3 = 2. The answer is 2.\n\n...\n\nQ: {{question}}\nA: {{answer}}\nRephrased:\n</code></pre>\n</div>\n<figcaption>Rephrasing with Algebraic prompt</figcaption>\n</figure>\n\n<figure id=\"prompt:Tools\">\n<div class=\"minipage\">\n<pre><code>You are given a math question with a blank value and an answer. Solve it step b step to find the value of blank. Strictly follow the format given in the examples below.\n\nQuestion: Ben has four boxes with ten basketball cards in each box. Ben received ______ cards from his mother. If he gives 58 cards to his classmates, how many cards does he has left?\nAnswer: 22\n\nPeano solution:\n\n\nLet a be number of boxes [[var a]]. We have [[eq a = 4]].\nLet b be number of cards in each box [[var b]]. We have [[eq b = 10]].\nLet c be number of cards Ben initially has [[var c]]. We have [[eq c = a * b]].\nLet d be cards received from mother [[var d]].\nLet e be cards given to classmates [[var e]]. We have [[eq e = 58]].\nLet f be cards left [[var f]]. From given Answer, we have [[eq f = 22]]. \nWe have [[eq d = f + e - c]]\nThe answer is the value of d [[answer d]].\n\n\n\n\nQuestion: Natalia sold _____ clips to her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\nAnswer: 72\n\nPeano solution:\n\n\nLet a be number of clips Natalia sold in April [[var a]].\nSo number of clips Natalia sold in May are half of a.\nLet b be number of clips sold altogether [[var b]]. From given Answer, we have [[eq b = 72]].\nWe have [[eq a = b / (1 + 1/2)]]\nThe answer is the value of a [[answer a]].\n\n...\n\nQ: {{question}}\nA: {{answer}}\n\nPeano solution:\n</code></pre>\n</div>\n<figcaption>Tools</figcaption>\n</figure>\n\n<figure id=\"prompt:rephrase_tools\">\n<div class=\"minipage\">\n<pre><code>Rephrase the given blanked question and answer pairs and then solve it step b step to find the value of blank. Strictly follow the format given in the examples below.\n\nQuestion: Ben has four boxes with ten basketball cards in each box. Ben received ______ cards from his mother. If he gives 58 cards to his classmates, how many cards does he has left?\nAnswer: 22\n\nRephrased: Ben has four boxes with ten basketball cards in each box. Ben received x cards from his mother. If he gives 58 cards to his classmates, he has 22 cards left. Find the value of x.\nPeano solution:\n\n\nLet a be number of boxes [[var a]]. We have [[eq a = 4]].\nLet b be number of cards in each box [[var b]]. We have [[eq b = 10]].\nLet c be number of cards Ben initially has [[var c]]. We have [[eq c = a * b]].\nLet x be cards received from mother [[var x]].\nLet d be total cards with Ben [[var d]]. We have [[eq d = c + x]]\nLet e be cards given to classmates [[var e]]. We have [[eq e = 58]].\nLet f be cards left [[var f]]. From given Answer, we have [[eq f = 22]]. \nAs cards left are also total cards - cards given to classmates, we have [[eq f = d - e]]\nThe answer will be the value of x [[answer x]].\n\n\n\n\n\nQuestion: Natalia sold _____ clips to her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\nAnswer: 72\n\nRephrased: Natalia sold clips to x of her friends in April, and then she sold half as many clips in May. Find the value of x such that she sold a total of 72 clips altogether in April and May.\nPeano solution:\n\n\nLet x be number of clips Natalia sold in April [[var x]]\nLet a be number of clips Natalia sold in May [[var a]]. We have [[eq a = x / 2]].\nLet b be number of clips sold altogether [[var b]]. From given Answer, we have [[eq b = 72]].\nAs clips sold altogether are also the sum of clips sold in April and May, we have [[eq b = x + a ]]\nThe answer will be the value of x [[answer x]].\n\n...\n\nQ: {{question}}\nA: {{answer}}\n\nRephrased:</code></pre>\n</div>\n<figcaption>Tools with Rephrasing</figcaption>\n</figure>\n\n<figure id=\"prompt:rephrase_pal\">\n<div class=\"minipage\">\n<pre><code>Rephrase the given blanked question and answer pairs and then find the solution to the rephrased question. Write a python function that finds the value of x by solving step by step. Make sure you name your method finding_x. A few examples are given below.:\n\nQuestion: Ben has four boxes with ten basketball cards in each box. Ben received ______ cards from his mother. If he gives 58 cards to his classmates, how many cards does he has left?\nAnswer: 22\nRephrased: Ben has four boxes with ten basketball cards in each box. Ben received x cards from his mother. He gives 58 cards to his classmates. He has 22 cards left.\nProgram:\n```python\ndef finding_x():\n    num_boxes = 4\n    cards_per_box = 10\n    # cards_received_from_mother = x - This line is commented because x is unknown\n    # hence the variable cards_received_from_mother can&#39;t be used in R.H.S. of any calculation\n    cards_given_to_classmates = 58\n    cards_left = 22\n    cards_in_boxes = num_boxes * cards_per_box\n    total_cards_before_given_to_classmates = cards_given_to_classmates + cards_left\n    \n    cards_received_from_mother = total_cards_before_given_to_classmates - cards_in_boxes \n    return cards_received_from_mother\n```\n\nQuestion: Olivia has $23. She bought _____ bagels for $3 each. How much money does she have left?\nAnswer: 8 \nRephrased: Olivia has $23. She bought x bagels for $3 each. She has $8 left. Find the value of x.\nProgram:\n```python\ndef finding_x():\n    money_initial = 23\n    # num_of_bagels = x - This line is commented because x is unknown\n    # hence the variable num_of_bagels can&#39;t be used in R.H.S. of any calculation\n    bagel_cost = 3\n    money_left = 8\n    money_spent = money_initial - money_left\n    \n    num_of_bagels = money_spent / bagel_cost\n    return num_of_bagels\n```\n\nQuestion: {{question}}\nAnswer: {{answer}}\nRephrased:</code></pre>\n</div>\n<figcaption>PAL with Rephrasing</figcaption>\n</figure>\n\n<figure id=\"prompt:rephrase_pal_tools\">\n<div class=\"minipage\">\n<pre><code>Rephrase the given blanked question and answer pairs and then write a python function called solution() to find the value of x in the rephrased question. Return the value of x. You may assume the neccessary libraries are imported. Strictly follow the format given in the examples below, as the method will be executed with the same name.\n\nQ: Ben has four boxes with ten basketball cards in each box. Ben received _____ cards from his mother. If he gives 58 cards to his classmates, how many cards does he has left?\nA: 22\nRephrased: Ben has four boxes with ten basketball cards in each box. Ben received x cards from his mother. He gives 58 cards to his classmates. He has 22 cards left. Find the value of x.\nProgram:\n```python\ndef solution():\n    num_boxes = 4\n    cards_per_box = 10\n    total_cards_in_boxes = num_boxes * cards_per_box\n    cards_from_mother = x\n    cards_given_to_classmates = 58\n    cards_left = 22\n    \n    equation = Eq(cards_from_mother + total_cards_in_boxes, cards_given_to_classmates + cards_left)\n    blank = solve(equation)[0]\n\n    return blank\n```\n\nQ: Natalia sold _____ clips to  her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\nA: 72\nRephrased: Natalia sold x clips to her friends in April, and then she sold half as many clips in May. Natalia sells 72 clips altogether in April and May. Find the value of x.\nProgram:\n```python\ndef solution():\n    april_clips = x\n    may_clips = april_clips / 2\n    total_clips = 72\n    \n    equation = Eq(april_clips + may_clips, total_clips)\n    blank = solve(equation)[0]\n\n    return blank\n```\n\n...\n\nQ: {{question}}\nA: {{answer}}\nRephrased:</code></pre>\n</div>\n<figcaption>PAL-Tools with Rephrasing</figcaption>\n</figure>\n\n<figure id=\"prompt:rephrase_check_your_work\">\n<div class=\"minipage\">\n<pre><code>Fill in the blank given the question and answer examples below. Give your answer as either a number or a decimal (no fractions). Check your work by substituting your answer in the blank, solving the question and comparing to the original answer. Follow the format specified in the examples below:\n\nQ: There are 15 trees in the grove. Grove workers will plant _____ trees in the grove today. After they are done, how many trees would be there?\nA: 21 \nRephrased: There are 15 trees in the grove. Grove workers will plant x trees in the grove today. After they are done, there would be 21 trees. Find the value of x.\nAnswer: There are 15 trees originally, Then there were 21 trees after some more were planted. So there must have been x = 21 - 15 = 6 trees. The answer is 6.\nFinal question: There are 15 trees in the grove. Grove workers will plant 6 trees in the grove today. After they are done, how many trees would be there?\nCheck: There would be 15 + 6 = 21 trees in total. This matches the original answer.\n\nQ: If there are 3 cars in the parking lot and _____ more cars arrive, how many cars are in the parking lot?\nA: 5\nRephrased: If there are 3 cars in the parking lot and x more cars arrive, there are 5 cars in the parking lot. Find the value of x.\nAnswer: There are originally 3 cars. x more cars arrive. 3 + x = 5, so x = 5 - 3 = 2. The answer is 2.\nFinal question: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\nCheck: There would be 3 + 2 = 5 cars in the parking lot. This matches the original answer.\n\n...\n\nQ: {{question}}\nA: {{answer}}\nRephrased: </code></pre>\n</div>\n<figcaption>Check your work with Rephrasing</figcaption>\n</figure>\n\n<figure id=\"prompt:self-refine-init\">\n<div class=\"minipage\">\n<pre><code>You are given a math question with a blank value and an answer. Rephrase the given blanked question and answer pairs and then write a python function called solution() to find the value of x in the rephrased question. Return the value of x. You may assume the neccessary libraries are imported. Strictly follow the format given in the examples below, as the method will be executed with the same name.\n\nQ: Ben has four boxes with ten basketball cards in each box. Ben received _____ cards from his mother. If he gives 58 cards to his classmates, how many cards does he has left?\nA: 22\nRephrased: Ben has four boxes with ten basketball cards in each box. Ben received x cards from his mother. He gives 58 cards to his classmates. He has 22 cards left. Find the value of x.\nProgram:\n```python\ndef solution():\n    num_boxes = 4\n    cards_per_box = 10\n    total_cards_in_boxes = num_boxes * cards_per_box\n    cards_from_mother = x\n    cards_given_to_classmates = 58\n    cards_left = 22\n    \n    equation = Eq(cards_from_mother + total_cards_in_boxes, cards_given_to_classmates + cards_left)\n    blank = solve(equation)[0]\n\n    return blank\n```\n\n\nQ: Natalia sold _____ clips to  her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\nA: 72\nRephrased: Natalia sold x clips to her friends in April, and then she sold half as many clips in May. Natalia sells 72 clips altogether in April and May. Find the value of x.\nProgram:\n```python\ndef solution():\n    april_clips = x\n    may_clips = april_clips / 2\n    total_clips = 72\n    \n    equation = Eq(april_clips + may_clips, total_clips)\n    blank = solve(equation)[0]\n\n    return blank\n```\n\nQ: {{question}}\nA: {{answer}}\nRephrased:</code></pre>\n</div>\n<figcaption>PAL-Tools with Rephrasing and Self-Refine: init prompt</figcaption>\n</figure>\n\n<figure id=\"prompt:self-refine-feedback\">\n<div class=\"minipage\">\n<pre><code>You are given a question-answer pair with a blank, and a chain of thought (CoT) for filling in the blank. Go through the chain of thought step by step and point out mistakes, if any. Provide the final corrected answer as shown below.\n\nQ: Kelly is grocery shopping at a supermarket and is making sure she has enough in her budget for the items in her cart. Her 5 packs of bacon cost $_____ in total and she has 6 packets of chicken which each cost twice as much as a pack of bacon. She also has 3 packs of strawberries, priced at $4 each, and 7 packs of apples, each priced at half the price of a pack of strawberries. If Kelly&#39;s budget is $65 then how much money, in dollars, does she have left in her budget?\nA: 5\nRephrased: Kelly is grocery shopping at a supermarket and is making sure she has enough in her budget for the items in her cart. Her 5 packs of bacon cost a total of x dollars, and she has 6 packets of chicken, each costing twice as much as a pack of bacon. She also has 3 packs of strawberries priced at $4 each, and 7 packs of apples, each priced at half the price of a pack of strawberries. If Kelly&#39;s budget is $65, then how much money, in dollars, does she have left in her budget?\n\nProgram:\n\n```python\ndef solution():\n    bacon_cost = x\n    chicken_cost = 2 * bacon_cost\n    strawberry_cost = 4\n    apple_cost = strawberry_cost / 2\n    budget = 65\n    remaining_budget = budget - (5 * bacon_cost + 6 * chicken_cost + 3 * strawberry_cost + 7 * apple_cost)\n    \n    equation = Eq(remaining_budget, 5)\n    blank = solve(equation)[0]\n\n    return blank\n```\n\nCorrection:\n\nThe rephrased problem does not end with &#39;Find the value of x&#39;. Instead, it asks us to find the money Kelly has left in her budget. This is incorrect.\n\nLet&#39;s check the program:\n\n    bacon_cost = x\n    chicken_cost = 2 * bacon_cost\n\nLooks good\n\n    strawberry_cost = 4\n    apple_cost = strawberry_cost / 2\n\nLooks good\n\n    budget = 65\n    remaining_budget = budget - (5 * bacon_cost + 6 * chicken_cost + 3 * strawberry_cost + 7 * apple_cost)\n\nThe equation formed is correct, as are the number of packs of bacon, chicken, strawberry and apples\n\n    equation = Eq(remaining_budget, 5)\n    blank = solve(equation)[0]\n    return blank\n\nThe equation has been equated to the correct answer, and the program returns the blank.\n\nThe program provided is completely correct!\n</code></pre>\n</div>\n<figcaption>PAL-Tools with Rephrasing and Self-Refine: feedback prompt</figcaption>\n</figure>\n\n<figure id=\"prom:self-refine-feedback_c\">\n<div class=\"minipage\">\n<pre><code>Final Rephrased Problem:\nKelly is grocery shopping at a supermarket and is making sure she has enough in her budget for the items in her cart. Her 5 packs of bacon cost a total of x dollars, and she has 6 packets of chicken, each costing twice as much as a pack of bacon. She also has 3 packs of strawberries priced at $4 each, and 7 packs of apples, each priced at half the price of a pack of strawberries. If Kelly&#39;s budget is $65, then she has $5 left in her budget after shopping. Find the value of x.\n\nFinal Program:\n```python\ndef solution():\n    bacon_cost = x\n    chicken_cost = 2 * bacon_cost\n    strawberry_cost = 4\n    apple_cost = strawberry_cost / 2\n    budget = 65\n    remaining_budget = budget - (5 * bacon_cost + 6 * chicken_cost + 3 * strawberry_cost + 7 * apple_cost)\n    \n    equation = Eq(remaining_budget, 5)\n    blank = solve(equation)[0]\n\n    return blank\n```\n...\n\nQ: {{question}}\nA: {{answer}}\nRephrased: {{rephrased}}\nProgram:\n```python\n{{program}}\n```\n\nCorrection:  \n</code></pre>\n</div>\n<figcaption>PAL-Tools with Rephrasing and Self-Refine: feedback prompt continued</figcaption>\n</figure>\n\n<figure id=\"prompt:verifier\">\n<div class=\"minipage\">\n<pre><code>Solve the given question step by step and check whether the answer obtained matches the given answer. Follow the format specified in the examples below:\n\nQ: There are 15 trees in the grove. Grove workers will plant 6 trees in the grove today. After they are done, how many trees would be there?\nA: 21 \nCheck: There would be 15 + 6 = 21 trees in total. The given answer is 21. This matches the given answer.\n\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\nA: 5\nCheck: There would be 3 + 2 = 5 cars in the parking lot. The answer is 5. This matches the given answer.\n\n...\n\nQ: {{question}}\nA: {{answer}}\nCheck: \n</code></pre>\n</div>\n<figcaption>Verifier prompt for ensembling</figcaption>\n</figure>\n\n<figure id=\"prompt:cot_phrase_masked\">\n<div class=\"minipage\">\n<pre><code>Find a phrase to fill in the blank given the question and answer. Your answer should contain a decimal. Follow the format specified in the examples below and solve step by step:\n\nQ: There are 15 trees in the grove. _____. After they are done, how many trees would be there?\nA: 21 \nAnswer: There are 15 trees originally, Then there are going to be 21 trees in the end. So there must have been 21 - 15 = 6 trees added.\nPhrase: Grove workers will plant 6 trees today\n\nQ: If there are 3 cars in the parking lot and _____, how many cars are in the parking lot?\nA: 5\nAnswer: There are originally 3 cars. There are finally 5 cars, so 5 - 3 = 2 cars arrived.\nPhrase: 2 cars arrive\n\n...\n\nQ: {{question}}\nA: {{answer}}\nAnswer:</code></pre>\n</div>\n<figcaption>CoT for phrase-masked task</figcaption>\n</figure>\n\n<figure id=\"prompt:cot_rephrase_phrase_masked\">\n<div class=\"minipage\">\n<pre><code>Given blanked question Q, we need to complete it such that its answer is A.\nFirst guess the blank. Then rephrase the question to find x by putting value in A. Then solve it step-by-step. Follow the format specified in the examples below:\n\nQ: There are 15 trees in the grove. _____. After they are done, how many trees would be there?\nA: 21\nGuess: x trees were added.\nRephrased: There are 15 trees in the grove. x trees were added. After they are done, there would be 21 trees. Find the value of x.\nAnswer: There are 15 trees originally, Then there were 21 trees after some more were planted. So there must have been x = 21 - 15 = 6 trees. The answer is 6.\n\nQ: If there are 3 cars in the parking lot and _____, how many cars are in the parking lot?\nA: 5\nGuess: x more cars arrive\nRephrased: If there are 3 cars in the parking lot and x more cars arrive, how many cars are in the parking lot?\nAnswer: There are originally 3 cars. x more cars arrive. 3 + x = 5, so x = 5 - 3 = 2. The answer is 2.\n\n...\n\nQ: {{question}}\nA: {{answer}}</code></pre>\n</div>\n<figcaption>CoT Rephrase for phrase-masked task</figcaption>\n</figure>\n\n<figure id=\"prompt:cyw_phrase_masked\">\n<div class=\"minipage\">\n<pre><code>Given blanked question Q, we need to complete it such that its answer is A.\nFirst guess the blank by making use of unknown x. Then solve it to find x step-by-step. Check your work by substituting your answer in the blank, solving the question and comparing to the original answer. Follow the format specified in the examples below:\n\nQ: There are 15 trees in the grove. _____. After they are done, how many trees would be there?\nA: 21\nGuess: x trees were added. \nAnswer: There are 15 trees originally, Then there were 21 trees after some more were planted. So there must have been x = 21 - 15 = 6 trees. The answer is 6.\nFinal question: There are 15 trees in the grove. 6 trees were added. After they are done, how many trees would be there?\nCheck: There would be 15 + 6 = 21 trees in total. The original answer was 21. This matches the original answer.\n\nQ: If there are 3 cars in the parking lot and _____, how many cars are in the parking lot?\nA: 5\nGuess: x more cars arrive\nAnswer: There are originally 3 cars. x more cars arrive. 3 + x = 5, so x = 5 - 3 = 2. The answer is 2.\nFinal question: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\nCheck: There would be 3 + 2 = 5 cars in the parking lot. The original answer was 5. This matches the original answer.\n\n...\n\nQ: {{question}}\nA: {{answer}}\nGuess:</code></pre>\n</div>\n<figcaption>Check-your-work for phrase-masked task</figcaption>\n</figure>\n\n<figure id=\"prompt:r_tools_phrase_masked\">\n<div class=\"minipage\">\n<pre><code>Given blanked question Q, we need to complete it such that its answer is A.\nFirst, guess the blank by making use of unknown x. Rephrase the question to find x by making use of the value of A. Then solve it step b step to find the value of blank. Strictly follow the format given in the examples below.\n\nQ: Ben has four boxes with ten basketball cards in each box. _____. If he gives 58 cards to his classmates, how many cards does he have left?\nA: 22\n\nGuess: He gets x more cards\nRephrased: Ben has four boxes with ten basketball cards in each box. He gets x more cards. He gives 58 cards to his classmates. He has 22 cards left. Find the value of x.\nPeano solution:\n\n\nLet a be number of boxes [[var a]]. We have [[eq a = 4]].\nLet b be number of cards in each box [[var b]]. We have [[eq b = 10]].\nLet c be number of cards Ben initially has [[var c]]. We have [[eq c = a * b]].\nLet x be cards he got [[var x]].\nLet d be total cards with Ben [[var d]]. We have [[eq d = c + x]]\nLet e be cards given to classmates [[var e]]. We have [[eq e = 58]].\nLet f be cards left [[var f]]. From given Answer, we have [[eq f = 22]]. \nAs cards left are also total cards - cards given to classmates, we have [[eq f = d - e]]\nThe answer will be the value of x [[answer x]].\n\n\n\n\n\nQ: Natalia sold 48 clips to her friends in April, _____. How many clips did Natalia sell altogether in April and May?\nA: 72\n\nGuess: and sold x in May\nRephrased: Natalia sold 48 clips to her friends in April, and sold x in May. Natalia sells 72 clips altogether in April and May. Find the value of x.\nPeano solution:\n\n\nLet x be number of clips Natalia sold in April [[var a]]. We have [[eq a = 48]].\nLet a be number of clips Natalia sold in May [[var x]].\nLet b be number of clips sold altogether [[var b]]. From given Answer, we have [[eq b = 72]].\nAs clips sold altogether are also the sum of clips sold in April and May, we have [[eq b = x + a ]]\nThe answer will be the value of x [[answer x]].\n\n...\n\nQ: {{question}}\nA: {{answer}}\nGuess:</code></pre>\n</div>\n<figcaption>Rephrase Tools for phrase-masked task</figcaption>\n</figure>\n\n<figure id=\"prompt:r_pal_tools_phrase_masked\">\n<div class=\"minipage\">\n<pre><code>Given blanked question Q, we need to complete it such that its answer is A.\nFirst, guess the blank by making use of unknown x. Rephrase the question to find x by making use of the value of A. Then write a Python function called solution() using sympy that assumes the value of the blank is x and creates an equation in x that is solved by sympy.solve. Return the value of the blank. You may assume the necessary libraries are imported. Strictly follow the format given in the examples below, as the method will be executed with the same name.\n\nQ: Ben has four boxes with ten basketball cards in each box. _____. If he gives 58 cards to his classmates, how many cards does he have left?\nA: 22\nGuess: He gets x more cards\nRephrased: Ben has four boxes with ten basketball cards in each box. He gets x more cards. He gives 58 cards to his classmates. He has 22 cards left. Find the value of x.\nProgram:\n```python\ndef solution():\n    num_boxes = 4\n    cards_per_box = 10\n    total_cards_in_boxes = num_boxes * cards_per_box\n    cards_got = x\n    cards_given_to_classmates = 58\n    cards_left = 22\n    \n    equation = Eq(cards_got + total_cards_in_boxes, cards_given_to_classmates + cards_left)\n    blank = solve(equation)[0]\n\n    return blank\n```\n\nQ: Natalia sold 48 clips to her friends in April, _____. How many clips did Natalia sell altogether in April and May?\nA: 72\nGuess: and sold x in May\nRephrased: Natalia sold 48 clips to her friends in April, and sold x in May. Natalia sells 72 clips altogether in April and May. Find the value of x.\nProgram:\n```python\ndef solution():\n    april_clips = 48\n    may_clips = x\n    total_clips = 72\n    \n    equation = Eq(april_clips + may_clips, total_clips)\n    blank = solve(equation)[0]\n\n    return blank\n```\n...\n\nQ: {{question}}\nA: {{answer}}\nGuess:</code></pre>\n</div>\n<figcaption>Rephrase Pal-Tools for phrase-masked task</figcaption>\n</figure>\n\n[^1]: Equal Contribution, $^\\dagger$Work done while at IIT Delhi.\\\n    Corresponding Authors:\\\n    `aniruddha.deb.2002@gmail.com`, `neevahoza@gmail.com`\n\n[^2]: <https://github.com/dair-iitd/fill-in-the-blank-mwp>\n\n[^3]: we use different number of shots for different models to have roughly the same size of prompts in each case\n\n[^4]: https://supercomputing.iitd.ac.in/"}],"approval":false,"conference":"iclr","rating":2,"year":2024,"id":"5d5dd38538cb02488ce2696b8a7ce9a57873e591a68cc1735a4b22971c1a0a74","y_true":0,"y_pred":0,"rationale_true":"Summary: This paper provides insight into the relatively unexplored area of backward reasoning in Math Word Problems (MWPs). The authors formally define the task of backward reasoning to derive missing information from given answers and incomplete questions.\nThe authors modify three datasets to evaluate this task. The experiments show that multiple Large Language Models (LLMs) showed a significant accuracy drop in backward reasoning compared to forward reasoning. \nThe authors propose three basic prompt methods as improvements, namely “Rephrasing”, “PAL-Tools” and “Reprompting and Verification”. The authors further propose one ensemble-based method via the use of a verifier. \nThrough extensive experimentation, the authors demonstrate that their techniques substantially enhance LLM performance on the backward reasoning task, especially the ensemble-based method further boost the accuracy by a significant margin.\n\nStrengths: 1. The paper explores the relatively understudied area of backward reasoning in mathematical word problems (MWPs) and formalizes the task of backward reasoning.\n2. The research methodology is rigorous. The authors used a variety of state-of-the-art prompt techniques for reverse reasoning with LLM, testing them to ensure a thorough evaluation.\n3. The paper is systematically structured and clearly distinguishes between problem definition, methodology, experimentation and analysis.\n\nWeaknesses: 1. The motivation seems to be Ambiguous. The paper's definition of backward reasoning essentially frames it as a fill-in-the-blank task, rather than a genuine backward reasoning or a broader sense of causal reasoning. In reference [1], a similar task is merely a sub-task in backward verification for verifying forward reasoning. The authors have repurposed it as a new backward reasoning task, which seems redundant and lacks research value. The paper's discussion on the practical application scenarios of this task is insufficient, making it challenging to discern its real-world significance. Moreover, the rationale behind comparing the difficulty levels of backward and forward reasoning remains unexplained.\n2. Lack of Methodological Novelty. The three primary methods presented are essentially repurposed from forward reasoning techniques that have been previously introduced and widely applied in other works. The authors have essentially transformed backward reasoning into forward reasoning, without designing specific methods tailored to the unique characteristics of backward reasoning, thereby undermining the essence of studying backward reasoning. Specifically:\n-----The “Rephrasing” method aligns closely with the “Condition Mask Verification” method from reference [1]. This should have been treated as a baseline rather than a novel approach due to its lack of originality.\n-----The “PAL-Tools” method is fundamentally the same as the method introduced in reference [2], with the authors merely employing the SymPy library for solving for ‘x’. This approach lacks innovation.\n-----The “Reprompting and Verification” method is essentially an inversion of a method from reference [3] used to verify the correctness of forward reasoning, which seems like a forced novelty.\n3. While the paper presents a range of experimental results, the depth of analysis behind these results is lacking. For instance, the paper doesn't delve deep into the differences between various prompting techniques and why certain techniques are more effective in specific scenarios. The comparative analysis mostly revolves around forward reasoning methods, lacking a direct comparison with potential backward reasoning techniques, making it difficult for readers to gauge the true advantages of the proposed methods.\n4. The authors' modifications to the datasets GSM8k, SVAMP, and MultiArith are minimal, merely replacing numbers in questions with blanks. However, they claim to have created “new datasets”, which seems to exaggerate their contribution.\n5. The paper contains many grammatical errors. One is the missing period at the end of the paragraph “In order to establish … on this task”, and the second is the incorrect punctuation in the paragraph “A forward or the typical … numeric value of the blank” with the misplaced colon in ’half.’.\n\n[1]\tWeng, Y., “Large Language Models are Better Reasoners with Self-Verification”, <i>arXiv e-prints</i>, 2022. doi:10.48550/arXiv.2212.09561.\n[2]\tLuyu Gao and Aman Madaan and Shuyan Zhou and Uri Alon and Pengfei Liu and Yiming Yang and Jamie Callan and Graham Neubig (2022)PAL: Program-aided Language Models International Conference on Machine Learning abs/2211.10435\n[3]\tAman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and S. Welleck and Bodhisattwa Prasad Majumder and Shashank Gupta and A. Yazdanbakhsh and Peter Clark (2023)Self-Refine: Iterative Refinement with Self-Feedback arXiv.org abs/2303.17651\n\nQuestions: 1. What is the research significance and practical implications of the proposed backward reasoning task? Specifically:\n---a) Why have you chosen to define backward reasoning as a fill-in-the-blank task and study the capabilities of LLMs on this particular task?\n---b) What motivated the exploration of the relative difficulty between backward and forward reasoning?\n---c) Could you elaborate on potential applications of this task in sectors like education, industry, or other domains?\n2. I found it challenging to understand the precise mechanism of the “Ensembling” method. Can you offer a more intuitive explanation, especially in the context of Figure 2 in your paper? Moreover:\n---a) How did you arrive at the decision to use a holdout set of 100 examples from the datasets?\n---b)What criteria or methods were used to select these examples for the holdout set? Is there a specific scientific basis for this choice?\n3. Would it be possible to design ablation studies to elucidate why the “Ensembling” method performs better? Can you shed light on the effectiveness of each module and whether the method seamlessly integrates the backward reasoning capabilities of the three basic methods?","rationale_pred":"Paper Summary: The paper explores the backward reasoning capabilities of LLMs on Math Word Problems (MWPs). It defines the backward reasoning task, modifies existing datasets (GSM8k, SVAMP, MultiArith) for evaluation, and demonstrates a performance drop compared to forward reasoning. The paper proposes three novel techniques (Rephrase, PAL-Tools, Check your Work) and a Bayesian ensemble method to improve performance. Experiments show substantial performance gains using the ensemble-based method compared to standard prompting techniques.\n\nSupporting Evidence:\n- ReasonAgain supports the paper by highlighting limitations of existing evaluation methods for LLMs in math reasoning and reinforces the claims about the significant accuracy drop in backward reasoning tasks.\n- Improving LLM Reasoning through Scaling Inference Computation with Collaborative Verification supports the paper by addressing the limitations of LLMs in reasoning tasks, particularly in mathematical contexts, and emphasizes the importance of verification and error detection.\n- MathScale supports the paper by providing a scalable method for generating high-quality mathematical reasoning data, which can enhance the training of LLMs.\n- Generative Verifiers supports the paper by introducing generative verifiers (GenRM) that enhance the reasoning performance of LLMs.\n- Dipper supports the paper by demonstrating the effectiveness of ensemble methods in enhancing reasoning capabilities of LLMs, particularly in math tasks.\n- Training Verifiers to Solve Math Word Problems supports the paper by providing a foundational dataset (GSM8K) that highlights the challenges LLMs face in multi-step mathematical reasoning.\n- Solving Math Word Problems by Combining Language Models With Symbolic Solvers supports the paper by demonstrating the effectiveness of combining LLMs with external symbolic solvers for solving math word problems.\n- Learning to Automatically Solve Algebra Word Problems supports the paper by presenting a novel approach for solving algebra word problems by constructing systems of linear equations.\n- Mapping to Declarative Knowledge for Word Problem Solving supports the paper by emphasizing the importance of declarative knowledge in solving math word problems.\n- Deep Neural Solver for Math Word Problems supports the paper by demonstrating advanced methodologies for solving math word problems.\n\nContradictory Evidence:\n- CHAMP contrasts the paper by emphasizing the importance of evaluating LLMs' reasoning capabilities through a focus on end-to-end correctness rather than backward reasoning.\n- Instructing Large Language Models to Identify and Ignore Irrelevant Conditions contrasts the paper by focusing on the issue of irrelevant conditions in Math Word Problems (MWPs), which the Main Paper does not address.\n- From Blind Solvers to Logical Thinkers contrasts the paper by highlighting that LLMs struggle to identify logical inconsistencies in mathematical problems, which is a fundamental aspect of reasoning that the Main Paper does not address.\n- Can LLMs Solve longer Math Word Problems Better? contrasts the paper by focusing on the impact of longer context lengths on the performance of LLMs in solving Math Word Problems (MWPs), while the Main Paper emphasizes backward reasoning capabilities.\n- Satisfiability-Aided Language Models Using Declarative Prompting contrasts the paper by emphasizing the limitations of programmatic representations in LLMs for constraint solving tasks, which require more sophisticated reasoning than what backward reasoning can provide.\n- Self-Consistency Improves Chain of Thought Reasoning in Language Models contrasts with the Main Paper by focusing on the effectiveness of chain-of-thought prompting and a new decoding strategy called self-consistency, which enhances performance on reasoning tasks.\n- How Can We Know When Language Models Know? contrasts the paper by focusing on the calibration of language models (LMs) in question answering, highlighting that LMs often fail to provide accurate answers despite their capabilities.\n- Calibrate Before Use: Improving Few-Shot Performance of Language Models contrasts the paper by highlighting the instability of few-shot learning in language models, suggesting that the performance of LLMs can vary significantly based on prompt format and example order, which is not addressed in the Main Paper's focus on backward reasoning.\n\nConclusion: While the paper introduces techniques to improve backward reasoning in LLMs for math word problems, the related works suggest that the novelty is limited. Many papers support the general idea of improving LLM reasoning and using ensemble methods, but contrasting papers highlight alternative approaches and limitations not addressed by this paper, such as logical integrity, irrelevant conditions, context length, and calibration issues. Therefore, the paper's specific approach to backward reasoning, while potentially useful, does not appear to be significantly novel in the broader context of LLM research.","structured_evaluation":{"paper_summary":"The paper explores the backward reasoning capabilities of LLMs on Math Word Problems (MWPs). It defines the backward reasoning task, modifies existing datasets (GSM8k, SVAMP, MultiArith) for evaluation, and demonstrates a performance drop compared to forward reasoning. The paper proposes three novel techniques (Rephrase, PAL-Tools, Check your Work) and a Bayesian ensemble method to improve performance. Experiments show substantial performance gains using the ensemble-based method compared to standard prompting techniques.","supporting_evidence":["ReasonAgain supports the paper by highlighting limitations of existing evaluation methods for LLMs in math reasoning and reinforces the claims about the significant accuracy drop in backward reasoning tasks.","Improving LLM Reasoning through Scaling Inference Computation with Collaborative Verification supports the paper by addressing the limitations of LLMs in reasoning tasks, particularly in mathematical contexts, and emphasizes the importance of verification and error detection.","MathScale supports the paper by providing a scalable method for generating high-quality mathematical reasoning data, which can enhance the training of LLMs.","Generative Verifiers supports the paper by introducing generative verifiers (GenRM) that enhance the reasoning performance of LLMs.","Dipper supports the paper by demonstrating the effectiveness of ensemble methods in enhancing reasoning capabilities of LLMs, particularly in math tasks.","Training Verifiers to Solve Math Word Problems supports the paper by providing a foundational dataset (GSM8K) that highlights the challenges LLMs face in multi-step mathematical reasoning.","Solving Math Word Problems by Combining Language Models With Symbolic Solvers supports the paper by demonstrating the effectiveness of combining LLMs with external symbolic solvers for solving math word problems.","Learning to Automatically Solve Algebra Word Problems supports the paper by presenting a novel approach for solving algebra word problems by constructing systems of linear equations.","Mapping to Declarative Knowledge for Word Problem Solving supports the paper by emphasizing the importance of declarative knowledge in solving math word problems.","Deep Neural Solver for Math Word Problems supports the paper by demonstrating advanced methodologies for solving math word problems."],"contradictory_evidence":["CHAMP contrasts the paper by emphasizing the importance of evaluating LLMs' reasoning capabilities through a focus on end-to-end correctness rather than backward reasoning.","Instructing Large Language Models to Identify and Ignore Irrelevant Conditions contrasts the paper by focusing on the issue of irrelevant conditions in Math Word Problems (MWPs), which the Main Paper does not address.","From Blind Solvers to Logical Thinkers contrasts the paper by highlighting that LLMs struggle to identify logical inconsistencies in mathematical problems, which is a fundamental aspect of reasoning that the Main Paper does not address.","Can LLMs Solve longer Math Word Problems Better? contrasts the paper by focusing on the impact of longer context lengths on the performance of LLMs in solving Math Word Problems (MWPs), while the Main Paper emphasizes backward reasoning capabilities.","Satisfiability-Aided Language Models Using Declarative Prompting contrasts the paper by emphasizing the limitations of programmatic representations in LLMs for constraint solving tasks, which require more sophisticated reasoning than what backward reasoning can provide.","Self-Consistency Improves Chain of Thought Reasoning in Language Models contrasts with the Main Paper by focusing on the effectiveness of chain-of-thought prompting and a new decoding strategy called self-consistency, which enhances performance on reasoning tasks.","How Can We Know When Language Models Know? contrasts the paper by focusing on the calibration of language models (LMs) in question answering, highlighting that LMs often fail to provide accurate answers despite their capabilities.","Calibrate Before Use: Improving Few-Shot Performance of Language Models contrasts the paper by highlighting the instability of few-shot learning in language models, suggesting that the performance of LLMs can vary significantly based on prompt format and example order, which is not addressed in the Main Paper's focus on backward reasoning."],"conclusion":"While the paper introduces techniques to improve backward reasoning in LLMs for math word problems, the related works suggest that the novelty is limited. Many papers support the general idea of improving LLM reasoning and using ensemble methods, but contrasting papers highlight alternative approaches and limitations not addressed by this paper, such as logical integrity, irrelevant conditions, context length, and calibration issues. Therefore, the paper's specific approach to backward reasoning, while potentially useful, does not appear to be significantly novel in the broader context of LLM research.","label":0,"rationale":"Paper Summary: The paper explores the backward reasoning capabilities of LLMs on Math Word Problems (MWPs). It defines the backward reasoning task, modifies existing datasets (GSM8k, SVAMP, MultiArith) for evaluation, and demonstrates a performance drop compared to forward reasoning. The paper proposes three novel techniques (Rephrase, PAL-Tools, Check your Work) and a Bayesian ensemble method to improve performance. Experiments show substantial performance gains using the ensemble-based method compared to standard prompting techniques.\n\nSupporting Evidence:\n- ReasonAgain supports the paper by highlighting limitations of existing evaluation methods for LLMs in math reasoning and reinforces the claims about the significant accuracy drop in backward reasoning tasks.\n- Improving LLM Reasoning through Scaling Inference Computation with Collaborative Verification supports the paper by addressing the limitations of LLMs in reasoning tasks, particularly in mathematical contexts, and emphasizes the importance of verification and error detection.\n- MathScale supports the paper by providing a scalable method for generating high-quality mathematical reasoning data, which can enhance the training of LLMs.\n- Generative Verifiers supports the paper by introducing generative verifiers (GenRM) that enhance the reasoning performance of LLMs.\n- Dipper supports the paper by demonstrating the effectiveness of ensemble methods in enhancing reasoning capabilities of LLMs, particularly in math tasks.\n- Training Verifiers to Solve Math Word Problems supports the paper by providing a foundational dataset (GSM8K) that highlights the challenges LLMs face in multi-step mathematical reasoning.\n- Solving Math Word Problems by Combining Language Models With Symbolic Solvers supports the paper by demonstrating the effectiveness of combining LLMs with external symbolic solvers for solving math word problems.\n- Learning to Automatically Solve Algebra Word Problems supports the paper by presenting a novel approach for solving algebra word problems by constructing systems of linear equations.\n- Mapping to Declarative Knowledge for Word Problem Solving supports the paper by emphasizing the importance of declarative knowledge in solving math word problems.\n- Deep Neural Solver for Math Word Problems supports the paper by demonstrating advanced methodologies for solving math word problems.\n\nContradictory Evidence:\n- CHAMP contrasts the paper by emphasizing the importance of evaluating LLMs' reasoning capabilities through a focus on end-to-end correctness rather than backward reasoning.\n- Instructing Large Language Models to Identify and Ignore Irrelevant Conditions contrasts the paper by focusing on the issue of irrelevant conditions in Math Word Problems (MWPs), which the Main Paper does not address.\n- From Blind Solvers to Logical Thinkers contrasts the paper by highlighting that LLMs struggle to identify logical inconsistencies in mathematical problems, which is a fundamental aspect of reasoning that the Main Paper does not address.\n- Can LLMs Solve longer Math Word Problems Better? contrasts the paper by focusing on the impact of longer context lengths on the performance of LLMs in solving Math Word Problems (MWPs), while the Main Paper emphasizes backward reasoning capabilities.\n- Satisfiability-Aided Language Models Using Declarative Prompting contrasts the paper by emphasizing the limitations of programmatic representations in LLMs for constraint solving tasks, which require more sophisticated reasoning than what backward reasoning can provide.\n- Self-Consistency Improves Chain of Thought Reasoning in Language Models contrasts with the Main Paper by focusing on the effectiveness of chain-of-thought prompting and a new decoding strategy called self-consistency, which enhances performance on reasoning tasks.\n- How Can We Know When Language Models Know? contrasts the paper by focusing on the calibration of language models (LMs) in question answering, highlighting that LMs often fail to provide accurate answers despite their capabilities.\n- Calibrate Before Use: Improving Few-Shot Performance of Language Models contrasts the paper by highlighting the instability of few-shot learning in language models, suggesting that the performance of LLMs can vary significantly based on prompt format and example order, which is not addressed in the Main Paper's focus on backward reasoning.\n\nConclusion: While the paper introduces techniques to improve backward reasoning in LLMs for math word problems, the related works suggest that the novelty is limited. Many papers support the general idea of improving LLM reasoning and using ensemble methods, but contrasting papers highlight alternative approaches and limitations not addressed by this paper, such as logical integrity, irrelevant conditions, context length, and calibration issues. Therefore, the paper's specific approach to backward reasoning, while potentially useful, does not appear to be significantly novel in the broader context of LLM research."},"arxiv_id":"2310.01991"},"terms":{"tasks":["backward reasoning task on math word problems","retrieve the missing information","evaluate backward reasoning capabilities of large language models"],"methods":["backward reasoning","Rephrase","PAL-Tools","Check your Work","Bayesian formulation for creating an ensemble"],"metrics":["accuracy"],"resources":["GSM8k","SVAMP","MultiArith","GPT4","GPT3.5","PaLM-2","LLaMa"],"relations":[{"head":"backward reasoning","tail":"backward reasoning task on math word problems"},{"head":"Rephrase","tail":"backward reasoning task on math word problems"},{"head":"PAL-Tools","tail":"backward reasoning task on math word problems"},{"head":"Check your Work","tail":"backward reasoning task on math word problems"},{"head":"Bayesian formulation for creating an ensemble","tail":"backward reasoning task on math word problems"},{"head":"accuracy","tail":"evaluate backward reasoning capabilities of large language models"},{"head":"GSM8k","tail":"evaluate backward reasoning capabilities of large language models"},{"head":"SVAMP","tail":"evaluate backward reasoning capabilities of large language models"},{"head":"MultiArith","tail":"evaluate backward reasoning capabilities of large language models"},{"head":"GPT4","tail":"evaluate backward reasoning capabilities of large language models"},{"head":"GPT3.5","tail":"evaluate backward reasoning capabilities of large language models"},{"head":"PaLM-2","tail":"evaluate backward reasoning capabilities of large language models"},{"head":"LLaMa","tail":"evaluate backward reasoning capabilities of large language models"}]},"background":"While forward reasoning (i.e., find the answer given the question) has been explored extensively in the recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?","target":"In this paper, we formally define the backward reasoning task on math word problems and modify three datasets to evaluate this task: GSM8k, SVAMP and MultiArith. Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa). Utilizing the specific format of this task, we propose three novel techniques that improve performance: Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps. Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over these base methods aided by a verifier to further boost the accuracy by a significant margin. Extensive experimentation demonstrates that our techniques successively improve the performance of LLMs on the backward reasoning task, with the final ensemble-based method resulting in a substantial performance gain compared to the raw LLMs with standard prompting techniques such as chain-of-thought."},{"graph":{"title":"Taming Sparsely Activated Transformer with Stochastic Experts","abstract":"Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts. In this paper, we propose a new expert-based model, THOR ($\\underline{\\textbf{T}}$ransformer wit$\\underline{\\textbf{H}}$ St$\\underline{\\textbf{O}}$chastic Expe$\\underline{\\textbf{R}}$ts). Unlike classic expert-based models, such as the Switch Transformer, experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions.  We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/Stochastic-Mixture-of-Experts.","entities":[{"label":"Taming Sparsely Activated Transformer with Stochastic Experts","type":"title","detail":null,"excerpts":null},{"label":"general machine learning (i.e., none of the above)","type":"primary_area","detail":null,"excerpts":null},{"label":"sparsely activated models","type":"keyword","detail":null,"excerpts":null},{"label":"mixture-of-experts","type":"keyword","detail":null,"excerpts":null},{"label":"stochastic experts","type":"keyword","detail":null,"excerpts":null},{"label":"transformer","type":"keyword","detail":null,"excerpts":null},{"label":"machine translation","type":"keyword","detail":null,"excerpts":null},{"label":"consistency regularization","type":"keyword","detail":null,"excerpts":null},{"label":"In this paper, we propose a new expert-based model, THOR ($\\underline{\\textbf{T}}$ransformer wit$\\underline{\\textbf{H}}$ St$\\underline{\\textbf{O}}$chastic Expe$\\underline{\\textbf{R}}$ts).","type":"tldr","detail":null,"excerpts":null},{"label":"THOR models are more parameter efficient and outperform Transformer and MoE models.","type":"claim","detail":"THOR models achieve better performance with fewer parameters compared to traditional Transformer and Mixture-of-Experts models, demonstrating improved parameter efficiency.","excerpts":[{"section":"Abstract","text":"Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings."},{"section":"Introduction","text":"Results show that $\\text{THOR}~$models outperform state-of-the-art MoE models by an average of 2 BLEU score on twelve low-resource translation tasks."},{"section":"Conclusion","text":"$\\text{THOR}~$models also demonstrate a better generalization capability in that they are more parameter-efficient, less likely to overfit, make more consistent predictions, and achieve better results consistently across different settings."}]},{"label":"THOR achieves state-of-the-art results on machine translation tasks.","type":"claim","detail":"THOR attains new state-of-the-art results on WMT'16 En-De and WMT'14 En-Fr translation benchmarks, surpassing previous models without data augmentation or pre-trained language models.","excerpts":[{"section":"Introduction","text":"In the rich-resource setting, $\\text{THOR}~$achieves new state-of-the-art results on the two widely-used translation benchmarks, WMT'16 En-De and WMT'14 En-Fr."},{"section":"Conclusion","text":"We validate the effectiveness of $\\text{THOR}~$via a comprehensive empirical study on machine translation."}]},{"label":"THOR is more parameter efficient than Switch Transformer.","type":"claim","detail":"The THOR model with 300 million parameters achieves the same BLEU score as a Switch Transformer with 5.5 billion parameters, indicating higher parameter efficiency.","excerpts":[{"section":"Abstract","text":"THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger."},{"section":"Introduction","text":"Moreover, our model achieves state-of-the-art results on these tasks --- the same BLEU score that is achieved by the Z-code MoE model [@kim2021scalable] with 5.5 billion parameters (18 times larger)."},{"section":"Conclusion","text":"In all the three settings (i.e., low-resource, rich-resource, and multilingual translation), $\\text{THOR}~$models significantly outperform the vanilla Transformer, and Switch Transformer, a state-of-the-art MoE model."}]},{"label":"THOR makes more consistent predictions than Switch Transformer.","type":"claim","detail":"THOR exhibits lower variance in model predictions compared to the Switch Transformer, attributed to the consistency regularizer used during training.","excerpts":[{"section":"Conclusion","text":"$\\text{THOR}~$models also demonstrate a better generalization capability in that they are more parameter-efficient, less likely to overfit, make more consistent predictions, and achieve better results consistently across different settings."},{"section":"Experiments","text":"As shown in Figure\\[fig:consistency\\](#fig:consistency){reference-type=\"ref\" reference=\"fig:consistency\"}, $\\text{THOR}~$makes more consistent predictions than Switch Transformer due to the use of the consistency regularizer for model training."}]},{"label":"THOR: Transformer with Stochastic Experts","type":"method","detail":"THOR is a new expert-based model where experts are randomly activated for each input during training and inference, trained with a consistency regularized loss.","excerpts":[{"section":"Abstract","text":"In this paper, we propose a new expert-based model, THOR ($\\underline{\\textbf{T}}$ransformer wit$\\underline{\\textbf{H}}$ St$\\underline{\\textbf{O}}$chastic Expe$\\underline{\\textbf{R}}$ts)."},{"section":"Introduction","text":"Inspired by our findings, we propose a new SAM, $\\text{THOR}~$([**T**]{.underline}ransformer wit[**H**]{.underline} St[**O**]{.underline}chastic Expe[**R**]{.underline}ts)."},{"section":"THOR: Transformer with Stochastic Experts","text":"The ineffectiveness of the gating mechanism, as shown in our experiments, motivates us to propose a new expert-based model, $\\text{THOR}~$([**T**]{.underline}ransformer wit[**H**]{.underline} St[**O**]{.underline}chastic Expe[**R**]{.underline}ts)."}]},{"label":"Low-Resource Translation","type":"experiment","detail":"Experiments were conducted on six language pairs from IWSLT and Europarl datasets to evaluate THOR's performance in low-resource settings.","excerpts":[{"section":"Experiments","text":"We adopt three settings: low-resource translation, rich-resource translation, and multilingual translation."},{"section":"Low-Resource Translation","text":"We use six language pairs: English to Vietnamese, English to German, and English to French from IWSLT; English to Romanian, English to Latvian, and English to Czech from Europarl[^4]."}]},{"label":"Rich-Resource Translation","type":"experiment","detail":"THOR was evaluated on WMT'16 English-German and WMT'14 English-French translation benchmarks to assess its performance in rich-resource scenarios.","excerpts":[{"section":"Experiments","text":"We adopt three settings: low-resource translation, rich-resource translation, and multilingual translation."},{"section":"Rich-Resource Translation","text":"We use two widely adopted rich-resource translation benchmarks: English to German translation from WMT'16 and English to French translation from WMT'14."}]},{"label":"Multilingual Translation","type":"experiment","detail":"Experiments were performed on 10 language pairs from WMT datasets to evaluate THOR's effectiveness in multilingual translation tasks.","excerpts":[{"section":"Experiments","text":"We adopt three settings: low-resource translation, rich-resource translation, and multilingual translation."},{"section":"Multilingual Translation","text":"We have collected $10$ language pairs from WMT datasets, and built a $64k$-entry dictionary for all the languages."}]},{"label":"Ablation Experiments","type":"experiment","detail":"Ablation studies were conducted to analyze the contribution of different loss terms, inference methods, and regularization strength in THOR.","excerpts":[{"section":"Experiments","text":"We adopt three settings: low-resource translation, rich-resource translation, and multilingual translation."},{"section":"Ablation Experiments","text":"We examine the relative contributions of the three loss terms used in the $\\text{THOR}~$training objective of Eq.\\[eq:step\\](#eq:step){reference-type=\"ref\" reference=\"eq:step\"}: $\\mathrm{CE_1}$, $\\mathrm{CE_2}$ and $\\mathrm{CR}$."}]}],"relationships":[{"source":"Taming Sparsely Activated Transformer with Stochastic Experts","target":"general machine learning (i.e., none of the above)"},{"source":"Taming Sparsely Activated Transformer with Stochastic Experts","target":"sparsely activated models"},{"source":"Taming Sparsely Activated Transformer with Stochastic Experts","target":"mixture-of-experts"},{"source":"Taming Sparsely Activated Transformer with Stochastic Experts","target":"stochastic experts"},{"source":"Taming Sparsely Activated Transformer with Stochastic Experts","target":"transformer"},{"source":"Taming Sparsely Activated Transformer with Stochastic Experts","target":"machine translation"},{"source":"Taming Sparsely Activated Transformer with Stochastic Experts","target":"consistency regularization"},{"source":"Taming Sparsely Activated Transformer with Stochastic Experts","target":"In this paper, we propose a new expert-based model, THOR ($\\underline{\\textbf{T}}$ransformer wit$\\underline{\\textbf{H}}$ St$\\underline{\\textbf{O}}$chastic Expe$\\underline{\\textbf{R}}$ts)."},{"source":"In this paper, we propose a new expert-based model, THOR ($\\underline{\\textbf{T}}$ransformer wit$\\underline{\\textbf{H}}$ St$\\underline{\\textbf{O}}$chastic Expe$\\underline{\\textbf{R}}$ts).","target":"THOR models are more parameter efficient and outperform Transformer and MoE models."},{"source":"In this paper, we propose a new expert-based model, THOR ($\\underline{\\textbf{T}}$ransformer wit$\\underline{\\textbf{H}}$ St$\\underline{\\textbf{O}}$chastic Expe$\\underline{\\textbf{R}}$ts).","target":"THOR achieves state-of-the-art results on machine translation tasks."},{"source":"In this paper, we propose a new expert-based model, THOR ($\\underline{\\textbf{T}}$ransformer wit$\\underline{\\textbf{H}}$ St$\\underline{\\textbf{O}}$chastic Expe$\\underline{\\textbf{R}}$ts).","target":"THOR is more parameter efficient than Switch Transformer."},{"source":"In this paper, we propose a new expert-based model, THOR ($\\underline{\\textbf{T}}$ransformer wit$\\underline{\\textbf{H}}$ St$\\underline{\\textbf{O}}$chastic Expe$\\underline{\\textbf{R}}$ts).","target":"THOR makes more consistent predictions than Switch Transformer."},{"source":"THOR models are more parameter efficient and outperform Transformer and MoE models.","target":"THOR: Transformer with Stochastic Experts"},{"source":"THOR achieves state-of-the-art results on machine translation tasks.","target":"THOR: Transformer with Stochastic Experts"},{"source":"THOR is more parameter efficient than Switch Transformer.","target":"THOR: Transformer with Stochastic Experts"},{"source":"THOR makes more consistent predictions than Switch Transformer.","target":"THOR: Transformer with Stochastic Experts"},{"source":"THOR: Transformer with Stochastic Experts","target":"Low-Resource Translation"},{"source":"THOR: Transformer with Stochastic Experts","target":"Rich-Resource Translation"},{"source":"THOR: Transformer with Stochastic Experts","target":"Multilingual Translation"},{"source":"THOR: Transformer with Stochastic Experts","target":"Ablation Experiments"}],"valid_status":"Valid","valid_status_all":["Valid"]},"related":[{"summary":"The Related Paper supports the Main Paper by addressing the common issue of parameter inefficiency in Mixture-of-Experts (MoE) models, which is also a central theme in the Main Paper. While the Main Paper introduces THOR, a model that activates experts randomly and employs a consistency regularized loss for improved performance, the Related Paper proposes a Stratified Mixture of Experts (SMoE) that assigns dynamic capacity to experts based on token complexity. Both papers highlight the limitations of traditional MoE models and present innovative solutions that enhance parameter efficiency and performance in multilingual machine translation tasks.","paper_id":"09d3a354d22d75deddb0dcc99870f307aae2fd3c","title":"Towards Being Parameter-Efficient: A Stratified Sparsely Activated Transformer with Dynamic Capacity","abstract":"Mixture-of-experts (MoE) models that employ sparse activation have demonstrated effectiveness in significantly increasing the number of parameters while maintaining low computational requirements per token. However, recent studies have established that MoE models are inherently parameter-inefficient as the improvement in performance diminishes with an increasing number of experts. We hypothesize this parameter inefficiency is a result of all experts having equal capacity, which may not adequately meet the varying complexity requirements of different tokens or tasks. In light of this, we propose Stratified Mixture of Experts (SMoE) models, which feature a stratified structure and can assign dynamic capacity to different tokens. We demonstrate the effectiveness of SMoE on three multilingual machine translation benchmarks, containing 4, 15, and 94 language pairs, respectively. We show that SMoE outperforms multiple state-of-the-art MoE models with the same or fewer parameters.","score":0.7471403479576111,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"In this paper, we propose a new expert-based model, THOR (\\underline{\\textbf{T}}ransformer wit\\underline{\\textbf{H}} St\\underline{\\textbf{O}}chastic Expe\\underline{\\textbf{R}}ts). Unlike classic expert-based models, such as the Switch Transformer, experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions. We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/Stochastic-Mixture-of-Experts."},{"summary":"The Related Paper supports the Main Paper by demonstrating the effectiveness of Transformer-based architectures in enhancing translation performance, particularly in low-resource settings. While the Main Paper introduces THOR, a novel expert-based model that improves parameter efficiency in machine translation, the Related Paper validates the use of Transformer models in challenging contexts, showing that they can outperform traditional methods. Both papers emphasize the importance of innovative approaches to model training and data utilization, reinforcing the Main Paper's claims about the potential of advanced architectures like THOR.","paper_id":"4b70f1733b1b85917eefc24e613cd769a1d3fcba","title":"Enhancing Neural Machine Translation for the Sinhala-Tamil Language Pair with Limited Resources","abstract":"Neural Machine Translation has emerged as a promising approach for language translation. Transformer-based deep learning architectures have also significantly enhanced translation performance across various language pairs. However, several language pairs with limited resources face challenges in adopting Neural Machine Translation because of their data requirements. This study investigates methods for expanding the parallel corpus to enhance translation quality.We establish a series of effective guidelines for enhancing Tamil-to-Sinhala machine translation based on cutting-edge Neural Machine Translation techniques like fine-tuning hyperparameters and data augmentation through both forward and backward translation. We validate our methods empirically using standard evaluation metrics. Based on our conducted experiments, we observed that Neural Machine Translation models trained on larger sets of back-translated data outperform other methods of synthetic data generation in Transformer-based training settings. We investigated if we could effectively use the Transformer architecture in the limited-resource context of translating Tamil to Sinhala. Our research demonstrated that Transformer models can surpass the top Statistical Machine Translation models, even in language pairs with limited resources. We achieved an improvement of 3.43 BLEU points in translation quality compared to the statistical translation models.","score":0.7082688808441162,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"In this paper, we propose a new expert-based model, THOR (\\underline{\\textbf{T}}ransformer wit\\underline{\\textbf{H}} St\\underline{\\textbf{O}}chastic Expe\\underline{\\textbf{R}}ts). Unlike classic expert-based models, such as the Switch Transformer, experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions. We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/Stochastic-Mixture-of-Experts."},{"summary":"The Related Paper, 'ResiDual: Transformer with Dual Residual Connections,' supports the Main Paper by providing insights into the optimization of Transformer architectures, which is relevant to the performance improvements discussed in the Main Paper. While the Main Paper introduces THOR, a model that enhances parameter efficiency through stochastic expert activation, the Related Paper addresses the challenges of residual connections in Transformers, which can impact training effectiveness. Both papers focus on improving Transformer models for machine translation tasks, with the Related Paper's findings on residual connections potentially complementing the Main Paper's approach to expert activation, thereby reinforcing the overall argument for enhancing Transformer efficiency and performance.","paper_id":"8f7f7b48184217c131844d725daefe6734735d8a","title":"ResiDual: Transformer with Dual Residual Connections","abstract":"Transformer networks have become the preferred architecture for many tasks due to their state-of-the-art performance. However, the optimal way to implement residual connections in Transformer, which are essential for effective training, is still debated. Two widely used variants are the Post-Layer-Normalization (Post-LN) and Pre-Layer-Normalization (Pre-LN) Transformers, which apply layer normalization after each residual block's output or before each residual block's input, respectively. While both variants enjoy their advantages, they also suffer from severe limitations: Post-LN causes gradient vanishing issue that hinders training deep Transformers, and Pre-LN causes representation collapse issue that limits model capacity. In this paper, we propose ResiDual, a novel Transformer architecture with Pre-Post-LN (PPLN), which fuses the connections in Post-LN and Pre-LN together and inherits their advantages while avoids their limitations. We conduct both theoretical analyses and empirical experiments to verify the effectiveness of ResiDual. Theoretically, we prove that ResiDual has a lower bound on the gradient to avoid the vanishing issue due to the residual connection from Pre-LN. Moreover, ResiDual also has diverse model representations to avoid the collapse issue due to the residual connection from Post-LN. Empirically, ResiDual outperforms both Post-LN and Pre-LN on several machine translation benchmarks across different network depths and data sizes. Thanks to the good theoretical and empirical performance, ResiDual Transformer can serve as a foundation architecture for different AI models (e.g., large language models). Our code is available at https://github.com/microsoft/ResiDual.","score":0.6991726160049438,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"In this paper, we propose a new expert-based model, THOR (\\underline{\\textbf{T}}ransformer wit\\underline{\\textbf{H}} St\\underline{\\textbf{O}}chastic Expe\\underline{\\textbf{R}}ts). Unlike classic expert-based models, such as the Switch Transformer, experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions. We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/Stochastic-Mixture-of-Experts."},{"summary":"The Related Paper, R-Drop, supports the Main Paper by introducing a regularization technique that enhances model consistency, which aligns with the Main Paper's approach of using a consistency regularized loss in THOR. Both papers emphasize the importance of training models to produce consistent predictions, with R-Drop demonstrating significant improvements in various tasks, including machine translation, similar to the performance gains reported for THOR. This connection highlights the effectiveness of regularization strategies in improving the performance of sparsely activated models.","paper_id":"520bd2331cca8d5a9c032c186a2a0f7704ead6ff","title":"R-Drop: Regularized Dropout for Neural Networks","abstract":"Dropout is a powerful and widely used technique to regularize the training of deep neural networks. In this paper, we introduce a simple regularization strategy upon dropout in model training, namely R-Drop, which forces the output distributions of different sub models generated by dropout to be consistent with each other. Specifically, for each training sample, R-Drop minimizes the bidirectional KL-divergence between the output distributions of two sub models sampled by dropout. Theoretical analysis reveals that R-Drop reduces the freedom of the model parameters and complements dropout. Experiments on $\\bf{5}$ widely used deep learning tasks ($\\bf{18}$ datasets in total), including neural machine translation, abstractive summarization, language understanding, language modeling, and image classification, show that R-Drop is universally effective. In particular, it yields substantial improvements when applied to fine-tune large-scale pre-trained models, e.g., ViT, RoBERTa-large, and BART, and achieves state-of-the-art (SOTA) performances with the vanilla Transformer model on WMT14 English$\\to$German translation ($\\bf{30.91}$ BLEU) and WMT14 English$\\to$French translation ($\\bf{43.95}$ BLEU), even surpassing models trained with extra large-scale data and expert-designed advanced variants of Transformer models. Our code is available at GitHub{\\url{https://github.com/dropreg/R-Drop}}.","score":0.6959944367408752,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"In this paper, we propose a new expert-based model, THOR (\\underline{\\textbf{T}}ransformer wit\\underline{\\textbf{H}} St\\underline{\\textbf{O}}chastic Expe\\underline{\\textbf{R}}ts). Unlike classic expert-based models, such as the Switch Transformer, experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions. We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/Stochastic-Mixture-of-Experts."},{"summary":"The Related Paper supports the Main Paper by highlighting the effectiveness of Transformer-based architectures in machine translation, particularly in low-resource scenarios. It emphasizes the importance of data augmentation and hyper-parameter tuning, which aligns with the Main Paper's focus on improving model efficiency and performance. Both papers demonstrate that innovative approaches can lead to significant performance gains, with the Related Paper providing empirical validation of methods that enhance translation quality, thereby reinforcing the Main Paper's claims about the advantages of the THOR model in outperforming traditional models.","paper_id":"06f2eff174b86f1952269ffab30e2e54b122489f","title":"Exploring Low-resource Neural Machine Translation for Sinhala-Tamil Language Pair","abstract":"At present, Neural Machine Translation is a promising approach for machine translation. Transformer-based deep learning architectures in particular show a substantial performance increase in translating between various language pairs. However, many low-resource language pairs still struggle to lend themselves to Neural Machine Translation due to their data-hungry nature. In this article, we investigate methods of expanding the parallel corpus to enhance translation quality within a model training pipeline, starting from the initial collection of parallel data to the training process of baseline models. Grounded on state-of-the-art Neural Machine Translation approaches such as hyper-parameter tuning, and data augmentation with forward and backward translation, we define a set of best practices for improving Tamil-to-Sinhala machine translation and empirically validate our methods using standard evaluation metrics. Our results demonstrate that the Neural Machine Translation models trained on larger amounts of back-translated data outperform other synthetic data generation approaches in Transformer base training settings. We further demonstrate that, even for language pairs with limited resources, Transformer models are able to tune to outperform existing state-of-the-art Statistical Machine Translation models by as much as 3.28 BLEU points in the Tamil to Sinhala translation scenarios.","score":0.694338321685791,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"In this paper, we propose a new expert-based model, THOR (\\underline{\\textbf{T}}ransformer wit\\underline{\\textbf{H}} St\\underline{\\textbf{O}}chastic Expe\\underline{\\textbf{R}}ts). Unlike classic expert-based models, such as the Switch Transformer, experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions. We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/Stochastic-Mixture-of-Experts."},{"summary":"The Related Paper critiques the Main Paper's assertion that random routing of inputs to experts is more effective than traditional gating mechanisms. It emphasizes that the performance of Sparse Mixture-of-Experts (MoE) models is heavily reliant on the routing strategy, arguing that poor routing can lead to suboptimal expert training. In contrast, the Related Paper introduces a novel routing mechanism that optimizes token-expert matching, demonstrating improved training efficiency and performance across multiple benchmarks, thereby challenging the Main Paper's claims about the efficacy of random activation.","paper_id":"6420b93373e8e95571471e672e3581b6e5335211","title":"Efficient Routing in Sparse Mixture-of-Experts","abstract":"Sparse Mixture-of-Experts (MoE) architectures provide the distinct benefit of substantially expanding the model’s parameter space without proportionally increasing the computational load on individual input tokens or samples. However, the efficacy of these models heavily depends on the routing strategy used to assign tokens to experts. Poor routing can lead to under-trained or overly specialized experts, diminishing the overall model performance. Previous approaches have relied on the Topk router, where each token is assigned to a subset of experts. In this paper, we propose a routing mechanism that replaces the Topk router with regularized optimal transport, leveraging the Sinkhorn algorithm to optimize token-expert matching. We conducted a comprehensive evaluation comparing the pre-training efficiency of our model, using computational resources equivalent to those employed in the GShard and Switch Transformers gating mechanisms. The results demonstrate that our model expedites training convergence, achieving a speedup of over 2× compared to these baseline models. Moreover, under the same computational constraints, our model exhibits superior performance across eleven tasks from the GLUE and SuperGLUE benchmarks. We show that our model contributes to the optimization of token-expert matching in sparsely-activated MoE models, offering substantial gains in both training efficiency and task performance.","score":0.8133469820022583,"polarity":"negative","source":"semantic","contexts":null,"background":"Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts.","target":null},{"summary":"The Related Paper critiques the Main Paper's approach by emphasizing the importance of expert routing strategies in Mixture-of-Experts (MoE) models. While the Main Paper advocates for random expert activation in THOR, the Related Paper argues that a poor routing strategy can lead to under-trained experts and proposes a method where experts select tokens, resulting in improved training convergence and performance on benchmark tasks. This contrast highlights the potential limitations of the Main Paper's methodology in achieving optimal parameter efficiency.","paper_id":"bbc57e1b3cf90e09b64377f13de455793bc81ad5","title":"Mixture-of-Experts with Expert Choice Routing","abstract":"Sparsely-activated Mixture-of-experts (MoE) models allow the number of parameters to greatly increase while keeping the amount of computation for a given token or a given sample unchanged. However, a poor expert routing strategy (e.g. one resulting in load imbalance) can cause certain experts to be under-trained, leading to an expert being under or over-specialized. Prior work allocates a fixed number of experts to each token using a top-k function regardless of the relative importance of different tokens. To address this, we propose a heterogeneous mixture-of-experts employing an expert choice method. Instead of letting tokens select the top-k experts, we have experts selecting the top-k tokens. As a result, each token can be routed to a variable number of experts and each expert can have a fixed bucket size. We systematically study pre-training speedups using the same computational resources of the Switch Transformer top-1 and GShard top-2 gating of prior work and find that our method improves training convergence time by more than 2x. For the same computational cost, our method demonstrates higher performance in fine-tuning 11 selected tasks in the GLUE and SuperGLUE benchmarks. For a smaller activation cost, our method outperforms the T5 dense model in 7 out of the 11 tasks.","score":0.7968876361846924,"polarity":"negative","source":"semantic","contexts":null,"background":"Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts.","target":null},{"summary":"The Related Paper, titled 'MoEC: Mixture of Expert Clusters', contrasts with the Main Paper by emphasizing the limitations of scaling up sparsely activated models (SAMs) like MoE, particularly highlighting issues of overfitting and sparse data allocation that arise with an increasing number of experts. While the Main Paper proposes a novel approach (THOR) that claims to improve parameter efficiency through random expert activation, the Related Paper argues that there is a performance upper bound to scaling MoE models, suggesting that simply increasing model size does not guarantee better performance. Additionally, the Related Paper introduces a variance-based constraint on routing to enhance expert diversity, which challenges the Main Paper's assertion that random routing can be effective.","paper_id":"1c1eaea99e0cbbd4616125049bae8c6787bd368c","title":"MoEC: Mixture of Expert Clusters","abstract":"Sparsely Mixture of Experts (MoE) has received great interest due to its promising scaling capability with affordable computational overhead. MoE models convert dense layers into sparse experts, and utilize a gated routing network to make experts conditionally activated. However, as the number of experts grows, MoE with outrageous parameters suffers from overfitting and sparse data allocation. Such problems are especially severe on tasks with limited data, thus hindering the progress towards improving performance by scaling up. We verify that there exists a performance upper bound of scaling up sparse MoE. In this work, we propose Mixture of Expert Clusters — a general approach to enable expert layers to learn more diverse and appropriate knowledge by imposing variance-based constraints on the routing stage. Given this, we could further propose a cluster-level expert dropout strategy specifically designed for the expert cluster structure. Our experiments reveal that MoEC could improve performance on machine translation and natural language understanding tasks. MoEC plays a positive role in mitigating overfitting and sparse data allocation problems, thus fully releasing the potential of large-scale sparse models.","score":0.7596080303192139,"polarity":"negative","source":"semantic","contexts":null,"background":"Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts.","target":null},{"summary":"The Related Paper critiques the Main Paper's approach by emphasizing the limitations of Soft Mixture of Experts (MoE) in achieving effective representation power, arguing that simply having many small experts does not equate to the capabilities of a single large expert. It highlights that the implicit biases introduced by the smooth gating mechanism in Soft MoE can hinder expert specialization, contrasting with the Main Paper's claim that randomly activating experts in THOR leads to improved parameter efficiency and performance. This suggests that the assumptions made in the Main Paper regarding expert activation and performance may overlook critical aspects of expert representation and specialization.","paper_id":"f5d66a1b1492579827147687a2a2e72537a90e05","title":"Beyond Parameter Count: Implicit Bias in Soft Mixture of Experts","abstract":"The traditional viewpoint on Sparse Mixture of Experts (MoE) models is that instead of training a single large expert, which is computationally expensive, we can train many small experts. The hope is that if the total parameter count of the small experts equals that of the singular large expert, then we retain the representation power of the large expert while gaining computational tractability and promoting expert specialization. The recently introduced Soft MoE replaces the Sparse MoE's discrete routing mechanism with a differentiable gating function that smoothly mixes tokens. While this smooth gating function successfully mitigates the various training instabilities associated with Sparse MoE, it is unclear whether it induces implicit biases that affect Soft MoE's representation power or potential for expert specialization. We prove that Soft MoE with a single arbitrarily powerful expert cannot represent simple convex functions. This justifies that Soft MoE's success cannot be explained by the traditional viewpoint of many small experts collectively mimicking the representation power of a single large expert, and that multiple experts are actually necessary to achieve good representation power (even for a fixed total parameter count). Continuing along this line of investigation, we introduce a notion of expert specialization for Soft MoE, and while varying the number of experts yet fixing the total parameter count, we consider the following (computationally intractable) task. Given any input, how can we discover the expert subset that is specialized to predict this input's label? We empirically show that when there are many small experts, the architecture is implicitly biased in a fashion that allows us to efficiently approximate the specialized expert subset. Our method can be easily implemented to potentially reduce computation during inference.","score":0.7402793169021606,"polarity":"negative","source":"semantic","contexts":null,"background":"Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts.","target":null},{"summary":"The Related Paper on Switch Transformers supports the Main Paper by highlighting the challenges and limitations of traditional Mixture-of-Experts (MoE) models, which the Main Paper addresses through its novel THOR model. Both papers emphasize the benefits of sparsely activated models, but while the Related Paper focuses on improving routing algorithms and training stability, the Main Paper proposes a fundamentally different approach with random expert activation and a consistency regularized loss. This contrast underscores the Main Paper's contribution to enhancing parameter efficiency and performance in machine translation tasks.","paper_id":"fdacf2a732f55befdc410ea927091cad3b791f13","title":"Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity","abstract":"In deep learning, models typically reuse the same parameters for all inputs. Mixture of Experts (MoE) defies this and instead selects different parameters for each incoming example. The result is a sparsely-activated model -- with outrageous numbers of parameters -- but a constant computational cost. However, despite several notable successes of MoE, widespread adoption has been hindered by complexity, communication costs and training instability -- we address these with the Switch Transformer. We simplify the MoE routing algorithm and design intuitive improved models with reduced communication and computational costs. Our proposed training techniques help wrangle the instabilities and we show large sparse models may be trained, for the first time, with lower precision (bfloat16) formats. We design models based off T5-Base and T5-Large to obtain up to 7x increases in pre-training speed with the same computational resources. These improvements extend into multilingual settings where we measure gains over the mT5-Base version across all 101 languages. Finally, we advance the current scale of language models by pre-training up to trillion parameter models on the\"Colossal Clean Crawled Corpus\"and achieve a 4x speedup over the T5-XXL model.","score":0.5169411897659302,"polarity":"positive","source":"citations","contexts":[{"sentence":"Unlike classic expert-based models, such as the Switch Transformer \\citep{fedus2021switch}, experts in THOR are randomly activated for each input during training and inference.","polarity":"positive"},{"sentence":"For example, the sparsely activated GShard \\citep{lepikhin2020gshard} consists of over 600 billion parameters and the Switch Transformer \\citep{fedus2021switch} 1.5 trillion parameters, while GPT-3 \\citep{brown2020language}, which is arguably the largest d","polarity":"positive"},{"sentence":"For example, training of Switch-large \\citep{fedus2021switch} and that of T5-large \\citep{raffel2019exploring} require the same forward FLOPs, despite that the former is 35 times larger (26.3 vs. 0.74 billion parameters).","polarity":"positive"},{"sentence":"Existing works \\citep{shazeer2017outrageously, lepikhin2020gshard, fedus2021switch, yang2021exploring} use a gating network for input routing.","polarity":"positive"},{"sentence":"Therefore, many methods are proposed to mitigate this issue, such as noisy gating \\citep{shazeer2017outrageously}, expert capacity \\citep{lepikhin2020gshard}, load balancing loss \\citep{lepikhin2020gshard, fedus2021switch}, and MATH_PLACEHOLDER Top- MATH_P","polarity":"positive"},{"sentence":"We consider two MoE models proposed in \\citet{shen2019mixture}, referred to as MoE(dec) and MoE(tok), respectively, and three variants of the Switch Transformer proposed in \\citet{fedus2021switch}.","polarity":"positive"},{"sentence":"The former is also reported in recent papers \\citep{shazeer2017outrageously, lepikhin2020gshard, fedus2021switch}.","polarity":"positive"},{"sentence":"We further investigate the Switch Transformer \\citep{fedus2021switch}, which is a state-of-the-art MoE variant that incorporates various methods to resolve the load imbalance issue.","polarity":"positive"},{"sentence":"{Switch Transformer} \\citep{fedus2021switch} is a state-of-the-art MoE model, which employs a gating mechanism to route inputs and uses a load balancing loss to reduce load imbalance.","polarity":"positive"},{"sentence":"-0.1in {l|cccccc} & En-Vi & Vi-En & En-De & De-En & En-Fr & Fr-En \\\\ Transformer \\citep{vaswani2017attention} & 31.3 & 29.4 & 28.1 & 34.8 & 39.2 & 38.1 \\\\ SMART \\citep{jiang2019smart} & 32.5 & 30.5 & 29.3 & 35.8 & 40.0 & 38.8 \\\\ R3F \\citep{aghajanyan2020be","polarity":"positive"},{"sentence":"Results of \\citet{jiang2019smart}, \\citet{aghajanyan2020better}, and \\citet{fedus2021switch} are from our implementation.}","polarity":"positive"},{"sentence":"-0.1in {l|cc} & En-De & En-Fr \\\\ \\citet{vaswani2017attention} & 28.4 & 41.8 \\\\ \\citet{ott2018scaling} & 29.3 & 43.2 \\\\ \\citet{wang2019learning} & 29.6 & --- \\\\ \\citet{wu2019pay} & 29.7 & 43.2 \\\\ \\citet{so2019evolved} & 29.8 & 41.3 \\\\ \\citet{jiang2019smart}","polarity":"positive"},{"sentence":"Our observations are consistent with existing literature \\citep{lepikhin2020gshard, fedus2021switch}.","polarity":"positive"},{"sentence":"For example, in \\citealt{fedus2021switch}, the sparsely activated Switch-base outperforms the densely activated T5-base using the same number of FLOPs.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper provides insights into the challenges of training Transformer models, highlighting the importance of model stability and effective initialization strategies. This supports the Main Paper's claims about the efficiency of the THOR model, as it addresses the common training difficulties faced by traditional Transformers. By demonstrating that THOR's random activation of experts can mitigate training instability, the Related Paper reinforces the Main Paper's assertion that innovative approaches to model design can lead to improved performance and parameter efficiency.","paper_id":"8d908042f139575d6688c745e94156c9df6eae07","title":"Understanding the Difficulty of Training Transformers","abstract":"Transformers have been proved effective for many deep learning tasks. Training transformers, however, requires non-trivial efforts regarding carefully designing learning rate schedulers and cutting-edge optimizers (the standard SGD fails to train Transformers effectively). In this paper, we study Transformer training from both theoretical and empirical perspectives. Our analysis reveals that unbalanced gradients are not the root cause of the instability of training. Instead, we identify an amplification effect that substantially influences training. Specifically, we observe that for each layer in a multi-layer Transformer model, heavy dependency on its residual branch makes training unstable since it amplifies small parameter perturbations (e.g., parameter updates) and result in significant disturbances in the model output, yet a light dependency limits the potential of model training and can lead to an inferior trained model. Inspired by our analysis, we propose Admin ($\\mathbf{Ad}$aptive $\\mathbf{m}$odel $\\mathbf{in}$itialization) to stabilize the training in the early stage and unleash its full potential in the late stage. Extensive experiments show that Admin is more stable, converges faster, and leads to better performance.","score":0.40364229679107666,"polarity":"positive","source":"citations","contexts":[{"sentence":"Specifically, lifts the previous state-of-the-art \\citep{liu2020admin,liu2020very} by MATH_PLACEHOLDER BLEU score on the En-De translation task and MATH_PLACEHOLDER BLEU score on the En-Fr translation task.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper, \"Exploring Sparse Expert Models and Beyond,\" supports the Main Paper by reinforcing the notion that while Mixture-of-Experts (MoE) models can scale effectively, the routing methods used significantly impact model performance. It highlights the importance of the number of activated experts and expert capacity, which aligns with the Main Paper's findings that traditional gating mechanisms may not be optimal. Additionally, the Related Paper's introduction of expert prototyping complements the Main Paper's approach by suggesting alternative strategies to enhance model quality while maintaining computational efficiency, thereby validating the Main Paper's emphasis on innovative routing methods.","paper_id":"7777a31341fa4bfbd25b96a5320681af8dccf3af","title":"Exploring Sparse Expert Models and Beyond","abstract":"Mixture-of-Experts (MoE) models can achieve promising results with outrageous large amount of parameters but constant computation cost, and thus it has become a trend in model scaling. Still it is a mystery how MoE layers bring quality gains by leveraging the parameters with sparse activation. In this work, we investigate several key factors in sparse expert models. We observe that load imbalance may not be a significant problem affecting model quality, contrary to the perspectives of recent studies, while the number of sparsely activated experts $k$ and expert capacity $C$ in top-$k$ routing can significantly make a difference in this context. Furthermore, we take a step forward to propose a simple method called expert prototyping that splits experts into different prototypes and applies $k$ top-$1$ routing. This strategy improves the model quality but maintains constant computational costs, and our further exploration on extremely large-scale models reflects that it is more effective in training larger models. We push the model scale to over $1$ trillion parameters and implement it on solely $480$ NVIDIA V100-32GB GPUs, in comparison with the recent SOTAs on $2048$ TPU cores. The proposed giant model achieves substantial speedup in convergence over the same-size baseline.","score":0.39850133657455444,"polarity":"positive","source":"citations","contexts":[{"sentence":"Existing works \\citep{shazeer2017outrageously, lepikhin2020gshard, fedus2021switch, yang2021exploring} use a gating network for input routing.","polarity":"positive"},{"sentence":"Therefore, many methods are proposed to mitigate this issue, such as noisy gating \\citep{shazeer2017outrageously}, expert capacity \\citep{lepikhin2020gshard}, load balancing loss \\citep{lepikhin2020gshard, fedus2021switch}, and MATH_PLACEHOLDER Top- MATH_P","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper, 'The Evolved Transformer', supports the Main Paper by demonstrating the effectiveness of innovative approaches to improve Transformer architectures, similar to the Main Paper's focus on enhancing sparsely activated models. Both papers emphasize the importance of parameter efficiency and performance in machine translation tasks, with the Related Paper showcasing a new state-of-the-art model that achieves better results with fewer parameters. This aligns with the Main Paper's findings that THOR outperforms existing models while maintaining parameter efficiency, reinforcing the argument for exploring novel architectures and training methods.","paper_id":"16c844fd4d97f3c6eb38b0d6527c87d184efedc3","title":"The Evolved Transformer","abstract":"Recent works have highlighted the strength of the Transformer architecture on sequence tasks while, at the same time, neural architecture search (NAS) has begun to outperform human-designed models. Our goal is to apply NAS to search for a better alternative to the Transformer. We first construct a large search space inspired by the recent advances in feed-forward sequence models and then run evolutionary architecture search with warm starting by seeding our initial population with the Transformer. To directly search on the computationally expensive WMT 2014 English-German translation task, we develop the Progressive Dynamic Hurdles method, which allows us to dynamically allocate more resources to more promising candidate models. The architecture found in our experiments -- the Evolved Transformer -- demonstrates consistent improvement over the Transformer on four well-established language tasks: WMT 2014 English-German, WMT 2014 English-French, WMT 2014 English-Czech and LM1B. At a big model size, the Evolved Transformer establishes a new state-of-the-art BLEU score of 29.8 on WMT'14 English-German; at smaller sizes, it achieves the same quality as the original \"big\" Transformer with 37.6% less parameters and outperforms the Transformer by 0.7 BLEU at a mobile-friendly model size of 7M parameters.","score":0.3927440345287323,"polarity":"positive","source":"citations","contexts":[{"sentence":"-0.1in {l|cc} & En-De & En-Fr \\\\ \\citet{vaswani2017attention} & 28.4 & 41.8 \\\\ \\citet{ott2018scaling} & 29.3 & 43.2 \\\\ \\citet{wang2019learning} & 29.6 & --- \\\\ \\citet{wu2019pay} & 29.7 & 43.2 \\\\ \\citet{so2019evolved} & 29.8 & 41.3 \\\\ \\citet{jiang2019smart}","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper supports the Main Paper by providing a foundational understanding of sparsely activated models (SAMs) and their potential for increasing model capacity through conditional computation. It highlights the challenges faced in practical implementations of such models, which the Main Paper addresses by proposing the THOR model that utilizes random activation of experts. Both papers emphasize the importance of parameter efficiency in machine translation tasks, with the Related Paper showcasing the benefits of the Sparsely-Gated Mixture-of-Experts layer, while the Main Paper demonstrates that THOR outperforms existing models, including MoE, in terms of performance and efficiency.","paper_id":"510e26733aaff585d65701b9f1be7ca9d5afc586","title":"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer","abstract":"The capacity of a neural network to absorb information is limited by its number of parameters. Conditional computation, where parts of the network are active on a per-example basis, has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation. In practice, however, there are significant algorithmic and performance challenges. In this work, we address these challenges and finally realize the promise of conditional computation, achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters. We introduce a Sparsely-Gated Mixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward sub-networks. A trainable gating network determines a sparse combination of these experts to use for each example. We apply the MoE to the tasks of language modeling and machine translation, where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora. We present model architectures in which a MoE with up to 137 billion parameters is applied convolutionally between stacked LSTM layers. On large language modeling and machine translation benchmarks, these models achieve significantly better results than state-of-the-art at lower computational cost.","score":0.35752832889556885,"polarity":"positive","source":"citations","contexts":[{"sentence":"To address these issues, sparsely activated models (SAMs, \\citealt{shazeer2017outrageously}) have been proposed.","polarity":"positive"},{"sentence":"Existing works \\citep{shazeer2017outrageously, lepikhin2020gshard, fedus2021switch, yang2021exploring} use a gating network for input routing.","polarity":"positive"},{"sentence":"Therefore, many methods are proposed to mitigate this issue, such as noisy gating \\citep{shazeer2017outrageously}, expert capacity \\citep{lepikhin2020gshard}, load balancing loss \\citep{lepikhin2020gshard, fedus2021switch}, and MATH_PLACEHOLDER Top- MATH_P","polarity":"positive"},{"sentence":"The former is also reported in recent papers \\citep{shazeer2017outrageously, lepikhin2020gshard, fedus2021switch}.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper contrasts the Main Paper by emphasizing the effectiveness of dense networks in Computer Vision, arguing that while the Main Paper's THOR model claims superior parameter efficiency in NLP, the V-MoE achieves competitive performance in image recognition with a sparse approach. Additionally, the Related Paper highlights an advanced routing algorithm that enhances performance and compute efficiency, suggesting that the routing methods proposed in the Main Paper may not be as universally applicable or effective in different domains.","paper_id":"8690d62d4bbbd0b1ed5e1f25320d10853bfbeb01","title":"Scaling Vision with Sparse Mixture of Experts","abstract":"Sparsely-gated Mixture of Experts networks (MoEs) have demonstrated excellent scalability in Natural Language Processing. In Computer Vision, however, almost all performant networks are\"dense\", that is, every input is processed by every parameter. We present a Vision MoE (V-MoE), a sparse version of the Vision Transformer, that is scalable and competitive with the largest dense networks. When applied to image recognition, V-MoE matches the performance of state-of-the-art networks, while requiring as little as half of the compute at inference time. Further, we propose an extension to the routing algorithm that can prioritize subsets of each input across the entire batch, leading to adaptive per-image compute. This allows V-MoE to trade-off performance and compute smoothly at test-time. Finally, we demonstrate the potential of V-MoE to scale vision models, and train a 15B parameter model that attains 90.35% on ImageNet.","score":0.4472891092300415,"polarity":"negative","source":"citations","contexts":[{"sentence":"There are other works in different research fields (e.g., computer vision) that draw different conclusions than ours \\citep{riquelme2021scaling}.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper introduces the BASE layer, which emphasizes balanced routing of tokens to experts, contrasting with the Main Paper's THOR model that advocates for random expert activation. While the Main Paper argues that traditional gating mechanisms are ineffective, the Related Paper claims that optimal token-to-expert allocation can enhance efficiency and simplify training without additional hyperparameters. This highlights a fundamental difference in approach: THOR's stochastic method versus BASE's structured routing.","paper_id":"b15ea460c77a4ee8aa159a30ab0331deedfcf392","title":"BASE Layers: Simplifying Training of Large, Sparse Models","abstract":"We introduce a new balanced assignment of experts (BASE) layer for large language models that greatly simplifies existing high capacity sparse layers. Sparse layers can dramatically improve the efficiency of training and inference by routing each token to specialized expert modules that contain only a small fraction of the model parameters. However, it can be difficult to learn balanced routing functions that make full use of the available experts; existing approaches typically use routing heuristics or auxiliary expert-balancing loss functions. In contrast, we formulate token-to-expert allocation as a linear assignment problem, allowing an optimal assignment in which each expert receives an equal number of tokens. This optimal assignment scheme improves efficiency by guaranteeing balanced compute loads, and also simplifies training by not requiring any new hyperparameters or auxiliary losses. Code is publicly released at https://github.com/pytorch/fairseq/","score":0.30092287063598633,"polarity":"negative","source":"citations","contexts":[{"sentence":"Existing works adopt various ad-hoc heuristics to mitigate this issue, e.g., adding Gaussian noise to Eq.~ (noisy gating, \\citealt{shazeer2017outrageously}), limiting the maximum number of inputs that can be routed to an expert (expert capacity, \\citealt{l","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper contrasts the Main Paper by presenting an alternative approach to training sparse layers in Transformer models through hashing, rather than the random activation of experts proposed in THOR. While the Main Paper claims that its method significantly outperforms existing models like the Switch Transformer, the Related Paper argues that its hashing technique is either competitive or superior without the need for routing parameters or complex algorithms. This suggests that the efficiency and performance improvements claimed by the Main Paper may not be as robust when compared to the simpler hashing approach.","paper_id":"0611d2f2ea6a3c8fb8534f42758a5a3e9c7bc8fe","title":"Hash Layers For Large Sparse Models","abstract":"We investigate the training of sparse layers that use different parameters for different inputs based on hashing in large Transformer models. Specifically, we modify the feedforward layer to hash to different sets of weights depending on the current token, over all tokens in the sequence. We show that this procedure either outperforms or is competitive with learning-to-route mixture-of-expert methods such as Switch Transformers and BASE Layers, while requiring no routing parameters or extra terms in the objective function such as a load balancing loss, and no sophisticated assignment algorithm. We study the performance of different hashing techniques, hash sizes and input features, and show that balanced and random hashes focused on the most local features work best, compared to either learning clusters or using longer-range context. We show our approach works well both on large language modeling and dialogue tasks, and on downstream fine-tuning tasks.","score":0.20581886172294617,"polarity":"negative","source":"citations","contexts":[{"sentence":"There are other works that remove the gating mechanism such that load imbalance is no longer an issue, e.g., by incorporating hash functions \\citep{roller2021hash}.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper presents the AI2 Reasoning Challenge (ARC), which highlights the limitations of existing models in advanced question answering, contrasting the Main Paper's claims about the effectiveness of the THOR model in improving parameter efficiency in machine translation. While the Main Paper asserts that THOR outperforms traditional models through innovative expert activation and training methods, the Related Paper emphasizes that even leading neural models struggle to surpass random baselines on challenging question sets, suggesting that improvements in model architecture alone may not guarantee better performance in complex reasoning tasks.","paper_id":"88bb0a28bb58d847183ec505dda89b63771bb495","title":"Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge","abstract":"We present a new question set, text corpus, and baselines assembled to encourage AI research in advanced question answering. Together, these constitute the AI2 Reasoning Challenge (ARC), which requires far more powerful knowledge and reasoning than previous challenges such as SQuAD or SNLI. The ARC question set is partitioned into a Challenge Set and an Easy Set, where the Challenge Set contains only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurence algorithm. The dataset contains only natural, grade-school science questions (authored for human tests), and is the largest public-domain set of this kind (7,787 questions). We test several baselines on the Challenge Set, including leading neural models from the SQuAD and SNLI tasks, and find that none are able to significantly outperform a random baseline, reflecting the difficult nature of this task. We are also releasing the ARC Corpus, a corpus of 14M science sentences relevant to the task, and implementations of the three neural baseline models tested. Can your model perform better? We pose ARC as a challenge to the community.","score":0.021020572632551193,"polarity":"negative","source":"citations","contexts":[{"sentence":"For example, the performance of Switch-large is worse than T5-large on the ARC Reasoning Challenge (66.0 vs. 68.8) \\citep{clark2018think}.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper, GLUE, emphasizes the need for unified models capable of generalizing across multiple natural language understanding tasks, contrasting with the Main Paper's focus on sparsely activated models that may not improve performance despite increased parameters. While the Main Paper claims that THOR outperforms existing models in specific tasks, the Related Paper highlights the limitations of current models in handling out-of-domain data and achieving robust understanding, suggesting that merely increasing model complexity does not equate to better generalization or performance.","paper_id":"451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c","title":"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding","abstract":"Human ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.","score":-0.06134873256087303,"polarity":"negative","source":"citations","contexts":[{"sentence":"For example, although the Switch-large model is 35 times larger than T5-large, its performance on the GLUE benchmark \\citep{wang2018glue} is only slightly better (88.5 vs. 87.8).","polarity":"negative"}],"background":null,"target":null}],"paper":{"title":"Taming Sparsely Activated Transformer with Stochastic Experts","abstract":"Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts. In this paper, we propose a new expert-based model, THOR ($\\underline{\\textbf{T}}$ransformer wit$\\underline{\\textbf{H}}$ St$\\underline{\\textbf{O}}$chastic Expe$\\underline{\\textbf{R}}$ts). Unlike classic expert-based models, such as the Switch Transformer, experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions.  We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/Stochastic-Mixture-of-Experts.","authors":["Simiao Zuo","Xiaodong Liu","Jian Jiao","Young Jin Kim","Hany Hassan","Ruofei Zhang","Jianfeng Gao","Tuo Zhao"],"sections":[{"heading":"Introduction","text":"# Introduction\n\nLarge neural network models have shown to be effective in many natural language processing tasks such as machine translation [@lewis2019bart; @lample2019cross], natural language understanding [@devlin2018bert; @liu2019roberta; @he2020deberta], and natural language generation [@radford2019language; @brown2020language]. These models are usually densely activated. That is, a model uses all its parameters to process all inputs. One drawback of these models is the prohibitive training cost. Moreover, the extreme size drastically reduces inference speed, further limiting the models' practicality.\n\nTo address these issues, sparsely activated models (SAMs, @shazeer2017outrageously) have been proposed. A SAM adaptively selects a subset of its parameters for different inputs during model training and inference. This makes it possible to train SAMs that are an order of magnitude larger than densely activated models without significant increase in computational cost. For example, the sparsely activated GShard [@lepikhin2020gshard] consists of over 600 billion parameters and the Switch Transformer [@fedus2021switch] 1.5 trillion parameters, while GPT-3 [@brown2020language], which is arguably the largest densely activated model, consists of only 175 billion parameters.\n\nThe building block of SAMs is the expert layer, which contains an attention mechanism and multiple feed-forward neural networks (FFNs) in parallel. Each FFN is referred to as an *expert*. During training, an input is routed to a fixed number of experts, such that the number of floating point operations (FLOPs) of one forward pass remains constant, regardless of the total number of experts. Thus, training SAMs is much more cost-efficient than training densely activated models. For example, training of Switch-large [@fedus2021switch] and that of T5-large [@raffel2019exploring] require the same forward FLOPs, despite that the former is 35 times larger (26.3 vs. 0.74 billion parameters).\n\nHowever, SAMs have been reported to be *parameter inefficient*. For example, although the Switch-large model is 35 times larger than T5-large, its performance on the GLUE benchmark [@wang2018glue] is only slightly better (88.5 vs. 87.8). There are also cases where the performance of SAMs is even worse than smaller densely activated models. For example, the performance of Switch-large is worse than T5-large on the ARC Reasoning Challenge (66.0 vs. 68.8) [@clark2018think]. In another example, although GShard [@lepikhin2020gshard] shows substantial gains over densely activated models, a diminishing return with larger number of parameters has been observed.\n\nMost on-going research has focused on improving SAMs by developing effective *routing methods*. Since only a subset of model parameters (i.e., experts) are updated for each input during training, we need to decide which experts to be activated given an input. Existing works [@shazeer2017outrageously; @lepikhin2020gshard; @fedus2021switch; @yang2021exploring] use a gating network for input routing. However, the gating mechanism suffers from the notorious *load imbalance* issue: the gate's weight could collapse such that nearly all the inputs are routed to the same expert. Therefore, many methods are proposed to mitigate this issue, such as noisy gating [@shazeer2017outrageously], expert capacity [@lepikhin2020gshard], load balancing loss [@lepikhin2020gshard; @fedus2021switch], and $k$ Top-$1$ gating [@yang2021exploring]. However, these routing methods have not been proved effective to make SAMs more parameter efficient. To understand why SAMs are not parameter efficient, we analyze the performance of several classic MoE models. Our analysis reveals that a SAM does not always outperform a densely activated model of a similar size, confirming the results reported in @yang2021exploring. Moreover, we also observe that the widely-used routing method based on the gating mechanism does not work better than randomly routing inputs to experts,\n\nInspired by our findings, we propose a new SAM, $\\text{THOR}~$([**T**]{.underline}ransformer wit[**H**]{.underline} St[**O**]{.underline}chastic Expe[**R**]{.underline}ts). Unlike classic SAMs, such as the Switch Transformer, experts in $\\text{THOR}~$are randomly activated (with no need of any gating mechanism) for each input during training and inference. $\\text{THOR}~$models are trained by minimizing both the cross-entropy loss and a consistency regularization term, such that experts can learn not only from training data but also from other experts as teachers so that all the experts make consistent predictions.\n\nTo validate the effectiveness of THOR, we have conducted extensive experiments on machine translation using three settings: low-resource, rich-resource, and multilingual. Results show that $\\text{THOR}~$models outperform state-of-the-art MoE models by an average of 2 BLEU score on twelve low-resource translation tasks. In the rich-resource setting, $\\text{THOR}~$achieves new state-of-the-art results on the two widely-used translation benchmarks, WMT'16 En-De and WMT'14 En-Fr. On multilingual translation tasks, the $\\text{THOR}~$model with 300 million parameters achieves 2 BLEU score improvement over a state-of-the-art MoE model of the same size. Moreover, our model achieves state-of-the-art results on these tasks --- the same BLEU score that is achieved by the Z-code MoE model [@kim2021scalable] with 5.5 billion parameters (18 times larger)."},{"heading":"Background","text":"# Background {#sec:background}\n\n**Transformer.** The Transformer [@vaswani2017attention] model has demonstrated its superior performance in many sequence-to-sequence natural language processing tasks, such as neural machine translation. The model contains an encoder and a decoder. The encoder consists of multiple encoder layers, each having an identical structure. An encoder layer employs a self-attention mechanism and a feed-forward neural network (FFN). The decoder is similarly constructed, except for an additional cross-attention mechanism in each decoder layer.\n\n**Sparsely Activated Models.** The building block of SAMs is the expert layer, which is similar to the Transformer layer. Each of these expert layers contain an attention mechanism and multiple FFNs in parallel, where each FFN is referred to as an *expert*. Let $\\{E_i\\}_{i=1}^N$ denote the experts, and $N$ denotes the total number of experts. A gating mechanism decides to which expert(s) an input should be routed. At each expert layer, given an input vector $x \\in \\RR^d$, where $d$ is the embedding dimension, the gate value of routing $x$ to expert $E_i$ is $$\\begin{aligned}\n \\label{eq:moe-gate}\n    & p_i(x) = \\left[ \\mathrm{Softmax}\\left(W_g x \\right) \\right]_i,\n\\end{aligned}$$ where $W_g \\in \\RR^{N \\times d}$ is the trainable weight matrix of the gating mechanism. Given the gate values $\\{p_i(x)\\}_{i=1}^N$, we select the top-$K$ experts to form an activated set of experts $\\cT \\subset \\{1 \\cdots N\\}$, where $|\\cT|=K$. Then the output $x\\textsubscript{out}$ of the expert layer is $$\\begin{aligned}\n \\label{eq:moe-output}\n    & x\\textsubscript{out} = \\sum_{i \\in \\cT} p_i(x) E_i(x).\n\\end{aligned}$$\n\nNotice that in Eq. [\\[eq:moe-output\\]](#eq:moe-output){reference-type=\"ref\" reference=\"eq:moe-output\"}, input $x$ only activates $K$ instead of $N$ experts, where $K \\ll N$, e.g., $K=2$ and $N=2048$ in GShard [@lepikhin2020gshard]. This implies that the number of FLOPs required for one forward pass does not increase with the number of experts $N$. Therefore, SAMs can scale to an enormous size without any significant increase in training time and inference time.\n\nThe gate weight matrix $W_g$ (Eq. [\\[eq:moe-gate\\]](#eq:moe-gate){reference-type=\"ref\" reference=\"eq:moe-gate\"}) is trained together with the rest of the model parameters. Because there is no constraint on the learned weights, it is possible that $W_g$ collapses such that one row dominates, i.e., all the inputs are routed to one expert. This problem is referred to as *load imbalance*. Existing works adopt various ad-hoc heuristics to mitigate this issue, e.g., adding Gaussian noise to Eq. [\\[eq:moe-gate\\]](#eq:moe-gate){reference-type=\"ref\" reference=\"eq:moe-gate\"} (noisy gating, @shazeer2017outrageously), limiting the maximum number of inputs that can be routed to an expert (expert capacity, @lepikhin2020gshard), imposing a load balancing loss [@lepikhin2020gshard; @fedus2021switch], and using linear assignment [@lewis2021base]. There are other works that remove the gating mechanism such that load imbalance is no longer an issue, e.g., by incorporating hash functions [@roller2021hash]. Besides the load imbalance issue, there are also heated discussions on how to construct $\\cT$ in Eq. [\\[eq:moe-output\\]](#eq:moe-output){reference-type=\"ref\" reference=\"eq:moe-output\"}. For example, @shazeer2017outrageously [@lepikhin2020gshard; @yang2021exploring] conjecture that routing inputs to $K>1$ experts is necessary, while @fedus2021switch argue that using $K=1$ is sufficient and more computationally efficient."},{"heading":"Analysis of Sparsely Activated Models","text":"# Analysis of Sparsely Activated Models {#sec:analysis}\n\nWe investigate behavior of the gating mechanism of several classic MoE models. We conduct experiments on a multilingual translation task, {De, Vi} $\\rightarrow$ En. More details are presented in Appendix [7](#app:analysis){reference-type=\"ref\" reference=\"app:analysis\"}.\n\nWe consider two MoE models proposed in @shen2019mixture, referred to as MoE(dec) and MoE(tok), respectively, and three variants of the Switch Transformer proposed in @fedus2021switch. The number of experts is set to two for all the MoE models. We compare them with the Transformer [@vaswani2017attention] model of the same model size.\n\nFigure [\\[fig:analysis:gate-moe-loss\\]](#fig:analysis:gate-moe-loss){reference-type=\"ref\" reference=\"fig:analysis:gate-moe-loss\"} shows the validation losses and BLEU scores of three models: Transformer, MoE(dec), and MoE(tok). We see that the two MoE models perform very similarly, and neither outperforms the Transformer by a significant margin.\n\nTo interpret the results of Figure [\\[fig:analysis:gate-moe-loss\\]](#fig:analysis:gate-moe-loss){reference-type=\"ref\" reference=\"fig:analysis:gate-moe-loss\"}, we examine the load of each expert and the confidence scores of routing inputs to different experts. An expert's load is defined as the proportion of inputs that are assigned to it. For an input that is routed to an expert, its routing confidence score (output of the gating mechanism) determines the level of preference, e.g., if the routing confidence score is 0.5, then the gate has no preference for either expert. For each expert, we compute the average routing confidence score over all the inputs assigned to it.\n\nFigure [1](#fig:analysis:gate-dec){reference-type=\"ref\" reference=\"fig:analysis:gate-dec\"} shows that after the early stage of training (i.e., the first $200$ iterations), the gate weight collapses and nearly all the inputs are routed to expert 2. Also, the average routing confidence score of expert 2 is close to $1.0$, which means that the gate strongly prefers expert 2 to expert 1. In this case, only one of the experts is sufficiently trained. Figure [\\[fig:analysis:gate-tok\\]](#fig:analysis:gate-tok){reference-type=\"ref\" reference=\"fig:analysis:gate-tok\"} depicts a different scenario, where the inputs are randomly dispatched to the experts. Notice that after approximately $4000$ iterations, the two experts are equally loaded, and the probabilities of assigning any input to expert 1 and expert 2 are almost identical, indicating that the gating mechanism has no preference for either expert.\n\nWe have identified two behaviors of the gating mechanism: *load imbalance* and *random routing*. The former is also reported in recent papers [@shazeer2017outrageously; @lepikhin2020gshard; @fedus2021switch]. We further investigate the Switch Transformer [@fedus2021switch], which is a state-of-the-art MoE variant that incorporates various methods to resolve the load imbalance issue. In addition, because behavior of the gating mechanism in the Switch Transformer mimics random routing (see Appendix [7](#app:analysis){reference-type=\"ref\" reference=\"app:analysis\"}), we examine the effect of discarding the gate and randomly assigning inputs to experts. Figure [2](#fig:analysis:gate-switch-loss){reference-type=\"ref\" reference=\"fig:analysis:gate-switch-loss\"} demonstrates the validation losses and BLEU scores of the Transformer and three variants of the Switch Transformer, where inputs are routed according to tokens (referred to as Switch(t)), sentences (Switch(s)), or are routed randomly (Switch(r)). Similar to the results in Figure [\\[fig:analysis:gate-moe-loss\\]](#fig:analysis:gate-moe-loss){reference-type=\"ref\" reference=\"fig:analysis:gate-moe-loss\"}, we see that the four models perform similarly. This shows that even after we alleviate load imbalance, model performance is not improved (i.e., the Switch Transformers do not outperform the vanilla Transformer), and the performance of the Switch Transformer does not vary much among different routing methods, including random routing.\n\n<figure id=\"fig:analysis:gate-dec\">\n<p><span> <img src=\"figures/gate-moe.png\" alt=\"image\" /> <span id=\"fig:analysis:gate-moe-loss\" label=\"fig:analysis:gate-moe-loss\"></span> </span></p>\n<p><span> <img src=\"figures/hdiff_prob.png\" style=\"width:50.0%\" alt=\"image\" /> <img src=\"figures/hdiff_load.png\" style=\"width:50.0%\" alt=\"image\" /> <span id=\"fig:analysis:gate-dec\" label=\"fig:analysis:gate-dec\"></span> </span></p>\n</figure>\n\n<figure id=\"fig:analysis:gate-switch-loss\">\n<p><span> <img src=\"figures/sMoEup_prob.png\" style=\"width:50.0%\" alt=\"image\" /> <img src=\"figures/sMoEup_load.png\" style=\"width:50.0%\" alt=\"image\" /> <span id=\"fig:analysis:gate-tok\" label=\"fig:analysis:gate-tok\"></span> </span></p>\n<p><span> <img src=\"figures/gate-switch.png\" alt=\"image\" /> <span id=\"fig:analysis:gate-switch-loss\" label=\"fig:analysis:gate-switch-loss\"></span> </span></p>\n</figure>\n\nWe remark that in this paper, we focus on natural language processing tasks, in particular neural machine translation. There are other works in different research fields (e.g., computer vision) that draw different conclusions than ours [@riquelme2021scaling]. We attribute this to the intrinsic differences between image classification and language generation, e.g., each input in the former belongs to a clearly-defined category, while no such knowledge exists in the latter.\n\nIn summary, the experiments reveal\n\n-   A sparsely activated model does not always outperform a densely activated model of the same model size.\n\n-   The widely-used routing method based on the gating mechanism does not work better than randomly routing inputs to experts."},{"heading":"THOR: Transformer with Stochastic Experts","text":"# THOR: Transformer with Stochastic Experts {#sec:method}\n\nThe ineffectiveness of the gating mechanism, as shown in our experiments, motivates us to propose a new expert-based model, $\\text{THOR}~$([**T**]{.underline}ransformer wit[**H**]{.underline} St[**O**]{.underline}chastic Expe[**R**]{.underline}ts). In THOR, a pair of experts are randomly selected and activated in each layer during a training iteration, and then all the inputs in a batch are processed using the same pair of experts. Our method drastically simplifies model design, and has two additional advantages. First, it eliminates the load imbalance issue because randomly selecting a pair of experts in each iteration allows each expert to have a fair chance to be sufficiently trained. The ad-hoc heuristics, such as the load balancing loss, as discussed in Section [2](#sec:background){reference-type=\"ref\" reference=\"sec:background\"}, are no longer needed. Second, unlike the gating mechanism, $\\text{THOR}~$does not introduce any additional model parameters.\n\nOne problem of $\\text{THOR}~$is that without a gating mechanism, experts need to be randomly selected during inference, and we may obtain inconsistent inference results due to different random seeds. For example, on a Czech-to-English translation dataset, our experiments show that randomness can result in a 0.5 BLEU score difference.\n\n![Illustration of a training iteration with stochastic experts. For conciseness, we show a model with only one Transformer layer.](figures/Reg-MoE.png){#fig:step width=\"80%\"}\n\nTo address this issue, we introduce a consistency regularizer in the training objective of THOR. Concretely, let $N$ denotes the number of experts, $L$ the number of layers, and $E_i^l$ an activated expert (which is a FFN) in layer $l$, where $1 \\le i \\le N$ and $1 \\le l \\le L$. We use $p = f(x; \\{E_i^l\\}_{l=1}^L)$ to indicate the prediction probability of input $x$ using the model $f$ where experts $\\{E_i^l\\}_{l=1}^L$ are activated. Figure [3](#fig:step){reference-type=\"ref\" reference=\"fig:step\"} illustrates one training iteration. Notice that instead of activating one expert for each layer in an iteration, we select to activate a pair of experts in THOR. As a result, we obtain two prediction probabilities produced by the two selections, respectively: $p_1 = f(x; \\{E_{i}^l\\}_{l=1}^L))$ and $p_2 = f(x; \\{E_{j}^l\\}_{l=1}^L))$. Then, the training objective of $\\text{THOR}~$with respect to training samples $(x,y)$ in the dataset $\\cD$ is $$\\begin{aligned} \\label{eq:step}\n    \\min \\sum_{(x,y) \\in \\cD} \\ell(x,y) &= \\mathrm{CE}(p_1; y) + \\mathrm{CE}(p_2; y)\n    + \\alpha \\mathrm{CR}(p_1; p_2), \\\\\n    \\text{where}~ \\mathrm{CR}(p_1; p_2) &= \\frac{1}{2} \\left( \\mathrm{KL}(p_1 \\| p_2) + \\mathrm{KL}(p_2 \\| p_1) \\right).\n\\end{aligned}$$ Here, $\\mathrm{CE}$ is the cross-entropy loss, the consistency regularizer $\\mathrm{CR}$ is defined as the average of the two Kullback--Leibler (KL) divergence terms, and $\\alpha$ is a hyper-parameter that controls the strength of the regularizer. In mini-batch SGD training, we randomly sample a pair of experts to activate at each layer for each batch. During inference, we can also randomly select an expert to activate at each layer for each input, similar to that in training. We can also use different expert-selection methods, such as expert-ensemble, as to be discussed in Section [5](#sec:experiment){reference-type=\"ref\" reference=\"sec:experiment\"} (Table [5](#tab:inference){reference-type=\"ref\" reference=\"tab:inference\"}).\n\nThe $\\text{THOR}~$training objective of Eq. [\\[eq:step\\]](#eq:step){reference-type=\"ref\" reference=\"eq:step\"} forces all the experts to minimize training errors while making the same predictions as much as possible. Thus, in each training step, each expert optimizes its parameters by learning from both the training data (via minimizing the cross-entropy loss) and its paired expert as a teacher (via minimizing the KL divergence). Although these experts are learned to make consistent predictions, they converge to different (local) optima given the randomness introduced in training, e.g., initialization, mini-batch SGD, random routing, etc. Thus, every expert learns from a set of diverse teachers during the course of training, which helps to improve model's performance. In addition, by penalizing experts that yield inconsistent predictions from the others, the consistency regularizer also helps reducing the variance of model prediction.\n\n$\\text{THOR}~$is conceptually similar to dropout [@srivastava2014dropout] since both methods route an input to some randomly selected sub-net components (i.e., experts in $\\text{THOR}~$and neurons in dropout). However, $\\text{THOR}~$differs from dropout in several important aspects, making it a better choice for efficient training and serving of large-scale neural models. First, $\\text{THOR}~$can be applied to both training and inference, while dropout is only used for training. Second, $\\text{THOR}~$is shown to be more robust in large-scale model training than dropout. For example, our models are less likely to overfit with the increase in the number of experts (see Figure [6](#fig:ablation-hidden){reference-type=\"ref\" reference=\"fig:ablation-hidden\"}). Third, $\\text{THOR}~$leads to a sparse model that is more structured than that of dropout, such that a large-scale $\\text{THOR}~$model can be much more easily trained using GPU clusters, e.g., by putting different experts on different GPUs in parallel."},{"heading":"Experiments","text":"# Experiments {#sec:experiment}\n\nWe evaluate $\\text{THOR}~$on neural machine translation. We adopt three settings: low-resource translation, rich-resource translation, and multilingual translation. For low-resource and rich-resource translation, we train all the models using *Fairseq*[^2] [@ott2019fairseq]. For multilingual translation, we use *DeepSpeed MoE*[^3] [@kim2021scalable] to implement the MoE models. All the experiments are conducted on NVIDIA V100 GPUs. Additional experiments, including model scale-up and comparison of inference speed, are deferred to Appendix [10](#app:additional){reference-type=\"ref\" reference=\"app:additional\"}.\n\n## Baseline\n\nWe use two baselines in the experiments.\n\n-   Transformer [@vaswani2017attention] achieves superior performance in many sequence-to-sequence learning tasks, such as neural machine translation.\n\n-   Switch Transformer [@fedus2021switch] is a state-of-the-art MoE model, which employs a gating mechanism to route inputs and uses a load balancing loss to reduce load imbalance.\n\nTo verify the effectiveness of the imposed consistency regularizer in Eq. [\\[eq:step\\]](#eq:step){reference-type=\"ref\" reference=\"eq:step\"}, we also compare $\\text{THOR}~$with Transformer models trained using two popular regularization methods. We remark that these two methods share similar computational costs with THOR, i.e., they also require two forward passes in each training iteration.\n\n-   SMART [@jiang2019smart] utilizes a smoothness inducing adversarial regularizer to penalize the worst case difference between predictions of a clean input and a perturbed input.\n\n-   R3F [@aghajanyan2020better] uses a regularizer to reduce representational collapse. The method has shown to be effective in various natural language processing tasks.\n\nAll the methods are trained for the same number of FLOPs in the experiments for fair comparison.\n\n## Low-Resource Translation\n\nWe use six language pairs: English to Vietnamese, English to German, and English to French from IWSLT; English to Romanian, English to Latvian, and English to Czech from Europarl[^4]. Dataset statistics are summarized in Table [3](#tab:low-dataset){reference-type=\"ref\" reference=\"tab:low-dataset\"} (Appendix [8](#app:dataset){reference-type=\"ref\" reference=\"app:dataset\"}).\n\n::: {#tab:low-results}\n                                          En-Vi      Vi-En      En-De      De-En      En-Fr      Fr-En\n  ------------------------------------- ---------- ---------- ---------- ---------- ---------- ----------\n  Transformer [@vaswani2017attention]      31.3       29.4       28.1       34.8       39.2       38.1\n  SMART [@jiang2019smart]                  32.5       30.5       29.3       35.8       40.0       38.8\n  R3F [@aghajanyan2020better]              32.2       30.7       29.2       35.7       39.7       38.9\n  Switch [@fedus2021switch]                31.7       29.5       28.4       34.6       39.1       38.2\n  $\\text{THOR}~$                         **34.0**   **33.0**   **31.1**   **37.8**   **40.7**   **40.0**\n                                          En-Ro      Ro-En      En-Lv      Lv-En      En-Cs      Cs-En\n  Transformer [@vaswani2017attention]      23.5       25.0       13.6       15.8       16.1       20.4\n  SMART [@jiang2019smart]                  24.6       25.7       14.2       16.3       16.7       21.4\n  R3F [@aghajanyan2020better]              23.8       25.8       14.4       16.3       16.8       21.6\n  Switch [@fedus2021switch]                23.8       24.4       13.8       16.1       16.1       20.6\n  $\\text{THOR}~$                         **25.2**   **27.1**   **15.2**   **17.4**   **17.6**   **22.4**\n\n  : Experimental results on low resource datasets. The best result on each dataset is in **bold**.\n:::\n\n[]{#tab:low-results label=\"tab:low-results\"}\n\nTo evaluate $\\text{THOR}~$with different model sizes, we use the Transformer-base [@vaswani2017attention] architecture on Europarl datasets, and a smaller model on IWSLT datasets. Compared with Transformer-base, the smaller model decreases the hidden dimension from $2048$ to $1024$, and decreases the number of heads from $8$ to $4$ with the dimension of each head doubled. We use two experts for the expert-based models. We remark that even though $\\text{THOR}~$increases the number of parameters, its inference speed (in terms of FLOPs) is the same as Transformer-base because only one expert is activated for each input. Interested readers refer to Appendix [9](#app:training-details){reference-type=\"ref\" reference=\"app:training-details\"} for more details.\n\nThe experimental results in Table [1](#tab:low-results){reference-type=\"ref\" reference=\"tab:low-results\"} show that performance of the Switch Transformer is on par with the vanilla Transformer, e.g., its average BLEU score on the $12$ datasets is $26.3$, the same as the Transformer. The results confirm that SAMs do not outperform densely activated models with similar model sizes. In contrast, $\\text{THOR}~$achieves more than $1.0$ BLEU score improvement over the Switch Transformer in all the $12$ tasks. $\\text{THOR}~$also significantly outperforms the models trained using the two competing regularization methods, SMART and R3F.\n\n## Rich-Resource Translation\n\nWe use two widely adopted rich-resource translation benchmarks: English to German translation from WMT'16 and English to French translation from WMT'14. The former dataset consists of $4.5$ million training sentence pairs, and the latter $36$ million pairs. We follow the pre-processing steps in @ott2018scaling.\n\nTo evaluate $\\text{THOR}~$, We use the Transformer-big architecture [@vaswani2017attention] and we set the number of experts for both $\\text{THOR}~$and the Switch Transformer to $4$. Interested readers refer to Appendix [9](#app:training-details){reference-type=\"ref\" reference=\"app:training-details\"} for more details.\n\nTable [\\[tab:rich-results\\]](#tab:rich-results){reference-type=\"ref\" reference=\"tab:rich-results\"} reports the BLEU scores and the sacreBLEU scores [@post-2018-call] of different models. We see that $\\text{THOR}~$achieves new state-of-the-art results in the setting where neither data augmentation nor pre-trained language model is used. Specifically, $\\text{THOR}~$lifts the previous state-of-the-art [@liu2020admin; @liu2020very] by $0.3$ BLEU score on the En-De translation task and $0.1$ BLEU score on the En-Fr translation task. $\\text{THOR}~$also significantly outperforms the models trained using the other two regularization methods, SMART [@jiang2019smart] and R3F [@aghajanyan2020better]. Similar to what is observed in low-resource translation, the Switch Transformer [@fedus2021switch] does not outperform the vanilla Transformer [@ott2018scaling].\n\n  *BLEU*                    En-De      En-Fr\n  ----------------------- ---------- ----------\n  @vaswani2017attention      28.4       41.8\n  @ott2018scaling            29.3       43.2\n  @wang2019learning          29.6       ---\n  @wu2019pay                 29.7       43.2\n  @so2019evolved             29.8       41.3\n  @jiang2019smart            29.8       43.4\n  @wu2019depth               29.9       43.3\n  @aghajanyan2020better      29.4       43.3\n  @liu2020very               30.1     **43.8**\n  @fedus2021switch           29.3       43.0\n  $\\text{THOR}~$           **30.4**   **43.8**\n  *sacreBLEU*               En-De      En-Fr\n  @ott2018scaling            28.6       41.4\n  @jiang2019smart            29.1       41.5\n  @so2019evolved             29.2       ---\n  @aghajanyan2020better      29.0       41.5\n  @liu2020very               29.5       41.8\n  @fedus2021switch           28.6       41.1\n  $\\text{THOR}~$           **29.6**   **41.9**\n\n[]{#tab:rich-results label=\"tab:rich-results\"}\n\n## Multilingual Translation\n\nWe have collected $10$ language pairs from WMT datasets, and built a $64k$-entry dictionary for all the languages. The detailed statistics are summarized in Table [4](#tab:multi-dataset){reference-type=\"ref\" reference=\"tab:multi-dataset\"} (Appendix [8](#app:dataset){reference-type=\"ref\" reference=\"app:dataset\"}). Please refer to @kim2021scalable for more details. We do not use multi-task learning or additional monolingual data in the experiments.\n\nWe use the following model architecture: the embedding dimension is set to $768$ and the hidden dimension for the FFN is set to $3072$; we use $12$ encoder layers and $6$ decoder layers, where each layer has $12$ attention heads, and the dimension of each head is $64$. We set the number of experts to $4$ for both $\\text{THOR}~$and the Switch Transformer.\n\nTable [2](#tab:multi-results){reference-type=\"ref\" reference=\"tab:multi-results\"} reports the average BLEU score of translating English to other languages, translating other languages to English, and the overall score of the $20$ tasks. We see that compared with the Switch Transformer of the same size (i.e., $300$ million parameters), our model achieves a $2$-point improvement in the overall BLEU score. In addition, our model is far more parameter efficient than the Switch Transformer. The $\\text{THOR}~$model with $300$ million parameters achieves the same BLEU score ($24.4$) that is achieved by the Switch Transformer with $5.5$ billion parameters, which is more than $18$ times larger.\n\n::: {#tab:multi-results}\n                              En$\\rightarrow$Others   Others$\\rightarrow$En   Average\n  -------------------------- ----------------------- ----------------------- ----------\n  Switch (32E, 5.5B)                   ---                     ---            **24.4**\n  Switch (4E, 300M)                   20.3                    24.6              22.4\n  $\\text{THOR}~$(4E, 300M)          **21.4**                **27.4**          **24.4**\n\n  : Multilingual translation results. Here \"*E*\" means the number of experts.\n:::\n\n[]{#tab:multi-results label=\"tab:multi-results\"}\n\nFigure [4](#fig:multi-results-details){reference-type=\"ref\" reference=\"fig:multi-results-details\"} shows BLEU scores in all the $20$ translation tasks. Notice that $\\text{THOR}~$outperforms the baseline on $17$ out of the $20$ tasks. The improvement is in general more significant on the tasks with smaller datasets. For example, our model achieves BLEU score improvement of $4.7$ and $6.7$ on Gu-En ($85k$) and Hi-En ($264k$), respectively. On the tasks with larger datasets, the improvement obtained by our model is less substantial, but still significant, e.g., $+0.9$ BLEU score on Cs-En ($10M$) and $+1.1$ Fi-En ($4.8M$). For the only three tasks where our model underperforms the baseline, the gaps are small, e.g., $-0.4$, $-0.2$, and $-0.4$ BLEU scores on En-Cs, En-De, and En-Fr, respectively.\n\n![Details of multilingual translation results.](figures/multi.png){#fig:multi-results-details width=\"85%\"}\n\n## Ablation Experiments\n\n#### Training Objective.\n\nWe examine the relative contributions of the three loss terms used in the $\\text{THOR}~$training objective of Eq. [\\[eq:step\\]](#eq:step){reference-type=\"ref\" reference=\"eq:step\"}: $\\mathrm{CE_1}$, $\\mathrm{CE_2}$ and $\\mathrm{CR}$. The result in Table [\\[tab:ablation\\]](#tab:ablation){reference-type=\"ref\" reference=\"tab:ablation\"} shows that the consistency regularizer $\\mathrm{CR}$ is crucial to the model performance, and that dropping one of the two $\\mathrm{CE}$ terms leads to only very small BLEU score loss since the two cross-entropy terms play the same role in training.\n\n#### Inference Methods.\n\nWe compare three inference methods: (1) `Dispatch(s)` uses sentence-level random routing, where all tokens in one sentence are routed to the same expert; (2) `Dispatch(t)` uses token-level random routing, where tokens within a sentence are routed to different experts; (3) `Ensemble`, where each sentence is routed to all the $N$ experts, and the $N$ hidden representations in each layer are averaged. Note that the number of FLOPs is larger for `Ensemble` because we need to run forward pass for each input through $N$ experts. Table [5](#tab:inference){reference-type=\"ref\" reference=\"tab:inference\"} shows that `Dispatch(s)` and `Dispatch(t)` perform similarly, and `Ensemble` yields the best BLEU score with a cost of longer inference time.\n\n#### Regularization strength.\n\nTo investigate the effect of the regularization strength $\\alpha$, we run experiments on the Cs-En translation dataset in the low-resource setting. Figure [\\[fig:ablation-alpha\\]](#fig:ablation-alpha){reference-type=\"ref\" reference=\"fig:ablation-alpha\"} shows that model performance is not very sensitive to $\\alpha$ as long as the value is large enough, say $\\alpha > 2.0$.\n\n#### Consistency of Model Prediction.\n\nWe study the variance of model prediction due to the use of randomly activated experts during inference. We compare $\\text{THOR}~$and the Switch Transformer, where we remove the trained gate during inference. For each model, we compute the variance of model prediction based on $20$ runs. As shown in Figure [\\[fig:consistency\\]](#fig:consistency){reference-type=\"ref\" reference=\"fig:consistency\"}, $\\text{THOR}~$makes more consistent predictions than Switch Transformer due to the use of the consistency regularizer for model training. The variance of $\\text{THOR}~$is below $0.002$, whereas the variance of Switch Transformer is $0.008$, four times larger. We remark that by removing the trained router from the Switch Transformer, model performance only marginally decreases (from $20.6$ to $20.4$). This further indicates that a trained router may not be better than a random router.\n\n#### Overfitting.\n\nWe compare the $\\text{THOR}~$model and the Transformer model regarding how likely they overfit the training data when the model size increases. We run experiments on the De-En data in the low-resource setting, where the dropout rate of the FFNs in the Transformer is selected such that the number of parameters trained in one iteration is the same as the $\\text{THOR}~$model. As shown in Figure [6](#fig:ablation-hidden){reference-type=\"ref\" reference=\"fig:ablation-hidden\"}, $\\text{THOR}~$does not show any sign of overfitting --- we observe a consistent improvement in BLEU score as we increase the number of experts from $2$ to $8$. In contrast, the Transformer model's performance deteriorates as we increase the hidden dimension of its FFN from $2k$ to $8k$. We remark that we also observe the overfitting phenomenon on larger datasets, e.g., the Transformer overfits on the Cs-En dataset when we set the hidden dimension of its FFN to $16k$.\n\n<figure id=\"tab:inference\">\n<table>\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Loss terms</th>\n<th style=\"text-align: center;\">BLEU</th>\n<th style=\"text-align: center;\"></th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\"><span class=\"math inline\">CE<sub>1</sub> + CE<sub>2</sub> + CR</span></td>\n<td style=\"text-align: center;\">22.4</td>\n<td style=\"text-align: center;\"></td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\"><span class=\"math inline\">CE<sub>1</sub> + CR</span></td>\n<td style=\"text-align: center;\">22.2</td>\n<td style=\"text-align: center;\"></td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\"><span class=\"math inline\">CE<sub>1</sub> + CE<sub>2</sub></span></td>\n<td style=\"text-align: center;\">20.8</td>\n<td style=\"text-align: center;\"></td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\"><span class=\"math inline\">CE<sub>1</sub></span></td>\n<td style=\"text-align: center;\">20.6</td>\n<td style=\"text-align: center;\"></td>\n</tr>\n</tbody>\n</table>\n<p><span id=\"tab:ablation\" label=\"tab:ablation\"></span></p>\n<table>\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\"></th>\n<th style=\"text-align: center;\">BLEU</th>\n<th style=\"text-align: center;\">time</th>\n<th style=\"text-align: center;\"></th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\"><code>Dispatch(s)</code></td>\n<td style=\"text-align: center;\">22.4</td>\n<td style=\"text-align: center;\"><span class=\"math inline\"> × 1</span></td>\n<td style=\"text-align: center;\"></td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\"><code>Dispatch(t)</code></td>\n<td style=\"text-align: center;\">22.4</td>\n<td style=\"text-align: center;\"><span class=\"math inline\"> × 1</span></td>\n<td style=\"text-align: center;\"></td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\"><code>Ensemble</code></td>\n<td style=\"text-align: center;\">22.6</td>\n<td style=\"text-align: center;\"><span class=\"math inline\"> × <em>N</em></span></td>\n<td style=\"text-align: center;\"></td>\n</tr>\n</tbody>\n</table>\n<p><span id=\"tab:inference\" label=\"tab:inference\"></span></p>\n</figure>\n\n<figure id=\"fig:ablation-hidden\">\n<p><span> <img src=\"figures/ablation-alpha.png\" style=\"width:100.0%\" alt=\"image\" /> <span id=\"fig:ablation-alpha\" label=\"fig:ablation-alpha\"></span> </span></p>\n<p><span> <img src=\"figures/consistency.png\" style=\"width:100.0%\" alt=\"image\" /> <span id=\"fig:consistency\" label=\"fig:consistency\"></span> </span></p>\n<p><span> <img src=\"figures/learning.png\" style=\"width:100.0%\" alt=\"image\" /> <span id=\"fig:ablation-hidden\" label=\"fig:ablation-hidden\"></span> </span></p>\n</figure>"},{"heading":"Conclusion","text":"# Conclusion {#sec:conclusion}\n\nWe present a new expert-based sparsely activated model, THOR. Unlike existing SAMs, such as the Switch Transformer, experts in $\\text{THOR}~$are randomly activated for each input during training and inference. $\\text{THOR}~$models are trained using a consistency regularized loss, where every expert learns not only from training data but also from other experts as teachers so that all the experts make consistent predictions. As a result, not only can large-scale $\\text{THOR}~$models be trained and served as efficiently as classic MoE models, $\\text{THOR}~$models also demonstrate a better generalization capability in that they are more parameter-efficient, less likely to overfit, make more consistent predictions, and achieve better results consistently across different settings. We validate the effectiveness of $\\text{THOR}~$via a comprehensive empirical study on machine translation. In all the three settings (i.e., low-resource, rich-resource, and multilingual translation), $\\text{THOR}~$models significantly outperform the vanilla Transformer, and Switch Transformer, a state-of-the-art MoE model."},{"heading":"Acknowledgments","text":"# Acknowledgments {#acknowledgments .unnumbered}\n\nWe thank Rukmini Lyer, Kevin Duh, Hao Cheng, Chunyuan Li, Johannes Gehrke, colleagues from Microsoft Bing Ads team and Microsoft Research for their valuable discussions and comments."},{"heading":"Analysis of Sparsely Activated Models","text":"# Analysis of Sparsely Activated Models {#app:analysis}\n\n## Training Details\n\nWe consider two Mixture-of-Experts (MoE) models proposed in @shen2019mixture, which are denoted \"MoE(dec)\" and \"MoE(tok)\". In the first variant, each expert is a separate Transformer decoder. In the second variant, each expert is a different token, i.e., if we route the input to expert one, then we replace the $\\langle \\textit{bos} \\rangle$ (begin-of-sentence) token in the input sentence with a $\\langle \\textit{expert}_1 \\rangle$ token. Note that embeddings of these expert tokens are trained together with the rest of the model parameters. These models are equipped with an expectation-maximization optimization framework. Such a framework facilitates computing the probability of assigning an input to a specific expert according to the gating mechanism. Please refer to @shen2019mixture for details about these models.\n\nWe use a multilingual translation setting, where we adopt two datasets: De-En from IWSLT'14 and Vi-En from IWSLT'15. For each dataset, we use byte pair encoding (BPE, @sennrich2015neural) with $10,000$ merge operations for pre-processing. Then we concatenate the two pre-processed datasets. We learn a separate dictionary for En and {De+Vi}, which resulted in approximately $9k$ and $12k$ vocabularies, respectively.\n\nFor training, we use Adam [@kingma2014adam] as the optimizer and we set the learning rate to $0.001$. We set the batch size to be equivalent to $64k$ tokens, e.g., we use $8k$ tokens per GPU with $8$ GPUs. Other training details follow the *Fairseq*[^5] implementation. For inference, we use a beam size of $5$ and a length penalty of $1.0$.\n\n## Additional Results\n\nWe also plot the average routing confidence score and the load of experts for Switch(s) and Switch(t), similar to Figure [1](#fig:analysis:gate-dec){reference-type=\"ref\" reference=\"fig:analysis:gate-dec\"} and Figure [\\[fig:analysis:gate-tok\\]](#fig:analysis:gate-tok){reference-type=\"ref\" reference=\"fig:analysis:gate-tok\"}. We first investigate the Switch Transformer without the load balancing loss.\n\n<figure id=\"fig:gate_prob_sentence\">\n<p><img src=\"figures/gate_prob_sentence.png\" style=\"width:40.0%\" alt=\"image\" /> <img src=\"figures/gate_load_sentence.png\" style=\"width:40.0%\" alt=\"image\" /></p>\n<figcaption>Switch(s) w/o load balancing. Left: average routing confidence; Right: load of experts.</figcaption>\n</figure>\n\n<figure id=\"fig:gate_prob_token\">\n<p><img src=\"figures/gate_prob_token.png\" style=\"width:40.0%\" alt=\"image\" /> <img src=\"figures/gate_load_token.png\" style=\"width:40.0%\" alt=\"image\" /></p>\n<figcaption>Switch(t) w/o load balancing. Left: average routing confidence; Right: load of experts.</figcaption>\n</figure>\n\nFigure [7](#fig:gate_prob_sentence){reference-type=\"ref\" reference=\"fig:gate_prob_sentence\"} shows the results for Switch(s) without the load balancing loss, where we route inputs to experts on the sentence-level. We see that after about $10k$ training iterations, the average routing confidence score of expert 1 and expert 2 becomes similar, and both of these scores are around $0.60$. Moreover, the load of the experts are not balanced, i.e., there is a $10\\%$ difference in the loads ($55\\%$ vs. $45\\%$). We conclude that behavior of the gating mechanism of Switch(s) is similar to Figure [\\[fig:analysis:gate-tok\\]](#fig:analysis:gate-tok){reference-type=\"ref\" reference=\"fig:analysis:gate-tok\"}, i.e., the gate is essentially randomly routing inputs to experts without any preference.\n\nFigure [8](#fig:gate_prob_token){reference-type=\"ref\" reference=\"fig:gate_prob_token\"} shows the results for Switch(t) without the load balancing loss, where we route inputs to experts on the token-level, i.e., different tokens within the same sentence may be routed to different experts. Similar to the Switch(s) case, the average routing confidence score of both of the two experts converges to around $0.55$. This indicates that the gate do not prefer any expert given an input. Moreover, the load of the experts are not balanced, the same as in Figure [7](#fig:gate_prob_sentence){reference-type=\"ref\" reference=\"fig:gate_prob_sentence\"}. Based on these observations, we conclude that behavior of the gating mechanism of Switch(t) is also *random routing*.\n\n<figure id=\"fig:gate_prob_balance_sentence\">\n<p><img src=\"figures/gate_prob_balance_sentence.png\" style=\"width:40.0%\" alt=\"image\" /> <img src=\"figures/gate_load_balance_sentence.png\" style=\"width:40.0%\" alt=\"image\" /></p>\n<figcaption>Switch(s) w/ load balancing. Left: average routing confidence; Right: load of experts.</figcaption>\n</figure>\n\n<figure id=\"fig:gate_prob_balance_token\">\n<p><img src=\"figures/gate_prob_balance_token.png\" style=\"width:40.0%\" alt=\"image\" /> <img src=\"figures/gate_load_balance_token.png\" style=\"width:40.0%\" alt=\"image\" /></p>\n<figcaption>Switch(t) w/ load balancing. Left: average routing confidence; Right: load of experts.</figcaption>\n</figure>\n\nFigure [9](#fig:gate_prob_balance_sentence){reference-type=\"ref\" reference=\"fig:gate_prob_balance_sentence\"} and Figure [10](#fig:gate_prob_balance_token){reference-type=\"ref\" reference=\"fig:gate_prob_balance_token\"} show behavior of the gating mechanism of Switch(s) and Switch(t) equipped with the load balancing loss, respectively. We see that the load balancing loss indeed balances the load for both Switch(s) and Switch(t), e.g., there is a less than $0.4\\%$ imbalance for Switch(s) and less than $0.2\\%$ imbalance for Switch(t). In comparison, the imbalance is around $10\\%$ for the two Switch Transformer variants without the load balancing loss. Also, similar to the case without the load balancing loss, the average routing confidence score converges to around $0.60$ for Switch(s) and around $0.55$ for Switch(t). Based on the observations, we conclude that behavior of the gating mechanism is still *random routing* when Switch(s) and Switch(t) are equipped with the load balancing loss."},{"heading":"Datasets","text":"# Datasets {#app:dataset}\n\nStatistics of low-resource datasets are shown in Table [3](#tab:low-dataset){reference-type=\"ref\" reference=\"tab:low-dataset\"}. The English-Vietnamese, English-German, and English-French datasets are from[^6] IWSLT'14, '15, and '16, respectively. The training data of English-Romanian, English-Latvian, and English-Czech are from Europarl[^7], and the validation and testing data are from WMT'17.\n\nStatistics and data sources used in the multilingual translation task are shown in Table [4](#tab:multi-dataset){reference-type=\"ref\" reference=\"tab:multi-dataset\"}.\n\n::: {#tab:low-dataset}\n                 En-Vi     En-De     En-Fr     En-Ro     En-Lv     En-Cs\n  ------------ --------- --------- --------- --------- --------- ---------\n  Train         117,055   160,239   218,256   390,746   591,631   619,029\n  Validation     5,098     7,283     8,453     1,900     1,949     2,902\n  Test           1,268     6,750     1,133     1,999     2,001     3,005\n\n  : Statistics of low resource translation datasets.\n:::\n\n[]{#tab:low-dataset label=\"tab:low-dataset\"}\n\n::: {#tab:multi-dataset}\n  Language        Czech (Cs)     German (De)   Estonian (Et)   Finnish (Fi)    French (Fr)\n  ------------- --------------- ------------- --------------- --------------- --------------\n  Data source       WMT'19         WMT'19         WMT'18          WMT'19          WMT'15\n  \\# Samples      10,273,696      4,613,192       695,227        4,838,576      9,999,995\n  Language       Gujarati (Gu)   Hindi (Hi)    Latvian (Lv)    Romanian (Ro)   Turkish (Tr)\n  Data source       WMT'19         WMT'14         WMT'17          WMT'16          WMT'18\n  \\# Samples        85,688         264,199       1,444,235        540,562        182,269\n\n  : Statistics of multilingual translation datasets. The other language in the translation tasks is English (En) for all the datasets.\n:::\n\n[]{#tab:multi-dataset label=\"tab:multi-dataset\"}"},{"heading":"Training Details","text":"# Training Details {#app:training-details}\n\n## Low Resource Translation\n\nWe build a joined dictionary for the source and target languages for each dataset. To facilitate this, we use byte pair encoding (BPE) with $10,000$ and $40,000$ split operations for the IWSLT and the WMT datasets, respectively. Other pre-processing steps follow the *Fairseq* implementation.\n\nFor training, the regularization strength is chosen to be $\\alpha=5.0$. We set the batch size to be equivalent to $32k$ tokens, i.e., if we have four GPUs, then we set the number of tokens on each GPU to be $4k$ and accumulate gradients for two steps. We use Adam as the optimizer with $\\beta_1=0.9$, $\\beta_2=0.98$, and we set the learning rate to be $0.0015$. We train the model for $40k$ steps, and we test the model that yield the highest validation BLEU. For validation and testing, we use a beam size $5$ and a length penalty $1.0$. Other training and inference details follow the *Fairseq* implementation.\n\n## Rich resource Translation\n\nStrength of the consistency regularizer is set as $\\alpha=2.0$. We use Adam [@kingma2014adam] as the optimizer with $\\beta_1=0.9$, $\\beta_2=0.98$, and the learning rate is chosen as $0.001$. For inference, we use a beam size $4$ and a length penalty $0.6$ for En-De; we use a beam size $10$ and a length penalty $1.0$ for En-Fr. Other post-processing steps follow @ott2018scaling. We report both the BLEU score and the sacreBLEU score [@post-2018-call], where the latter is a safer token-agnostic version of BLEU.\n\n## Multilingual Translation\n\nFor training, we set the batch size to be equivalent to $1.6$ million tokens, e.g., $4096$ tokens per GPU with $24$ GPUs, and we accumulate gradients for $16$ steps. We use RAdam [@liu2019variance] as the optimizer with parameters $\\beta_1=0.9$ and $\\beta_2=0.98$. The learning rate is set to be $0.05$. Also, we set the dropout ratio to be $0.1$, and we use label smoothed cross entropy [@szegedy2016rethinking] with a smoothing factor $0.1$. The regularization strength is set to be $\\alpha=4.0$. For inference, we use a beam size $5$ and a length penalty $1.0$."},{"heading":"Additional Experiments","text":"# Additional Experiments {#app:additional}\n\nWe further test behavior of $\\text{THOR}~$and the Switch Transformer when we increase the number of experts. To avoid overfitting, we use a small model (*Transformer-IWSLT*) on the WMT'16 En-De translation dataset. In this experiment, the Transformer model has $48M$ parameters, models with $2$, $16$, and $64$ experts have $55M$, $143M$, and $456M$ parameters, respectively.\n\n::: figure*\n![image](figures/large_train_en2de.png){width=\"40%\"} ![image](figures/large_valid_en2de.png){width=\"40%\"}\n:::\n\nFigure [\\[fig:large\\]](#fig:large){reference-type=\"ref\" reference=\"fig:large\"} demonstrates the results. In Figure [\\[fig:large\\]](#fig:large){reference-type=\"ref\" reference=\"fig:large\"} (left), notice that the Switch Transformer trains faster than the vanilla Transformer, and this scaling property is more significant when we increase the number of experts.\n\nFrom Figure [\\[fig:large\\]](#fig:large){reference-type=\"ref\" reference=\"fig:large\"} (right), we see that with $2$ experts, the Switch Transformer behaves slightly worse the vanilla Transformer in terms of validation BLEU. However, when we increase the number of experts, performance of the Switch Transformer continues to improve and outperforms the vanilla Transformer with the same number of FLOPs. This indicates that in order for a sparsely activated model to outperform a densely activated one, we need to scale the former to contain much more parameters than the latter. Our observations are consistent with existing literature [@lepikhin2020gshard; @fedus2021switch]. For example, in @fedus2021switch, the sparsely activated Switch-base outperforms the densely activated T5-base using the same number of FLOPs. However, the former is more than $30$ times larger ($7.5$ billion vs. $0.22$ billion parameters).\n\nOur method is more *parameter efficient* than the conventional methods. From Figure [\\[fig:large\\]](#fig:large){reference-type=\"ref\" reference=\"fig:large\"} (right), we see that $\\text{THOR}~$significantly outperforms the vanilla Transformer and the Switch Transformer even with only $2$ experts. Moreover, when we increase the number of experts, performance of $\\text{THOR}~$also improves.\n\nWe also compare inference speed of Transformer, Switch Transformer, and $\\text{THOR}~$in Table [5](#tab:inference-speed){reference-type=\"ref\" reference=\"tab:inference-speed\"}. Note that for $\\text{THOR}~$, we use the `Dispatch(s)` method in Table [5](#tab:inference){reference-type=\"ref\" reference=\"tab:inference\"}. Note that the inference speed of Switch Transformer and $\\text{THOR}~$is slower than the vanilla Transformer because of the computation and communication overhead induced by input routing. Such an overhead is more noticeable when the number of experts is large. We remark that in @fedus2021switch, the speed of Switch-base is about half of T5-base ($780$ vs. $1600$ samples per second).\n\n::: {#tab:inference-speed}\n  ------------ ----------------- ------------ ------- ------ ---------- ------- ------\n                **Transformer**   **Switch**                  **THOR**          \n  \\# experts          ---             2         16      64       2        16      64\n  Speed              15.2k          15.0k      10.4k   7.4k    15.1k     10.6k   7.5k\n  ------------ ----------------- ------------ ------- ------ ---------- ------- ------\n\n  : Inference speed (tokens/second).\n:::\n\n[^1]: Work was done during an internship at Microsoft.\n\n[^2]: <https://github.com/pytorch/fairseq>\n\n[^3]: <https://github.com/microsoft/DeepSpeed>\n\n[^4]: <https://www.statmt.org/europarl>\n\n[^5]: <https://github.com/pytorch/fairseq/blob/master/examples/translation/>\n\n[^6]: <https://iwslt.org/>\n\n[^7]: <https://www.statmt.org/europarl/>"}],"approval":true,"conference":"iclr","rating":4,"year":2022,"id":"1029608eccb089d55e5b64c816584ae0c1b41f2dc98cdfdd3c3e52f4d1e27f42","y_true":1,"y_pred":1,"rationale_true":"","rationale_pred":"Paper Summary: The paper introduces THOR, a Transformer model with Stochastic Experts, where experts are randomly activated and trained with a consistency regularized loss. It claims improved parameter efficiency and state-of-the-art results in machine translation compared to traditional Transformers and Mixture-of-Experts models.\n\nSupporting Evidence:\n- Several papers support the idea of improving Transformer architectures for better performance and parameter efficiency.\n- R-Drop supports the use of consistency regularization, which is a key component of THOR.\n- Papers on low-resource NMT and Sinhala-Tamil translation support the effectiveness of Transformers in such settings, aligning with THOR's experiments.\n- The Switch Transformer paper highlights the challenges of MoE models, which THOR aims to address.\n\nContradictory Evidence:\n- Several papers argue that routing strategies are crucial for MoE performance, contradicting THOR's claim that random routing is effective.\n- Some papers suggest that simply scaling up MoE models does not guarantee better performance and can lead to overfitting, challenging THOR's approach.\n- One paper emphasizes the limitations of Soft MoE in achieving effective representation power, questioning the assumptions made in the Main Paper regarding expert activation and performance.\n- The BASE Layers paper claims that balanced routing of tokens to experts can enhance efficiency and simplify training, contrasting with THOR's stochastic method.\n\nConclusion: While the paper presents a novel approach to sparsely activated Transformers with stochastic experts and consistency regularization, the novelty is questionable. Several existing works contradict the claim that random routing is effective, and others highlight the limitations of simply scaling up MoE models. Although the paper demonstrates improved performance in machine translation tasks, the core ideas may not be entirely unique, and the effectiveness of random routing is debated in the literature. The approval decision is True, so the novelty label should be 1.","structured_evaluation":{"paper_summary":"The paper introduces THOR, a Transformer model with Stochastic Experts, where experts are randomly activated and trained with a consistency regularized loss. It claims improved parameter efficiency and state-of-the-art results in machine translation compared to traditional Transformers and Mixture-of-Experts models.","supporting_evidence":["Several papers support the idea of improving Transformer architectures for better performance and parameter efficiency.","R-Drop supports the use of consistency regularization, which is a key component of THOR.","Papers on low-resource NMT and Sinhala-Tamil translation support the effectiveness of Transformers in such settings, aligning with THOR's experiments.","The Switch Transformer paper highlights the challenges of MoE models, which THOR aims to address."],"contradictory_evidence":["Several papers argue that routing strategies are crucial for MoE performance, contradicting THOR's claim that random routing is effective.","Some papers suggest that simply scaling up MoE models does not guarantee better performance and can lead to overfitting, challenging THOR's approach.","One paper emphasizes the limitations of Soft MoE in achieving effective representation power, questioning the assumptions made in the Main Paper regarding expert activation and performance.","The BASE Layers paper claims that balanced routing of tokens to experts can enhance efficiency and simplify training, contrasting with THOR's stochastic method."],"conclusion":"While the paper presents a novel approach to sparsely activated Transformers with stochastic experts and consistency regularization, the novelty is questionable. Several existing works contradict the claim that random routing is effective, and others highlight the limitations of simply scaling up MoE models. Although the paper demonstrates improved performance in machine translation tasks, the core ideas may not be entirely unique, and the effectiveness of random routing is debated in the literature. The approval decision is True, so the novelty label should be 1.","label":1,"rationale":"Paper Summary: The paper introduces THOR, a Transformer model with Stochastic Experts, where experts are randomly activated and trained with a consistency regularized loss. It claims improved parameter efficiency and state-of-the-art results in machine translation compared to traditional Transformers and Mixture-of-Experts models.\n\nSupporting Evidence:\n- Several papers support the idea of improving Transformer architectures for better performance and parameter efficiency.\n- R-Drop supports the use of consistency regularization, which is a key component of THOR.\n- Papers on low-resource NMT and Sinhala-Tamil translation support the effectiveness of Transformers in such settings, aligning with THOR's experiments.\n- The Switch Transformer paper highlights the challenges of MoE models, which THOR aims to address.\n\nContradictory Evidence:\n- Several papers argue that routing strategies are crucial for MoE performance, contradicting THOR's claim that random routing is effective.\n- Some papers suggest that simply scaling up MoE models does not guarantee better performance and can lead to overfitting, challenging THOR's approach.\n- One paper emphasizes the limitations of Soft MoE in achieving effective representation power, questioning the assumptions made in the Main Paper regarding expert activation and performance.\n- The BASE Layers paper claims that balanced routing of tokens to experts can enhance efficiency and simplify training, contrasting with THOR's stochastic method.\n\nConclusion: While the paper presents a novel approach to sparsely activated Transformers with stochastic experts and consistency regularization, the novelty is questionable. Several existing works contradict the claim that random routing is effective, and others highlight the limitations of simply scaling up MoE models. Although the paper demonstrates improved performance in machine translation tasks, the core ideas may not be entirely unique, and the effectiveness of random routing is debated in the literature. The approval decision is True, so the novelty label should be 1."},"arxiv_id":"2110.04260"},"terms":{"tasks":["scaling models","improving sparsely activated models","routing inputs to experts","parameter efficiency in machine translation"],"methods":["Mixture-of-Experts","THOR","consistency regularized loss"],"metrics":["BLEU score"],"resources":["code"],"relations":[{"head":"Mixture-of-Experts","tail":"improving sparsely activated models"},{"head":"THOR","tail":"scaling models"},{"head":"THOR","tail":"parameter efficiency in machine translation"},{"head":"consistency regularized loss","tail":"routing inputs to experts"},{"head":"BLEU score","tail":"parameter efficiency in machine translation"},{"head":"code","tail":"scaling models"}]},"background":"Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts.","target":"In this paper, we propose a new expert-based model, THOR (\\underline{\\textbf{T}}ransformer wit\\underline{\\textbf{H}} St\\underline{\\textbf{O}}chastic Expe\\underline{\\textbf{R}}ts). Unlike classic expert-based models, such as the Switch Transformer, experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions. We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/Stochastic-Mixture-of-Experts."},{"graph":{"title":"Multimodal Structure Preservation Learning","abstract":"When selecting data to build machine learning models in practical applications, factors such as availability, acquisition cost, and discriminatory power are crucial considerations. Different data modalities often capture unique aspects of the underlying phenomenon, making their utilities complementary. On the other hand, some sources of data host structural information that is key to their value. Hence, the utility of one data type can sometimes be enhanced by matching the structure of another. We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality. We demonstrate the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications. The results show that MSPL can imbue the learned features with external structures and help reap the beneficial synergies occurring across disparate data modalities.","entities":[{"label":"Multimodal Structure Preservation Learning","type":"title","detail":null,"excerpts":null},{"label":"representation learning for computer vision, audio, language, and other modalities","type":"primary_area","detail":null,"excerpts":null},{"label":"multimodal learning","type":"keyword","detail":null,"excerpts":null},{"label":"structure preservation","type":"keyword","detail":null,"excerpts":null},{"label":"data representation","type":"keyword","detail":null,"excerpts":null},{"label":"clustering","type":"keyword","detail":null,"excerpts":null},{"label":"epidemiology","type":"keyword","detail":null,"excerpts":null},{"label":"mass spectrometry","type":"keyword","detail":null,"excerpts":null},{"label":"whole genome sequencing","type":"keyword","detail":null,"excerpts":null},{"label":"antimicrobial resistance","type":"keyword","detail":null,"excerpts":null},{"label":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality.","type":"tldr","detail":null,"excerpts":null},{"label":"MSPL effectively uncovers latent structures in synthetic time series data.","type":"claim","detail":"MSPL can effectively identify latent structures on a synthetic time series dataset by learning representations of the time series such that their pairwise distances match the external pairwise dissimilarity, which is defined as the Euclidean distance between their respective parameters.","excerpts":[{"section":"Introduction","text":"We first demonstrate the effectiveness of MSPL in identifying latent structures on a synthetic time series dataset."},{"section":"Experiments and Results","text":"Uncovering latent structure in Synth-TS."}]},{"label":"MSPL effectively recovers clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications.","type":"claim","detail":"MSPL can recover clusters from whole genome sequencing (WGS) and antimicrobial resistance (AMR) data using mass spectrometry (MALDI) data, enhancing the utility of MALDI by leveraging the clustering structure in WGS and AMR data.","excerpts":[{"section":"Introduction","text":"We then apply MSPL to epidemiology settings, where we enhance the utility of MALDI mass spectrometry by leveraging the clustering structure in whole genome sequencing (WGS) and antimicrobial resistance (AMR) data, respectively."},{"section":"Abstract","text":"We demonstrate the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications."}]},{"label":"MSPL can effectively inject structural information of one modality into the representations of another, improve the clustering performance, bridge the utility gap of two modalities, substantially reduce data acquisition cost, and increase feasibility of learning.","type":"claim","detail":"MSPL can inject structural information from one modality into the representations of another, leading to improved clustering performance, bridging the utility gap between modalities, reducing data acquisition costs, and increasing the feasibility of learning.","excerpts":[{"section":"Introduction","text":"Our results demonstrate that MSPL can effectively inject structural information of one modality into the representations of another, improve the clustering performance, bridge the utility gap of two modalities, substantially reduce data acquisition cost, and increase feasibility of learning."},{"section":"Abstract","text":"The results show that MSPL can imbue the learned features with external structures and help reap the beneficial synergies occurring across disparate data modalities."}]},{"label":"MSPL excels in preserving highly diverse substructures and remains robust to the difficulty of the pretext task.","type":"claim","detail":"MSPL offers two advantages: it excels in preserving highly diverse substructures and remains robust to the difficulty of the pretext task, making it a novel addition to multimodal machine learning techniques.","excerpts":[{"section":"Discussion","text":"Additionally, MSPL offers two advantages: it excels in preserving highly diverse substructures and remains robust to the difficulty of the pretext task."}]},{"label":"Multimodal Structure Preservation Learning (MSPL)","type":"method","detail":"MSPL is a novel machine learning framework that learns data representations that enhance the utility of one data modality through alignment with the dissimilarity-based clustering structure provided by another data modality. It entails three objectives: (1) reconstruction of the input data, (2) a pretext task, and (3) structure preservation through alignment between the clustering structure of two modalities.","excerpts":[{"section":"Methods","text":"We propose a novel machine learning framework called **Multimodal Structure Preservation Learning (MSPL)** that learns data representations that enhance the utility of one data modality through alignment with the dissimilarity-based clustering structure provided by another data modality."},{"section":"Methods","text":"MSPL entails three objectives: (1) reconstruction of the input data as in standard autoencoders for feature extraction, (2) a pretext task on which the input data has discriminatory power, and (3) structure preservation through alignment between the clustering structure of two modalities."}]},{"label":"Synth-TS Dataset Experiment","type":"experiment","detail":"The Synth-TS dataset is a synthetic time series dataset used to demonstrate the ability of MSPL to learn representations that preserve external structure. Each time series is a superposition of seasonal, trend, and noise components, parameterized by frequency and slope.","excerpts":[{"section":"Datasets","text":"We construct a synthetic time series dataset called Synth-TS to demonstrate the ability of MSPL to learn representations that preserve external structure."},{"section":"Datasets","text":"Each time series in Synth-TS is a superposition of three components: (1) a seasonal component consisting of full-wave rectified sine waves (i.e., the absolute value of a sine wave) or triangle waves, (2) a trend component consisting of a linearly increasing or declining trend, and (3) a Gaussian noise component."}]},{"label":"Proprietary Dataset Experiment","type":"experiment","detail":"The proprietary dataset consists of bacterial samples with MALDI spectra and corresponding WGS information (SNP distance). Species identification from MALDI spectra forms the pretext classification task, and the SNP distances define the external dissimilarity matrix.","excerpts":[{"section":"Datasets","text":"The proprietary dataset consists of $1862$ bacterial samples with MALDI spectra spanning $42$ species with corresponding WGS information from a single hospital."},{"section":"Datasets","text":"In our framework, species identification from MALDI spectra forms the pretext classification task, and the SNP distances define the external dissimilarity matrix $\\bm{d}$ (Eq.\tref{fstruct})."}]},{"label":"DRIAMS Dataset Experiment","type":"experiment","detail":"The DRIAMS dataset is a public dataset with paired MALDI spectra and antimicrobial resistance (AMR) profiles. Species identification from MALDI spectra is the pretext classification task, and the AMR profiles are used to construct the external dissimilarity matrix.","excerpts":[{"section":"Datasets","text":"DRIAMS\tcitep{weis2022direct} is a public dataset with paired MALDI spectra and antimicrobial resistance (AMR) profiles."},{"section":"Datasets","text":"As above, we define species identification from MALDI spectra as the pretext classification task."},{"section":"Datasets","text":"We preprocess the AMR profiles to construct the external dissimilarity matrix $\\bm{d}$, where each entry is an integer ranging from $0$ to $33$."}]}],"relationships":[{"source":"Multimodal Structure Preservation Learning","target":"representation learning for computer vision, audio, language, and other modalities"},{"source":"Multimodal Structure Preservation Learning","target":"multimodal learning"},{"source":"Multimodal Structure Preservation Learning","target":"structure preservation"},{"source":"Multimodal Structure Preservation Learning","target":"data representation"},{"source":"Multimodal Structure Preservation Learning","target":"clustering"},{"source":"Multimodal Structure Preservation Learning","target":"epidemiology"},{"source":"Multimodal Structure Preservation Learning","target":"mass spectrometry"},{"source":"Multimodal Structure Preservation Learning","target":"whole genome sequencing"},{"source":"Multimodal Structure Preservation Learning","target":"antimicrobial resistance"},{"source":"Multimodal Structure Preservation Learning","target":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality."},{"source":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality.","target":"MSPL effectively uncovers latent structures in synthetic time series data."},{"source":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality.","target":"MSPL effectively recovers clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications."},{"source":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality.","target":"MSPL can effectively inject structural information of one modality into the representations of another, improve the clustering performance, bridge the utility gap of two modalities, substantially reduce data acquisition cost, and increase feasibility of learning."},{"source":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality.","target":"MSPL excels in preserving highly diverse substructures and remains robust to the difficulty of the pretext task."},{"source":"MSPL effectively uncovers latent structures in synthetic time series data.","target":"Multimodal Structure Preservation Learning (MSPL)"},{"source":"MSPL effectively recovers clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications.","target":"Multimodal Structure Preservation Learning (MSPL)"},{"source":"MSPL can effectively inject structural information of one modality into the representations of another, improve the clustering performance, bridge the utility gap of two modalities, substantially reduce data acquisition cost, and increase feasibility of learning.","target":"Multimodal Structure Preservation Learning (MSPL)"},{"source":"MSPL excels in preserving highly diverse substructures and remains robust to the difficulty of the pretext task.","target":"Multimodal Structure Preservation Learning (MSPL)"},{"source":"Multimodal Structure Preservation Learning (MSPL)","target":"Synth-TS Dataset Experiment"},{"source":"Multimodal Structure Preservation Learning (MSPL)","target":"Proprietary Dataset Experiment"},{"source":"Multimodal Structure Preservation Learning (MSPL)","target":"DRIAMS Dataset Experiment"}],"valid_status":"Valid","valid_status_all":["Valid"]},"related":[{"summary":"The Related Paper supports the Main Paper by providing a foundational understanding of data representation techniques, particularly through the use of Laplacian Eigenmaps for clustering and information fusion in bioinformatics. It emphasizes the importance of preserving cluster structures in data, which aligns with the Main Paper's focus on leveraging structural information from one modality to enhance another. Both papers highlight the utility of advanced data representation methods in extracting valuable insights from complex datasets, reinforcing the effectiveness of the Multimodal Structure Preservation Learning (MSPL) approach proposed in the Main Paper.","paper_id":"485c4f573b9f706b905948698611200687a86e4a","title":"Data Representation for Learning and Information Fusion in Bioinformatics","abstract":"Title of dissertation: Data Representation for Learning and Information Fusion in Bioinformatics Vinodh N. Rajapakse, Doctor of Philosophy, 2013 Dissertation directed by: Professor Wojciech Czaja Department of Mathematics This thesis deals with the rigorous application of nonlinear dimension reduction and data organization techniques to biomedical data analysis. The Laplacian Eigenmaps algorithm is representative of these methods and has been widely applied in manifold learning and related areas. While their asymptotic manifold recovery behavior has been well-characterized, the clustering properties of Laplacian embeddings with finite data are largely motivated by heuristic arguments. We develop a precise bound, characterizing cluster structure preservation under Laplacian embeddings. From this foundation, we introduce flexible and mathematically well-founded approaches for information fusion and feature representation. These methods are applied to three substantial case studies in bioinformatics, illustrating their capacity to extract scientifically valuable information from complex data. DATA REPRESENTATION FOR LEARNING AND INFORMATION FUSION IN BIOINFORMATICS","score":0.6090163588523865,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality. We demonstrate the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications. The results show that MSPL can imbue the learned features with external structures and help reap the beneficial synergies occurring across disparate data modalities."},{"summary":"The Related Paper, 'MulMol: Transformer-based Multi-Task Molecular Representation Learning', supports the Main Paper by emphasizing the importance of integrating structural information in data representations, similar to the Main Paper's focus on leveraging clustering structures across modalities. Both papers highlight the limitations of existing models in generalization and the need for innovative approaches to enhance data utility. The multi-task pre-training strategy proposed in the Related Paper aligns with the Main Paper's Multimodal Structure Preservation Learning (MSPL) by showcasing how structural knowledge can improve performance in diverse applications, reinforcing the claims of the Main Paper regarding the benefits of combining different data modalities.","paper_id":"63d7f90ead2e5700df1f43bca82ad55ed095f97b","title":"MulMol: Transformer-based Multi-Task Molecular Representation Learning","abstract":"Molecular representations are crucial for accurately predicting molecular properties and are fundamental in drug design and related fields. Recently, self-supervised models have leveraged large-scale unlabeled molecular data, with transformers extending learning capabilities. However, existing frameworks predominantly rely on training data for understanding molecular structures, leading to limited generalization on diverse downstream tasks. Moreover, these models often fail to integrate molecular property knowledge effectively, further constraining their ability to generalize. To address these limitations, we propose a multi-task pre-training strategy, MulMol, which combines masked molecular structure reconstruction with property reconstruction, and incorporates contrastive learning to enhance performance. Furthermore, we introduce a similarity comparison task to ensure that the model maintains property consistency despite structural deficiencies at different positions. Evaluations on 11 benchmark datasets demonstrate that MulMol outperforms existing baselines in molecular property prediction across various domains, offering a robust AI-driven tool for drug discovery. The source code is publicly accessible on https://github.com/CMACH508/MulMol.","score":0.6016365885734558,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality. We demonstrate the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications. The results show that MSPL can imbue the learned features with external structures and help reap the beneficial synergies occurring across disparate data modalities."},{"summary":"The Related Paper, 'Binning microbial genomes using deep learning', supports the Main Paper's claims by demonstrating the effectiveness of integrating heterogeneous data sources through advanced deep learning techniques. Both papers emphasize the importance of leveraging structural information from one data modality to enhance the utility of another, as seen in the Related Paper's use of variational autoencoders to improve microbial genome reconstruction. This alignment highlights the potential of Multimodal Structure Preservation Learning (MSPL) in achieving similar synergies across diverse datasets, reinforcing the Main Paper's contributions to the field.","paper_id":"62c38988124dd3d17bcdcb09429e59f8e14e7228","title":"Binning microbial genomes using deep learning","abstract":"Identification and reconstruction of microbial species from metagenomics wide genome sequencing data is an important and challenging task. Current existing approaches rely on gene or contig co-abundance information across multiple samples and k-mer composition information in the sequences. Here we use recent advances in deep learning to develop an algorithm that uses variational autoencoders to encode co-abundance and compositional information prior to clustering. We show that the deep network is able to integrate these two heterogeneous datasets without any prior knowledge and that our method outperforms existing state-of-the-art by reconstructing 1.8 - 8 times more highly precise and complete genome bins from three different benchmark datasets. Additionally, we apply our method to a gene catalogue of almost 10 million genes and 1,270 samples from the human gut microbiome. Here we are able to cluster 1.3 - 1.8 million extra genes and reconstruct 117 - 246 more highly precise and complete bins of which 70 bins were completely new compared to previous methods. Our method Variational Autoencoders for Metagenomic Binning (VAMB) is freely available at: https://github.com/jakobnissen/vamb","score":0.5958920121192932,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality. We demonstrate the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications. The results show that MSPL can imbue the learned features with external structures and help reap the beneficial synergies occurring across disparate data modalities."},{"summary":"The Related Paper, 'Structure-Driven Representation Learning for Deep Clustering', supports the Main Paper by emphasizing the importance of incorporating structural information into representation learning for clustering tasks. Both papers highlight the utility of leveraging structural data to enhance model performance, with the Main Paper proposing Multimodal Structure Preservation Learning (MSPL) to improve data representation across different modalities. The Related Paper's focus on local and global structure-driven strategies aligns with the Main Paper's approach, reinforcing the idea that integrating structural context can lead to better clustering outcomes and improved synergies between diverse data types.","paper_id":"bdf648a3804565c9f5762881024557de34a76624","title":"Structure-Driven Representation Learning for Deep Clustering","abstract":"As an important branch of unsupervised learning methods, clustering makes a wide contribution in the area of data mining. It is well known that capturing the group-discriminative properties of each sample for clustering is crucial. Among them, deep clustering delivers promising results due to the strong representational power of neural networks. However, most of them adopt sample-level learning strategies, and the standalone data point barely captures its holistic cluster’s context and may undergo sub-optimal cluster assignment. To tackle this issue, we propose a Structure-driven Representation Learning (SRL) method by introducing latent structure information into the representation learning process at both the local and global levels. Specifically, a local-structure-driven sample representation strategy is proposed to approximate the estimation of data distribution, which models the neighborhood distribution of samples with potential structure information and exploits statistical dependencies between them to improve cluster consistency. A global-structure-driven cluster representation strategy is designed, where the context of each cluster is sufficiently encoded according to its samples (exemplar-theory) and corresponding prototype (prototype-theory). In this case, each cluster can only be related to its most similar samples, and different clusters are separated as much as possible. These two models are seamlessly combined into a joint optimization problem, which can be efficiently solved. Experiments on six widely-used datasets demonstrate the superiority of SRL over state-of-the-art clustering methods.","score":0.5939186811447144,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality. We demonstrate the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications. The results show that MSPL can imbue the learned features with external structures and help reap the beneficial synergies occurring across disparate data modalities."},{"summary":"The Related Paper, 'Cross-Domain Contrastive Learning for Time Series Clustering,' supports the Main Paper by addressing similar challenges in data representation and clustering. Both papers emphasize the importance of leveraging multiple data modalities to enhance model performance. While the Main Paper introduces Multimodal Structure Preservation Learning (MSPL) to utilize structural information from one modality to improve another, the Related Paper presents an end-to-end approach that integrates feature extraction and clustering across temporal and frequency domains. This alignment in focus on multimodal data and structural enhancement reinforces the claims made in the Main Paper regarding the benefits of combining different data types for improved learning outcomes.","paper_id":"f97766ea14aa26b89a7981eb7f63567c413e3c82","title":"Cross-Domain Contrastive Learning for Time Series Clustering","abstract":"Most deep learning-based time series clustering models concentrate on data representation in a separate process from clustering. This leads to that clustering loss cannot guide feature extraction. Moreover, most methods solely analyze data from the temporal domain, disregarding the potential within the frequency domain.\n\nTo address these challenges, we introduce a novel end-to-end Cross-Domain Contrastive learning model for time series Clustering (CDCC). Firstly, it integrates the clustering process and feature extraction using contrastive constraints at both cluster-level and instance-level. Secondly, the data is encoded simultaneously in both temporal and frequency domains, leveraging contrastive learning to enhance within-domain representation. Thirdly, cross-domain constraints are proposed to align the latent representations and category distribution across domains. With the above strategies, CDCC not only achieves end-to-end output but also effectively integrates frequency domains. Extensive experiments and visualization analysis are conducted on 40 time series datasets from UCR, demonstrating the superior performance of the proposed model.","score":0.582746684551239,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality. We demonstrate the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications. The results show that MSPL can imbue the learned features with external structures and help reap the beneficial synergies occurring across disparate data modalities."},{"summary":"The Related Paper contrasts the Main Paper by emphasizing the challenges of learning representations from non-identically distributed and dependent data, which the Main Paper does not address. While the Main Paper proposes a method (MSPL) that assumes complementary data modalities enhance learning, the Related Paper highlights that such assumptions may not hold in practical scenarios, where data dependencies and distributional differences complicate the learning process. This suggests that the Main Paper's approach may be limited in its applicability to real-world situations compared to the guarantees established in the Related Paper.","paper_id":"674974e4a04a6f00a42b9f45b7b88c32d031a84a","title":"Guarantees for Nonlinear Representation Learning: Non-identical Covariates, Dependent Data, Fewer Samples","abstract":"A driving force behind the diverse applicability of modern machine learning is the ability to extract meaningful features across many sources. However, many practical domains involve data that are non-identically distributed across sources, and statistically dependent within its source, violating vital assumptions in existing theoretical studies. Toward addressing these issues, we establish statistical guarantees for learning general $\\textit{nonlinear}$ representations from multiple data sources that admit different input distributions and possibly dependent data. Specifically, we study the sample-complexity of learning $T+1$ functions $f_\\star^{(t)} \\circ g_\\star$ from a function class $\\mathcal F \\times \\mathcal G$, where $f_\\star^{(t)}$ are task specific linear functions and $g_\\star$ is a shared nonlinear representation. A representation $\\hat g$ is estimated using $N$ samples from each of $T$ source tasks, and a fine-tuning function $\\hat f^{(0)}$ is fit using $N'$ samples from a target task passed through $\\hat g$. We show that when $N \\gtrsim C_{\\mathrm{dep}} (\\mathrm{dim}(\\mathcal F) + \\mathrm{C}(\\mathcal G)/T)$, the excess risk of $\\hat f^{(0)} \\circ \\hat g$ on the target task decays as $\\nu_{\\mathrm{div}} \\big(\\frac{\\mathrm{dim}(\\mathcal F)}{N'} + \\frac{\\mathrm{C}(\\mathcal G)}{N T} \\big)$, where $C_{\\mathrm{dep}}$ denotes the effect of data dependency, $\\nu_{\\mathrm{div}}$ denotes an (estimatable) measure of $\\textit{task-diversity}$ between the source and target tasks, and $\\mathrm C(\\mathcal G)$ denotes the complexity of the representation class $\\mathcal G$. In particular, our analysis reveals: as the number of tasks $T$ increases, both the sample requirement and risk bound converge to that of $r$-dimensional regression as if $g_\\star$ had been given, and the effect of dependency only enters the sample requirement, leaving the risk bound matching the iid setting.","score":0.638982892036438,"polarity":"negative","source":"semantic","contexts":null,"background":"When selecting data to build machine learning models in practical applications, factors such as availability, acquisition cost, and discriminatory power are crucial considerations. Different data modalities often capture unique aspects of the underlying phenomenon, making their utilities complementary. On the other hand, some sources of data host structural information that is key to their value. Hence, the utility of one data type can sometimes be enhanced by matching the structure of another.","target":null},{"summary":"The Related Paper contrasts with the Main Paper by focusing on the challenges of data integration across organizations due to privacy and legal constraints, while the Main Paper emphasizes enhancing data utility through structural matching across modalities. The Related Paper introduces a federated transfer learning framework that prioritizes user privacy and allows knowledge sharing without direct data integration, whereas the Main Paper proposes a method that relies on the complementary nature of different data modalities to improve model performance.","paper_id":"cc8379abcda8faa78e2c5e17deb96785ea447461","title":"A Secure Federated Transfer Learning Framework","abstract":"Machine learning relies on the availability of vast amounts of data for training. However, in reality, data are mostly scattered across different organizations and cannot be easily integrated due to many legal and practical constraints. To address this important challenge in the field of machine learning, we introduce a new technique and framework, known as federated transfer learning (FTL), to improve statistical modeling under a data federation. FTL allows knowledge to be shared without compromising user privacy and enables complementary knowledge to be transferred across domains in a data federation, thereby enabling a target-domain party to build flexible and effective models by leveraging rich labels from a source domain. This framework requires minimal modifications to the existing model structure and provides the same level of accuracy as the nonprivacy-preserving transfer learning. It is flexible and can be effectively adapted to various secure multiparty machine learning tasks.","score":0.6120600700378418,"polarity":"negative","source":"semantic","contexts":null,"background":"When selecting data to build machine learning models in practical applications, factors such as availability, acquisition cost, and discriminatory power are crucial considerations. Different data modalities often capture unique aspects of the underlying phenomenon, making their utilities complementary. On the other hand, some sources of data host structural information that is key to their value. Hence, the utility of one data type can sometimes be enhanced by matching the structure of another.","target":null},{"summary":"The Related Paper contrasts the Main Paper by focusing on the acquisition of training data through a federated approach in data markets, emphasizing the importance of selecting valuable data points without centralized access. While the Main Paper proposes a method (MSPL) that enhances data utility through structural matching across modalities, the Related Paper highlights a decentralized strategy that optimizes data acquisition for prediction accuracy, suggesting that the two approaches address different aspects of data utility and acquisition in machine learning.","paper_id":"83890b98b9d5aa899453eafeedef09c9e8e37196","title":"Data Acquisition via Experimental Design for Data Markets","abstract":"The acquisition of training data is crucial for machine learning applications. Data markets can increase the supply of data, particularly in data-scarce domains such as healthcare, by incentivizing potential data providers to join the market. A major challenge for a data buyer in such a market is choosing the most valuable data points from a data seller. Unlike prior work in data valuation, which assumes centralized data access, we propose a federated approach to the data acquisition problem that is inspired by linear experimental design. Our proposed data acquisition method achieves lower prediction error without requiring labeled validation data and can be optimized in a fast and federated procedure. The key insight of our work is that a method that directly estimates the benefit of acquiring data for test set prediction is particularly compatible with a decentralized market setting.","score":0.5977404713630676,"polarity":"negative","source":"semantic","contexts":null,"background":"When selecting data to build machine learning models in practical applications, factors such as availability, acquisition cost, and discriminatory power are crucial considerations. Different data modalities often capture unique aspects of the underlying phenomenon, making their utilities complementary. On the other hand, some sources of data host structural information that is key to their value. Hence, the utility of one data type can sometimes be enhanced by matching the structure of another.","target":null},{"summary":"The Related Paper contrasts with the Main Paper by focusing on automated model selection for tabular data, emphasizing the importance of individual feature contributions and their interactions, rather than leveraging multimodal data structures as proposed in the Main Paper. While the Main Paper introduces Multimodal Structure Preservation Learning to enhance data utility through structural matching across modalities, the Related Paper addresses the challenges of feature selection in a single modality context, highlighting the complexity of interactions in tabular datasets without considering multimodal synergies.","paper_id":"f8df30e1be6a54d63942d00de060665a88347c81","title":"Automated Model Selection for Tabular Data","abstract":"Structured data in the form of tabular datasets contain features that are distinct and discrete, with varying individual and relative importances to the target. Combinations of one or more features may be more predictive and meaningful than simple individual feature contributions. R's mixed effect linear models library allows users to provide such interactive feature combinations in the model design. However, given many features and possible interactions to select from, model selection becomes an exponentially difficult task. We aim to automate the model selection process for predictions on tabular datasets incorporating feature interactions while keeping computational costs small. The framework includes two distinct approaches for feature selection: a Priority-based Random Grid Search and a Greedy Search method. The Priority-based approach efficiently explores feature combinations using prior probabilities to guide the search. The Greedy method builds the solution iteratively by adding or removing features based on their impact. Experiments on synthetic demonstrate the ability to effectively capture predictive feature combinations.","score":0.5974212884902954,"polarity":"negative","source":"semantic","contexts":null,"background":"When selecting data to build machine learning models in practical applications, factors such as availability, acquisition cost, and discriminatory power are crucial considerations. Different data modalities often capture unique aspects of the underlying phenomenon, making their utilities complementary. On the other hand, some sources of data host structural information that is key to their value. Hence, the utility of one data type can sometimes be enhanced by matching the structure of another.","target":null},{"summary":"The Related Paper contrasts the Main Paper by emphasizing the challenges of using relational databases for machine learning, where current methods require manual feature engineering to aggregate data from multiple tables. In contrast, the Main Paper proposes a method (MSPL) that enhances data utility by leveraging the structural information from one modality to improve another. While the Main Paper focuses on multimodal data integration, the Related Paper introduces a novel approach (RDL) for directly learning from relational data without the need for manual preprocessing, highlighting a fundamental difference in their methodologies.","paper_id":"1181c36f7b932384defbc97c9b5d792618fda1a5","title":"Position: Relational Deep Learning - Graph Representation Learning on Relational Databases","abstract":"Much of the world’s most valued data is stored in relational databases and data warehouses, where the data is organized into tables connected by primary-foreign key relations. However, building machine learning models using this data is both challenging and time consuming because no ML algorithm can directly learn from multiple connected tables. Current approaches can only learn from a single table, so data must first be manually joined and aggregated into this format, the laborious process known as feature engineering. This position paper introduces Relational Deep Learning (RDL) , a blueprint for end-to-end learning on relational databases. The key is to represent relational databases as temporal, heterogeneous graphs, with a node for each row in each table, and edges specified by primary-foreign key links. Graph Neural Networks then learn representations that leverage all input data, without any manual feature engineering. We also introduce R EL B ENCH , and benchmark and testing suite, demonstrating strong initial results. Overall, we define a new research area that generalizes graph machine learning and broadens its applicability.","score":0.5922025442123413,"polarity":"negative","source":"semantic","contexts":null,"background":"When selecting data to build machine learning models in practical applications, factors such as availability, acquisition cost, and discriminatory power are crucial considerations. Different data modalities often capture unique aspects of the underlying phenomenon, making their utilities complementary. On the other hand, some sources of data host structural information that is key to their value. Hence, the utility of one data type can sometimes be enhanced by matching the structure of another.","target":null},{"summary":"The Related Paper, 'Preserving Modality Structure Improves Multi-Modal Learning', supports the Main Paper by emphasizing the importance of preserving modality-specific structures in multi-modal learning. Both papers highlight the complementary nature of different data modalities and propose methods to enhance learning by leveraging structural information. While the Main Paper introduces Multimodal Structure Preservation Learning (MSPL) to improve data representation across modalities, the Related Paper presents a Semantic-Structure-Preserving Consistency approach that further enhances generalizability in joint embedding spaces. Together, they underscore the significance of structural preservation in achieving effective multi-modal learning.","paper_id":"0d25f5f48d829d9528f214dc7b905e7d3f197ddf","title":"Preserving Modality Structure Improves Multi-Modal Learning","abstract":"Self-supervised learning on large-scale multi-modal datasets allows learning semantically meaningful embeddings in a joint multi-modal representation space without relying on human annotations. These joint embeddings enable zero-shot cross-modal tasks like retrieval and classification. However, these methods often struggle to generalize well on out-of-domain data as they ignore the semantic structure present in modality-specific embeddings. In this context, we propose a novel Semantic-Structure-Preserving Consistency approach to improve generalizability by preserving the modality-specific relationships in the joint embedding space. To capture modality-specific semantic relationships between samples, we propose to learn multiple anchors and represent the multifaceted relationship between samples with respect to their relationship with these anchors. To assign multiple anchors to each sample, we propose a novel Multi-Assignment Sinkhorn-Knopp algorithm. Our experimentation demonstrates that our proposed approach learns semantically meaningful anchors in a self-supervised manner. Furthermore, our evaluation on MSR-VTT and YouCook2 datasets demonstrates that our proposed multi-anchor assignment based solution achieves state-of-the-art performance and generalizes to both in-and out-of-domain datasets. Code: https://github.com/Swetha5/Multi_Sinkhorn_Knopp","score":0.7685238122940063,"polarity":"positive","source":"citations","contexts":[{"sentence":"Alternatively, \\citet{swetha2023preserving} preserved modality-specific relationships in the joint embedding space by learning semantically meaningful ``anchors\" and representing inter-sample relations with sample-anchor relations.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper on Multimodal Clustering Networks supports the Main Paper by emphasizing the importance of learning shared representations across different data modalities, which aligns with the Main Paper's focus on enhancing data utility through structural preservation. Both papers highlight the complementary nature of multimodal data and propose methods that leverage structural information to improve learning outcomes. Additionally, the Related Paper's success in zero-shot retrieval and semantic similarity grouping reinforces the effectiveness of the Main Paper's Multimodal Structure Preservation Learning approach in uncovering latent structures and enhancing model performance.","paper_id":"d9b1bb8053f32c6da9bbbec564d750d55b486f00","title":"Multimodal Clustering Networks for Self-supervised Learning from Unlabeled Videos","abstract":"Multimodal self-supervised learning is getting more and more attention as it allows not only to train large networks without human supervision but also to search and retrieve data across various modalities. In this context, this paper proposes a framework that, starting from a pre-trained backbone, learns a common multimodal embedding space that, in addition to sharing representations across different modalities, enforces a grouping of semantically similar instances. To this end, we extend the concept of instance-level contrastive learning with a multimodal clustering step in the training pipeline to capture semantic similarities across modalities. The resulting embedding space enables retrieval of samples across all modalities, even from unseen datasets and different domains. To evaluate our approach, we train our model on the HowTo100M dataset and evaluate its zero-shot retrieval capabilities in two challenging domains, namely text-to-video retrieval, and temporal action localization, showing state-of-the-art results on four different datasets.","score":0.5039278864860535,"polarity":"positive","source":"citations","contexts":[{"sentence":"To remedy this issue, \\citet{chen2021multimodal} proposed to combine the contrastive objective with a joint multimodal clustering objective to capture the cross-modal semantic similarity structure.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper supports the Main Paper by demonstrating the effectiveness of leveraging complementary data modalities, specifically through the use of natural language supervision to enhance visual model training. Both papers emphasize the importance of utilizing diverse data sources to improve model performance, with the Main Paper focusing on multimodal structure preservation and the Related Paper showcasing how textual data can enrich visual representations. This alignment highlights the potential for synergistic benefits across different modalities, reinforcing the claims made in the Main Paper.","paper_id":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","title":"Learning Transferable Visual Models From Natural Language Supervision","abstract":"State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/OpenAI/CLIP.","score":0.4459057152271271,"polarity":"positive","source":"citations","contexts":[{"sentence":"Pre-training approaches in multimodal self-supervised learning, e.g., CLIP~\\citep{radford2021learning}, commonly employ an instance-wise contrastive objective ~\\citep{oord2018representation} to learn joint features.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper on Contrastive Predictive Coding supports the Main Paper's claims by demonstrating the effectiveness of unsupervised learning in extracting useful representations across multiple data modalities. Both papers emphasize the importance of leveraging structural information from one modality to enhance the utility of another, with the Related Paper providing a robust framework for learning representations that can be applied to diverse domains. This alignment reinforces the Main Paper's proposal of Multimodal Structure Preservation Learning (MSPL) as a method that capitalizes on the complementary nature of different data types.","paper_id":"b227f3e4c0dc96e5ac5426b85485a70f2175a205","title":"Representation Learning with Contrastive Predictive Coding","abstract":"While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.","score":0.41908565163612366,"polarity":"positive","source":"citations","contexts":[{"sentence":"Pre-training approaches in multimodal self-supervised learning, e.g., CLIP~\\citep{radford2021learning}, commonly employ an instance-wise contrastive objective ~\\citep{oord2018representation} to learn joint features.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper, BLIP-2, supports the Main Paper's claims by demonstrating an efficient approach to bridging modality gaps through the use of frozen pre-trained models, which aligns with the Main Paper's focus on leveraging complementary data modalities. Both papers emphasize the importance of structural information in enhancing the utility of different data types, with BLIP-2 showcasing how effective representation learning can be achieved with fewer parameters, thereby reinforcing the Main Paper's argument for the benefits of multimodal learning strategies.","paper_id":"3f5b31c4f7350dc88002c121aecbdc82f86eb5bb","title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models","abstract":"The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pre-training strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pre-trained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.","score":0.41161268949508667,"polarity":"positive","source":"citations","contexts":[{"sentence":"Traditionally, research in multimodal machine learning attempts to bridge this gap by learning a shared feature space between data modalities~\\citep{li2023blip, liu2024visual, liu2024improved}.","polarity":"positive"},{"sentence":"In vision-language pre-training, \\citet{li2023blip} proposed the Querying Transformer (Q-Former), a connector that learns query vectors to extract the visual features most relevant to the text.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper contrasts with the Main Paper by focusing on a broader survey of multimodal machine learning rather than a specific method like Multimodal Structure Preservation Learning (MSPL). While the Main Paper emphasizes the utility of leveraging structural information from one modality to enhance another, the Related Paper discusses general challenges in multimodal learning, such as representation and alignment, without proposing a novel method. This highlights a gap in the Main Paper's approach, as it does not address the comprehensive challenges identified in the Related Paper.","paper_id":"6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91","title":"Multimodal Machine Learning: A Survey and Taxonomy","abstract":"Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.","score":0.5788620114326477,"polarity":"negative","source":"citations","contexts":[{"sentence":"On the other hand, distinct data modalities may encode different information about the same underlying phenomenon~\\citep{xu2013survey, baltruvsaitis2018multimodal}, thus forming a gap in utility.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper contrasts the Main Paper by focusing on the diversity and consensus principles in multi-view learning, rather than the structural preservation aspect emphasized by the Main Paper. While the Main Paper proposes a method (MSPL) that enhances data utility through structural matching between modalities, the Related Paper reviews various multi-view learning approaches that prioritize the integration of different views based on their complementary properties. This highlights a fundamental difference in methodology: the Main Paper seeks to leverage structural information, whereas the Related Paper emphasizes the importance of consensus and diversity among views.","paper_id":"032d67d27ecacbf6c5b82eb67e5d02d81fb43a7a","title":"A Survey on Multi-view Learning","abstract":"In recent years, a great many methods of learning from multi-view data by considering the diversity of different views have been proposed. These views may be obtained from multiple sources or different feature subsets. In trying to organize and highlight similarities and differences between the variety of multi-view learning approaches, we review a number of representative multi-view learning algorithms in different areas and classify them into three groups: 1) co-training, 2) multiple kernel learning, and 3) subspace learning. Notably, co-training style algorithms train alternately to maximize the mutual agreement on two distinct views of the data; multiple kernel learning algorithms exploit kernels that naturally correspond to different views and combine kernels either linearly or non-linearly to improve learning performance; and subspace learning algorithms aim to obtain a latent subspace shared by multiple views by assuming that the input views are generated from this latent subspace. Though there is significant variance in the approaches to integrating multiple views to improve learning performance, they mainly exploit either the consensus principle or the complementary principle to ensure the success of multi-view learning. Since accessing multiple views is the fundament of multi-view learning, with the exception of study on learning a model from multiple views, it is also valuable to study how to construct multiple views and how to evaluate these views. Overall, by exploring the consistency and complementary properties of different views, multi-view learning is rendered more effective, more promising, and has better generalization ability than single-view learning.","score":0.48005378246307373,"polarity":"negative","source":"citations","contexts":[{"sentence":"On the other hand, distinct data modalities may encode different information about the same underlying phenomenon~\\citep{xu2013survey, baltruvsaitis2018multimodal}, thus forming a gap in utility.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper contrasts the Main Paper by highlighting the limitations of current multimodal models, specifically their struggles with object recognition and detail accuracy in visual instructions. While the Main Paper proposes a method (MSPL) that enhances data utility through structural matching across modalities, the Related Paper critiques the effectiveness of multimodal connectors due to insufficient training data and suggests a different approach (TUNA) that focuses on retrieval-augmented information to improve performance. This divergence emphasizes the challenges in multimodal learning and the need for innovative solutions beyond structural preservation.","paper_id":"10e88b978fd2a455c9addc9fb4abca72fce83e34","title":"Reminding Multimodal Large Language Models of Object-aware Knowledge with Retrieved Tags","abstract":"Despite recent advances in the general visual instruction-following ability of Multimodal Large Language Models (MLLMs), they still struggle with critical problems when required to provide a precise and detailed response to a visual instruction: (1) failure to identify novel objects or entities, (2) mention of non-existent objects, and (3) neglect of object's attributed details. Intuitive solutions include improving the size and quality of data or using larger foundation models. They show effectiveness in mitigating these issues, but at an expensive cost of collecting a vast amount of new data and introducing a significantly larger model. Standing at the intersection of these approaches, we examine the three object-oriented problems from the perspective of the image-to-text mapping process by the multimodal connector. In this paper, we first identify the limitations of multimodal connectors stemming from insufficient training data. Driven by this, we propose to enhance the mapping with retrieval-augmented tag tokens, which contain rich object-aware information such as object names and attributes. With our Tag-grounded visual instruction tuning with retrieval Augmentation (TUNA), we outperform baselines that share the same language model and training data on 12 benchmarks. Furthermore, we show the zero-shot capability of TUNA when provided with specific datastores.","score":0.4524155855178833,"polarity":"negative","source":"citations","contexts":[{"sentence":"However, \\citet{qi2024reminding} found that multimodal connectors can be performance bottlenecks for multimodal large language models and may fall short with insufficient training data compared to the amount of pre-training data.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper, MERLOT, contrasts with the Main Paper by focusing on self-supervised learning from video data to develop multimodal reasoning capabilities, rather than enhancing data utility through structural matching as proposed in the Main Paper. While the Main Paper emphasizes the importance of structural information across different data modalities for improving machine learning outcomes, MERLOT showcases a model that learns contextual understanding and temporal commonsense from unlabelled video content, achieving superior performance on video question-answering tasks without relying on external structural data.","paper_id":"90357a6dc817e2f7cec477a51156675fbf545cf1","title":"MERLOT: Multimodal Neural Script Knowledge Models","abstract":"As humans, we understand events in the visual world contextually, performing multimodal reasoning across time to make inferences about the past, present, and future. We introduce MERLOT, a model that learns multimodal script knowledge by watching millions of YouTube videos with transcribed speech -- in an entirely label-free, self-supervised manner. By pretraining with a mix of both frame-level (spatial) and video-level (temporal) objectives, our model not only learns to match images to temporally corresponding words, but also to contextualize what is happening globally over time. As a result, MERLOT exhibits strong out-of-the-box representations of temporal commonsense, and achieves state-of-the-art performance on 12 different video QA datasets when finetuned. It also transfers well to the world of static images, allowing models to reason about the dynamic context behind visual scenes. On Visual Commonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy, outperforming state-of-the-art models of similar size by over 3%, even those that make heavy use of auxiliary supervised data (like object bounding boxes). Ablation analyses demonstrate the complementary importance of: 1) training on videos versus static images; 2) scaling the magnitude and diversity of the pretraining video corpus; and 3) using diverse objectives that encourage full-stack multimodal reasoning, from the recognition to cognition level.","score":0.4234391450881958,"polarity":"negative","source":"citations","contexts":[{"sentence":"However, the contrastive objective ignores the underlying semantic structure across samples~\\citep{zellers2021merlot, singh2022flava}, and thus may adversely impact model performance.","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper, FLAVA, contrasts with the Main Paper by emphasizing the need for a holistic foundational model that integrates vision and language tasks, rather than focusing on the complementary utility of different data modalities as proposed in the Main Paper. While the Main Paper introduces Multimodal Structure Preservation Learning (MSPL) to enhance data representation through structural matching across modalities, FLAVA critiques this approach by advocating for a unified model that performs well across all tasks simultaneously, suggesting that the separation of modalities may limit overall performance.","paper_id":"2fd6f77540c1cc8e70b96208ccf9971b4251fc02","title":"FLAVA: A Foundational Language And Vision Alignment Model","abstract":"State-of-the-art vision and vision-and-language models rely on large-scale visio-linguistic pretraining for obtaining good performance on a variety of downstream tasks. Generally, such models are often either cross-modal (contrastive) or multi-modal (with earlier fusion) but not both; and they often only target specific modalities or tasks. A promising direction would be to use a single holistic universal model, as a “foundation”, that targets all modalities at once-a true vision and language foundation model should be good at vision tasks, language tasks, and cross- and multi-modal vision and language tasks. We introduce FLAVA as such a model and demonstrate impressive performance on a wide range of 35 tasks spanning these target modalities.","score":0.37387874722480774,"polarity":"negative","source":"citations","contexts":[{"sentence":"However, the contrastive objective ignores the underlying semantic structure across samples~\\citep{zellers2021merlot, singh2022flava}, and thus may adversely impact model performance.","polarity":"negative"}],"background":null,"target":null}],"paper":{"title":"Multimodal Structure Preservation Learning","abstract":"When selecting data to build machine learning models in practical applications, factors such as availability, acquisition cost, and discriminatory power are crucial considerations. Different data modalities often capture unique aspects of the underlying phenomenon, making their utilities complementary. On the other hand, some sources of data host structural information that is key to their value. Hence, the utility of one data type can sometimes be enhanced by matching the structure of another. We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality. We demonstrate the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications. The results show that MSPL can imbue the learned features with external structures and help reap the beneficial synergies occurring across disparate data modalities.","authors":["Chang Liu","Jieshi Chen","Lee H Harrison","Artur Dubrawski"],"sections":[{"heading":"Introduction","text":"# Introduction\n\nSelecting the appropriate data is critical when deploying machine learning models in real-world applications. Factors such as availability, acquisition cost, and discriminatory power (reflected by information density, resolution, etc.) are of primary concern. On the other hand, distinct data modalities may encode different information about the same underlying phenomenon [@xu2013survey; @baltruvsaitis2018multimodal], thus forming a gap in utility. For instance, in medical diagnostics, imaging data such as X-ray and CT scans reveal structural anomalies, while genomic sequencing offers insights into the molecular mechanisms of diseases [@esteva2019guide].\n\nTraditionally, research in multimodal machine learning attempts to bridge this gap by learning a shared feature space between data modalities [@li2023blip; @liu2024visual; @liu2024improved]. Deviating from these feature-level alignment approaches that require complete data in two modalities, we approach the problem from *structure*-level alignment: In scenarios such as clustering, it is the structure of the data that directly influences the results. Thus, learning representations of one data modality that preserve the structure of another can extend the utility of the former and effectively bridge their gap.\n\nFor instance, in hospital outbreak investigations, epidemiologists use the single nucleotide polymorphism (SNP) distance defined on whole genome sequencing (WGS) data to cluster microbial samples, assess their lineages, and identify outbreaks. WGS provides the highest discriminatory power and is considered the gold standard in microbial disease epidemiology [@bertelli2013rapid]. However, the labor, cost, and expertise required for WGS make it prohibitive to deploy broadly [@rossen2018practical]. On the other hand, due to its low cost and rapid time to generate results, Matrix-Assisted Laser Desorption Ionization--Time of Flight (MALDI-TOF) mass spectrometry rose as a standard tool for microbial species identification in clinical microbiology laboratories [@croxatto2012applications; @clark2013matrix]. Though MALDI has weaker discriminatory power than WGS, it is gaining attention as a potential cost-effective alternative to WGS for hospital outbreak detection [@griffin2012use]. Hence, if MALDI representations that preserve the SNP distance structure can be learned, its utility can extend from species identification to outbreak detection, making it a viable substitute for WGS in practice.\n\nTo achieve the aforementioned goals, we propose a novel machine learning framework called **Multimodal Structure Preservation Learning (MSPL)** that learns data representations that enhance the utility of one data modality through alignment with the dissimilarity-based clustering structure provided by another data modality. We first demonstrate the effectiveness of MSPL in identifying latent structures on a synthetic time series dataset. We then apply MSPL to epidemiology settings, where we enhance the utility of MALDI mass spectrometry by leveraging the clustering structure in whole genome sequencing (WGS) and antimicrobial resistance (AMR) data, respectively. Our results demonstrate that MSPL can effectively inject structural information of one modality into the representations of another, improve the clustering performance, bridge the utility gap of two modalities, substantially reduce data acquisition cost, and increase feasibility of learning."},{"heading":"Related work","text":"# Related work\n\n**Multimodal connectors**. In multimodal machine learning models, connectors are employed to bridge the gap between different modalities in the feature space. In vision-language pre-training, @li2023blip proposed the Querying Transformer (Q-Former), a connector that learns query vectors to extract the visual features most relevant to the text. The Q-Former architecture has also been adopted to align time series and text features [@cai2023jolt]. Llava [@liu2024visual], a pioneering work in visual instruction fine-tuning, introduced a more lightweight connector using just a linear projection that projects image features onto the word embedding space. @liu2024improved later improved Llava's multimodal capabilities by changing the linear projection connector to a two-layer multilayer perceptron (MLP), which affords more representation power. However, @qi2024reminding found that multimodal connectors can be performance bottlenecks for multimodal large language models and may fall short with insufficient training data compared to the amount of pre-training data. They proposed to enhance the connector with retrieval-augmented tag tokens that contain rich object-aware information.\n\n**Structure in multimodal self-supervised learning**. Pre-training approaches in multimodal self-supervised learning, e.g., CLIP [@radford2021learning], commonly employ an instance-wise contrastive objective  [@oord2018representation] to learn joint features. However, the contrastive objective ignores the underlying semantic structure across samples [@zellers2021merlot; @singh2022flava], and thus may adversely impact model performance. To remedy this issue, @chen2021multimodal proposed to combine the contrastive objective with a joint multimodal clustering objective to capture the cross-modal semantic similarity structure. Alternatively, @swetha2023preserving preserved modality-specific relationships in the joint embedding space by learning semantically meaningful \"anchors\\\" and representing inter-sample relations with sample-anchor relations.\n\n**Deep learning for MALDI spectrometry**. Deep learning is widely applied to MALDI spectra analysis. @weis2022direct used an MLP to encode MALDI spectra of bacterial strains and predict their antimicrobial resistance to a range of drugs. @normand2022identification utilized a 1-D CNN to identify a subpopulation from MALDI data of the same species. @abdelmoula2021peak employed a variational autoencoder to learn low-dimensional latent features of MALDI spectra that reveal biologically relevant clusters of tumor regions."},{"heading":"Methods","text":"# Methods\n\n![Overview of the MSPL framework.](figures/fig1.pdf){#overview width=\"\\\\textwidth\"}\n\n#### Multimodal Structure Preservation Learning.\n\nFigure [1](#overview){reference-type=\"ref\" reference=\"overview\"} presents an overview of the MSPL framework. MSPL entails three objectives: (1) reconstruction of the input data as in standard autoencoders for feature extraction, (2) a pretext task on which the input data has discriminatory power, and (3) structure preservation through alignment between the clustering structure of two modalities.\n\nFormally, the input data to MSPL is $\\bm{x}$ with batch size $N$. An autoencoder consisting of an encoder $\\text{Enc}_x(\\cdot)$ and a decoder $\\text{Dec}(\\cdot)$ encodes $\\bm{x}$ to a latent representation $\\bm{h}_0$ and uses it to obtain the reconstructed input data $\\hat{\\bm{x}}$. A further encoding step $\\text{Enc}_h(\\cdot)$ prepares $\\bm{h}_0$ for the pretext task and structure preservation. In all our experiments, the autoencoder adopts the U-Net [@ronneberger2015u] architecture on 1-D data, and the pretext task is defined as a classification task, accomplished by the classification head $\\text{CLS}(\\cdot)$. The mathematical formulation for the MSPL framework is as follows: $$\\begin{aligned}\n    &\\bm{h}_0 = \\text{Enc}_x(\\bm{x}),\\\\\n    &\\hat{\\bm{x}} = \\text{Dec}(\\bm{h}_0),\\\\\n    &\\bm{h} = \\text{Enc}_h(\\bm{h}_0),~\\label{h}\\\\\n    &\\bm{z} = \\text{CLS}(\\bm{h}).~\\label{z}\n\\end{aligned}$$\n\nWe then define the loss functions corresponding to the three objectives: $$\\begin{aligned}\n    &\\mathcal{L}_{\\text{recon}} = \\frac{1}{N}\\|\\bm{x} - \\hat{\\bm{x}}\\|_2^2,\\\\\n    &\\mathcal{L}_{\\text{pretext}} = \\text{CE}(\\bm{z}, \\bm{y}),\\\\\n    &\\mathcal{L}_{\\text{struct}} = f_{\\text{struct}}(\\text{pdist}(\\bm{h}), \\bm{d})\\label{fstruct}.\n\\end{aligned}$$ Here, $\\bm{y}$ represents the labels for the pretext task, $\\text{CE}(\\cdot)$ stands for the cross-entropy loss, $\\text{pdist}(\\bm{h})$ computes the $\\ell_2$ distance between each pair of row vectors in the learned feature matrix $\\bm{h}$, and $\\bm{d}$ refers to the external dissimilarity matrix computed from another modality. The function $f_{\\text{struct}}$ matches these dissimilarities measured in the two modalities and by default is implemented as the mean squared error, but can vary as required by application.\n\nThe loss for MSPL is a weighted sum of these three losses: $$\\mathcal{L}_{\\text{MSPL}} = \\mathcal{L}_{\\text{recon}} + \\lambda_0 \\mathcal{L}_{\\text{pretext}} + \\lambda_1 \\mathcal{L}_{\\text{struct}},$$ where $\\lambda_0$ and $\\lambda_1$ are hyperparameters controlling the relative weights of the component losses.\n\nThrough MSPL, we aim to learn input data representations $\\bm{h}$ that retain discriminatory power on the pretext task while preserving the clustering structure characterized by the external dissimilarity matrix $\\bm{d}$. For example, we learn representations of MALDI spectra that readily identify species (a pretext task) while their pairwise distances recover the clusters defined by the dissimilarity among WGS or AMR data.\n\n#### Baseline models.\n\nIn comparison with MSPL, we develop two baseline models. The first model, named \"onlyCLS,\\\" constructs an ablation study by removing the structure preservation objective, i.e., $\\mathcal{L}_{\\text{struct}}$, from the MSPL loss. Hence, onlyCLS can only rely on the feature extraction capabilities of the autoencoder and the discriminatory power of the pretext task to implicitly recover the clustering structure of another modality.\n\nThe second model, named \"clusCLS,\\\" formulates structure preservation through classification. Specifically, the ground truth cluster labels $\\mathcal{C}_T$ are derived beforehand using the external dissimilarity matrix $\\bm{d}$ on the full dataset. Then, an additional classification head $\\text{CLS}_C(\\cdot)$is used to classify these cluster labels: $$\\bm{z}_c = \\text{CLS}_C(\\bm{h}\\|\\bm{z}),$$ where \"$\\|$\\\" stands for the concatenation operation, and $\\bm{h}$ and $\\bm{z}$ are the learned features and pretext classification logits as computed in Eqs. [\\[h\\]](#h){reference-type=\"ref\" reference=\"h\"} and [\\[z\\]](#z){reference-type=\"ref\" reference=\"z\"}, respectively. clusCLS also replaces $\\mathcal{L}_{\\text{struct}}$ with the following cross-entropy loss: $$\\mathcal{L}_{\\text{structCLS}} = \\text{CE}(\\bm{z}_c, \\mathcal{C}_T).$$\n\n#### Cluster evaluation.\n\nWe cluster the learned representations $\\bm{h}$ and measure the similarity of the generated clusters to those derived from the external dissimilarity matrix $\\bm{d}$. Besides adopting the Adjusted Rand Index (ARI) and Normalized Mutual Information (NMI) as standard evaluation metrics, we propose an alternative cluster similarity metric, *cluster F1 score*, as described below.\n\nWe first define the *purity* of a cluster assignment with respect to ground truth labels: given a dataset $X$, a set of clusters $\\{C_1,\\cdots, C_p\\}$ and a label set $Y$ on $X$, the purity score for the $j$-th cluster is defined as $$\\text{Purity}(C_j, Y) = \\frac{1}{|C_j|} \\max_{k\\in Y} |C_j \\cap T_k|,$$ where $T_k$ is the set of data points in $X$ with label $k$.\n\nWe then extend the purity metric to our cluster evaluation setting. Specifically, given dataset $X$, predicted clusters $\\mathcal{C}_S = \\{C_S^1, \\cdots, C_S^p\\}$ derived from the input data representations $\\bm{h}$, and \"ground truth\\\" clusters $\\mathcal{C}_T = \\{C_T^1, \\cdots, C_T^q\\}$ derived from the external dissimilarity matrix $\\bm{d}$, we define the cluster *precision*, *recall*, and *F1 score* of the predicted $\\mathcal{C}_S$ with respect to $\\mathcal{C}_T$ as follows: $$\\begin{aligned}\n    &\\text{Prec}(\\mathcal{C}_S,\\mathcal{C}_T) = \\frac{1}{p} \\sum_{i=1}^p \\text{Purity}(C_S^i, \\mathcal{C}_T),\\\\\n    &\\text{Rec}(\\mathcal{C}_S,\\mathcal{C}_T) = \\frac{1}{q} \\sum_{j=1}^q \\text{Purity}(C_T^j, \\mathcal{C}_S),\\\\\n    &\\text{F1}(\\mathcal{C}_S,\\mathcal{C}_T) = 2 \\cdot \\frac{\\text{Prec}(\\mathcal{C}_S,\\mathcal{C}_T) \\cdot \\text{Rec}(\\mathcal{C}_S,\\mathcal{C}_T)} {\\text{Prec}(\\mathcal{C}_S,\\mathcal{C}_T) + \\text{Rec}(\\mathcal{C}_S,\\mathcal{C}_T)}.\n\\end{aligned}$$\n\nTo reach high precision, each predicted cluster must contain as few distinct ground truth cluster labels as possible (i.e., be pure). To achieve high recall, the data points with the same ground truth label should be clustered together in the predictions. The defined precision reaches its maximum value $1$ when $p=|X|$ and $|C_S^i|=1$ for all $i$, while the recall reaches its maximum value $1$ when $p=1$ and $|C_S^1|=|X|$. In contrast, a cluster assignment with a high $F_1$ score does not fall into either extreme. Nevertheless, to avoid the impact of singleton ground truth clusters ($|C_T^j|= 1$) on the above metrics, we only evaluate them on the subset of the dataset where the ground truth cluster has more than $1$ element, i.e., $\\cup_{j: |C_T^j|\\ge 2} C_T^{j}\\subseteq X$."},{"heading":"Datasets","text":"# Datasets\n\nTo demonstrate the ability of MSPL to learn representations that preserve external clustering structure from another modality, we utilized three datasets: a synthetic time series dataset (Synth-TS), a proprietary dataset of MALDI spectra with paired whole genome sequencing SNP distance profiles, and a public dataset of MALDI spectra paired with AMR profiles, Database of Resistance Information on Antimicrobials and MALDI-TOF Mass Spectra (DRIAMS) [@weis2022direct].\n\n#### Synth-TS. {#synthts}\n\n![Generating the Synth-TS dataset.](figures/fig2_synthts.pdf){#synth-TS width=\"80%\"}\n\nWe construct a synthetic time series dataset called Synth-TS to demonstrate the ability of MSPL to learn representations that preserve external structure. Each time series in Synth-TS is a superposition of three components: (1) a seasonal component consisting of full-wave rectified sine waves (i.e., the absolute value of a sine wave) or triangle waves, (2) a trend component consisting of a linearly increasing or declining trend, and (3) a Gaussian noise component. Each time series is parameterized by the frequency $f$ of the seasonal component and the slope $k$ of the trend component. As shown in Figure [2](#synth-TS){reference-type=\"ref\" reference=\"synth-TS\"}, $(f,k)$ are jointly sampled from a two-dimensional Gaussian distribution. In Synth-TS, we construct a grid of such two-dimensional Gaussians and randomly generate multiple time series from each Gaussian. Formally, the dataset Synth-TS$(m, n)$ generates $2n$ samples from each Gaussian in a $m\\times m$ grid, with $n$ samples having a sine wave component and $n$ samples having a triangle wave component.\n\nWe define the pretext task as the binary classification of seasonal components (sine or triangle waves). The MSPL framework learns representations of the time series such that their pairwise distances match the external pairwise dissimilarity, which we defined as the Euclidean distance between their respective parameters $(f,k)$. This encourages the time series to cluster according to the Gaussian distributions generating their parameters. More details about the construction of Synth-TS can be found in Appendix [7](#synth_ts){reference-type=\"ref\" reference=\"synth_ts\"}.\n\n#### Proprietary dataset.\n\nThe proprietary dataset consists of $1862$ bacterial samples with MALDI spectra spanning $42$ species with corresponding WGS information from a single hospital. Though the raw WGS data were unavailable, we have access to the pairwise dissimilarity of this data, measured by SNP distance. In our framework, species identification from MALDI spectra forms the pretext classification task, and the SNP distances define the external dissimilarity matrix $\\bm{d}$ (Eq. [\\[fstruct\\]](#fstruct){reference-type=\"ref\" reference=\"fstruct\"}).\n\nIn bacterial outbreak investigations, SNP distances lower than a pre-defined threshold indicate closely related or nearly identical strains that may form an outbreak cluster [@guerra2015recurrence; @hatherell2016interpreting]. In our experiments, the threshold is set to $15$ as used by epidemiologists [@xiao2024define]. To derive the ground truth outbreak clusters from the SNP distances, we apply hierarchical clustering with complete linkage on the full SNP distance matrix, using $15$ as the distance threshold.\n\nWhile small SNP distances are crucial to outbreak cluster detection, the distances can vary drastically in scale, ranging from less than $10$ to more than $10^5$. Here, we develop a custom loss function for the structure preservation objective that avoids potential overfitting to large SNP distances:\n\n$$\\begin{aligned}\n    &\\mathcal{L}_{\\text{struct}} = \\frac{1}{N^2}\\sum_{i,j\\in[N]^2} f_{\\text{SNP}}(\\text{pdist}(\\bm{h})_{ij}, \\bm{d}_{ij}, t),\\\\\n    &f_{\\text{SNP}}(x, y, t) = \\begin{cases}\n        (x - y)^2 & y \\le t, \\\\\n        (\\max\\{0, t - x\\})^2 & y > t,\n        \\end{cases}\n\\end{aligned}$$ where $\\text{pdist}(\\bm{h})$ and $\\bm{d}$ are the feature distance and SNP distance matrices, respectively (Eq. [\\[fstruct\\]](#fstruct){reference-type=\"ref\" reference=\"fstruct\"}), $N$ is the batch size, and $t$ is the chosen SNP threshold. Under this custom loss function, no penalty is imposed when both the feature distance and SNP distance exceed the SNP threshold, as they have no impact on the practice of outbreak detection.\n\n#### DRIAMS data.\n\nDRIAMS [@weis2022direct] is a public dataset with paired MALDI spectra and antimicrobial resistance (AMR) profiles. In our experiments, we use the DRIAMS-B and DRIAMS-C subsets, which consist of $10404$ bacterial samples with MALDI spectra spanning $251$ species. As above, we define species identification from MALDI spectra as the pretext classification task.\n\nThe AMR profile of each bacterial sample documents its resistance to various antibiotics. We utilize the AMR profiles against $33$ shared drugs recorded in both DRIAMS subsets. We preprocess the AMR profiles to construct the external dissimilarity matrix $\\bm{d}$, where each entry is an integer ranging from $0$ to $33$. Details about the AMR profile preprocessing can be found in Appendix [8](#driams-sim){reference-type=\"ref\" reference=\"driams-sim\"}.\n\nTo derive ground truth outbreak clusters from the AMR dissimilarity matrix, we apply hierarchical clustering with varying distance thresholds from $1$ to $33$. The optimal threshold---chosen to maximize the number of non-singleton clusters---is set to $10$ for ground truth generation."},{"heading":"Experiments and Results","text":"# Experiments and Results\n\nIn our experiments, we adopt two different clustering schemes for the features $\\bm{h}$ learned from MSPL and onlyCLS. The first scheme involves hierarchical clustering with a distance threshold, denoted by the subscript \"thr.\" For the proprietary dataset and DRIAMS, we first determine the distance threshold that yields the optimal cluster F1 score on the training data. Specifically, for the proprietary dataset, the upper bound of the thresholds is set to $20$, an alternative threshold used by epidemiologists for outbreak detection [@szarvas2021rapid], which is close to the threshold we used to obtain groud-truth clusters. For DRIAMS, the upper bound is set to $33$, the maximum dissimilarity between AMR profiles (see Appendix [8](#driams-sim){reference-type=\"ref\" reference=\"driams-sim\"}). The same threshold is then used for evaluation. The second scheme also employs hierarchical clustering, but the number of output clusters is set to match that of the ground truth. We denote this scheme by the subscript \"num.\\\" For Synth-TS, only the second clustering scheme is used since the ground truth clusters are not derived from hierarchical clustering with a distance threshold.\n\nFor evaluation, we perform $2$-fold cross-validation on Synth-TS and the proprietary dataset and $5$-fold cross-validation for DRIAMS. Each cross-validation experiment is repeated over $5$ random trials, using different random seeds for data splitting. We first average the metrics across the validation folds, then report the mean and the $95\\%$ confidence interval (using $t$-distribution) of the averaged metrics across the $5$ random trials.\n\n## Observation 1: MSPL effectively preserves external structure {#perfromance eval .unnumbered}\n\n#### Uncovering latent structure in Synth-TS.\n\nWe evaluate our models on three versions of the Synth-TS dataset: Synth-TS$(5, 80)$, Synth-TS$(10, 20)$, and Synth-TS$(16, 10)$, containing $80$, $20$, and $10$ samples per type of the seasonal component (sine or triangle) per Gaussian, respectively.\n\nAs shown in Table [\\[performance\\]](#performance){reference-type=\"ref\" reference=\"performance\"}, while MSPL falls short of clusCLS in terms of F1 score and ARI on Synth-TS$(5, 80)$, it significantly outperforms clusCLS across *all* clustering metrics on Synth-TS$(10, 20)$ and Synth-TS$(16, 10)$, suggesting that MSPL has a marked advantage over the classification approach on sparser datasets.\n\nFurthermore, for the clusCLS model, all reported clustering metrics-----except NMI-----exhibit a clear downward trend as the number of samples per class decreases. This is expected, as fewer samples make it more challenging for the cluster label classifier to accurately capture class characteristics. In contrast, the metrics for MSPL remain consistent despite the decreasing number of samples per Gaussian, suggesting that MSPL is more effective at preserving external clustering structures and is robust to cluster sparsity.\n\nAdditionally, MSPL consistently outperforms onlyCLS in ARI, NMI, cluster recall, and cluster F1 score, underscoring the importance of dissimilarity matching in $\\mathcal{L}_{\\text{struct}}$ for structure preservation.\n\n#### Recovering WGS clusters in the proprietary dataset.\n\n::: wrapfigure\nR0.45 ![image](figures/KLP_bipartite_11.pdf){width=\"\\\\linewidth\"}\n:::\n\nWe first observe that when the number of predicted clusters is constrained to match the ground truth, $\\text{MSPL}_\\text{num}$ outperforms the other models in both NMI and cluster F1 score. Furthermore, $\\text{MSPL}_\\text{thr}$ vastly outperforms both $\\text{onlyCLS}_\\text{thr}$ and clusCLS in terms of cluster recall and F1 score. This demonstrates the superior ability of MSPL to preserve structure in real-world settings, effectively mimicking the decision-making criterion of epidemiologists during outbreak investigations.\n\nFigure [\\[fig:klpBip\\]](#fig:klpBip){reference-type=\"ref\" reference=\"fig:klpBip\"} presents the bipartite graph showing the correspondence between ground truth WGS clusters and predicted clusters for one of the species, *Klebsiella pneumoniae*, with links indicating matched clusters with at least two samples. Our method manages to group data points of the same ground truth cluster together (high recall), though the precision is lower given the two large MALDI clusters, instead of eight smaller WGS clusters.\n\n#### Recovering AMR clusters in DRIAMS.\n\nAs shown in Table [\\[performance\\]](#performance){reference-type=\"ref\" reference=\"performance\"}, MSPL outperforms all baseline models in precision, recall, and F1 score. Additionally, when we constrain the number of output clusters to match the ground truth, $\\text{MSPL}_\\text{num}$ outperforms other models in NMI. Figure [3](#fig:driamsDuo){reference-type=\"ref\" reference=\"fig:driamsDuo\"} illustrates the ground truth and predicted clusters of data points projected through multidimensional scaling of the predicted dissimilarity matrix ($\\text{pdist}(\\bm{h})$). These findings further validate MSPL's ability to learn representations that preserve external structure, effectively bridging different modalities.\n\n<figure id=\"fig:driamsDuo\">\n<table>\n<tbody>\n<tr>\n<td style=\"text-align: center;\"><embed src=\"figures/DRIAMS_gt4.pdf\" style=\"width:45.0%\" /></td>\n<td style=\"text-align: center;\"><embed src=\"figures/DRIAMS_predicted4.pdf\" style=\"width:45.0%\" /></td>\n</tr>\n</tbody>\n</table>\n<figcaption>Multidimensional scaling projection based on predicted distance matrix of DRIAMS data using MSPL model, colored in ground truth clusters (left) and predicted clusters (right) respectively. MSPL recovered most of the clusters in ground truth. </figcaption>\n</figure>\n\n## Observation 2: MSPL thrives in diverse data subsets {#entropy .unnumbered}\n\n![Lift in F1 score for different species in the proprietary dataset and DRIAMS, sorted by the entropy of ground truth clusters or the pretext accuracy. The dot size reflects the number of MALDI samples in that species. Species label descriptions are listed in Appendix [9](#species_label){reference-type=\"ref\" reference=\"species_label\"}.](figures/fig5_lift.pdf){#lift width=\"\\\\linewidth\"}\n\nAfter evaluating the model performance on the full datasets, we now investigate the impact of data substructure on MSPL's performance. In both the proprietary dataset and DRIAMS, the ground truth clusters assigned to MALDI samples within a single bacterial species naturally represent such substructures. For each species-defined subset, we calculate the *lift* in cluster F1-score between MSPL and the two baseline models. The lift is defined as the ratio of MSPL's cluster F1-score to that of clusCLS or onlyCLS. To characterize the substructure, we measure the \"diversity\\\" of each subset using the mean Shannon entropy of the ground truth cluster assignment on its samples across the validation sets.\n\nWe then plot the lift against the Shannon entropy for all species in both the proprietary dataset and DRIAMS. We find that MSPL achieves outperforms onlyCLS (i.e., $\\text{lift}>1$) in all subsets of the proprietary dataset except *Stenotrophomonas maltophilia* (STEN) (Figure [5(a)](#lift)) and in the majority of subsets in DRIAMS (Appendix [10](#lift-appendix){reference-type=\"ref\" reference=\"lift-appendix\"}). This result underscores the importance of the dissimilarity matching to MSPL's ability to preserve structure across different subsets of the data.\n\nOn the other hand, when compared to clusCLS, MSPL achieves higher lift for species with greater Shannon entropy in both datasets (Figure [5(c,e)](#lift)). This finding suggests that, compared to the classification approach, MSPL excels when the data exhibits high diversity in cluster distribution.\n\n## Observation 3: MSPL is robust to the difficulty of its pretext task {#observation-3-mspl-is-robust-to-the-difficulty-of-its-pretext-task .unnumbered}\n\nWe further investigate whether the difficulty of the pretext task affects structure preservation in MSPL. Again, we evaluate model performance on the species-defined subsets of both the proprietary dataset and DRIAMS.\n\nTo quantify the difficulty of the pretext task for each species, we calculate the mean accuracy of predicting that species across the validation sets. As illustrated in Figure [5(b,d)](#lift), the relationship between MSPL and baseline F1 scores in the proprietary dataset is agnostic to pretext task accuracy. Notably, the lift can exceed $1$ for species with both high and low pretext task accuracies. A similar pattern is observed in DRIAMS (Figure [5(f)](#lift) and Appendix [10](#lift-appendix){reference-type=\"ref\" reference=\"lift-appendix\"}). These results suggest that the difficulty of the pretext task does not limit MSPL's ability to preserve structure."},{"heading":"Discussion","text":"# Discussion\n\nWe introduced Multimodal Structure Preservation Learning (MSPL), a method designed to enhance the utility of a data modality by learning representations that preserve external clustering structures from another modality. Through empirical evaluation, we demonstrate that MSPL can effectively capture and preserve latent structures in synthetic time series, whole genome sequencing (WGS), and antimicrobial resistance (AMR) data. Additionally, MSPL offers two advantages: it excels in preserving highly diverse substructures and remains robust to the difficulty of the pretext task. Our approach is a novel addition to the family of multimodal machine learning techniques in that it aggregates information across different forms of its representation, even though the underlying form of data may originally be transactional in both sources. It can be useful in applications where a pattern structure present in some data sources can support models trained on other data sources.\n\n![Distributions of clusters on the proprietary dataset. There are $544$ ground truth clusters while $\\text{MSPL}_{\\text{thr}}$ predicted only $38$ clusters.](figures/fig6_discuss.pdf){#clusdistribution width=\"\\\\linewidth\"}\n\n#### Limitations.\n\nIn our performance evaluation (Table [\\[performance\\]](#performance){reference-type=\"ref\" reference=\"performance\"}), we observed that MSPL yields low NMI scores on both the proprietary dataset and DRIAMS when clustering the learned features using a distance threshold ($\\text{MSPL}_{\\text{thr}}$). However, when constraining the number of clusters ($\\text{MSPL}_{\\text{num}}$), the NMI score improves and surpasses the baseline, albeit resulting in a drop in the F1 score. Additionally, for both clustering schemes, the ARI remains consistently low. While NMI can be inadequate when comparing predictions to a large number of clusters [@amelio2015normalized], and ARI is more suitable for comparisons involving large, equally sized clusters [@romano2016adjusting], the low NMI and ARI scores indicate a potential limitation of the current MSPL framework in handling imbalanced cluster distributions, as observed in the proprietary dataset (Figure [5](#clusdistribution){reference-type=\"ref\" reference=\"clusdistribution\"}). Moreover, in real-world clinical applications (e.g., outbreak detection), the number of clusters is often unknown, making it infeasible to apply the $\\text{MSPL}_{\\text{num}}$ model.\n\n#### Future work.\n\nGiven the limitations of the current MSPL framework, future research will focus on improving it in the face of cluster imbalance. Specifically, we plan to enhance the structure preservation objective ($\\mathcal{L}_{\\text{struct}}$) by incorporating additional supervision that encourages MSPL to accurately estimate the number of ground truth clusters as well as their distribution. We will also experiment with more than one source of structural information (e.g., including WGS *and* AMR simultaneously in support of learning on MALDI data), and consider other than clustering structures as sources of predictive information for associated tasks.\n\n### Acknowledgments {#acknowledgments .unnumbered}\n\nThis study was partially funded by the National Institute of Allergy and Infectious Diseases (R01AI127472) and the National Science Foundation award (2406231). The authors thank Nicholas Gisolfi and Jiayi Li for helpful discussions."},{"heading":"Constructing Synth-TS","text":"# Constructing Synth-TS {#synth_ts}\n\n#### Gaussian grid.\n\nWe first construct an $N_\\mu \\times N_\\mu$ grid to define the means of the Gaussians from which we sample $(f, k)$. For simplicity, we assume the two dimensions of the Gaussians are independent, with standard deviations $\\sigma_f$ and $\\sigma_k$ for all Gaussians.\n\nThe mean frequency and slopes are defined as follows: $$\\begin{aligned}\n    &\\mu_f\\in [\\mu_0, \\mu_0 + 2\\sqrt{2}\\sigma_f, \\cdots, \\mu_0 + 2(N_\\mu - 1)\\sqrt{2}\\sigma_f],\\\\\n    &\\mu_k\\in [-\\sqrt{2}N_\\mu\\sigma_k, (-N_\\mu +2)\\sqrt{2}\\sigma_k,  \\cdots, (-N_\\mu +2(N_\\mu - 1))\\sqrt{2}\\sigma_k].\n\\end{aligned}$$\n\nIn the frequency direction, the distance between two points sampled from the same Gaussian follows a normal distribution $\\mathcal{N}(0, 2\\sigma^2_f)$. Conversely, for two points sampled from distinct Gaussians, their distance follows a distribution $\\mathcal{N}(2\\sqrt{2}k\\sigma_f, 2\\sigma^2_f)$ for $k\\geq 1$. The results for the slope direction are analogous. In our experiments, we set $\\mu_0=0.2$, $\\sigma_f=0.4$, and $\\sigma_k=0.5$.\n\n#### Seasonal component.\n\nFrom each Gaussian in the grid, we generate time series of duration $2$ seconds and sampling rate $256$Hz. The sine waves and triangle waves are defined as follows: $$\\begin{aligned}\n    &\\text{Sine}(f, t) = |\\sin(\\pi ft)| + b,\\\\\n    &\\text{Triangle}(f, t) = \n    \\begin{cases} \n    4fx -1 + b& 0 \\le x < \\frac{1}{2},\\\\\n    -4fx + 2 + b& \\frac{1}{2} \\le x < 1,\\\\\n    \\end{cases}\n\\end{aligned}$$ where $x = tf - \\lfloor tf \\rfloor$ and the offset $b$ is set to $1$.\n\n#### Trend component.\n\nThe trend component, parameterized by $k$, is defined as follows: $$\\text{Trend}(k, t) = \n\\begin{cases}\n    kt & k \\le 0,\\\\\n    k(t - \\max(t)) & k < 0.\n\\end{cases}$$\n\n#### Gaussian noise.\n\nFor each sampled data point on the time series, we added a Gaussian noise component: $\\textit{Noise}\\sim \\mathcal{N}(0, \\sigma_n^2)$. We set $\\sigma_n=0.02$ in our experiments."},{"heading":"AMR profile Preprocessing in DRIAMS","text":"# AMR profile Preprocessing in DRIAMS {#driams-sim}\n\nAMR profiles The DRIAMS dataset uses a mixed labeling scheme to represent AMR. Each AMR label can be one of 'S'(susceptible), 'R'(resistant), 'I'(Intermediate), '1'(susceptible or intermediate), '0'(susceptible), or unknown (we labeled as 'N').\n\nWe first build the following similarity lookup table between labels:\n\n::: center\n      S   I   R   1   0   N\n  --- --- --- --- --- --- ---\n  S   1   0   0   0   1   0\n  I   0   1   0   1   0   0\n  R   0   0   1   1   0   0\n  1   0   1   1   1   0   0\n  0   1   0   0   0   1   0\n  N   0   0   0   0   0   0\n\n  : Similarity between AMR labels in DRIAMS.\n:::\n\nFor a pair of AMR profiles, we look up and sum the similarity for each pair of AMR labels to get the similarity between the AMR profiles. For example, profiles \\['1', 'S', 'N'\\] and \\['I', '0', 'R'\\] will have similarity $1 + 1 + 0 = 2$. The *dissimilarity* between the two profiles is calculated by subtracting the similarity from the length of the AMR profiles, i.e., the number of drugs."},{"heading":"Species Label Descriptions of the Proprietary Dataset","text":"# Species Label Descriptions of the Proprietary Dataset {#species_label}\n\n::: {#species_table}\n  **Label**   **Species**\n  ----------- -----------------------------------\n  ACIN        Acinetobacter baumannii\n  BC          Burkholderia cepaciae\n  CB          Citrobacter\n  EB          Enterobacter cloacae\n  EC          Escherichia coli\n  KLO         Klebsiella oxytoca\n  KLP         Klebsiella pneumoniae\n  MRSA        Staphylococcus aureus\n  PR          Proteus mirabilis\n  PRV         Providencia\n  PSA         Pseudomonas aeruginosa\n  PSB         Pseudomonas\n  SER         Serratia marcescens\n  STEN        Stenotrophomonas maltophilia\n  VRE         Vancomycin-resistant Enterococcus\n\n  : Reference table for species appearing in Figure [\\[entropy\\]](#entropy){reference-type=\"ref\" reference=\"entropy\"}.\n:::"},{"heading":"Lift in F1 score for MSPL vs onlyCLS on DRIAMS","text":"# Lift in F1 score for MSPL vs onlyCLS on DRIAMS {#lift-appendix}\n\n![Lift in F1 score between MSPL and onlyCLS for different species on DRIAMS, sorted by the entropy of ground truth clusters or the pretext accuracy. The dot size reflects the number of MALDI samples in that species.](figures/appendix_lift.pdf){width=\"100%\"}"}],"approval":false,"conference":"iclr","rating":2,"year":2025,"id":"004c04c2897abc170e9934b2d2a968d130d3e6054e1677412b882beb2c564ecf","y_true":0,"y_pred":0,"rationale_true":"Summary: The paper proposed a domain adaptation method that learns the data distribution structure in one modal and transfer it to the other modal. They applied it to the problem of hospital outbreak detection that using MALDI and whole genome sequencing.\n\nStrengths: The stated problem is pervasive in biomedical applications and is challenging.\n\nWeaknesses: 1) This is a typical subset of domain adaptation problems. However, they did not include SOTA domain adaptation methods into the baseline. The baseline methods are weak.\n2) Also, from references we see that there are already methods that perform prediction tasks directly based on MALDI, which were not compared.\n3) The experiments are carried out only on MALDI-WGS datasets and most are synthetic datasets. Due to the small-sample nature of these problems, the models are vulnerable to short-cut learning and testing on several similar datasets is not reliable. I don't see any reason that the problem should be restricted on MALDI-WGS data. There are lots of two-domain problems with similar character in biomedical fields and the data should be tested on more types of applications.\n\nQuestions: How does the \"seasonal and trend components\" in the synthetic datasets related to MALDI-WGS matching?","rationale_pred":"Paper Summary: The paper introduces Multimodal Structure Preservation Learning (MSPL), a novel method for learning data representations. MSPL leverages the clustering structure of one data modality to enhance the utility of another. It demonstrates the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data. The method involves reconstruction of input data, a pretext task, and structure preservation through alignment between the clustering structure of two modalities.\n\nSupporting Evidence:\n- The paper 'Data Representation for Learning and Information Fusion in Bioinformatics' supports the main paper by providing a foundational understanding of data representation techniques, particularly through the use of Laplacian Eigenmaps for clustering and information fusion in bioinformatics, emphasizing the importance of preserving cluster structures in data.\n- The paper 'MulMol: Transformer-based Multi-Task Molecular Representation Learning' supports the main paper by emphasizing the importance of integrating structural information in data representations.\n- The paper 'Binning microbial genomes using deep learning' supports the main paper's claims by demonstrating the effectiveness of integrating heterogeneous data sources through advanced deep learning techniques.\n- The paper 'Structure-Driven Representation Learning for Deep Clustering' supports the main paper by emphasizing the importance of incorporating structural information into representation learning for clustering tasks.\n- The paper 'Preserving Modality Structure Improves Multi-Modal Learning' supports the main paper by emphasizing the importance of preserving modality-specific structures in multi-modal learning.\n\nContradictory Evidence:\n- The paper 'Guarantees for Nonlinear Representation Learning: Non-identical Covariates, Dependent Data, Fewer Samples' contrasts the main paper by emphasizing the challenges of learning representations from non-identically distributed and dependent data, which the main paper does not address.\n- The paper 'A Secure Federated Transfer Learning Framework' contrasts with the main paper by focusing on the challenges of data integration across organizations due to privacy and legal constraints.\n- The paper 'Data Acquisition via Experimental Design for Data Markets' contrasts the main paper by focusing on the acquisition of training data through a federated approach in data markets, emphasizing the importance of selecting valuable data points without centralized access.\n- The paper 'Automated Model Selection for Tabular Data' contrasts with the main paper by focusing on automated model selection for tabular data, emphasizing the importance of individual feature contributions and their interactions, rather than leveraging multimodal data structures.\n- The paper 'Multimodal Machine Learning: A Survey and Taxonomy' contrasts with the main paper by focusing on a broader survey of multimodal machine learning rather than a specific method like Multimodal Structure Preservation Learning (MSPL), discussing general challenges in multimodal learning, such as representation and alignment, without proposing a novel method.\n\nConclusion: While the paper introduces a specific method (MSPL) for multimodal learning, several related papers highlight the challenges and alternative approaches in the field. Some papers support the idea of leveraging structural information, but others focus on different aspects such as data dependencies, privacy constraints, and the need for holistic models. Given the existence of alternative approaches and the limitations of MSPL in addressing broader challenges, the paper's novelty is questionable.","structured_evaluation":{"paper_summary":"The paper introduces Multimodal Structure Preservation Learning (MSPL), a novel method for learning data representations. MSPL leverages the clustering structure of one data modality to enhance the utility of another. It demonstrates the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data. The method involves reconstruction of input data, a pretext task, and structure preservation through alignment between the clustering structure of two modalities.","supporting_evidence":["The paper 'Data Representation for Learning and Information Fusion in Bioinformatics' supports the main paper by providing a foundational understanding of data representation techniques, particularly through the use of Laplacian Eigenmaps for clustering and information fusion in bioinformatics, emphasizing the importance of preserving cluster structures in data.","The paper 'MulMol: Transformer-based Multi-Task Molecular Representation Learning' supports the main paper by emphasizing the importance of integrating structural information in data representations.","The paper 'Binning microbial genomes using deep learning' supports the main paper's claims by demonstrating the effectiveness of integrating heterogeneous data sources through advanced deep learning techniques.","The paper 'Structure-Driven Representation Learning for Deep Clustering' supports the main paper by emphasizing the importance of incorporating structural information into representation learning for clustering tasks.","The paper 'Preserving Modality Structure Improves Multi-Modal Learning' supports the main paper by emphasizing the importance of preserving modality-specific structures in multi-modal learning."],"contradictory_evidence":["The paper 'Guarantees for Nonlinear Representation Learning: Non-identical Covariates, Dependent Data, Fewer Samples' contrasts the main paper by emphasizing the challenges of learning representations from non-identically distributed and dependent data, which the main paper does not address.","The paper 'A Secure Federated Transfer Learning Framework' contrasts with the main paper by focusing on the challenges of data integration across organizations due to privacy and legal constraints.","The paper 'Data Acquisition via Experimental Design for Data Markets' contrasts the main paper by focusing on the acquisition of training data through a federated approach in data markets, emphasizing the importance of selecting valuable data points without centralized access.","The paper 'Automated Model Selection for Tabular Data' contrasts with the main paper by focusing on automated model selection for tabular data, emphasizing the importance of individual feature contributions and their interactions, rather than leveraging multimodal data structures.","The paper 'Multimodal Machine Learning: A Survey and Taxonomy' contrasts with the main paper by focusing on a broader survey of multimodal machine learning rather than a specific method like Multimodal Structure Preservation Learning (MSPL), discussing general challenges in multimodal learning, such as representation and alignment, without proposing a novel method."],"conclusion":"While the paper introduces a specific method (MSPL) for multimodal learning, several related papers highlight the challenges and alternative approaches in the field. Some papers support the idea of leveraging structural information, but others focus on different aspects such as data dependencies, privacy constraints, and the need for holistic models. Given the existence of alternative approaches and the limitations of MSPL in addressing broader challenges, the paper's novelty is questionable.","label":0,"rationale":"Paper Summary: The paper introduces Multimodal Structure Preservation Learning (MSPL), a novel method for learning data representations. MSPL leverages the clustering structure of one data modality to enhance the utility of another. It demonstrates the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data. The method involves reconstruction of input data, a pretext task, and structure preservation through alignment between the clustering structure of two modalities.\n\nSupporting Evidence:\n- The paper 'Data Representation for Learning and Information Fusion in Bioinformatics' supports the main paper by providing a foundational understanding of data representation techniques, particularly through the use of Laplacian Eigenmaps for clustering and information fusion in bioinformatics, emphasizing the importance of preserving cluster structures in data.\n- The paper 'MulMol: Transformer-based Multi-Task Molecular Representation Learning' supports the main paper by emphasizing the importance of integrating structural information in data representations.\n- The paper 'Binning microbial genomes using deep learning' supports the main paper's claims by demonstrating the effectiveness of integrating heterogeneous data sources through advanced deep learning techniques.\n- The paper 'Structure-Driven Representation Learning for Deep Clustering' supports the main paper by emphasizing the importance of incorporating structural information into representation learning for clustering tasks.\n- The paper 'Preserving Modality Structure Improves Multi-Modal Learning' supports the main paper by emphasizing the importance of preserving modality-specific structures in multi-modal learning.\n\nContradictory Evidence:\n- The paper 'Guarantees for Nonlinear Representation Learning: Non-identical Covariates, Dependent Data, Fewer Samples' contrasts the main paper by emphasizing the challenges of learning representations from non-identically distributed and dependent data, which the main paper does not address.\n- The paper 'A Secure Federated Transfer Learning Framework' contrasts with the main paper by focusing on the challenges of data integration across organizations due to privacy and legal constraints.\n- The paper 'Data Acquisition via Experimental Design for Data Markets' contrasts the main paper by focusing on the acquisition of training data through a federated approach in data markets, emphasizing the importance of selecting valuable data points without centralized access.\n- The paper 'Automated Model Selection for Tabular Data' contrasts with the main paper by focusing on automated model selection for tabular data, emphasizing the importance of individual feature contributions and their interactions, rather than leveraging multimodal data structures.\n- The paper 'Multimodal Machine Learning: A Survey and Taxonomy' contrasts with the main paper by focusing on a broader survey of multimodal machine learning rather than a specific method like Multimodal Structure Preservation Learning (MSPL), discussing general challenges in multimodal learning, such as representation and alignment, without proposing a novel method.\n\nConclusion: While the paper introduces a specific method (MSPL) for multimodal learning, several related papers highlight the challenges and alternative approaches in the field. Some papers support the idea of leveraging structural information, but others focus on different aspects such as data dependencies, privacy constraints, and the need for holistic models. Given the existence of alternative approaches and the limitations of MSPL in addressing broader challenges, the paper's novelty is questionable."},"arxiv_id":"2410.22520"},"terms":{"tasks":["building machine learning models","enhancing the utility of data from another modality","uncovering latent structures in synthetic time series data","recovering clusters from whole genome sequencing and antimicrobial resistance data","supporting epidemiology applications"],"methods":["Multimodal Structure Preservation Learning"],"metrics":[],"resources":["mass spectrometry data"],"relations":[{"head":"Multimodal Structure Preservation Learning","tail":"building machine learning models"},{"head":"Multimodal Structure Preservation Learning","tail":"enhancing the utility of data from another modality"},{"head":"Multimodal Structure Preservation Learning","tail":"uncovering latent structures in synthetic time series data"},{"head":"Multimodal Structure Preservation Learning","tail":"recovering clusters from whole genome sequencing and antimicrobial resistance data"},{"head":"mass spectrometry data","tail":"supporting epidemiology applications"}]},"background":"When selecting data to build machine learning models in practical applications, factors such as availability, acquisition cost, and discriminatory power are crucial considerations. Different data modalities often capture unique aspects of the underlying phenomenon, making their utilities complementary. On the other hand, some sources of data host structural information that is key to their value. Hence, the utility of one data type can sometimes be enhanced by matching the structure of another.","target":"We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality. We demonstrate the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications. The results show that MSPL can imbue the learned features with external structures and help reap the beneficial synergies occurring across disparate data modalities."},{"graph":{"title":"SelfVC: Voice Conversion With Iterative Refinement using Self Transformations","abstract":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples. Previous efforts on voice conversion focus on factorizing speech into explicitly disentangled representations that separately encode speaker characteristics and linguistic content. However, disentangling speech representations to capture such attributes using task-specific loss terms can lead to information loss by discarding finer nuances such as accent and emotion of the original signal. In this work, instead of explicitly disentangling attributes with loss terms, we present a framework to train a controllable voice conversion model on entangled speech representations derived from self-supervised learning (SSL) and speaker verification models. First, we develop techniques to derive prosodic information from the audio signal and SSL representations to train predictive submodules in the synthesis model. Next, we propose a training strategy to iteratively improve the synthesis model for voice conversion, by creating a challenging training objective using self-synthesized examples. In this training approach, the current state of the synthesis model is used to generate voice-converted variations of an utterance, which serve as inputs for the reconstruction task, ensuring a continuous and purposeful refinement of the model. We demonstrate that incorporating such self-synthesized examples during training improves the speaker similarity of generated speech as compared to a baseline voice conversion model trained solely on heuristically perturbed inputs. Our framework is trained without any text and is applicable to a range of tasks such as zero-shot voice conversion, voice conversion across different languages, and controllable speech synthesis with pitch and pace modifications. We conduct extensive comparisons against prior work and find that SelfVC achieves state-of-the-art results in zero-shot voice conversion on metrics evaluating naturalness, speaker similarity, and intelligibility of synthesized audio.","entities":[{"label":"SelfVC: Voice Conversion With Iterative Refinement using Self Transformations","type":"title","detail":null,"excerpts":null},{"label":"representation learning for computer vision, audio, language, and other modalities","type":"primary_area","detail":null,"excerpts":null},{"label":"voice conversion","type":"keyword","detail":null,"excerpts":null},{"label":"self-supervised learning","type":"keyword","detail":null,"excerpts":null},{"label":"speech synthesis","type":"keyword","detail":null,"excerpts":null},{"label":"disentangled representations","type":"keyword","detail":null,"excerpts":null},{"label":"iterative refinement","type":"keyword","detail":null,"excerpts":null},{"label":"self transformations","type":"keyword","detail":null,"excerpts":null},{"label":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples.","type":"tldr","detail":null,"excerpts":null},{"label":"SelfVC improves speaker similarity using self transformations.","type":"claim","detail":"The paper claims that using self transformations to train a voice conversion model on imperfectly disentangled representations results in considerable improvement in speaker similarity metrics as compared to a model trained only with heuristic transformations.","excerpts":[{"section":"Introduction","text":"We develop a training strategy using self transformations to train a voice conversion model on imperfectly disentangled representations, resulting in considerable improvement in speaker similarity metrics as compared to a model trained only with heuristic transformations."},{"section":"Conclusion","text":"Our results indicate a clear benefit of incorporating self-synthesized examples while training a voice conversion model, as shown by a significant improvement in speaker similarity metrics while keeping the model architecture unchanged."}]},{"label":"SelfVC enables controllable speech synthesis.","type":"claim","detail":"The paper claims that techniques are proposed to derive prosodic information from uncompressed SSL feature vectors and use the derived information to train a controllable synthesizer that can either mimic the prosody of a source utterance or adapt the prosody given a target speaker.","excerpts":[{"section":"Introduction","text":"We propose techniques to derive prosodic information from uncompressed SSL feature vectors and use the derived information to train a controllable synthesizer that can either mimic the prosody of a source utterance or adapt the prosody given a target speaker."},{"section":"Conclusion","text":"By deriving and modelling prosodic information during training, SelfVC allows for both fine-grained and high-level control over the prosody of the synthesized speech."}]},{"label":"SelfVC scales to multiple languages.","type":"claim","detail":"The paper claims that the models are trained in a text-free manner and independent of phonetic posteriograms, hence making it simple and efficient to scale up the training data, including other languages.","excerpts":[{"section":"Introduction","text":"Our models are trained in a text-free manner and independent of phonetic posteriograms, hence making it simple and efficient to scale up the training data, including other languages."},{"section":"Conclusion","text":"SelfVC achieves SOTA results in zero-shot voice conversion for English and can be easily scaled to multiple languages in a text-free manner, outperforming prior approaches in cross-lingual voice conversion."}]},{"label":"SelfVC achieves state-of-the-art results in zero-shot voice conversion.","type":"claim","detail":"The paper claims that SelfVC achieves state-of-the-art results in zero-shot any-to-any voice conversion in English.","excerpts":[{"section":"Introduction","text":"SelfVC achieves state-of-the-art results in zero-shot any-to-any voice conversion in English."},{"section":"Abstract","text":"We conduct extensive comparisons against prior work and find that SelfVC achieves state-of-the-art results in zero-shot voice conversion on metrics evaluating naturalness, speaker similarity, and intelligibility of synthesized audio."}]},{"label":"Self Transformation Training Strategy","type":"method","detail":"The method involves using the synthesis model itself to create challenging voice-converted transformations of a given speech utterance. At any given training iteration, the current state of the synthesis model is used to transform the input SSL features and the model is updated to minimize the reconstruction error of the original utterance.","excerpts":[{"section":"Method","text":"To allow controllable synthesis from imperfectly disentangled representations, we propose a training strategy that challenges the model to reconstruct the audio from self-generated perturbations of the content representation (Section\n[3.3](#sec:selfrefine){reference-type=\"ref\" reference=\"sec:selfrefine\"})."},{"section":"Method","text":"That is, given a synthesizer model MATH_PLACEHOLDER trained until training iteration MATH_PLACEHOLDER, we obtain a self transformed audio for iteration MATH_PLACEHOLDER as: MATH_PLACEHOLDER where MATH_PLACEHOLDER is the content embedding of the original audio MATH_PLACEHOLDER and MATH_PLACEHOLDER is the speaker embedding obtained from an utterance MATH_PLACEHOLDER of a different randomly selected speaker, that is, MATH_PLACEHOLDER."}]},{"label":"Prosodic Information Derivation","type":"method","detail":"The method involves deriving prosodic information from uncompressed SSL feature vectors and using this information to train a controllable synthesizer. This allows the synthesizer to either mimic the prosody of a source utterance or adapt the prosody given a target speaker.","excerpts":[{"section":"Introduction","text":"We propose techniques to derive prosodic information from uncompressed SSL feature vectors and use the derived information to train a controllable synthesizer that can either mimic the prosody of a source utterance or adapt the prosody given a target speaker."},{"section":"Method","text":"We derive the following features from an audio signal to train our synthesis models."}]},{"label":"Text-Free Training","type":"method","detail":"The method involves training the models in a text-free manner, independent of phonetic posteriograms, to enable simple and efficient scaling up of training data, including other languages.","excerpts":[{"section":"Introduction","text":"Our models are trained in a text-free manner and independent of phonetic posteriograms, hence making it simple and efficient to scale up the training data, including other languages."},{"section":"Method","text":"All the components in our framework are trained in a text-free manner requiring only audio data."}]},{"label":"Mel-spectrogram Synthesizer","type":"method","detail":"The mel-spectrogram synthesizer reconstructs the mel-spectrogram from the derived features. It is composed of two feed-forward transformers and intermediate modules to predict the duration and pitch contour.","excerpts":[{"section":"Method","text":"Our mel-spectrogram synthesizer MATH_PLACEHOLDER is composed of two feed-forward transformers MATH_PLACEHOLDER and MATH_PLACEHOLDER and intermediate modules to predict the duration and pitch contour similar to~\\citep{lancucki2021fastpitch} but operates on the grouped content representation MATH_PLACEHOLDER instead of text."},{"section":"Method","text":"The task of the synthesizer is to first reconstruct the ground-truth mel-spectrogram from the extracted speech representations and then vocode the mel-spectrogram into a listenable audio waveform."}]},{"label":"Reconstruction Experiment","type":"experiment","detail":"The experiment evaluates how effectively the setup can reconstruct audio from the extracted representations for unseen utterances and speakers. The synthesizers operate in two modes: Guided (using ground truth pitch and duration) and Predictive (using predicted pitch and duration).","excerpts":[{"section":"Experiments","text":"First, we evaluate how effectively our setup can reconstruct audio from the extracted representations for unseen utterances and speakers."},{"section":"Experiments","text":"Our synthesizers can operate in two modes during inference --- *1) **Guided:*** In this scenario, we use ground truth pitch and duration information derived from the source utterance. *2) **Predictive:*** In this case, we use the predicted pitch and duration for synthesis."}]},{"label":"Voice Conversion Experiment","type":"experiment","detail":"The experiment converts the voice of a given source utterance to a target speaker by deriving the content embedding from the source utterance and estimating the speaker embedding from the target speaker's audio. The experiment compares the zero-shot voice conversion method against prior work.","excerpts":[{"section":"Experiments","text":"To convert the voice of a given source utterance to a target speaker, we derive the content embedding from the source utterance and estimate the speaker embedding from the target speaker's audio and feed both as input to the synthesizer."},{"section":"Experiments","text":"To compare our zero-shot voice conversion method against prior work, we choose utterances from the LibriTTS test-clean subset since it is an unseen dataset across all voice conversion methods."}]}],"relationships":[{"source":"SelfVC: Voice Conversion With Iterative Refinement using Self Transformations","target":"representation learning for computer vision, audio, language, and other modalities"},{"source":"SelfVC: Voice Conversion With Iterative Refinement using Self Transformations","target":"voice conversion"},{"source":"SelfVC: Voice Conversion With Iterative Refinement using Self Transformations","target":"self-supervised learning"},{"source":"SelfVC: Voice Conversion With Iterative Refinement using Self Transformations","target":"speech synthesis"},{"source":"SelfVC: Voice Conversion With Iterative Refinement using Self Transformations","target":"disentangled representations"},{"source":"SelfVC: Voice Conversion With Iterative Refinement using Self Transformations","target":"iterative refinement"},{"source":"SelfVC: Voice Conversion With Iterative Refinement using Self Transformations","target":"self transformations"},{"source":"SelfVC: Voice Conversion With Iterative Refinement using Self Transformations","target":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples."},{"source":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples.","target":"SelfVC improves speaker similarity using self transformations."},{"source":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples.","target":"SelfVC enables controllable speech synthesis."},{"source":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples.","target":"SelfVC scales to multiple languages."},{"source":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples.","target":"SelfVC achieves state-of-the-art results in zero-shot voice conversion."},{"source":"SelfVC improves speaker similarity using self transformations.","target":"Self Transformation Training Strategy"},{"source":"SelfVC enables controllable speech synthesis.","target":"Prosodic Information Derivation"},{"source":"SelfVC scales to multiple languages.","target":"Text-Free Training"},{"source":"SelfVC achieves state-of-the-art results in zero-shot voice conversion.","target":"Mel-spectrogram Synthesizer"},{"source":"Self Transformation Training Strategy","target":"Reconstruction Experiment"},{"source":"Self Transformation Training Strategy","target":"Voice Conversion Experiment"},{"source":"Prosodic Information Derivation","target":"Reconstruction Experiment"},{"source":"Text-Free Training","target":"Voice Conversion Experiment"},{"source":"Mel-spectrogram Synthesizer","target":"Reconstruction Experiment"},{"source":"Mel-spectrogram Synthesizer","target":"Voice Conversion Experiment"}],"valid_status":"Valid","valid_status_all":["Valid"]},"related":[{"summary":"The Related Paper supports the Main Paper by emphasizing the importance of controllable speech representation learning, which aligns with the Main Paper's focus on improving voice conversion through self-synthesized examples. Both papers address the challenges of preserving speech nuances while enhancing model performance, with the Related Paper providing a complementary approach through its introduction of invertible representations and AIC loss. This connection reinforces the Main Paper's claims about the effectiveness of self-supervised learning in achieving high-quality voice conversion.","paper_id":"69e69e106f22e3a53ea5b1c51fdcfe57e555dc6d","title":"Controllable Speech Representation Learning Via Voice Conversion and AIC Loss","abstract":"Speech representation learning transforms speech into features that are suitable for downstream tasks, e.g. speech recognition, phoneme classification, or speaker identification. For such recognition tasks, a representation can be lossy (non-invertible), which is typical of BERT-like self-supervised models. However, when used for synthesis tasks, we find these lossy representations prove to be insufficient to plausibly reconstruct the input signal. This paper introduces a method for invertible and controllable speech representation learning based on disentanglement. The representation can be decoded into a signal perceptually identical to the original. Moreover, its disentangled components (content, pitch, speaker identity, and energy) can be controlled independently to alter the synthesis result. Our model builds upon a zero-shot voice conversion model AutoVC-F0, in which we introduce alteration invariant content loss (AIC loss) and adversarial training (GAN). Through objective measures and subjective tests, we show that our formulation offers significant improvement in voice conversion sound quality as well as more precise control over the disentangled features.","score":0.7706788778305054,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples. In this work, instead of explicitly disentangling attributes with loss terms, we present a framework to train a controllable voice conversion model on entangled speech representations derived from self-supervised learning (SSL) and speaker verification models. First, we develop techniques to derive prosodic information from the audio signal and SSL representations to train predictive submodules in the synthesis model. Next, we propose a training strategy to iteratively improve the synthesis model for voice conversion, by creating a challenging training objective using self-synthesized examples. In this training approach, the current state of the synthesis model is used to generate voice-converted variations of an utterance, which serve as inputs for the reconstruction task, ensuring a continuous and purposeful refinement of the model. We demonstrate that incorporating such self-synthesized examples during training improves the speaker similarity of generated speech as compared to a baseline voice conversion model trained solely on heuristically perturbed inputs. Our framework is trained without any text and is applicable to a range of tasks such as zero-shot voice conversion, voice conversion across different languages, and controllable speech synthesis with pitch and pace modifications. We conduct extensive comparisons against prior work and find that SelfVC achieves state-of-the-art results in zero-shot voice conversion on metrics evaluating naturalness, speaker similarity, and intelligibility of synthesized audio."},{"summary":"The Related Paper supports the Main Paper by highlighting the advantages of self-supervised representations in voice conversion systems. While the Main Paper focuses on using entangled speech representations for voice conversion, the Related Paper emphasizes the benefits of speaker-disentangled representations, which enhance speaker similarity and naturalness in generated speech. Both papers advocate for self-supervised learning approaches, but the Related Paper provides empirical evidence of improved performance metrics, reinforcing the Main Paper's claims about the effectiveness of self-synthesized examples in training voice conversion models.","paper_id":"527d11bae71c4a91f2e66637476e991f4a1d309b","title":"Enhancing the Stability of LLM-based Speech Generation Systems through Self-Supervised Representations","abstract":"Large Language Models (LLMs) are one of the most promising technologies for the next era of speech generation systems, due to their scalability and in-context learning capabilities. Nevertheless, they suffer from multiple stability issues at inference time, such as hallucinations, content skipping or speech repetitions. In this work, we introduce a new self-supervised Voice Conversion (VC) architecture which can be used to learn to encode transitory features, such as content, separately from stationary ones, such as speaker ID or recording conditions, creating speaker-disentangled representations. Using speaker-disentangled codes to train LLMs for text-to-speech (TTS) allows the LLM to generate the content and the style of the speech only from the text, similarly to humans, while the speaker identity is provided by the decoder of the VC model. Results show that LLMs trained over speaker-disentangled self-supervised representations provide an improvement of 4.7pp in speaker similarity over SOTA entangled representations, and a word error rate (WER) 5.4pp lower. Furthermore, they achieve higher naturalness than human recordings of the LibriTTS test-other dataset. Finally, we show that using explicit reference embedding negatively impacts intelligibility (stability), with WER increasing by 14pp compared to the model that only uses text to infer the style.","score":0.7706497311592102,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples. In this work, instead of explicitly disentangling attributes with loss terms, we present a framework to train a controllable voice conversion model on entangled speech representations derived from self-supervised learning (SSL) and speaker verification models. First, we develop techniques to derive prosodic information from the audio signal and SSL representations to train predictive submodules in the synthesis model. Next, we propose a training strategy to iteratively improve the synthesis model for voice conversion, by creating a challenging training objective using self-synthesized examples. In this training approach, the current state of the synthesis model is used to generate voice-converted variations of an utterance, which serve as inputs for the reconstruction task, ensuring a continuous and purposeful refinement of the model. We demonstrate that incorporating such self-synthesized examples during training improves the speaker similarity of generated speech as compared to a baseline voice conversion model trained solely on heuristically perturbed inputs. Our framework is trained without any text and is applicable to a range of tasks such as zero-shot voice conversion, voice conversion across different languages, and controllable speech synthesis with pitch and pace modifications. We conduct extensive comparisons against prior work and find that SelfVC achieves state-of-the-art results in zero-shot voice conversion on metrics evaluating naturalness, speaker similarity, and intelligibility of synthesized audio."},{"summary":"The Related Paper, Make-A-Voice, supports the Main Paper, SelfVC, by emphasizing the importance of self-supervised learning in voice synthesis, which aligns with SelfVC's approach of using entangled speech representations. Both papers advocate for reducing reliance on annotated data, highlighting the potential for improved scalability and capturing acoustic variations such as emotion and prosody. Additionally, Make-A-Voice's focus on controllability and flexibility in voice synthesis complements SelfVC's iterative refinement strategy, reinforcing the effectiveness of self-synthesized examples in enhancing voice conversion outcomes.","paper_id":"c0045bc9eb96efd4ac5e97742aa5cb4bddb55506","title":"Make-A-Voice: Unified Voice Synthesis With Discrete Representation","abstract":"Various applications of voice synthesis have been developed independently despite the fact that they generate\"voice\"as output in common. In addition, the majority of voice synthesis models currently rely on annotated audio data, but it is crucial to scale them to self-supervised datasets in order to effectively capture the wide range of acoustic variations present in human voice, including speaker identity, emotion, and prosody. In this work, we propose Make-A-Voice, a unified framework for synthesizing and manipulating voice signals from discrete representations. Make-A-Voice leverages a\"coarse-to-fine\"approach to model the human voice, which involves three stages: 1) semantic stage: model high-level transformation between linguistic content and self-supervised semantic tokens, 2) acoustic stage: introduce varying control signals as acoustic conditions for semantic-to-acoustic modeling, and 3) generation stage: synthesize high-fidelity waveforms from acoustic tokens. Make-A-Voice offers notable benefits as a unified voice synthesis framework: 1) Data scalability: the major backbone (i.e., acoustic and generation stage) does not require any annotations, and thus the training data could be scaled up. 2) Controllability and conditioning flexibility: we investigate different conditioning mechanisms and effectively handle three voice synthesis applications, including text-to-speech (TTS), voice conversion (VC), and singing voice synthesis (SVS) by re-synthesizing the discrete voice representations with prompt guidance. Experimental results demonstrate that Make-A-Voice exhibits superior audio quality and style similarity compared with competitive baseline models. Audio samples are available at https://Make-A-Voice.github.io","score":0.7428005933761597,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples. In this work, instead of explicitly disentangling attributes with loss terms, we present a framework to train a controllable voice conversion model on entangled speech representations derived from self-supervised learning (SSL) and speaker verification models. First, we develop techniques to derive prosodic information from the audio signal and SSL representations to train predictive submodules in the synthesis model. Next, we propose a training strategy to iteratively improve the synthesis model for voice conversion, by creating a challenging training objective using self-synthesized examples. In this training approach, the current state of the synthesis model is used to generate voice-converted variations of an utterance, which serve as inputs for the reconstruction task, ensuring a continuous and purposeful refinement of the model. We demonstrate that incorporating such self-synthesized examples during training improves the speaker similarity of generated speech as compared to a baseline voice conversion model trained solely on heuristically perturbed inputs. Our framework is trained without any text and is applicable to a range of tasks such as zero-shot voice conversion, voice conversion across different languages, and controllable speech synthesis with pitch and pace modifications. We conduct extensive comparisons against prior work and find that SelfVC achieves state-of-the-art results in zero-shot voice conversion on metrics evaluating naturalness, speaker similarity, and intelligibility of synthesized audio."},{"summary":"The Related Paper supports the Main Paper by addressing the challenges of zero-shot voice conversion, particularly the issues of prosody leakage in traditional disentanglement methods. While the Main Paper introduces SelfVC, which utilizes self-synthesized examples to enhance voice conversion without explicit disentanglement, the Related Paper complements this by proposing a self-supervised approach to learn disentangled prosody representations. Both papers emphasize the importance of preserving prosodic features for improved speaker similarity and performance in voice conversion, with the Related Paper's findings reinforcing the effectiveness of the Main Paper's approach.","paper_id":"3608311276e2a773da02722f8af799305522248b","title":"Zero-shot Voice Conversion via Self-supervised Prosody Representation Learning","abstract":"Voice Conversion (VC) for unseen speakers, also known as zero-shot VC, is an attractive research topic as it enables a range of applications like voice customizing, animation production, and others. Recent work in this area made progress with disentanglement methods that separate utterance content and speaker characteristics from speech audio recordings. However, many of these methods are subject to the leakage of prosody (e.g., pitch, volume), causing the speaker voice in the synthesized speech to be different from the desired target speakers. To prevent this issue, we propose a novel self-supervised approach that effectively learns disentangled pitch and volume representations that can represent the prosody styles of different speakers. We then use the learned prosodic representations as conditional information to train and enhance our VC model for zero-shot conversion. In our experiments, we show that our prosody representations are disentangled and rich in prosody information. Moreover, we demonstrate that the addition of our prosody representations improves our VC performance and surpasses state-of-the-art zero-shot VC performances.","score":0.7322424650192261,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples. In this work, instead of explicitly disentangling attributes with loss terms, we present a framework to train a controllable voice conversion model on entangled speech representations derived from self-supervised learning (SSL) and speaker verification models. First, we develop techniques to derive prosodic information from the audio signal and SSL representations to train predictive submodules in the synthesis model. Next, we propose a training strategy to iteratively improve the synthesis model for voice conversion, by creating a challenging training objective using self-synthesized examples. In this training approach, the current state of the synthesis model is used to generate voice-converted variations of an utterance, which serve as inputs for the reconstruction task, ensuring a continuous and purposeful refinement of the model. We demonstrate that incorporating such self-synthesized examples during training improves the speaker similarity of generated speech as compared to a baseline voice conversion model trained solely on heuristically perturbed inputs. Our framework is trained without any text and is applicable to a range of tasks such as zero-shot voice conversion, voice conversion across different languages, and controllable speech synthesis with pitch and pace modifications. We conduct extensive comparisons against prior work and find that SelfVC achieves state-of-the-art results in zero-shot voice conversion on metrics evaluating naturalness, speaker similarity, and intelligibility of synthesized audio."},{"summary":"The Related Paper, 'Unsupervised Speech Decomposition via Triple Information Bottleneck', contrasts with the Main Paper by emphasizing the need for disentangled representations of speech components, specifically targeting timbre, pitch, and rhythm, which the Main Paper's SelfVC approach does not explicitly address. While SelfVC focuses on improving voice conversion through self-synthesized examples without disentangling attributes, the Related Paper highlights the limitations of current systems in fully separating these components, suggesting that further disentanglement is necessary for effective speech analysis and generation.","paper_id":"9b0fffdb696614b4e917edfb166733ecdae2c7e9","title":"Unsupervised Speech Decomposition via Triple Information Bottleneck","abstract":"Speech information can be roughly decomposed into four components: language content, timbre, pitch, and rhythm. Obtaining disentangled representations of these components is useful in many speech analysis and generation applications. Recently, state-of-the-art voice conversion systems have led to speech representations that can disentangle speaker-dependent and independent information. However, these systems can only disentangle timbre, while information about pitch, rhythm and content is still mixed together. Further disentangling the remaining speech components is an under-determined problem in the absence of explicit annotations for each component, which are difficult and expensive to obtain. In this paper, we propose SpeechSplit, which can blindly decompose speech into its four components by introducing three carefully designed information bottlenecks. SpeechSplit is among the first algorithms that can separately perform style transfer on timbre, pitch and rhythm without text labels. Our code is publicly available at this https URL.","score":0.7918528318405151,"polarity":"negative","source":"semantic","contexts":null,"background":"Previous efforts on voice conversion focus on factorizing speech into explicitly disentangled representations that separately encode speaker characteristics and linguistic content. However, disentangling speech representations to capture such attributes using task-specific loss terms can lead to information loss by discarding finer nuances such as accent and emotion of the original signal.","target":null},{"summary":"The Related Paper, MoCoVC, contrasts with the Main Paper, SelfVC, by emphasizing the need for explicit constraints in voice conversion through momentum contrastive representation learning, while the Main Paper advocates for a self-supervised approach that avoids explicit disentanglement of speech attributes. MoCoVC relies on external models and transformations to maintain utterance content, whereas SelfVC focuses on iteratively refining a model using self-synthesized examples without requiring text data. Additionally, MoCoVC claims comparable performance to existing methods, while SelfVC asserts state-of-the-art results in zero-shot voice conversion.","paper_id":"ea5c6cfe0116b65598d66c852b151404d126ca57","title":"MoCoVC: Non-parallel Voice Conversion with Momentum Contrastive Representation Learning","abstract":"Non-parallel voice conversion with deep neural net-works often disentangle speaker individuality and speech content. However, these methods rely on external models, text data, or implicit constraints for ways to disentangle. They may require learning other models or annotating text, or may not understand how latent representations are acquired. Therefore, we pro-pose voice conversion with momentum contrastive representation learning (MoCo V C), a method of explicitly adding constraints to intermediate features using contrastive representation learning, which is a self-supervised learning method. Using contrastive rep-resentation learning with transformations that preserve utterance content allows us to explicitly constrain the intermediate features to preserve utterance content. We present transformations used for contrastive representation learning that could be used for voice conversion and verify the effectiveness of each in an exper-iment. Moreover, MoCoVC demonstrates a high or comparable performance to the vector quantization constrained method in terms of both naturalness and speaker individuality in subjective evaluation experiments.","score":0.7480452060699463,"polarity":"negative","source":"semantic","contexts":null,"background":"Previous efforts on voice conversion focus on factorizing speech into explicitly disentangled representations that separately encode speaker characteristics and linguistic content. However, disentangling speech representations to capture such attributes using task-specific loss terms can lead to information loss by discarding finer nuances such as accent and emotion of the original signal.","target":null},{"summary":"The Related Paper contrasts the Main Paper by emphasizing the importance of disentangled speech representations for achieving robust and controllable voice conversion, while the Main Paper advocates for a framework that utilizes entangled representations derived from self-supervised learning. The Related Paper critiques the Main Paper's approach, arguing that the lack of explicit disentanglement can lead to reduced control over prosody-related factors, whereas it proposes an adversarial learning method to enhance the robustness of multi-factor voice conversion.","paper_id":"607c18c160aa66c13314b9da1e89639b79f67bca","title":"Adversarially learning disentangled speech representations for robust multi-factor voice conversion","abstract":"Factorizing speech as disentangled speech representations is vital to achieve highly controllable style transfer in voice conversion (VC). Conventional speech representation learning methods in VC only factorize speech as speaker and content, lacking controllability on other prosody-related factors. State-of-the-art speech representation learning methods for more speechfactors are using primary disentangle algorithms such as random resampling and ad-hoc bottleneck layer size adjustment,which however is hard to ensure robust speech representationdisentanglement. To increase the robustness of highly controllable style transfer on multiple factors in VC, we propose a disentangled speech representation learning framework based on adversarial learning. Four speech representations characterizing content, timbre, rhythm and pitch are extracted, and further disentangled by an adversarial Mask-And-Predict (MAP)network inspired by BERT. The adversarial network is used tominimize the correlations between the speech representations,by randomly masking and predicting one of the representationsfrom the others. Experimental results show that the proposedframework significantly improves the robustness of VC on multiple factors by increasing the speech quality MOS from 2.79 to3.30 and decreasing the MCD from 3.89 to 3.58.","score":0.7475903630256653,"polarity":"negative","source":"semantic","contexts":null,"background":"Previous efforts on voice conversion focus on factorizing speech into explicitly disentangled representations that separately encode speaker characteristics and linguistic content. However, disentangling speech representations to capture such attributes using task-specific loss terms can lead to information loss by discarding finer nuances such as accent and emotion of the original signal.","target":null},{"summary":"The Related Paper, SpeechTripleNet, contrasts with the Main Paper, SelfVC, by advocating for a disentangled approach to speech representation, focusing on separating spoken content, speaker timbre, and prosody. While SelfVC emphasizes the benefits of using entangled representations and self-synthesized examples to improve voice conversion, SpeechTripleNet argues that explicit disentanglement is necessary to avoid performance degradation and prosody leakage. This fundamental difference in approach highlights the Main Paper's reliance on self-supervised learning without explicit factor separation, which the Related Paper critiques.","paper_id":"d975f3db785ad488afbe349f6b858f53d5ae5e5b","title":"SpeechTripleNet: End-to-End Disentangled Speech Representation Learning for Content, Timbre and Prosody","abstract":"Disentangled speech representation learning aims to separate different factors of variation from speech into disjoint representations. This paper focuses on disentangling speech into representations for three factors: spoken content, speaker timbre, and speech prosody. Many previous methods for speech disentanglement have focused on separating spoken content and speaker timbre. However, the lack of explicit modeling of prosodic information leads to degraded speech generation performance and uncontrollable prosody leakage into content and/or speaker representations. While some recent methods have utilized explicit speaker labels or pre-trained models to facilitate triple-factor disentanglement, there are no end-to-end methods to simultaneously disentangle three factors using only unsupervised or self-supervised learning objectives. This paper introduces SpeechTripleNet, an end-to-end method to disentangle speech into representations for content, timbre, and prosody. Based on VAE, SpeechTripleNet restricts the structures of the latent variables and the amount of information captured in them to induce disentanglement. It is a pure unsupervised/self-supervised learning method that only requires speech data and no additional labels. Our qualitative and quantitative results demonstrate that SpeechTripleNet is effective in achieving triple-factor speech disentanglement, as well as controllable speech editing concerning different factors.","score":0.7430967092514038,"polarity":"negative","source":"semantic","contexts":null,"background":"Previous efforts on voice conversion focus on factorizing speech into explicitly disentangled representations that separately encode speaker characteristics and linguistic content. However, disentangling speech representations to capture such attributes using task-specific loss terms can lead to information loss by discarding finer nuances such as accent and emotion of the original signal.","target":null},{"summary":"The Related Paper, AdaptVC, contrasts with the Main Paper, SelfVC, by emphasizing the importance of disentangling linguistic content and speaker characteristics for effective voice conversion. While SelfVC advocates for using entangled representations and self-synthesized examples to improve model performance, AdaptVC focuses on achieving high-quality voice conversion through adaptive learning and dynamic encoding of features, highlighting a more traditional approach to feature separation. Additionally, AdaptVC claims superior performance in zero-shot scenarios, suggesting that its method may be more robust compared to the iterative refinement strategy proposed in SelfVC.","paper_id":"b9c9951f5669343381b70471f86051e3ed69c5bd","title":"AdaptVC: High Quality Voice Conversion with Adaptive Learning","abstract":"The goal of voice conversion is to transform the speech of a source speaker to sound like that of a reference speaker while preserving the original content. A key challenge is to extract disentangled linguistic content from the source and voice style from the reference. While existing approaches leverage various methods to isolate the two, a generalization still requires further attention, especially for robustness in zero-shot scenarios. In this paper, we achieve successful disentanglement of content and speaker features by tuning self-supervised speech features with adapters. The adapters are trained to dynamically encode nuanced features from rich self-supervised features, and the decoder fuses them to produce speech that accurately resembles the reference with minimal loss of content. Moreover, we leverage a conditional flow matching decoder with cross-attention speaker conditioning to further boost the synthesis quality and efficiency. Subjective and objective evaluations in a zero-shot scenario demonstrate that the proposed method outperforms existing models in speech quality and similarity to the reference speech.","score":0.7290732264518738,"polarity":"negative","source":"semantic","contexts":null,"background":"Previous efforts on voice conversion focus on factorizing speech into explicitly disentangled representations that separately encode speaker characteristics and linguistic content. However, disentangling speech representations to capture such attributes using task-specific loss terms can lead to information loss by discarding finer nuances such as accent and emotion of the original signal.","target":null},{"summary":"The Related Paper, S3PRL-VC, supports the Main Paper by demonstrating the effectiveness of self-supervised speech representations (S3R) in voice conversion tasks, which aligns with the Main Paper's focus on using self-synthesized examples for model improvement. Both papers emphasize the advantages of avoiding explicit disentanglement of speech attributes, with the Related Paper providing empirical evidence that S3R can achieve state-of-the-art results in voice conversion, thereby reinforcing the Main Paper's claims about the benefits of entangled representations and iterative refinement in voice conversion models.","paper_id":"2c5a410b781f90c145efac05fea235c5c3e44861","title":"S3PRL-VC: Open-Source Voice Conversion Framework with Self-Supervised Speech Representations","abstract":"This paper introduces S3PRL-VC, an open-source voice conversion (VC) framework based on the S3PRL toolkit. In the context of recognition-synthesis VC, self-supervised speech representation (S3R) is valuable in its potential to replace the expensive supervised representation adopted by state-of-the-art VC systems. Moreover, we claim that VC is a good probing task for S3R analysis. In this work, we provide a series of in-depth analyses by benchmarking on the two tasks in VCC2020, namely intra-/cross-lingual any-to-one (A2O) VC, as well as an any-to-any (A2A) setting. We also provide comparisons between not only different S3Rs but also top systems in VCC2020 with supervised representations. Systematic objective and subjective evaluation were conducted, and we show that S3R is comparable with VCC2020 top systems in the A2O setting in terms of similarity, and achieves state-of-the-art in S3R-based A2A VC. We believe the extensive analysis, as well as the toolkit itself, contribute to not only the S3R community but also the VC community. The codebase is now open-sourced1.","score":0.7603261470794678,"polarity":"positive","source":"citations","contexts":[{"sentence":"To derive disentangled speech representations in a text-free manner, recent methods~\\citep{lakhotia2021generative,polyak2021speech,lin2021fragmentvc,huang2022s3prl,choi2021neural} have proposed to obtain speaker information from a speaker verification mode","polarity":"positive"},{"sentence":"While the representations obtained from SSL models are highly correlated with phonetic information, they also contain speaker information~\\citep{huang2022s3prl,hussain2022multi}.","polarity":"positive"},{"sentence":"}{ {l|rrr|rr|r} {c}{} & {c}{ } & {c}{ } & {c}{ } \\\\ Technique & SV-EER MATH_PLACEHOLDER & SV-Sim MATH_PLACEHOLDER & Sim-MOS MATH_PLACEHOLDER & PER MATH_PLACEHOLDER & CER MATH_PLACEHOLDER & MOS MATH_PLACEHOLDER \\\\ Real Data & MATH_PLACEHOLDER & MATH_PLACEHO","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper supports the Main Paper by addressing the limitations of conventional voice conversion methods, such as the degradation of speech quality and loss of spectral details. It highlights the importance of using deep neural networks (DNNs) for modeling non-linear relationships between speakers, which aligns with the Main Paper's focus on improving voice conversion through innovative training strategies. Both papers emphasize the significance of advanced modeling techniques to enhance speaker similarity and naturalness in synthesized speech, reinforcing the Main Paper's claims about the effectiveness of its SelfVC framework.","paper_id":"5cb6307f25a8af6e8081405db88dc9c837cf5b27","title":"Voice Conversion Using Deep Neural Networks With Layer-Wise Generative Training","abstract":"This paper presents a new spectral envelope conversion method using deep neural networks (DNNs). The conventional joint density Gaussian mixture model (JDGMM) based spectral conversion methods perform stably and effectively. However, the speech generated by these methods suffer severe quality degradation due to the following two factors: 1) inadequacy of JDGMM in modeling the distribution of spectral features as well as the non-linear mapping relationship between the source and target speakers, 2) spectral detail loss caused by the use of high-level spectral features such as mel-cepstra. Previously, we have proposed to use the mixture of restricted Boltzmann machines (MoRBM) and the mixture of Gaussian bidirectional associative memories (MoGBAM) to cope with these problems. In this paper, we propose to use a DNN to construct a global non-linear mapping relationship between the spectral envelopes of two speakers. The proposed DNN is generatively trained by cascading two RBMs, which model the distributions of spectral envelopes of source and target speakers respectively, using a Bernoulli BAM (BBAM). Therefore, the proposed training method takes the advantage of the strong modeling ability of RBMs in modeling the distribution of spectral envelopes and the superiority of BAMs in deriving the conditional distributions for conversion. Careful comparisons and analysis among the proposed method and some conventional methods are presented in this paper. The subjective results show that the proposed method can significantly improve the performance in terms of both similarity and naturalness compared to conventional methods.","score":0.6460428833961487,"polarity":"positive","source":"citations","contexts":[{"sentence":"Traditionally, voice conversion models were trained as a speech-to-speech translation system on a parallel dataset containing multiple speakers saying the same utterance~\\citep{sun2015dblstm, chen2014dnn}.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper supports the Main Paper by demonstrating an innovative approach to voice conversion that enhances the understanding of speaker and content representation separation. While the Main Paper focuses on iteratively refining voice conversion through self-synthesized examples without explicit disentanglement, the Related Paper introduces a one-shot voice conversion method that successfully separates speaker and content using instance normalization. Both papers highlight advancements in voice conversion techniques that improve speaker similarity and applicability in various scenarios, reinforcing the Main Paper's claims about the effectiveness of novel training strategies.","paper_id":"c77fa76a857051a6c7deb135a45af8d4a5f32f0f","title":"One-shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization","abstract":"Recently, voice conversion (VC) without parallel data has been successfully adapted to multi-target scenario in which a single model is trained to convert the input voice to many different speakers. However, such model suffers from the limitation that it can only convert the voice to the speakers in the training data, which narrows down the applicable scenario of VC. In this paper, we proposed a novel one-shot VC approach which is able to perform VC by only an example utterance from source and target speaker respectively, and the source and target speaker do not even need to be seen during training. This is achieved by disentangling speaker and content representations with instance normalization (IN). Objective and subjective evaluation shows that our model is able to generate the voice similar to target speaker. In addition to the performance measurement, we also demonstrate that this model is able to learn meaningful speaker representations without any supervision.","score":0.6438446044921875,"polarity":"positive","source":"citations","contexts":[{"sentence":"More recently, voice conversion systems have been developed by training neural synthesizers to reconstruct speech from disentangled representations describing linguistic content and speaker characteristics~\\citep{qian2019autovc,chou2019one}.","polarity":"positive"},{"sentence":"}{ {l|rrr|rr|r} {c}{} & {c}{ } & {c}{ } & {c}{ } \\\\ Technique & SV-EER MATH_PLACEHOLDER & SV-Sim MATH_PLACEHOLDER & Sim-MOS MATH_PLACEHOLDER & PER MATH_PLACEHOLDER & CER MATH_PLACEHOLDER & MOS MATH_PLACEHOLDER \\\\ Real Data & MATH_PLACEHOLDER & MATH_PLACEHO","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper, MediumVC, supports the Main Paper, SelfVC, by addressing the challenges of voice conversion through innovative reconstruction tasks that enhance feature decoupling. While SelfVC focuses on iteratively refining voice conversion using self-synthesized examples, MediumVC introduces a two-stage approach that utilizes synthetic specific-speaker speeches to improve performance, particularly for unseen speakers. Both papers emphasize the importance of maintaining naturalness and speaker similarity in generated speech, highlighting complementary strategies in advancing voice conversion technology.","paper_id":"3cdbe7e9cfc5b2b9fcfcc5cb729b40b94829df8e","title":"MediumVC: Any-to-any voice conversion using synthetic specific-speaker speeches as intermedium features","abstract":"To realize any-to-any (A2A) voice conversion (VC), most methods are to perform symmetric self-supervised reconstruction tasks (Xi to Xi), which usually results in inefficient performances due to inadequate feature decoupling, especially for unseen speakers. We propose a two-stage reconstruction task (Xi to Yi to Xi) using synthetic specific-speaker speeches as intermedium features, where A2A VC is divided into two stages: any-to-one (A2O) and one-to-Any (O2A). In the A2O stage, we propose a new A2O method: SingleVC, by employing a noval data augment strategy(pitch-shifted and duration-remained, PSDR) to accomplish Xi to Yi. In the O2A stage, MediumVC is proposed based on pre-trained SingleVC to conduct Yi to Xi. Through such asymmetrical reconstruction tasks (Xi to Yi in SingleVC and Yi to Xi in MediumVC), the models are to capture robust disentangled features purposefully. Experiments indicate MediumVC can enhance the similarity of converted speeches while maintaining a high degree of naturalness.","score":0.5942878723144531,"polarity":"positive","source":"citations","contexts":[{"sentence":"To remove speaker information from the SSL model outputs, some techniques utilize an information bottleneck approach such as quantization~\\citep{polyak2021speech,lakhotia2021generative,gu2021mediumvc}.","polarity":"positive"},{"sentence":"One line of research~\\citep{polyak2021speech,lee2021voicemixer,lakhotia2021generative,gu2021mediumvc} aiming to disentangle the speaker and content representations, proposes an information bottleneck approach to quantize SSL model outputs thereby limiting ","polarity":"positive"},{"sentence":"}{ {l|rrr|rr|r} {c}{} & {c}{ } & {c}{ } & {c}{ } \\\\ Technique & SV-EER MATH_PLACEHOLDER & SV-Sim MATH_PLACEHOLDER & Sim-MOS MATH_PLACEHOLDER & PER MATH_PLACEHOLDER & CER MATH_PLACEHOLDER & MOS MATH_PLACEHOLDER \\\\ Real Data & MATH_PLACEHOLDER & MATH_PLACEHO","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper, FragmentVC, supports the Main Paper, SelfVC, by demonstrating a similar approach to voice conversion that avoids explicit disentanglement of speaker and content attributes, thereby minimizing information loss. Both papers emphasize the importance of utilizing self-supervised learning and reconstruction loss without requiring parallel data, which enhances the flexibility and applicability of their models. Additionally, FragmentVC's success in achieving state-of-the-art results in any-to-any voice conversion complements SelfVC's findings on improving speaker similarity and naturalness, reinforcing the effectiveness of their respective methodologies.","paper_id":"0202e13a9d49b40b934e16ae6a095d0f0ecbc99f","title":"Fragmentvc: Any-To-Any Voice Conversion by End-To-End Extracting and Fusing Fine-Grained Voice Fragments with Attention","abstract":"Any-to-any voice conversion aims to convert the voice from and to any speakers even unseen during training, which is much more challenging compared to one-to-one or many-to-many tasks, but much more attractive in real-world scenarios. In this paper we proposed FragmentVC, in which the latent phonetic structure of the utterance from the source speaker is obtained from Wav2Vec 2.0, while the spectral features of the utterance(s) from the target speaker are obtained from log mel-spectrograms. By aligning the hidden structures of the two different feature spaces with a two-stage training process, FragmentVC is able to extract fine-grained voice fragments from the target speaker utterance(s) and fuse them into the desired utterance, all based on the attention mechanism of Transformer as verified with analysis on attention maps, and is accomplished end-to-end. This approach is trained with reconstruction loss only without any disentanglement considerations between content and speaker information and doesn't require parallel data. Objective evaluation based on speaker verification and subjective evaluation with MOS both showed that this approach outperformed SOTA approaches, such as AdaIN-VC and AutoVC.","score":0.5874308347702026,"polarity":"positive","source":"citations","contexts":[{"sentence":"To derive disentangled speech representations in a text-free manner, recent methods~\\citep{lakhotia2021generative,polyak2021speech,lin2021fragmentvc,huang2022s3prl,choi2021neural} have proposed to obtain speaker information from a speaker verification mode","polarity":"positive"},{"sentence":"}{ {l|rrr|rr|r} {c}{} & {c}{ } & {c}{ } & {c}{ } \\\\ Technique & SV-EER MATH_PLACEHOLDER & SV-Sim MATH_PLACEHOLDER & Sim-MOS MATH_PLACEHOLDER & PER MATH_PLACEHOLDER & CER MATH_PLACEHOLDER & MOS MATH_PLACEHOLDER \\\\ Real Data & MATH_PLACEHOLDER & MATH_PLACEHO","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper, ACE-VC, contrasts with the Main Paper, SelfVC, by emphasizing the importance of explicitly disentangled speech representations for voice conversion, while SelfVC advocates for using entangled representations to avoid information loss. ACE-VC employs a multi-task model and Siamese networks to decompose speech into distinct features, whereas SelfVC focuses on iterative refinement using self-synthesized examples without explicit disentanglement. Additionally, ACE-VC claims state-of-the-art results through its controlled synthesis approach, which differs from SelfVC's methodology that relies on self-supervised learning for continuous model improvement.","paper_id":"5c767b6b026405ee8e342983ee613989494ff97f","title":"ACE-VC: Adaptive and Controllable Voice Conversion Using Explicitly Disentangled Self-Supervised Speech Representations","abstract":"In this work, we propose a zero-shot voice conversion method using speech representations trained with self-supervised learning. First, we develop a multi-task model to decompose a speech utterance into features such as linguistic content, speaker characteristics, and speaking style. To disentangle content and speaker representations, we propose a training strategy based on Siamese networks that encourages similarity between the content representations of the original and pitch-shifted audio. Next, we develop a synthesis model with pitch and duration predictors that can effectively reconstruct the speech signal from its decomposed representation. Our framework allows controllable and speaker-adaptive synthesis to perform zero-shot any-to-any voice conversion achieving state-of-the-art results on metrics evaluating speaker similarity, intelligibility, and naturalness. Using just 10 seconds of data for a target speaker, our framework can perform voice swapping and achieves a speaker verification EER of 5.5% for seen speakers and 8.4% for unseen speakers. 1","score":0.7647701501846313,"polarity":"negative","source":"citations","contexts":[{"sentence":"While some techniques~\\citep{defossez2022highfi,eloff2019unsupervised,singingspeechcodec,kumar2023highfidelity} aim to compress speech into a data-efficient codec, another line of research has focused on disentangling the learned features into components s","polarity":"negative"},{"sentence":"Alternatively, several researchers have proposed training strategies that employ an information perturbation technique to eliminate speaker information without quantization~\\citep{qian2022contentvec,choi2021neural,choi2023nansy,hussain2023ace}.","polarity":"negative"},{"sentence":"}{ {l|rrr|rr|r} {c}{} & {c}{ } & {c}{ } & {c}{ } \\\\ Technique & SV-EER MATH_PLACEHOLDER & SV-Sim MATH_PLACEHOLDER & Sim-MOS MATH_PLACEHOLDER & PER MATH_PLACEHOLDER & CER MATH_PLACEHOLDER & MOS MATH_PLACEHOLDER \\\\ Real Data & MATH_PLACEHOLDER & MATH_PLACEHO","polarity":"negative"},{"sentence":"}{ {l|rr|rr|rr} {c}{} & {c}{ } & {c}{ } & {c}{ } \\\\ Technique & SV-EER MATH_PLACEHOLDER & PER MATH_PLACEHOLDER & SV-EER MATH_PLACEHOLDER & PER MATH_PLACEHOLDER & SV-EER MATH_PLACEHOLDER & PER MATH_PLACEHOLDER \\\\ Real Data & MATH_PLACEHOLDER & MATH_PLACEHOL","polarity":"negative"},{"sentence":"[h] } {l|rrr|rrr} {c}{} & {c}{ } & {c}{ } \\\\ Technique & SV-EER MATH_PLACEHOLDER & PER MATH_PLACEHOLDER & CER MATH_PLACEHOLDER & SV-EER MATH_PLACEHOLDER & PER MATH_PLACEHOLDER & CER MATH_PLACEHOLDER \\\\ Real Data & MATH_PLACEHOLDER & MATH_PLACEHOLDER & MATH","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper, AGAIN-VC, contrasts with the Main Paper, SelfVC, by emphasizing the use of disentangled representations for voice conversion, which the Main Paper critiques for potentially losing important nuances like accent and emotion. While SelfVC advocates for a framework that leverages entangled representations and self-synthesized examples to enhance model refinement, AGAIN-VC focuses on a one-shot approach that utilizes an information bottleneck to balance synthesis quality and speaker similarity. This fundamental difference in methodology highlights the contrasting philosophies regarding the handling of speaker and content information in voice conversion.","paper_id":"ac38d44780aea27b41b041f8557a4b7f95490f12","title":"Again-VC: A One-Shot Voice Conversion Using Activation Guidance and Adaptive Instance Normalization","abstract":"Recently, voice conversion (VC) has been widely studied. Many VC systems use disentangle-based learning techniques to separate the speaker and the linguistic content information from a speech signal. Subsequently, they convert the voice by changing the speaker information to that of the target speaker. To prevent the speaker information from leaking into the content embeddings, previous works either reduce the dimension or quantize the content embedding as a strong information bottleneck. These mechanisms somehow hurt the synthesis quality. In this work, we propose AGAIN-VC, an innovative VC system using Activation Guidance and Adaptive Instance Normalization. AGAIN-VC is an auto-encoder-based model, comprising of a single encoder and a decoder. With a proper activation as an information bottleneck on content embeddings, the trade-off between the synthesis quality and the speaker similarity of the converted speech is improved drastically. This one-shot VC system obtains the best performance regardless of the subjective or objective evaluations.","score":0.744779646396637,"polarity":"negative","source":"citations","contexts":[{"sentence":"While some techniques~\\citep{defossez2022highfi,eloff2019unsupervised,singingspeechcodec,kumar2023highfidelity} aim to compress speech into a data-efficient codec, another line of research has focused on disentangling the learned features into components s","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper presents a one-shot voice conversion method using vector quantization, emphasizing the ability to disentangle content and speaker information through reconstruction loss without supervision. This contrasts with the Main Paper's SelfVC approach, which focuses on iteratively refining a voice conversion model using self-synthesized examples and entangled representations, arguing that explicit disentanglement can lead to information loss. While the Main Paper advocates for a self-supervised learning framework to enhance speaker similarity, the Related Paper highlights a simpler, unsupervised method that achieves voice conversion with less complexity.","paper_id":"097067541e0d5c140104ce21a8bb187c73b41b10","title":"One-Shot Voice Conversion by Vector Quantization","abstract":"In this paper, we propose a vector quantization (VQ) based one-shot voice conversion (VC) approach without any supervision on speaker label. We model the content embedding as a series of discrete codes and take the difference between quantize-before and quantize-after vector as the speaker embedding. We show that this approach has a strong ability to disentangle the content and speaker information with reconstruction loss only, and one-shot VC is thus achieved.","score":0.6658097505569458,"polarity":"negative","source":"citations","contexts":[{"sentence":"While some techniques~\\citep{defossez2022highfi,eloff2019unsupervised,singingspeechcodec,kumar2023highfidelity} aim to compress speech into a data-efficient codec, another line of research has focused on disentangling the learned features into components s","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper, KaraSinger, contrasts with the Main Paper, SelfVC, by focusing on singing voice synthesis rather than voice conversion, emphasizing a score-free approach where prosody and melody are generated spontaneously by the model. While SelfVC aims to improve speaker similarity through iterative refinement of voice conversion using self-synthesized examples, KaraSinger employs a vector-quantized variational autoencoder and a language model to predict discrete codes from lyrics, highlighting a different methodology and application in the realm of audio synthesis.","paper_id":"14f57efb445571f1bb16fb4e685eb69788f80fb9","title":"KaraSinger: Score-Free Singing Voice Synthesis with VQ-VAE Using Mel-Spectrograms","abstract":"In this paper, we propose a novel neural network model called KaraSinger for a less-studied singing voice synthesis (SVS) task named score-free SVS, in which the prosody and melody are spontaneously decided by machine. KaraSinger comprises a vector-quantized variational autoencoder (VQ-VAE) that compresses the Mel-spectrograms of singing audio to sequences of discrete codes, and a language model (LM) that learns to predict the discrete codes given the corresponding lyrics. For the VQ-VAE part, we employ a Connectionist Temporal Classification (CTC) loss to encourage the discrete codes to carry phoneme-related information. For the LM part, we use location-sensitive attention for learning a robust alignment between the input phoneme sequence and the output discrete code. We keep the architecture of both the VQ-VAE and LM light-weight for fast training and inference speed. We validate the effectiveness of the proposed design choices using a proprietary collection of 550 English pop songs sung by multiple amateur singers. The result of a listening test shows that KaraSinger achieves high scores in intelligibility, musicality, and the overall quality.","score":0.5212312340736389,"polarity":"negative","source":"citations","contexts":[{"sentence":"While some techniques~\\citep{defossez2022highfi,eloff2019unsupervised,singingspeechcodec,kumar2023highfidelity} aim to compress speech into a data-efficient codec, another line of research has focused on disentangling the learned features into components s","polarity":"negative"}],"background":null,"target":null},{"summary":"The Related Paper contrasts with the Main Paper by focusing on high-fidelity audio compression using a neural codec, rather than voice conversion. While the Main Paper emphasizes iterative refinement of voice conversion models through self-synthesized examples, the Related Paper prioritizes real-time audio processing and artifact reduction through a novel loss balancing mechanism. Additionally, the Related Paper employs a different training objective and architecture, highlighting a distinct approach to audio representation that does not involve the self-supervised learning techniques central to the Main Paper.","paper_id":"cdcfeb447fa8554c131c0a13a7ffcba30c0381e1","title":"High Fidelity Neural Audio Compression","abstract":"We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging neural networks. It consists in a streaming encoder-decoder architecture with quantized latent space trained in an end-to-end fashion. We simplify and speed-up the training by using a single multiscale spectrogram adversary that efficiently reduces artifacts and produce high-quality samples. We introduce a novel loss balancer mechanism to stabilize training: the weight of a loss now defines the fraction of the overall gradient it should represent, thus decoupling the choice of this hyper-parameter from the typical scale of the loss. Finally, we study how lightweight Transformer models can be used to further compress the obtained representation by up to 40%, while staying faster than real time. We provide a detailed description of the key design choices of the proposed model including: training objective, architectural changes and a study of various perceptual loss functions. We present an extensive subjective evaluation (MUSHRA tests) together with an ablation study for a range of bandwidths and audio domains, including speech, noisy-reverberant speech, and music. Our approach is superior to the baselines methods across all evaluated settings, considering both 24 kHz monophonic and 48 kHz stereophonic audio. Code and models are available at github.com/facebookresearch/encodec.","score":0.4175361692905426,"polarity":"negative","source":"citations","contexts":[{"sentence":"While some techniques~\\citep{defossez2022highfi,eloff2019unsupervised,singingspeechcodec,kumar2023highfidelity} aim to compress speech into a data-efficient codec, another line of research has focused on disentangling the learned features into components s","polarity":"negative"}],"background":null,"target":null}],"paper":{"title":"SelfVC: Voice Conversion With Iterative Refinement using Self Transformations","abstract":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples. Previous efforts on voice conversion focus on factorizing speech into explicitly disentangled representations that separately encode speaker characteristics and linguistic content. However, disentangling speech representations to capture such attributes using task-specific loss terms can lead to information loss by discarding finer nuances such as accent and emotion of the original signal. In this work, instead of explicitly disentangling attributes with loss terms, we present a framework to train a controllable voice conversion model on entangled speech representations derived from self-supervised learning (SSL) and speaker verification models. First, we develop techniques to derive prosodic information from the audio signal and SSL representations to train predictive submodules in the synthesis model. Next, we propose a training strategy to iteratively improve the synthesis model for voice conversion, by creating a challenging training objective using self-synthesized examples. In this training approach, the current state of the synthesis model is used to generate voice-converted variations of an utterance, which serve as inputs for the reconstruction task, ensuring a continuous and purposeful refinement of the model. We demonstrate that incorporating such self-synthesized examples during training improves the speaker similarity of generated speech as compared to a baseline voice conversion model trained solely on heuristically perturbed inputs. Our framework is trained without any text and is applicable to a range of tasks such as zero-shot voice conversion, voice conversion across different languages, and controllable speech synthesis with pitch and pace modifications. We conduct extensive comparisons against prior work and find that SelfVC achieves state-of-the-art results in zero-shot voice conversion on metrics evaluating naturalness, speaker similarity, and intelligibility of synthesized audio.","authors":["Paarth Neekhara","Shehzeen Samarah Hussain","Rafael Valle","Boris Ginsburg","Rishabh Ranjan","Shlomo Dubnov","Farinaz Koushanfar","Julian McAuley"],"sections":[{"heading":"Introduction","text":"# Introduction {#sec:introduction}\n\nDeriving meaningful representations from speech has been a topic of significant interest because such representations can be useful for both downstream recognition and upstream speech generation tasks. While some techniques [@defossez2022highfi; @eloff2019unsupervised; @singingspeechcodec; @kumar2023highfidelity] aim to compress speech into a data-efficient codec, another line of research has focused on disentangling the learned features into components such as speaker characteristics (voice or timbre), linguistic content (phonetic information) and prosodic information (pitch modulation and speaking rate)  [@chou2019one; @qian2019autovc; @wu2020one; @chen2021again; @qian2022contentvec; @hussain2023ace]. Representation disentanglement allows controllable speech synthesis by training a model to reconstruct the audio from the disentangled features. During inference, the relevant disentangled representations can be modified for performing tasks like voice conversion (changing the speaker of an utterance) or changing the prosody.\n\nTo derive disentangled speech representations in a text-free manner, recent methods [@lakhotia2021generative; @polyak2021speech; @lin2021fragmentvc; @huang2022s3prl; @choi2021neural] have proposed to obtain speaker information from a speaker verification model and linguistic content information from the output of models trained using self-supervised learning (SSL) [@wav2vec2; @gulati2020conformer]. While the representations obtained from SSL models are highly correlated with phonetic information, they also contain speaker information [@huang2022s3prl; @hussain2022multi]. To remove speaker information from the SSL model outputs, some techniques utilize an information bottleneck approach such as quantization [@polyak2021speech; @lakhotia2021generative; @gu2021mediumvc]. Alternatively, several researchers have proposed training strategies that employ an information perturbation technique to eliminate speaker information without quantization [@qian2022contentvec; @choi2021neural; @choi2023nansy; @hussain2023ace]. Notably, for training synthesizers, NANSY [@choi2021neural] and NANSY++ [@choi2023nansy] propose to heuristically perturb the voice of a given utterance with hand-engineered data augmentations, before obtaining the output from the SSL model. To reconstruct the original audio accurately, the synthesizer is forced to derive the speaker characteristics from the speaker embedding since the speaker information in the SSL model's output is perturbed. While such techniques are effective, heuristic voice perturbation algorithms based on pitch randomization and formant shifting represent a very limited set of transformations. We hypothesize that such training strategies can be improved by utilizing neural network-generated augmentations.\n\nWhile SSL based VC models do not require transcriptions during training, they lack the ability to explicitly control prosody due to the challenge of estimating durations from SSL features. Conversely, models that have the ability to explicitly control prosody lack the ability to use SSL, making it extremely hard to support multiple languages. What if we could combine the benefits of each approach to circumvent their weakness, and use iterative refinement to obtain better results?\n\nIn this work, we propose SelfVC, a learning framework to automatically generate diverse data transformations during training and enable controllable speech synthesis from imperfectly disentangled but uncompressed speech representations. First, we propose a feature extraction pipeline to derive SSL representations, speaker embeddings and prosodic information from a given audio signal. Next, we design a synthesis model to reconstruct a given utterance from the SSL features and speaker embedding, while using the fundamental frequency contour and duration as targets for training intermediate submodules. Finally, to train an effective voice conversion model, we propose a training strategy that utilizes the synthesis model itself to create challenging voice-converted transformations of a given speech utterance. At any given training iteration, the current state of the synthesis model is used to transform the input SSL features and the model is updated to minimize the reconstruction error of the original utterance.\n\nAll the components in our framework are trained in a text-free manner requiring only audio data. Once trained, our framework can be used for tasks such as zero-shot voice conversion, audio reconstruction with pitch and duration modulation as well as multilingual voice conversion across languages outside of the training set. On metrics evaluating speaker similarity, intelligibility and naturalness of synthesized speech we demonstrate that our model outperforms previously proposed zero-shot voice conversion methods. The main contributions of our work are:\n\n1.  We develop a training strategy using self transformations to train a voice conversion model on imperfectly disentangled representations, resulting in considerable improvement in speaker similarity metrics as compared to a model trained only with heuristic transformations.\n\n2.  We propose techniques to derive prosodic information from uncompressed SSL feature vectors and use the derived information to train a controllable synthesizer that can either mimic the prosody of a source utterance or adapt the prosody given a target speaker.\n\n3.  Our models are trained in a text-free manner and independent of phonetic posteriograms, hence making it simple and efficient to scale up the training data, including other languages.\n\n4.  SelfVC achieves state-of-the-art results in zero-shot any-to-any voice conversion in English. When fine-tuned on a few hours of multi-lingual data, SelfVC outperforms prior voice conversion methods on the cross-lingual voice conversion task."},{"heading":"Related work","text":"# Related work {#sec:related_work}\n\n**Voice conversion:** Voice conversion is the task of modifying an utterance of a source speaker to match the vocal qualities of a target speaker. Traditionally, voice conversion models were trained as a speech-to-speech translation system on a parallel dataset containing multiple speakers saying the same utterance [@sun2015dblstm; @chen2014dnn]. More recently, voice conversion systems have been developed by training neural synthesizers to reconstruct speech from disentangled representations describing linguistic content and speaker characteristics [@qian2019autovc; @chou2019one]. For example,  [@sun2016phonetic; @tian2018average] have utilized pre-trained automatic speech recognition (ASR) and speaker verification (SV) models to disentangle content and speaker information respectively. The predicted text or phonetic posteriogram (PPG) obtained from the ASR model is taken as the content representation. However, such voice conversion systems have limitations: 1) Training such systems requires transcribed speech data and the synthesis is limited to the language the model is trained on. 2) Text and PPG do not capture all linguistic features such as accent, expressions, emotions or speaker-independent style resulting in neutral-sounding synthesized speech.\n\nTo derive linguistic content in a text-free manner, some prior works have utilized SSL based models. However, as noted by prior work [@polyak2021speech; @huang2022s3prl], SSL model outputs do not necessarily separate speaker and content information. One line of research [@polyak2021speech; @lee2021voicemixer; @lakhotia2021generative; @gu2021mediumvc] aiming to disentangle the speaker and content representations, proposes an information bottleneck approach to quantize SSL model outputs thereby limiting the information to only capture the content or pseudo-text of the audio. However, the loss of information during such a quantization approach leads to sub-optimal reconstruction quality. Moreover, information bottleneck by itself does not guarantee disentanglement.\n\nAddressing the limitations of information bottleneck approaches, researchers have proposed training strategies based on heuristic transformations. For example, in ContentVec [@qian2022contentvec] and ACE-VC [@hussain2023ace], while training the SSL-based feature extractor model, the audio is transformed using pitch-shift transformation and the SSL model is trained to output similar representations for the original and transformed audio. Alternatively, in NANSY [@choi2021neural], the transformations are applied while training the synthesizer, i.e. the synthesizer is tasked to reconstruct the original audio from the speaker embedding of the original audio and the SSL features of audio perturbed using transforms such as formant-shift, pitch-randomization and randomized frequency shaping. Although these heuristic transformations serve as a reasonable proxy for voice conversion methods, we hypothesize such methods can be greatly improved by utilizing the voice conversion system itself to generate more diverse input transformations.\n\n**Transformation invariant representation learning:** In unsupervised representation learning, prior work has investigated methods to learn representations that are invariant to various input transformations [@bachman2019learning; @misra2020self]. Several techniques addressing this challenge utilize domain-specific and hand-engineered data augmentation methods for training transformation invariant representation encoders [@chen2020simple; @caron2020unsupervised; @tian2020makes; @grill2020bootstrap; @misra2020self]. More recently, [@tamkinviewmaker] proposed to train generative models to produce diverse views from a given input by adding a bounded perturbation. Their results demonstrate that neural generative models can produce a more diverse set of input distortions (compared to hand-engineered augmentations) without requiring domain-specific knowledge. While these techniques have proven valuable for learning transformation-invariant representations in downstream recognition tasks, their applicability in upstream generative tasks remains unexplored. In contrast, we develop a novel framework for training a controllable synthesis model using self-generated input transformations, without the need for additional networks for data augmentation."},{"heading":"Method","text":"# Method {#sec:methodology}\n\nOur goal is to design a voice conversion framework that can modify the voice of a given utterance, while also providing control over the prosody of the synthesized speech. To this end, our framework consists of two main components: (1) A feature extractor that derives content (linguistic features), speaker embedding and prosody information from a given speech utterance (Section [3.1](#sec:featureextraction){reference-type=\"ref\" reference=\"sec:featureextraction\"}); and (2) A synthesizer model that reconstructs the audio from the derived representations (Section [3.2](#sec:synth){reference-type=\"ref\" reference=\"sec:synth\"}). To allow controllable synthesis from imperfectly disentangled representations, we propose a training strategy that challenges the model to reconstruct the audio from self-generated perturbations of the content representation (Section [3.3](#sec:selfrefine){reference-type=\"ref\" reference=\"sec:selfrefine\"}). Specifically, we train the model to reconstruct the audio from the content representation of a heuristically modified or self transformed audio, while preserving the speaker and style representations. The content and speaker encoder networks remain frozen during synthesis model training. Figure [1](#figs:maindiag){reference-type=\"ref\" reference=\"figs:maindiag\"} provides an overview of our voice conversion framework and the synthesizer training procedure.\n\n## Feature Extraction {#sec:featureextraction}\n\nThe overview of the feature extraction pipeline is shown in Figure [2](#figs:extractorsynthesizer){reference-type=\"ref\" reference=\"figs:extractorsynthesizer\"} (a). We derive the following features from an audio signal to train our synthesis models.\n\n**Content Embedding:** We define content as a temporal feature that encodes the linguistic information of a given speech utterance. We use the output of the Conformer-SSL [@gulati2020conformer] model ($G_c$) as the content representation of speech ($z$). The Conformer-SSL model is a convolution-augmented transformer architecture that is trained to reconstruct the masked areas of the mel-spectrogram on English speech data, using contrastive and masked language modelling (MLM) losses (Refer to Appendix [7](#sec:modelarch){reference-type=\"ref\" reference=\"sec:modelarch\"} for model details). Given a speech utterance as a sequence of mel-spectrogram frames $x=x_1 \\dots x_T$, the Conformer-SSL model outputs a temporally downsampled sequence of feature vectors $z=G_c(x)=z_1 \\dots z_{T'}$. While $z$ primarily encodes phonetic information, it also encompasses speaker and prosodic information. We explain our approach to address this challenge for training a voice conversion model in Section [3.3](#sec:selfrefine){reference-type=\"ref\" reference=\"sec:selfrefine\"}.\n\n![SelfVC Overview: The synthesizer $G_{\\textit{synth}}$ is trained to reconstruct the mel-spectrogram from SSL-based content representation of a transformed audio and speaker embedding of the original audio. The transformation function is either a heuristic transform or a voice-converted audio generated using self-synthesis with a different speaker embedding. ](figures/NeuripsMainDiagram_ver3.pdf){#figs:maindiag width=\"80%\"}\n\n**Duration:** Duration or rhythm characterizes the speaking rate at a granular level, that is, how long the speaker vocalizes each phoneme of a given utterance. Accurate modelling of rhythm during synthesis is important to capture the nuances between the different speakers, accents and emotions. Since SSL representations have a high correlation with phonemes [@wav2vec2; @gulati2020conformer], we conjecture that if a phoneme is emphasized in an utterance, the consecutive content vectors at the corresponding timesteps will have high similarity. Therefore, we group together consecutive content vectors with cosine similarity higher than a threshold $\\tau$, and set the target duration for the averaged vector as the number of grouped vectors multiplied by the duration of a single vector. That is, we process the content representation $z=z_1 \\dots z_{T'}$ into a duration-augmented content representation $z'=z'_1 \\dots z'_{\\hat{T}}$ and $d'=d'_1 \\dots d'_{\\hat{T}}$ where $\\hat{T} \\leq T'$ and $d'_{t}$ represents the duration of $z'_{t}$. This similarity based grouping approach is analogous to prior approaches [@lee2021voicemixer; @qian2021global]. We refer readers to Algorithm [\\[alg:grouping\\]](#alg:grouping){reference-type=\"ref\" reference=\"alg:grouping\"} in the Appendix which details our approach to obtain $z', d'$ and highlights key differences with prior methods.\n\n**Speaker Embedding:** The speaker embeddings in our setup are derived from the TitaNet [@titanet22] speaker verification model ($G_s$). The speaker verification model is trained to differentiate speakers and generate similar embeddings for utterances from the same speaker. The output from the TitaNet speaker verification model is a $192$ dimensional speaker embedding $s=G_s(x)$. We provide more details on this model in the Appendix [7](#sec:modelarch){reference-type=\"ref\" reference=\"sec:modelarch\"}.\n\n**Pitch Contour:** The pitch contour $p$ is derived from the fundamental frequency $f_0$ contour of the speech signal that represents the prosodic modulations over time. The raw values in the fundamental frequency contour (derived from PYin algorithm [@pyin]) are speaker-dependent, therefore $f_0$ is not strictly disentangled from the speaker information. To ensure that the pitch contour only encodes the intonation and not the speaker identity, we normalize $f_0$ using the mean ($f_{\\textit{mean}}$) and standard deviation ($f_{\\textit{std}}$) of all pitch contours of the given speaker. That is, $p=(f_0 - f_{\\textit{mean}})/f_{\\textit{std}}$.\n\n## Synthesizer {#sec:synth}\n\nThe task of the synthesizer is to first reconstruct the ground-truth mel-spectrogram from the extracted speech representations and then vocode the mel-spectrogram into a listenable audio waveform. For vocoding, we use a HiFiGAN [@kong2020hifi] vocoder, which is trained separately on spectrogram and waveform pairs from a multi-speaker dataset.\n\nOur mel-spectrogram synthesizer $G_{\\textit{synth}}$ is composed of two feed-forward transformers $F_e$ and $F_d$ and intermediate modules to predict the duration and pitch contour similar to [@lancucki2021fastpitch] but operates on the grouped content representation $z'=z'_1 \\dots z'_{T'}$ instead of text. The speaker embedding $s$ is repeated across all time-steps and concatenated with each $z'_t$ to be fed as input to the first feed-forward transformer $F_e$. The hidden representation from $F_e$ is then used to predict the duration and pitch contour, that is: $h=F_e(z', s)$; $\\hat{y_d} = \\textit{DurationPredictor}(h)$, $\\hat{y_p} = \\textit{PitchPredictor}(h)$. The pitch contour is projected and averaged over each time-step of the hidden representation $h$ and added to $h$ to get $k = h + \\textit{PitchEmbedding}(p)$. Finally, $k$ is discretely upsampled as per the ground-truth duration $d'$ and fed as input to the second transformer $F_d$ to get the predicted mel-spectrogram $\\hat{y} = F_d( \\textit{DurationRegulation}(k, d') )$. Our model is trained to optimize three losses --- mel-reconstruction error, pitch prediction error and duration prediction error such that $$L_\\textit{synth} = \\lVert \\hat{{y}} - {y}\\rVert^2_2 + \n    \\lambda_1      \\lVert \\hat{{y_p}} - {p}\\rVert^2_2 + \n    \\lambda_2      \\lVert \\hat{{y_d}} - {d'}\\rVert^2_2 \n\\label{eq:trainingobjective}$$\n\nDuring inference, we can use either the predicted pitch and duration, in which case the prosody is derived from both the content and speaker embeddings; or we can mimic the prosody and speaking rate of the source utterance by using ground-truth duration and pitch.\n\n![(a) Feature Extraction: The feature extractor derives the duration augmented content information from an SSL model, pitch contour using PYin algorithm and speaker embedding from a speaker verification model. (b) Mel Spectrogram Synthesizer: reconstructs the mel-spectrogram from the derived features. ](figures/NeuripsFeatureExtractor_horiz.pdf){#figs:extractorsynthesizer width=\"80%\"}\n\n## Synthesizer Training: Iterative Refinement using Self Transformations {#sec:selfrefine}\n\nWhile the mel-spectrogram can be accurately reconstructed from a synthesizer trained using the objective given by Equation [\\[eq:trainingobjective\\]](#eq:trainingobjective){reference-type=\"ref\" reference=\"eq:trainingobjective\"}, during inference, we cannot effectively modify the voice of a given utterance. This is because the content representation $z'$ is not strictly disentangled from the speaker information. To address this challenge, past works [@choi2021neural; @choi2023nansy], have proposed an information perturbation based training strategy as follows: Instead of feeding the content embedding of the original audio as the input, the audio is perturbed to synthetically modify the speaker characteristics using formant-shifting, pitch-randomization and randomized frequency shaping transforms to obtain $x_{p}=g_{\\textit{heuristic}}(x)$. Next, the content embedding is derived from the perturbed audio $z'=G_{c}(x_{p})$, while the speaker embedding is still derived from the original audio $s=G_s(x)$. The network is then tasked to reconstruct the original audio from $z'$ and $s$. While heuristically perturbed content representations play a crucial role in enhancing the synthesizer model's attention towards the speaker embedding, they are limited in terms of the range of transformations they can introduce. Heuristic transformations represent only a subset of the potential natural variations that can occur during voice conversion.\n\nTo expand on the heuristic set of transforms, we propose to utilize the synthesizer model itself to generate a voice-converted variation of a given utterance $x$. That is, given a synthesizer model $G_{\\textit{synth}}^i$ trained until training iteration $i$, we obtain a self transformed audio for iteration $i+1$ as: $$\\begin{aligned}\n& x_p=g_{\\textit{self}}(x) = G_{\\textit{synth}}^i( G_{c}(x), s') \n\\label{eq:selftransform}\n\\end{aligned}$$ where $G_{c}(x)$ is the content embedding of the original audio $x$ and $s'$ is the speaker embedding obtained from an utterance $x'$ of a different randomly selected speaker, that is, $s'=G_s(x')$. The content embedding input for the training step $i+1$ is then derived as $z'=G_{c}(x_{p})$.\n\nSelf transformations not only provide a more diverse set of transformations but also present an increasingly challenging reconstruction task for the synthesizer, as its voice conversion capabilities improve with each training iteration. Figure [1](#figs:maindiag){reference-type=\"ref\" reference=\"figs:maindiag\"} demonstrates the proposed self transformation training strategy. In our experiments, we begin self transformations after $100k$ mini-batch iterations of training with heuristically modified audio. Thereafter, we get a reasonable initialization for a voice conversion model, and we start using self transformations to obtain $x_p$ as per Equation [\\[eq:selftransform\\]](#eq:selftransform){reference-type=\"ref\" reference=\"eq:selftransform\"}."},{"heading":"Experiments","text":"# Experiments {#sec:experiments}\n\n::: table*\n[]{#tab:reconstruction label=\"tab:reconstruction\"}\n:::\n\n## Dataset and Training {#datasettraining}\n\nThe Conformer-SSL model used as the content encoder is pretrained on $56k$ hours of unlabelled English speech from the LibriLight [@librilight] corpus sampled at $16$ KHz. We fine-tune the Conformer-SSL model (using self-supervision with contrastive and MLM loss) on the *train-clean-360* subset of LibriTTS [@zen2019libritts] dataset with audio sampled at $22050\\mathit{Hz}$ to make the model compatible with the mel-spectrogram representation of the synthesizer. For both the content encoder and synthesizer, we use $80$ bands for mel spectrogram with the FFT, window, and hop size set to $1024$, $1024$, and $256$ respectively. We fine-tune the Conformer-SSL on this revised spectrogram representation for $50$ epochs with a batch size of $32$ using the AdamW optimizer with a fixed learning rate of $5e-5$ and $\\beta_1=0.9, \\beta_2=0.99$. Fine-tuning takes around $50$ hours on a single NVIDIA RTX A6000 GPU.\n\nFor our primary experiments, the mel-spectrogram synthesizer and the HifiGAN vocoder are also trained on the train-clean-360 subset of the LibriTTS dataset which contains $360$ hours of speech from $904$ speakers. We train three variants of the mel-spectrogram synthesizer:\\\n**1. Baseline--NoTransform** is trained to simply reconstruct the mel-spectrogram from the embeddings of the given utterance without any information perturbation procedure.\\\n**2. Baseline--Heuristic** is trained to reconstruct the mel-spectrogram from the content embedding of the heuristically perturbed utterance and the speaker embedding of the original utterance. We employ two transforms $g_1, g_2$ proposed in [@choi2021neural]. $g_1$ perturbs formant, pitch, and frequency response and $g_2$ perturbs formant and frequency response while preserving pitch. The hyperparameter details of these transformations are provided in the Appendix [8](#sec:heuristicfunctions){reference-type=\"ref\" reference=\"sec:heuristicfunctions\"}.\\\n**3. SelfVC** is first trained in the same way as Baseline--Heuristic for the first $100k$ mini batch iterations. Thereafter, we use the $g_\\textit{self}$ transformation procedure given by Equation [\\[eq:selftransform\\]](#eq:selftransform){reference-type=\"ref\" reference=\"eq:selftransform\"}.\n\nWe point readers to Appendix [7](#sec:modelarch){reference-type=\"ref\" reference=\"sec:modelarch\"} for detailed architectures and training details of various components.\n\n::: table*\n[]{#tab:voiceconversion label=\"tab:voiceconversion\"}\n:::\n\n## Evaluation Metrics {#sec:metrics}\n\nWe encourage readers to listen to our audio examples linked in the footnote on the first page. Quantitatively, we evaluate the synthesized audio on the following aspects:\n\n**Intelligibility:** For intelligibility, we transcribe the synthesized and original through and ASR and compute two error metrics between the transcriptions --- Character Error Rate **(CER)** and Phoneme Error Rate **(PER)**. For CER, we transcribe the audio using the Quartznet [@kriman2020quartznet] ASR model. For multilingual evaluation, we compute the PER on the transcriptions obtained from the pre-trained wav2vec2-Large-XLSR-53 ASR model which has been trained to recognize phonetic labels in multiple languages. [@Xu2021SimpleAE]. We also report the CER and PER between the predicted and ground truth transcripts of real data for reference in our Results.\n\n**Speaker Similarity Metrics:** To evaluate speaker similarity to our target speaker, we compute the speaker embeddings of synthesized and real utterances using a separate pre-trained speaker verification model [@koluguri2020speakernet]. Then we pair the synthesized and real utterances to create an equal number of positive (same-speaker) and negative (alternate-speaker) pairs for each target speaker to compute the Equal Error Rate **(SV-EER)**. We also report the mean cosine similarity between the positive pairs **(SV-SIM)**. Finally, we also ask human listeners to rate the speaker similarity of the generated and real utterance from the target speaker on a 5-point scale to obtain **Sim-MOS**.\n\n**Naturalness (MOS):** We ask human listeners to rate the naturalness of each utterance on a $1$ to $5$ scale with $1$ point increments. We include details of *MOS* and *SIM-MOS* evaluations in Appendix [11](#sec:humaneval){reference-type=\"ref\" reference=\"sec:humaneval\"}\n\n**Prosodic Similarity (GPE):** To evaluate prosodic similarity for the reconstruction task (Section [4.3](#sec:Reconstruction){reference-type=\"ref\" reference=\"sec:Reconstruction\"}), we compute error between the fundamental frequency contours of the original and synthesized audio. Specifically, we use Gross Pitch Error (GPE) [@chu2009reducing] to evaluate prosodic similarity.\n\n## Reconstruction {#sec:Reconstruction}\n\nFirst, we evaluate how effectively our setup can reconstruct audio from the extracted representations for unseen utterances and speakers. Our synthesizers can operate in two modes during inference --- *1) **Guided:*** In this scenario, we use ground truth pitch and duration information derived from the source utterance. *2) **Predictive:*** In this case, we use the predicted pitch and duration for synthesis. We conduct the reconstruction test on two unseen datasets --- 1) We choose $200$ utterances from the VCTK [@yamagishi2019vctk] dataset (English) with $20$ random utterances from each of the $10$ speakers ($5$ random male and $5$ random female speakers); 2) To evaluate performance on unseen languages, we choose $200$ utterances from the CSS10 [@park2019css10] dataset with $20$ random utterances from each of the $10$ unseen languages. The CSS10 dataset has a single speaker per language and contains at least $4$ hours of speech per language. For both of these evaluations, we use the synthesizer models trained on the same dataset, i.e. train-clean-360 subset of LibriTTS (English). The synthesized speech is evaluated on the intelligibility, speaker similarity and prosodic similarity metrics.\n\nAs indicated by the results in Table [\\[tab:reconstruction\\]](#tab:reconstruction){reference-type=\"ref\" reference=\"tab:reconstruction\"}, all three synthesizers achieve similar performance on the above metrics. This is expected since the speaker and content embedding are derived from the same utterance and all three synthesizers are trained for the reconstruction task. However, for controllable synthesis tasks such as voice conversion, we demonstrate that SelfVC considerably outperforms these baselines (Section [4.4](#sec:vcresults){reference-type=\"ref\" reference=\"sec:vcresults\"}). Since our model is trained in a text-free manner, we also see a promising generalization to unseen languages. The PER on CSS10 is higher than VCTK due to the larger phonetic vocabulary in non-English languages and the PER of the wav2vec2 model [@Xu2021SimpleAE] being higher even on real data. For unseen languages, our synthesizers produce more intelligible speech in the guided mode, where the duration information of the source utterance is kept intact.\n\n## Voice Conversion {#sec:vcresults}\n\nTo convert the voice of a given source utterance to a target speaker, we derive the content embedding from the source utterance and estimate the speaker embedding from the target speaker's audio and feed both as input to the synthesizer. To compare our zero-shot voice conversion method against prior work, we choose utterances from the LibriTTS test-clean subset since it is an unseen dataset across all voice conversion methods. We randomly choose $10$ target speakers ($5$ male and $5$ female) and $20$ source utterances from the remaining speakers to create $200$ voice conversion trials for each technique and report the results in Table [\\[tab:voiceconversion\\]](#tab:voiceconversion){reference-type=\"ref\" reference=\"tab:voiceconversion\"}. For our primary evaluation, we use $10$ seconds of speech from each target speaker to derive the speaker embedding. We split the $10$ second target-speaker utterance into $2$ second segments and estimate the speaker embedding as the mean speaker embedding across the segments. To be consistent with past work, we keep the duration of the source utterance unchanged during synthesis using duration guided mode and use predictive mode for pitch. We evaluate speaker-similarity across varying target speaker data amounts, with results detailed in Figure [3](#figs:speakergraphs){reference-type=\"ref\" reference=\"figs:speakergraphs\"} of the Appendix. Additionally, we include voice conversion results on seen speakers and out-of-domain VCTK dataset in Appendix [9](#sec:additionalvc){reference-type=\"ref\" reference=\"sec:additionalvc\"}.\n\n**Effectiveness of Self Transformations:** We perform ablations to compare effectiveness of different input transformation techniques. As reported in Table [\\[tab:voiceconversion\\]](#tab:voiceconversion){reference-type=\"ref\" reference=\"tab:voiceconversion\"}, incorporating heuristic transformations during training (Baseline--Heuristic) improves speaker similarity of generated audio over a baseline that does not use any transformations (Baseline--NoTransform). The speaker similarity metrics (SV-EER, SV-Sim and Sim-MOS) further improve in SelfVC when we incorporate the self transformation based iterative refinement procedure (Section [3.3](#sec:selfrefine){reference-type=\"ref\" reference=\"sec:selfrefine\"}). Note that both the baseline techniques and the SelfVC approach use identical neural architectures and undergo training for the same number of epochs with consistent optimizer hyperparameters. While Baseline-NoTransform produces intelligible and natural sounding audio, it clearly lacks in speaker similarity metrics, emphasizing the significance of input transformation methods in voice conversion.\n\n::: table*\n[]{#tab:crosslingual label=\"tab:crosslingual\"}\n:::\n\n**Comparison against Prior Work:** Although we have conducted controlled experiments by varying input transformation techniques in our models, it is challenging to make similar comparisons with prior research due to disparities in vocoders, datasets, and compatibility of model architectures between synthesizers and vocoders. We use the official open-source implementations and model checkpoints of six previously proposed techniques. For a fair comparison, we evaluate all prior techniques on the same voice conversion trial pairs as our methods, using the same ASR and SV models for calculating CER, PER and SV metrics. While NANSY [@choi2023nansy] is not officially open-sourced, our Baseline--Heuristic method closely follows the training strategy proposed in NANSY using the same hyperparameters for heuristic functions (Appendix [8](#sec:heuristicfunctions){reference-type=\"ref\" reference=\"sec:heuristicfunctions\"}), incorporating more recent neural architectures for the synthesizer and feature extractors. As shown in Table [\\[tab:voiceconversion\\]](#tab:voiceconversion){reference-type=\"ref\" reference=\"tab:voiceconversion\"}, SelfVC outperforms previously proposed voice conversion models on all quantitative metrics. It is interesting to note that SelfVC trained on just the train-clean-360 subset of LibriTTS outperforms YourTTS which is trained on a much larger dataset comprising LibirTTS (train-clean-360, train-clean-100), VCTK and two additional languages (French and Portugese).\n\n**Cross-lingual Voice Conversion:** For Cross-lingual voice conversion, we use the CSS10 dataset that contains speech utterances from $10$ different languages. We consider three voice conversion scenarios: 1) **English to CSS10:** Source utterance is from the test-clean subset of LibriTTS (English) and target speaker is from the CSS10 dataset 2) **CSS10 to CSS10:** Source utterance from a language in the CSS10 dataset and target speaker is from another language of CSS10. 3) **CSS10 to English:** Source utterance from a language in the CSS10 dataset and target speaker is from LibriTTS (English).\n\nFor *English to CSS10* we create $200$ voice conversion trials considering $20$ source utterances and $10$ target speakers in CSS10. For *CSS10 to CSS10* and *CSS10 to English*, we generate $500$ voice conversion trials each, considering $50$ source utterances ($5$ each from the $10$ languages) and $10$ target speakers. We use $10$ seconds of target speaker data across all experiments. We compare different voice conversion techniques on these trial pairs and present the results in Table [\\[tab:crosslingual\\]](#tab:crosslingual){reference-type=\"ref\" reference=\"tab:crosslingual\"}.\n\nIn the *English to CSS10* experiments, SelfVC (LibriTTS), which is trained solely on train-clean-360 LibriTTS subset, outperforms baseline methods and prior work, achieving lower SV-EER and PER. It is interesting to note that SelfVC (LibriTTS) outperforms YourTTS, which is trained on a more extensive trilingual dataset as discussed above. For *CSS10 to CSS10* voice conversion, we observe a higher SV-EER and PER for SelfVC (LibriTTS) as compared to YourTTS. This is not very surprising, since YourTTS model was trained on multilingual speech data while SelfVC (LibriTTS) has only been trained on English speech. For *CSS10 to English* voice conversion, SelfVC (LibriTTS) outperforms all baselines and prior work. Interestingly, ACE-VC, which uses similar model architectures and the same training data as our setup, does not generate intelligible speech when the source utterance is from CSS10. This result indicates that the text-free nature of our model allows generalization to unseen languages.\n\nTo adapt SelfVC for new languages, we conduct fine-tuning of only the synthesis model on both LibriTTS (train-clean-360) and CSS10 utterances (using data other than the test trial pairs), which considerably improves SV-EER and PER for the SelfVC (LibriTTS + CSS10) model. The improvement in SV-EER is significant but not surprising since the $10$ CSS10 speakers are now seen during training in the SelfVC (LibriTTS + CSS10) model. The improvement in PER is promising and demonstrates the effective adaptability of our model to different languages. We delve into details of the finetuning process and report the phoneme error rates for each of the $10$ CSS10 languages in Appendix [10](#sec:languagewiseper){reference-type=\"ref\" reference=\"sec:languagewiseper\"}."},{"heading":"Conclusion","text":"# Conclusion {#sec:discussion}\n\nWe introduce a novel training strategy, SelfVC, that utilizes self transformations to train controllable synthesis models on imperfectly disentangled representations. Our results indicate a clear benefit of incorporating self-synthesized examples while training a voice conversion model, as shown by a significant improvement in speaker similarity metrics while keeping the model architecture unchanged. By deriving and modelling prosodic information during training, SelfVC allows for both fine-grained and high-level control over the prosody of the synthesized speech. SelfVC achieves SOTA results in zero-shot voice conversion for English and can be easily scaled to multiple languages in a text-free manner, outperforming prior approaches in cross-lingual voice conversion. We recommend future work to apply our training strategy in other data domains for creating controllable synthesis models.\n\n[]{#sec:references label=\"sec:references\"}"},{"heading":"Deriving Duration-augmented Content Embeddings","text":"# Deriving Duration-augmented Content Embeddings\n\nGiven the output $z = G_c(x) = z_1 \\dots z_T$ from the Conformer-SSL model, we group together consecutive feature vectors with high cosine similarity. That is, we maintain a running average of consecutive vectors with cosine similarity greater than a threshold $\\tau$ and obtain the target duration for the averaged vector as the product of the number of grouped vectors and the duration of a single vector. The original duration $\\delta$ of a single vector is $4$ mel-spectrogram frames or $46$ms or raw audio. This procedure differs slightly from previous work [@lee2021voicemixer] in that, instead of computing similarities between consecutive pairs of the original vectors, we now compare the average embedding of the current group with the next original embedding. Our temporal downsampling procedure is similar to [@qian2021global] but we additionally maintain the durations of the grouped vectors to be used as targets for the duration predictor in our synthesizer. Our technique also differs from prior work [@kreuk-etal-2022-textless; @maimon2022speaking] that obtains duration/rhythm information from discrete SSL representations instead of the continuous vectors. Algorithm [\\[alg:grouping\\]](#alg:grouping){reference-type=\"ref\" reference=\"alg:grouping\"} details our grouping procedure to obtain duration-augmented content embeddings.\n\n:::: algorithm\n::: algorithmic\n$z' \\gets [z_1]$ $d' \\gets [\\delta]$ $num\\_grouped \\gets 1$ $z'[-1] \\gets (z_t + num\\_grouped * z'[-1])/(num\\_grouped + 1)$ $d'[-1] \\gets \\delta * (num\\_grouped + 1)$ $num\\_grouped \\gets num\\_grouped + 1$ $z'.append(z_t)$ $d'.append(\\delta)$ $num\\_grouped \\gets 1$ **return** $z', d'$\n:::\n\n[]{#alg:grouping label=\"alg:grouping\"}\n::::"},{"heading":"Model Architecture and Implementation Details","text":"# Model Architecture and Implementation Details {#sec:modelarch}\n\nOur voice conversion comprises the following neural networks. Total number of parameters and inference latency for each model are listed in Table [1](#tab:modelsize){reference-type=\"ref\" reference=\"tab:modelsize\"}\n\n**Conformer-SSL Model:** The Conformer-SSL model [@gulati2020conformer] used in this work is a convolution-augmented transformer architecture that is trained to reconstruct the masked areas of the mel-spectrogram on English speech data, using contrastive and masked language modelling (MLM) losses. It is pre-trained on the LibriLight corpus which consists of $56$k hrs of unlabeled English speech. The model consists of $18$ layers, $8$ attention heads and a hidden dimension of $512$. The output head of the Conformer model gives a $256$ dimensional encoding per timestep. The model temporally downsamples the input mel-spectrogram by a factor of $4$. With the STFT parameters used in our setup, each vector from the Conformer-SSL model corresponds to a contextualized representation of $46$ms of audio.\n\n**Speaker Verification TitaNet Model:** TitaNet [@titanet22] is based on a 1-D depthwise separable convolution architecture with Squeeze and Excitation layers that provide global context, followed by channel attention-based statistics pooling layer to map variable-length utterances to a fixed-length embedding. The TitaNet speaker verification model is trained using additive angular margin loss [@Liu_2017_CVPR] on $3373$ hours of speech from multiple datasets that span $16681$ speakers. Comprising of $25.3$ million parameters, the TitaNet model is designed to be parameter-efficient and achieves state-of-the-art results on the VoxCeleb-1 speaker verification benchmark with an EER of $0.68\\%$. The output from this speaker verification model is a $192$ dimensional speaker embedding.\n\n**Mel-spectrogram Synthesizer:** The spectrogram synthesizer takes as input the content and speaker embeddings and predicts the mel-spectrogram. The speaker and content embeddings derived from the Conformer-SSL and TitaNet models respectively are first projected to $256$ dimensions each using a learnable linear layer. The projected speaker embedding is then repeated across all time-steps and concatenated with the projected content embeddings. The synthesizer is a FastPitch [@lancucki2021fastpitch] based model that contains two feed forward transformer networks (encoder and decoder) that follow an identical architecture. Each transformer network contains $6$ layers, with a hidden dimension of $1536$. Each layer is composed of a single-headed attention module with an attention head of size $64$ followed by a 1-d convolutional block. Each convolutional block is a sequential operation of Conv1d, ReLU, Conv1d, Dropout and Layer Normalization. The kernel size for the convolution is $3$ and dropout probability is $0.1$.\n\nThe mel-spectrogram synthesizer also contains two submodules for predicting pitch and duration. The pitch and duration predictors take as input the output of the encoder network and predict a sequence of scalar values for duration or pitch (speaker normalized $F_0$ contour). Duration is used to regulate the length of the encoder output and pitch is embedded and concatenated with the encoder's output to be fed as input to the decoder. Both the pitch and duration predictor follow the same architecture --- Each network contains two convolutional blocks. Each convolutional block is a serial composition of Conv1d, ReLU and layer normalization with a kernel size of $3$ and hidden dimension of $256$, followed by a linear layer that maps the hidden dimension to a scalar value for duration or pitch.\n\nAll three variants of the synthesizer listed in Section [4.1](#datasettraining){reference-type=\"ref\" reference=\"datasettraining\"} are optimized using an AdamW optimizer [@loshchilov2018decoupled] with a fixed learning rate of $1e-4$ and $\\beta_1=0.8, \\beta_2=0.99$ for $500$ epochs with a batch size of $32$. The threshold $\\tau$ for duration extraction is set as $0.925$. The loss coefficients for the duration and pitch loss are set as $\\lambda_1=\\lambda_2=0.1$. The training time for Synth (SelfTransform) model is around $5$ days on $4$ NVIDIA RTX A6000 GPUs.\n\n**HiFiGAN Vocoder:** The HiFi-GAN [@kong2020hifi] vocoder used in this work consists of one generator and two discriminators: multi-scale and multi-period discriminators. In the generator network, consists of $4$ upsampling blocks with an upsampling factor of $8$, $8$, $2$, $2$ with kernel sizes $16$, $16$, $4$, $4$ respectively. The model outputs audio at $22050$Hz. The HiFiGAN vocoder is trained for $350$ epochs on train-clean-360 subset of LibriTTS. Thereafter, the vocoder is additionally fine-tuned on synthetic mel-spectrograms, generated by the three mel-spectrogram synthesizers (Baseline-NoTransform, Baseline-Heuristic and SelfVC) for the same dataset for $5$ epochs.\n\n::: {#tab:modelsize}\n  ----------------------------- --------------- ------------------ ------\n                                                  *Inference Time* \n                                                       *(Seconds)* \n  Model                           \\# Parameters                CPU    GPU\n  Speaker Encoder TiTaNet                  25 M               0.13   0.05\n  Conformer-SSL                           121 M               0.44   0.10\n  Mel-Spectrogram Synthesizer              59 M               0.15   0.01\n  HiFiGAN Vocoder                          85 M                2.1   0.08\n  ----------------------------- --------------- ------------------ ------\n\n  : Model size and wall clock inference time for a speech utterance of length $10$ seconds using a batch size of $1$ on CPU and NVIDIA RTX A6000 GPU.\n:::\n\n[]{#tab:modelsize label=\"tab:modelsize\"}"},{"heading":"Heuristic transformation functions","text":"# Heuristic transformation functions {#sec:heuristicfunctions}\n\nFor heuristic transformations, we follow the perturbation functions and hyperparameters proposed in [@choi2023nansy]. The three fundamental perturbation functions used are 1) Formant Shifting (fs) 2) Pitch Randomization (pr) and 3) Random Frequency Shaping (peq).\n\nDuring training, the source utterance is perturbed by randomly choosing a transformation function $g_1$ or $g_2$ --- Transformation function $g_1$ is a serial composition of *peq* and *fs*; And $g_2$ is a serial composition of *peq*, *pr* and *fs*.\n\nFor *pr*, pitch shift ratio is sampled uniformly from $U(1, 2)$ and pitch range ratio is sampled from $U(1, 1.5)$. Random frequency shaping (*peq*) is serial composition of low-shelfing, peaking and high-shelfing filters. Following NANSY, we use one low-shelving $H^\\text{LS}$, one high-shelving $H^\\text{HS}$, and eight peaking filters $H^\\text{Peak}_1, \\cdots, H^\\text{Peak}_8$.\n\n$$H^\\text{PEQ}(z) = H^\\text{LS}(z)H^\\text{HS}(z)\\prod_{i=1}^8H^\\text{Peak}_i(z).$$\n\nEach component is a second-order IIR filter parameterized by a cutoff/center frequency, quality factor, and gain parameter. The cutoff frequencies for $H^\\text{LS}$ and $H^\\text{HS}$ are set at $60 Hz$ and $10 kHz$, respectively. Center frequencies of $H^\\text{Peak}_1, \\cdots, H^\\text{Peak}_8$ are uniformly spaced in between the shelving filters on a logarithmic scale. The quality factor of each component is randomly sampled as $Q = Q_\\text{min}(Q_\\text{max}/Q_\\text{min})^z$ where $Q_\\text{min} = 2$, $Q_\\text{max} = 5$, and $z \\sim U(0, 1)$. The gain (in decibel) of each component is randomly sampled from $U(-12, 12)$.\n\nWe refer the readers to the link in the footnote (an unofficial open-source implementation of NANSY) for the precise implementation of transformation functions used in our work. [^2]"},{"heading":"Voice Conversion on Seen Speakers and VCTK Datasets","text":"# Voice Conversion on Seen Speakers and VCTK Datasets {#sec:additionalvc}\n\nWe present results for additional experiments on speen speakers from train-clean-360 (using utterances from the hold out set) and unseen speakers from VCTK dataset in Table [2](#tab:seenvctkresults){reference-type=\"ref\" reference=\"tab:seenvctkresults\"}. We choose VCTK because it is an out-of-domain test set of unseen speakers for our models trained on LibriTTS. Similar to our primary experiments, we consider $20$ source utterances, each from a different speaker and $10$ target speakers resulting in $200$ voice conversion trials. We compare against one prior work ACE-VC [@hussain2023ace], since ACE-VC is trained on the same dataset and VCTK dataset is not used during training. Other prior techniques considered in our main experiments conduct training on the VCTK dataset.\n\nOn the VCTK dataset, we find that SelfVC significantly outperforms the baselines and ACE-VC on the SV-EER metric. We also present the t-SNE plots for speaker embeddings of generated and real utterances in Figure [3](#figs:speakergraphs){reference-type=\"ref\" reference=\"figs:speakergraphs\"}. It can be observed that the embeddings of generated audio are closely clustered with the real embeddings of the target speaker for both seen and unseen speakers. We study the effect using different amounts of target speaker data when deriving speaker embedding for voice conversion in Figure [3](#figs:speakergraphs){reference-type=\"ref\" reference=\"figs:speakergraphs\"}. While the SV-EER improves as we incorporate more data from the target speaker, we observe marginal improvement beyond $16$ seconds of target speaker data. In this graph, *seen speakers* refers to LibriTTS train-clean-360 and *unseen speakers* refers to VCTK.\n\n![**Left**: SV-EER of voice converted speech generated by SelfVC using different amounts of target speaker data for estimating the speaker embedding. **Right:** t-SNE visualization of speaker embeddings of SelfVC synthesized and ground-truth audio for $10$ target speakers. Each color represents a different speaker.](figures/SelfVCGraphs.pdf){#figs:speakergraphs width=\"100%\"}\n\n::: {#tab:seenvctkresults}\n                               *LibriTTS (train-clean-360)*                                                      *VCTK*                    \n  -------------------------- ------------------------------ ------------------ ------------------ --------------------- ------------------ ------------------\n  Technique                             SV-EER $\\downarrow$   PER $\\downarrow$   CER $\\downarrow$   SV-EER $\\downarrow$   PER $\\downarrow$   CER $\\downarrow$\n  Real Data                                         $2.9\\%$            $8.7\\%$            $6.3\\%$               $3.1\\%$            $9.8\\%$            $5.1\\%$\n  ACE-VC [@hussain2023ace]                          $5.3\\%$            $8.8\\%$            $3.7\\%$               $9.2\\%$           $22.1\\%$            $8.2\\%$\n  Baseline--NoTransform                            $19.1\\%$            $5.5\\%$            $2.6\\%$              $25.2\\%$            $7.6\\%$            $3.8\\%$\n  Baseline--Heuristic                               $4.4\\%$            $5.5\\%$            $2.3\\%$               $8.5\\%$            $7.6\\%$            $3.1\\%$\n  SelfVC                                   $\\mathbf{3.0\\%}$   $\\mathbf{5.4\\%}$   $\\mathbf{2.2\\%}$      $\\mathbf{4.3\\%}$            $7.4\\%$   $\\mathbf{3.8\\%}$\n\n  : Voice Conversion experiments on seen speakers (LibriTTS train-clean-360) and out-of-domain unseen speakers (VCTK). We compare against one prior work trained on the same dataset as ours.\n:::\n\n[]{#tab:seenvctkresults label=\"tab:seenvctkresults\"}"},{"heading":"Multilingual Phoneme Error Rate","text":"# Multilingual Phoneme Error Rate {#sec:languagewiseper}\n\nIn Figure [4](#figs:languagepers){reference-type=\"ref\" reference=\"figs:languagepers\"} we present phoneme error rate on individual languages for *CSS10 to CSS10* and *CSS10 to LibriTTS* cross-lingual voice conversion experiments respectively. We also compare against the YourTTS model, which has the lowest average PER amongst the prior work considered in our work. As evident from the graphs, PER across all languages improve when SelfVC is fine-tuned on the LibriTTS train-clean-360 and CSS10 dataset (SelfVC (LibriTTS + CSS10) ). The fine-tuning is conducted for $10$ epochs with a fixed learning rate of $1e-4$ on the combined LibriTTS and CSS10 dataset and takes around $5$ hours on a single NVIDIA RTX A6000 GPU. Certain languages such as Chinese, Russian and Japanese have higher PER across all methods. This is because of the large phonetic vocabulary of such languages which results in a higher PER from the wav2vec2 model even on real utterances [@Xu2021SimpleAE].\n\n![Phoneme Error Rate on Individual Languages of the CSS10 dataset for voice conversion experiments when the source utterance is from CSS10 and the target speaker is from another language in CSS10 or the LibriTTS test-clean dataset.](figures/PERHorizontal.png){#figs:languagepers width=\"1.\\\\linewidth\"}"},{"heading":"MOS and Sim-MOS Evaluation","text":"# MOS and Sim-MOS Evaluation {#sec:humaneval}\n\n**Naturalness MOS Evaluation:** We ask human listeners to rate the audio on a scale of $1$ to $5$ point naturalness scale with $1$ point increments. We present $200$ audio examples of each technique and each audio is independently rated by at least $4$ listeners. This results in a total of at least $800$ evaluations per technique. The template used for the Naturalness human study is shown in Figure [\\[figs:naturalnesstemplate\\]](#figs:naturalnesstemplate){reference-type=\"ref\" reference=\"figs:naturalnesstemplate\"}. We report the MOS with $95\\%$ confidence intervals in Table [\\[tab:voiceconversion\\]](#tab:voiceconversion){reference-type=\"ref\" reference=\"tab:voiceconversion\"} of the paper.\n\n**Speaker Similarity MOS (Sim-MOS):** For Sim-MOS evaluation, we ask human listeners to rate the speaker similarity of a given pair of utterances. For this evaluation, each synthetic utterance is paired with a real utterance of the target speaker. We create pairs for all of the $200$ synthesized utterances of each technique. Each pair is rated by at least $4$ independent listeners resulting in at least $800$ speaker similarity evaluations of each technique. We ask the listeners to judge only the voice/speaker of the utterances and ignore the accent, content, grammar and expressiveness of speech following past work [@transferspeakerverification; @casanova2022yourtts]. The template used for this user study is shown in Figure [5](#figs:spksimmos){reference-type=\"ref\" reference=\"figs:spksimmos\"}. The Sim-MOS with $95\\%$ confidence intervals in Table [\\[tab:voiceconversion\\]](#tab:voiceconversion){reference-type=\"ref\" reference=\"tab:voiceconversion\"} of the paper. For reference, the reported Sim-MOS for same-speaker ground truth pairs is $4.36 \\pm 0.08$ and different-speaker ground truth pairs is $1.77 \\pm 0.10$.\n\n<figure id=\"figs:spksimmos\">\n<div class=\"minipage\">\n<img src=\"figures/naturalness.png\" />\n</div>\n<div class=\"minipage\">\n<img src=\"figures/speakersimilarity.png\" />\n</div>\n<figcaption><span>User Study template used for Speaker Similarity MOS evaluation</span></figcaption>\n</figure>\n\n[]{#sef:appendix label=\"sef:appendix\"}\n\n[^1]:\n\n[^2]: <https://github.com/dhchoi99/NANSY/blob/master/datasets/functional.py>"}],"approval":false,"conference":"iclr","rating":2,"year":2024,"id":"1c7cda09d2e6cf1181186ba285f9e636627d837149711f6ec53a564970122e1b","y_true":0,"y_pred":0,"rationale_true":"Summary: The paper introduces SelfVC, a novel training strategy aimed at enhancing voice conversion models using self-synthesized examples. The proposed model integrates prosodic information from the audio signal for predictive training and uses a unique iterative training approach with self-synthesized examples for continuous model refinement. Compared to previous methods, SelfVC sets new SOTA in zero-shot voice conversion regarding naturalness, speaker similarity, and audio intelligibility.\n\nStrengths: 1. The paper is well-composed, presenting its methodology with clarity. \n2. The extensive experiments support the presented claims. \n3. The demo provided by the author indicates the method's effectiveness.\n\nWeaknesses: Self-VC is similar to recent VC work (NANSY), except it uses pitch and duration predictors like ACE-VC. Also, as for the proposed training strategy (self transformations), random speaker embedding are commonly used for training a voice conversion model (e.g., https://arxiv.org/pdf/1806.02169.pdf, https://arxiv.org/pdf/2305.15816.pdf, https://arxiv.org/pdf/2305.07204.pdf,https://proceedings.neurips.cc/paper/2021/file/0266e33d3f546cb5436a10798e657d97-Paper.pdf). The fundamental idea seems the same. This point needs to be discussed more carefully.\n\nQuestions: /","rationale_pred":"Paper Summary: The paper introduces SelfVC, a novel training strategy for voice conversion that iteratively improves a model using self-synthesized examples. Instead of explicitly disentangling speech representations, SelfVC trains a controllable voice conversion model on entangled speech representations derived from self-supervised learning (SSL) and speaker verification models. The method includes deriving prosodic information from SSL representations, using a mel-spectrogram synthesizer, and employing a text-free training approach. The paper claims state-of-the-art results in zero-shot voice conversion.\n\nSupporting Evidence:\n- Several supporting papers highlight the benefits of self-supervised learning in voice conversion and speech synthesis, aligning with SelfVC's approach.\n- Some supporting papers also emphasize the advantages of avoiding explicit disentanglement of speech attributes, which is a key feature of SelfVC.\n- Other supporting papers demonstrate innovative approaches to voice conversion that enhance speaker and content representation separation, reinforcing the potential of novel training strategies like SelfVC.\n\nContradictory Evidence:\n- Several contrasting papers emphasize the importance of disentangled speech representations for robust and controllable voice conversion, directly contradicting SelfVC's use of entangled representations.\n- Some contrasting papers argue that the lack of explicit disentanglement in SelfVC can lead to reduced control over prosody-related factors.\n- Other contrasting papers present alternative methods for voice conversion, such as one-shot approaches or those using vector quantization, suggesting that SelfVC's iterative refinement strategy may not be unique.\n\nConclusion: While SelfVC presents an interesting approach to voice conversion using self-synthesized examples and entangled representations, the existence of several contrasting papers that advocate for disentangled representations and alternative voice conversion methods suggests that the paper's novelty is limited. The core idea of iterative refinement using self-generated data might have been explored in similar contexts, and the benefits of using entangled representations are debatable given the arguments for disentanglement.","structured_evaluation":{"paper_summary":"The paper introduces SelfVC, a novel training strategy for voice conversion that iteratively improves a model using self-synthesized examples. Instead of explicitly disentangling speech representations, SelfVC trains a controllable voice conversion model on entangled speech representations derived from self-supervised learning (SSL) and speaker verification models. The method includes deriving prosodic information from SSL representations, using a mel-spectrogram synthesizer, and employing a text-free training approach. The paper claims state-of-the-art results in zero-shot voice conversion.","supporting_evidence":["Several supporting papers highlight the benefits of self-supervised learning in voice conversion and speech synthesis, aligning with SelfVC's approach.","Some supporting papers also emphasize the advantages of avoiding explicit disentanglement of speech attributes, which is a key feature of SelfVC.","Other supporting papers demonstrate innovative approaches to voice conversion that enhance speaker and content representation separation, reinforcing the potential of novel training strategies like SelfVC."],"contradictory_evidence":["Several contrasting papers emphasize the importance of disentangled speech representations for robust and controllable voice conversion, directly contradicting SelfVC's use of entangled representations.","Some contrasting papers argue that the lack of explicit disentanglement in SelfVC can lead to reduced control over prosody-related factors.","Other contrasting papers present alternative methods for voice conversion, such as one-shot approaches or those using vector quantization, suggesting that SelfVC's iterative refinement strategy may not be unique."],"conclusion":"While SelfVC presents an interesting approach to voice conversion using self-synthesized examples and entangled representations, the existence of several contrasting papers that advocate for disentangled representations and alternative voice conversion methods suggests that the paper's novelty is limited. The core idea of iterative refinement using self-generated data might have been explored in similar contexts, and the benefits of using entangled representations are debatable given the arguments for disentanglement.","label":0,"rationale":"Paper Summary: The paper introduces SelfVC, a novel training strategy for voice conversion that iteratively improves a model using self-synthesized examples. Instead of explicitly disentangling speech representations, SelfVC trains a controllable voice conversion model on entangled speech representations derived from self-supervised learning (SSL) and speaker verification models. The method includes deriving prosodic information from SSL representations, using a mel-spectrogram synthesizer, and employing a text-free training approach. The paper claims state-of-the-art results in zero-shot voice conversion.\n\nSupporting Evidence:\n- Several supporting papers highlight the benefits of self-supervised learning in voice conversion and speech synthesis, aligning with SelfVC's approach.\n- Some supporting papers also emphasize the advantages of avoiding explicit disentanglement of speech attributes, which is a key feature of SelfVC.\n- Other supporting papers demonstrate innovative approaches to voice conversion that enhance speaker and content representation separation, reinforcing the potential of novel training strategies like SelfVC.\n\nContradictory Evidence:\n- Several contrasting papers emphasize the importance of disentangled speech representations for robust and controllable voice conversion, directly contradicting SelfVC's use of entangled representations.\n- Some contrasting papers argue that the lack of explicit disentanglement in SelfVC can lead to reduced control over prosody-related factors.\n- Other contrasting papers present alternative methods for voice conversion, such as one-shot approaches or those using vector quantization, suggesting that SelfVC's iterative refinement strategy may not be unique.\n\nConclusion: While SelfVC presents an interesting approach to voice conversion using self-synthesized examples and entangled representations, the existence of several contrasting papers that advocate for disentangled representations and alternative voice conversion methods suggests that the paper's novelty is limited. The core idea of iterative refinement using self-generated data might have been explored in similar contexts, and the benefits of using entangled representations are debatable given the arguments for disentanglement."},"arxiv_id":"2310.09653"},"terms":{"tasks":["improve a voice conversion model","disentangling speech representations","train a controllable voice conversion model","derive prosodic information","train predictive submodules in the synthesis model","iteratively improve the synthesis model for voice conversion","generate voice-converted variations of an utterance","ensure a continuous and purposeful refinement of the model","improve the speaker similarity of generated speech","achieve state-of-the-art results in zero-shot voice conversion","evaluate naturalness of synthesized audio","evaluate speaker similarity of synthesized audio","evaluate intelligibility of synthesized audio","perform zero-shot voice conversion","perform voice conversion across different languages","perform controllable speech synthesis with pitch and pace modifications"],"methods":["SelfVC","self-supervised learning","speaker verification models","techniques to derive prosodic information","training strategy to iteratively improve the synthesis model","create a challenging training objective using self-synthesized examples"],"metrics":["naturalness","speaker similarity","intelligibility"],"resources":["self-synthesized examples","baseline voice conversion model"],"relations":[{"head":"SelfVC","tail":"improve a voice conversion model"},{"head":"SelfVC","tail":"train a controllable voice conversion model"},{"head":"self-supervised learning","tail":"train a controllable voice conversion model"},{"head":"speaker verification models","tail":"train a controllable voice conversion model"},{"head":"techniques to derive prosodic information","tail":"derive prosodic information"},{"head":"training strategy to iteratively improve the synthesis model","tail":"iteratively improve the synthesis model for voice conversion"},{"head":"create a challenging training objective using self-synthesized examples","tail":"generate voice-converted variations of an utterance"},{"head":"self-synthesized examples","tail":"improve the speaker similarity of generated speech"},{"head":"baseline voice conversion model","tail":"improve the speaker similarity of generated speech"},{"head":"naturalness","tail":"evaluate naturalness of synthesized audio"},{"head":"speaker similarity","tail":"evaluate speaker similarity of synthesized audio"},{"head":"intelligibility","tail":"evaluate intelligibility of synthesized audio"},{"head":"self-synthesized examples","tail":"perform controllable speech synthesis with pitch and pace modifications"}]},"background":"Previous efforts on voice conversion focus on factorizing speech into explicitly disentangled representations that separately encode speaker characteristics and linguistic content. However, disentangling speech representations to capture such attributes using task-specific loss terms can lead to information loss by discarding finer nuances such as accent and emotion of the original signal.","target":"We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples. In this work, instead of explicitly disentangling attributes with loss terms, we present a framework to train a controllable voice conversion model on entangled speech representations derived from self-supervised learning (SSL) and speaker verification models. First, we develop techniques to derive prosodic information from the audio signal and SSL representations to train predictive submodules in the synthesis model. Next, we propose a training strategy to iteratively improve the synthesis model for voice conversion, by creating a challenging training objective using self-synthesized examples. In this training approach, the current state of the synthesis model is used to generate voice-converted variations of an utterance, which serve as inputs for the reconstruction task, ensuring a continuous and purposeful refinement of the model. We demonstrate that incorporating such self-synthesized examples during training improves the speaker similarity of generated speech as compared to a baseline voice conversion model trained solely on heuristically perturbed inputs. Our framework is trained without any text and is applicable to a range of tasks such as zero-shot voice conversion, voice conversion across different languages, and controllable speech synthesis with pitch and pace modifications. We conduct extensive comparisons against prior work and find that SelfVC achieves state-of-the-art results in zero-shot voice conversion on metrics evaluating naturalness, speaker similarity, and intelligibility of synthesized audio."},{"graph":{"title":"Decodable and Sample Invariant Continuous Object Encoder","abstract":"We propose Hyper-Dimensional Function Encoding (HDFE). Given samples of a continuous object (e.g. a function), HDFE produces an explicit vector representation of the given object, invariant to the sample distribution and density. Sample distribution and density invariance enables HDFE to consistently encode continuous objects regardless of their sampling, and therefore allows neural networks to receive continuous objects as inputs for machine learning tasks, such as classification and regression. Besides, HDFE does not require any training and is proved to map the object into an organized embedding space, which facilitates the training of the downstream tasks.  In addition, the encoding is decodable, which enables neural networks to regress continuous objects \nby regressing their encodings.  Therefore, HDFE serves as an interface for processing continuous objects. \n\nWe apply HDFE to function-to-function mapping, where vanilla HDFE achieves competitive performance with the state-of-the-art algorithm. We apply HDFE to point cloud surface normal estimation, where a simple replacement from PointNet to HDFE leads to  12\\% and 15\\% error reductions in two benchmarks. \nIn addition, by integrating HDFE into the PointNet-based SOTA network, we improve the SOTA baseline by 2.5\\% and 1.7\\% on the same benchmarks.","entities":[{"label":"Decodable and Sample Invariant Continuous Object Encoder","type":"title","detail":null,"excerpts":null},{"label":"representation learning for computer vision, audio, language, and other modalities","type":"primary_area","detail":null,"excerpts":null},{"label":"Hyper-Dimensional Function Encoding","type":"keyword","detail":null,"excerpts":null},{"label":"HDFE","type":"keyword","detail":null,"excerpts":null},{"label":"continuous object encoder","type":"keyword","detail":null,"excerpts":null},{"label":"sample invariance","type":"keyword","detail":null,"excerpts":null},{"label":"decodability","type":"keyword","detail":null,"excerpts":null},{"label":"Lipschitz continuity","type":"keyword","detail":null,"excerpts":null},{"label":"point cloud surface normal estimation","type":"keyword","detail":null,"excerpts":null},{"label":"function-to-function mapping","type":"keyword","detail":null,"excerpts":null},{"label":"We propose Hyper-Dimensional Function Encoding (HDFE) that produces an explicit vector representation of a continuous object, invariant to the sample distribution and density, enabling neural networks to receive continuous objects as inputs for machine learning tasks.","type":"tldr","detail":null,"excerpts":null},{"label":"HDFE encodes Lipschitz functions while upholding all four properties.","type":"claim","detail":"HDFE is presented as an encoder for continuous objects without any training that exhibits sample invariance, decodability, and distance-preservation, and is claimed to be the only algorithm that can encode Lipschitz functions while upholding all the four properties.","excerpts":[{"section":"Introduction","text":"-   We present HDFE, an encoder for continuous objects without any training that exhibits sample invariance, decodability, and distance-preservation. [To the best of our knowledge, HDFE is the only algorithm that can encode Lipschitz functions while upholding all the four properties.]{style=\"color: black\"}"}]},{"label":"HDFE achieves competitive performance as the specialized state-of-the-art (SOTA) in function-to-function mapping tasks and improves performance in point cloud normal estimation.","type":"claim","detail":"HDFE is evaluated on mesh-grid data and sparse data, achieving competitive performance as the specialized state-of-the-art (SOTA) in function-to-function mapping tasks and leading to average error decreases of 12% and 15% in two benchmarks when replacing PointNet, and average error decreases of 2.5% and 1.7% when incorporating HDFE into the PointNet-based SOTA architecture in the sparse data domain.","excerpts":[{"section":"Introduction","text":"-   [We evaluate HDFE on mesh-grid data and sparse data. In the mesh-grid data domain, HDFE achieves competitive performance as the specialized state-of-the-art (SOTA) in function-to-function mapping tasks. In the sparse data domain, replacing PointNet with HDFE leads to average error decreases of 12% and 15% in two benchmarks, and incorporating HDFE into the PointNet-based SOTA architecture leads to average error decreases of 2.5% and 1.7%.]{style=\"color: black\"}"}]},{"label":"HDFE-based architecture attains significantly reduced errors compared to PointNet-based counterparts, especially in the presence of density perturbations.","type":"claim","detail":"The study demonstrates that the HDFE-based architecture attains significantly reduced errors compared to PointNet-based counterparts, especially in the presence of density perturbations, revealing that HDFE presents a promising complement to PointNet and its variations for processing point cloud data.","excerpts":[{"section":"Conclusion","text":"[We introduced Hyper-Dimensional Function Encoding (HDFE), which constructs vector representations for continuous objects. The representation, without any training, is sample invariant, decodable, and isometric. These properties position HDFE as an interface for the processing of continuous objects by neural networks. Our study demonstrates that the HDFE-based architecture attains significantly reduced errors compared to PointNet-based counterparts, especially in the presence of density perturbations. This reveals that HDFE presents a promising complement to PointNet and its variations for processing point cloud data. Adapting HDFE (e.g. imposing rotational invariance to HDFE) to tasks like point cloud classification and segmentation offers promising avenues for exploration.]{style=\"color: black\"}"}]},{"label":"Hyper-Dimensional Function Encoding (HDFE)","type":"method","detail":"HDFE is a novel function encoding method that satisfies key properties of VFA while relaxing the strict assumption on function space to Lipschitz continuity. It involves mapping samples to a high-dimensional space and computing weighted averages of the samples in that space, using an iterative refinement process to decide the weight of each sample to maintain sample invariance.","excerpts":[{"section":"Abstract","text":"We propose Hyper-Dimensional Function Encoding (HDFE). Given samples of a continuous object (e.g. a function), HDFE produces an explicit vector representation of the given object, invariant to the sample distribution and density."},{"section":"Introduction","text":"We propose hyper-dimensional function encoding (HDFE), which does not assume any explicit form of input functions but only requires Lipschitz continuity (Appendix [10](#sec:app6_input_types){reference-type=\"ref\" reference=\"sec:app6_input_types\"} illustrates some suitable input types). Consequently, HDFE can encode *a much larger class of functions*, while holding all four properties without any training."},{"section":"Introduction","text":"A challenge in HDFE design is maintaining sample invariance, for which we propose a novel iterative refinement process to decide the weight of each sample."}]},{"label":"Function-to-function mapping using HDFE","type":"experiment","detail":"Vanilla HDFE is applied to function-to-function mapping, achieving competitive performance with the state-of-the-art algorithm.","excerpts":[{"section":"Abstract","text":"We apply HDFE to function-to-function mapping, where vanilla HDFE achieves competitive performance with the state-of-the-art algorithm."}]},{"label":"Point cloud surface normal estimation using HDFE","type":"experiment","detail":"HDFE is applied to point cloud surface normal estimation, where a simple replacement from PointNet to HDFE leads to 12% and 15% error reductions in two benchmarks. Integrating HDFE into the PointNet-based SOTA network improves the SOTA baseline by 2.5% and 1.7% on the same benchmarks.","excerpts":[{"section":"Abstract","text":"We apply HDFE to point cloud surface normal estimation, where a simple replacement from PointNet to HDFE leads to  12\\% and 15\\% error reductions in two benchmarks. \nIn addition, by integrating HDFE into the PointNet-based SOTA network, we improve the SOTA baseline by 2.5\\% and 1.7\\% on the same benchmarks."}]},{"label":"PDE Solver","type":"experiment","detail":"HDFE is used to solve partial differential equations (PDE) by encoding the PDE and its solution into vector embeddings and training a multi-layer perceptron to map the embedding of the PDE to the embedding of its solution. It is evaluated on 1d Burgers' Equation and 2d Darcy Flow, achieving competitive performance to FNO and overcoming limitations of FNO by providing an explicit function representation and working for sparsely sampled functions.","excerpts":[{"section":"Experiment","text":"Sec. [3.1](#sec:PDE_solver){reference-type=\"ref\" reference=\"sec:PDE_solver\"} showcases how HDFE can be leveraged for solving partial differential equations (PDE). This exemplifies how HDFE can enhance neural networks to receive function inputs and produce function outputs."},{"section":"Experiment","text":"To solve PDEs using neural networks, we first encode the PDE and its solution into their vector embeddings using HDFE. Then, we train a multi-layer perceptron to map the embedding of the PDE to the embedding of its solution."},{"section":"Experiment","text":"In addition to comparable performance, **HDFE overcomes two limitations of FNO**. First, HDFE provides an explicit function representation, resolving the restriction of FNO, which only models the mappings between functions without extracting attributes from them. Second, HDFE not only works for grid-sampled functions but also for sparsely sampled functions."}]}],"relationships":[{"source":"Decodable and Sample Invariant Continuous Object Encoder","target":"representation learning for computer vision, audio, language, and other modalities"},{"source":"Decodable and Sample Invariant Continuous Object Encoder","target":"Hyper-Dimensional Function Encoding"},{"source":"Decodable and Sample Invariant Continuous Object Encoder","target":"HDFE"},{"source":"Decodable and Sample Invariant Continuous Object Encoder","target":"continuous object encoder"},{"source":"Decodable and Sample Invariant Continuous Object Encoder","target":"sample invariance"},{"source":"Decodable and Sample Invariant Continuous Object Encoder","target":"decodability"},{"source":"Decodable and Sample Invariant Continuous Object Encoder","target":"Lipschitz continuity"},{"source":"Decodable and Sample Invariant Continuous Object Encoder","target":"point cloud surface normal estimation"},{"source":"Decodable and Sample Invariant Continuous Object Encoder","target":"function-to-function mapping"},{"source":"Decodable and Sample Invariant Continuous Object Encoder","target":"We propose Hyper-Dimensional Function Encoding (HDFE) that produces an explicit vector representation of a continuous object, invariant to the sample distribution and density, enabling neural networks to receive continuous objects as inputs for machine learning tasks."},{"source":"We propose Hyper-Dimensional Function Encoding (HDFE) that produces an explicit vector representation of a continuous object, invariant to the sample distribution and density, enabling neural networks to receive continuous objects as inputs for machine learning tasks.","target":"HDFE encodes Lipschitz functions while upholding all four properties."},{"source":"We propose Hyper-Dimensional Function Encoding (HDFE) that produces an explicit vector representation of a continuous object, invariant to the sample distribution and density, enabling neural networks to receive continuous objects as inputs for machine learning tasks.","target":"HDFE achieves competitive performance as the specialized state-of-the-art (SOTA) in function-to-function mapping tasks and improves performance in point cloud normal estimation."},{"source":"We propose Hyper-Dimensional Function Encoding (HDFE) that produces an explicit vector representation of a continuous object, invariant to the sample distribution and density, enabling neural networks to receive continuous objects as inputs for machine learning tasks.","target":"HDFE-based architecture attains significantly reduced errors compared to PointNet-based counterparts, especially in the presence of density perturbations."},{"source":"HDFE encodes Lipschitz functions while upholding all four properties.","target":"Hyper-Dimensional Function Encoding (HDFE)"},{"source":"HDFE achieves competitive performance as the specialized state-of-the-art (SOTA) in function-to-function mapping tasks and improves performance in point cloud normal estimation.","target":"Hyper-Dimensional Function Encoding (HDFE)"},{"source":"HDFE-based architecture attains significantly reduced errors compared to PointNet-based counterparts, especially in the presence of density perturbations.","target":"Hyper-Dimensional Function Encoding (HDFE)"},{"source":"Hyper-Dimensional Function Encoding (HDFE)","target":"Function-to-function mapping using HDFE"},{"source":"Hyper-Dimensional Function Encoding (HDFE)","target":"Point cloud surface normal estimation using HDFE"},{"source":"Hyper-Dimensional Function Encoding (HDFE)","target":"PDE Solver"}],"valid_status":"Valid","valid_status_all":["Valid"]},"related":[{"summary":"The Related Paper explores the integration of Kolmogorov-Arnold Networks (KANs) into PointNet, demonstrating competitive performance in 3D point cloud classification and segmentation tasks. This supports the Main Paper's claims by highlighting the effectiveness of alternative encoding methods, such as HDFE, in improving neural network performance on continuous objects. Both papers emphasize the importance of innovative architectures in enhancing the processing of point clouds, with the Main Paper showcasing significant error reductions when applying HDFE, further validating the potential of novel encoding techniques in machine learning.","paper_id":"5567d2aee99702be0507372b54f30a3d74f1a6c4","title":"PointNet with KAN versus PointNet with MLP for 3D Classification and Segmentation of Point Sets","abstract":"Kolmogorov-Arnold Networks (KANs) have recently gained attention as an alternative to traditional Multilayer Perceptrons (MLPs) in deep learning frameworks. KANs have been integrated into various deep learning architectures such as convolutional neural networks, graph neural networks, and transformers, with their performance evaluated. However, their effectiveness within point-cloud-based neural networks remains unexplored. To address this gap, we incorporate KANs into PointNet for the first time to evaluate their performance on 3D point cloud classification and segmentation tasks. Specifically, we introduce PointNet-KAN, built upon two key components. First, it employs KANs instead of traditional MLPs. Second, it retains the core principle of PointNet by using shared KAN layers and applying symmetric functions for global feature extraction, ensuring permutation invariance with respect to the input features. In traditional MLPs, the goal is to train the weights and biases with fixed activation functions; however, in KANs, the goal is to train the activation functions themselves. We use Jacobi polynomials to construct the KAN layers. We extensively and systematically evaluate PointNet-KAN across various polynomial degrees and special types such as the Lagrange, Chebyshev, and Gegenbauer polynomials. Our results show that PointNet-KAN achieves competitive performance compared to PointNet with MLPs on benchmark datasets for 3D object classification and segmentation, despite employing a shallower and simpler network architecture. We hope this work serves as a foundation and provides guidance for integrating KANs, as an alternative to MLPs, into more advanced point cloud processing architectures.","score":0.6716923117637634,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose Hyper-Dimensional Function Encoding (HDFE). Therefore, HDFE serves as an interface for processing continuous objects. We apply HDFE to function-to-function mapping, where vanilla HDFE achieves competitive performance with the state-of-the-art algorithm. We apply HDFE to point cloud surface normal estimation, where a simple replacement from PointNet to HDFE leads to 12% and 15% error reductions in two benchmarks. In addition, by integrating HDFE into the PointNet-based SOTA network, we improve the SOTA baseline by 2.5% and 1.7% on the same benchmarks."},{"summary":"The Related Paper presents a novel normal estimation method that combines geometric estimators with deep learning, addressing challenges in unstructured point clouds. This supports the Main Paper's claims by highlighting the importance of effective feature preservation and accuracy in normal estimation, which aligns with the Main Paper's application of HDFE in point cloud surface normal estimation. Both papers emphasize improvements in performance metrics, with the Main Paper achieving significant error reductions, thereby reinforcing the effectiveness of HDFE in enhancing neural network capabilities for continuous object processing.","paper_id":"ce071e27d14bcba1a837f41721218711a6239f4c","title":"Geometry and Learning Co-Supported Normal Estimation for Unstructured Point Cloud","abstract":"In this paper, we propose a normal estimation method for unstructured point cloud. We observe that geometric estimators commonly focus more on feature preservation but are hard to tune parameters and sensitive to noise, while learning-based approaches pursue an overall normal estimation accuracy but cannot well handle challenging regions such as surface edges. This paper presents a novel normal estimation method, under the co-support of geometric estimator and deep learning. To lowering the learning difficulty, we first propose to compute a suboptimal initial normal at each point by searching for a best fitting patch. Based on the computed normal field, we design a normal-based height map network (NH-Net) to fine-tune the suboptimal normals. Qualitative and quantitative evaluations demonstrate the clear improvements of our results over both traditional methods and learning-based methods, in terms of estimation accuracy and feature recovery.","score":0.665959894657135,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose Hyper-Dimensional Function Encoding (HDFE). Therefore, HDFE serves as an interface for processing continuous objects. We apply HDFE to function-to-function mapping, where vanilla HDFE achieves competitive performance with the state-of-the-art algorithm. We apply HDFE to point cloud surface normal estimation, where a simple replacement from PointNet to HDFE leads to 12% and 15% error reductions in two benchmarks. In addition, by integrating HDFE into the PointNet-based SOTA network, we improve the SOTA baseline by 2.5% and 1.7% on the same benchmarks."},{"summary":"The Related Paper, 'Rethinking Network Design and Local Geometry in Point Cloud', supports the Main Paper by highlighting the challenges in point cloud analysis and presenting a competitive alternative approach with the PointMLP framework. While the Main Paper introduces the Hyper-Dimensional Function Encoding (HDFE) for improved performance in point cloud tasks, the Related Paper emphasizes the effectiveness of a simpler architecture that achieves state-of-the-art results without complex local geometric extractors. Together, these papers underscore the potential for innovative methods in point cloud processing, with the Related Paper reinforcing the Main Paper's claims about performance improvements in this domain.","paper_id":"a7cc9851d78bd718e17f6fca05efa16710344952","title":"Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework","abstract":"Point cloud analysis is challenging due to irregularity and unordered data structure. To capture the 3D geometries, prior works mainly rely on exploring sophisticated local geometric extractors using convolution, graph, or attention mechanisms. These methods, however, incur unfavorable latency during inference, and the performance saturates over the past few years. In this paper, we present a novel perspective on this task. We notice that detailed local geometrical information probably is not the key to point cloud analysis -- we introduce a pure residual MLP network, called PointMLP, which integrates no sophisticated local geometrical extractors but still performs very competitively. Equipped with a proposed lightweight geometric affine module, PointMLP delivers the new state-of-the-art on multiple datasets. On the real-world ScanObjectNN dataset, our method even surpasses the prior best method by 3.3% accuracy. We emphasize that PointMLP achieves this strong performance without any sophisticated operations, hence leading to a superior inference speed. Compared to most recent CurveNet, PointMLP trains 2x faster, tests 7x faster, and is more accurate on ModelNet40 benchmark. We hope our PointMLP may help the community towards a better understanding of point cloud analysis. The code is available at https://github.com/ma-xu/pointMLP-pytorch.","score":0.6478780508041382,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose Hyper-Dimensional Function Encoding (HDFE). Therefore, HDFE serves as an interface for processing continuous objects. We apply HDFE to function-to-function mapping, where vanilla HDFE achieves competitive performance with the state-of-the-art algorithm. We apply HDFE to point cloud surface normal estimation, where a simple replacement from PointNet to HDFE leads to 12% and 15% error reductions in two benchmarks. In addition, by integrating HDFE into the PointNet-based SOTA network, we improve the SOTA baseline by 2.5% and 1.7% on the same benchmarks."},{"summary":"The Related Paper, SSRNet, supports the Main Paper's claims by addressing the challenges of scalability and detail preservation in surface reconstruction from point clouds, which aligns with the Main Paper's focus on encoding continuous objects for machine learning tasks. Both papers emphasize the importance of effective representation and processing of large-scale data, with SSRNet showcasing superior generalization and efficiency, which complements the Main Paper's HDFE method that enhances performance in point cloud applications. Together, they highlight advancements in handling complex data structures in machine learning.","paper_id":"e17641988b2c664398e203506c18dc04f0a14406","title":"SSRNet: Scalable 3D Surface Reconstruction Network","abstract":"Existing learning-based surface reconstruction methods from point clouds are still facing challenges in terms of scalability and preservation of details on large-scale point clouds. In this paper, we propose the SSRNet, a novel scalable learning-based method for surface reconstruction. The proposed SSRNet constructs local geometry-aware features for octree vertices and designs a scalable reconstruction pipeline, which not only greatly enhances the predication accuracy of the relative position between the vertices and the implicit surface facilitating the surface reconstruction quality, but also allows dividing the point cloud and octree vertices and processing different parts in parallel for superior scalability on large-scale point clouds with millions of points. Moreover, SSRNet demonstrates outstanding generalization capability and only needs several surface data for training, much less than other learning-based reconstruction methods, which can effectively avoid overfitting. The trained model of SSRNet on one dataset can be directly used on other datasets with superior performance. Finally, the time consumption with SSRNet on a large-scale point cloud is acceptable and competitive. To our knowledge, the proposed SSRNet is the first to really bring a convincing solution to the scalability issue of the learning-based surface reconstruction methods, and is an important step to make learning-based methods competitive with respect to geometry processing methods on real-world and challenging data. Experiments show that our method achieves a breakthrough in scalability and quality compared with state-of-the-art learning-based methods.","score":0.6396245956420898,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose Hyper-Dimensional Function Encoding (HDFE). Therefore, HDFE serves as an interface for processing continuous objects. We apply HDFE to function-to-function mapping, where vanilla HDFE achieves competitive performance with the state-of-the-art algorithm. We apply HDFE to point cloud surface normal estimation, where a simple replacement from PointNet to HDFE leads to 12% and 15% error reductions in two benchmarks. In addition, by integrating HDFE into the PointNet-based SOTA network, we improve the SOTA baseline by 2.5% and 1.7% on the same benchmarks."},{"summary":"The Related Paper, RISurConv, supports the Main Paper by addressing the challenge of rotation invariance in 3D point cloud analysis, which complements the Main Paper's focus on sample distribution and density invariance through HDFE. Both papers emphasize the importance of encoding continuous objects effectively for machine learning tasks, with RISurConv achieving high accuracy in classification and segmentation, thereby reinforcing the potential of HDFE in enhancing neural network performance. Together, they highlight the significance of developing robust encoding methods that maintain performance across various transformations.","paper_id":"48fcd6cde48590d2efd87c0ef0e839bcd19a921c","title":"RISurConv: Rotation Invariant Surface Attention-Augmented Convolutions for 3D Point Cloud Classification and Segmentation","abstract":"Despite the progress on 3D point cloud deep learning, most prior works focus on learning features that are invariant to translation and point permutation, and very limited efforts have been devoted for rotation invariant property. Several recent studies achieve rotation invariance at the cost of lower accuracies. In this work, we close this gap by proposing a novel yet effective rotation invariant architecture for 3D point cloud classification and segmentation. Instead of traditional pointwise operations, we construct local triangle surfaces to capture more detailed surface structure, based on which we can extract highly expressive rotation invariant surface properties which are then integrated into an attention-augmented convolution operator named RISurConv to generate refined attention features via self-attention layers. Based on RISurConv we build an effective neural network for 3D point cloud analysis that is invariant to arbitrary rotations while maintaining high accuracy. We verify the performance on various benchmarks with supreme results obtained surpassing the previous state-of-the-art by a large margin. We achieve an overall accuracy of 96.0% (+4.7%) on ModelNet40, 93.1% (+12.8%) on ScanObjectNN, and class accuracies of 91.5% (+3.6%), 82.7% (+5.1%), and 78.5% (+9.2%) on the three categories of the FG3D dataset for the fine-grained classification task. Additionally, we achieve 81.5% (+1.0%) mIoU on ShapeNet for the segmentation task. Code is available here: https://github.com/cszyzhang/RISurConv","score":0.6395998001098633,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"We propose Hyper-Dimensional Function Encoding (HDFE). Therefore, HDFE serves as an interface for processing continuous objects. We apply HDFE to function-to-function mapping, where vanilla HDFE achieves competitive performance with the state-of-the-art algorithm. We apply HDFE to point cloud surface normal estimation, where a simple replacement from PointNet to HDFE leads to 12% and 15% error reductions in two benchmarks. In addition, by integrating HDFE into the PointNet-based SOTA network, we improve the SOTA baseline by 2.5% and 1.7% on the same benchmarks."},{"summary":"The Related Paper, 'Copula Density Neural Estimation', contrasts with the Main Paper by focusing on probability density estimation rather than encoding continuous objects. While the Main Paper emphasizes the invariance of its encoding method (HDFE) to sample distribution and density, the Related Paper highlights the challenges posed by the big data era in analyzing complex dependencies in data. Additionally, the Related Paper employs a copula-based approach to model joint dependence structures, which differs fundamentally from the Main Paper's objective of providing a decodable and sample-invariant representation for machine learning tasks.","paper_id":"c85035395c6ad96f01579cdff6279147b7e7ceb3","title":"Copula Density Neural Estimation","abstract":"Probability density estimation from observed data constitutes a central task in statistics. Recent advancements in machine learning offer new tools but also pose new challenges. The big data era demands analysis of long-range spatial and long-term temporal dependencies in large collections of raw data, rendering neural networks an attractive solution for density estimation. In this paper, we exploit the concept of copula to explicitly build an estimate of the probability density function associated to any observed data. In particular, we separate univariate marginal distributions from the joint dependence structure in the data, the copula itself, and we model the latter with a neural network-based method referred to as copula density neural estimation (CODINE). Results show that the novel learning approach is capable of modeling complex distributions and it can be applied for mutual information estimation and data generation.","score":0.6077769994735718,"polarity":"negative","source":"semantic","contexts":null,"background":"Given samples of a continuous object (e.g. a function), HDFE produces an explicit vector representation of the given object, invariant to the sample distribution and density. Sample distribution and density invariance enables HDFE to consistently encode continuous objects regardless of their sampling, and therefore allows neural networks to receive continuous objects as inputs for machine learning tasks, such as classification and regression. Besides, HDFE does not require any training and is proved to map the object into an organized embedding space, which facilitates the training of the downstream tasks. In addition, the encoding is decodable, which enables neural networks to regress continuous objects by regressing their encodings.","target":null},{"summary":"The Related Paper contrasts the Main Paper by focusing on the enhancement of 3D implicit shape representations through periodic activation functions, rather than the sample invariant encoding proposed by HDFE. While the Main Paper emphasizes the advantages of HDFE in providing a decodable and sample distribution invariant representation for continuous objects, the Related Paper critiques the reliance on conventional discrete representations and highlights the importance of network architecture in improving shape quality. This suggests that the approaches to continuous object representation differ significantly, with the Related Paper advocating for a more nuanced exploration of neural network design.","paper_id":"c31689332ecf7941675ec43619396892300be784","title":"Enhancing 3D implicit shape representation by leveraging periodic activation functions","abstract":"Conventional discrete representations of 3D objects have been replaced by representations that are implicitly described and continuously differentiable. With the increase in popularity of deep neural networks, parameterization of these continuous functions has emerged as a powerful paradigm. Various machine learning problems like inferring information from 3D images, videos and scene reconstruction require continuous parameterization as they yield memory efficiency, allowing the model to produce finer details. In this paper, improvement of implicit shape representation has been proposed by investigating the neural architecture of periodic activation functions-based networks. To demonstrate the effect of network size and depth on shape quality and detail, we conduct both qualitative and quantitative experiments.","score":0.5988885164260864,"polarity":"negative","source":"semantic","contexts":null,"background":"Given samples of a continuous object (e.g. a function), HDFE produces an explicit vector representation of the given object, invariant to the sample distribution and density. Sample distribution and density invariance enables HDFE to consistently encode continuous objects regardless of their sampling, and therefore allows neural networks to receive continuous objects as inputs for machine learning tasks, such as classification and regression. Besides, HDFE does not require any training and is proved to map the object into an organized embedding space, which facilitates the training of the downstream tasks. In addition, the encoding is decodable, which enables neural networks to regress continuous objects by regressing their encodings.","target":null},{"summary":"The Related Paper contrasts the Main Paper by emphasizing the challenges of achieving coherent latent spaces in neural networks due to factors like random weight initialization and training hyperparameters, which can hinder reuse. While the Main Paper claims to provide a sample distribution invariant encoding method (HDFE) that does not require training, the Related Paper suggests that even with fixed data and modeling choices, latent spaces can still be incoherent. Furthermore, the Related Paper introduces a method for enforcing invariances through relative representations, highlighting a different approach to achieving latent space communication without additional training, which contrasts with the Main Paper's focus on a specific encoding technique.","paper_id":"f56d363635bc378a196bae6d886ddd2d2899a220","title":"Relative representations enable zero-shot latent space communication","abstract":"Neural networks embed the geometric structure of a data manifold lying in a high-dimensional space into latent representations. Ideally, the distribution of the data points in the latent space should depend only on the task, the data, the loss, and other architecture-specific constraints. However, factors such as the random weights initialization, training hyperparameters, or other sources of randomness in the training phase may induce incoherent latent spaces that hinder any form of reuse. Nevertheless, we empirically observe that, under the same data and modeling choices, the angles between the encodings within distinct latent spaces do not change. In this work, we propose the latent similarity between each sample and a fixed set of anchors as an alternative data representation, demonstrating that it can enforce the desired invariances without any additional training. We show how neural architectures can leverage these relative representations to guarantee, in practice, invariance to latent isometries and rescalings, effectively enabling latent space communication: from zero-shot model stitching to latent space comparison between diverse settings. We extensively validate the generalization capability of our approach on different datasets, spanning various modalities (images, text, graphs), tasks (e.g., classification, reconstruction) and architectures (e.g., CNNs, GCNs, transformers).","score":0.5966615676879883,"polarity":"negative","source":"semantic","contexts":null,"background":"Given samples of a continuous object (e.g. a function), HDFE produces an explicit vector representation of the given object, invariant to the sample distribution and density. Sample distribution and density invariance enables HDFE to consistently encode continuous objects regardless of their sampling, and therefore allows neural networks to receive continuous objects as inputs for machine learning tasks, such as classification and regression. Besides, HDFE does not require any training and is proved to map the object into an organized embedding space, which facilitates the training of the downstream tasks. In addition, the encoding is decodable, which enables neural networks to regress continuous objects by regressing their encodings.","target":null},{"summary":"The Related Paper contrasts the Main Paper by focusing on gated auto-encoders (GAEs) as a representation learning method, emphasizing their theoretical underpinnings and applications in classification, which differ from the Main Paper's focus on Hyper-Dimensional Function Encoding (HDFE) for continuous object representation. While the Main Paper claims sample distribution invariance and decodability of encodings for continuous objects, the Related Paper highlights the less explored dynamics and scoring of GAEs, suggesting that traditional auto-encoders may not achieve the same level of invariance or direct applicability to continuous object encoding as proposed by HDFE.","paper_id":"d88da6e013c49c70312fd73d8654fd5dbce097c7","title":"Analyzing the Dynamics of Gated Auto-encoders","abstract":"Auto-encoders are perhaps the best-known non-probabilistic methods for representation learning. They are conceptually simple and easy to train. Recent theoretical work has shed light on their ability to capture manifold structure, and drawn connections to density modeling. This has motivated researchers to seek ways of auto-encoder scoring, which has furthered their use in classification. Gated autoencoders (GAEs) are an interesting and flexible extension of auto-encoders which can learn transformations among different images or pixel covariances within images. However, they have been much less studied, theoretically or empirically. In this work, we apply dynamical systems view to GAEs, deriving a means of GAE scoring, and drawing connections to RBMs and score matching. Experimenting on a set of deep learning benchmarks, we also demonstrate their effectiveness for classification.","score":0.5961381793022156,"polarity":"negative","source":"semantic","contexts":null,"background":"Given samples of a continuous object (e.g. a function), HDFE produces an explicit vector representation of the given object, invariant to the sample distribution and density. Sample distribution and density invariance enables HDFE to consistently encode continuous objects regardless of their sampling, and therefore allows neural networks to receive continuous objects as inputs for machine learning tasks, such as classification and regression. Besides, HDFE does not require any training and is proved to map the object into an organized embedding space, which facilitates the training of the downstream tasks. In addition, the encoding is decodable, which enables neural networks to regress continuous objects by regressing their encodings.","target":null},{"summary":"The Related Paper contrasts with the Main Paper by emphasizing the importance of learning representations that capture both individual sample characteristics and their relationships within a dataset, using graph convolution methods. While the Main Paper focuses on a sample-invariant encoding approach (HDFE) that does not require training and aims to process continuous objects, the Related Paper highlights the limitations of such methods in capturing relational information, suggesting that effective representation learning necessitates a more interconnected approach. This difference underscores a potential gap in the Main Paper's claims regarding the sufficiency of HDFE for complex tasks.","paper_id":"518b2676f9a5aed61f50da55783996da1de7277e","title":"Spectral Graph Theory and Deep Learning on Graphs","abstract":"A significant challenge in machine learning problems is learning meaningful representations that encode all the information that is relevant to a given task. Neural networks focus on learning parameters based on the ability to successfully represent individual samples of a dataset. Our goal is to learn representations that combine a sample’s individual characteristics and its relationships with other samples by utilizing the concept of the graph convolution. We employ methods and tools from the emerging field of deep learning on graphs to achieve that. Our models implement approximations to the graph spectral definition of the graph convolution, on graphs defined over batches of the dataset. We report better performance than regular convolutional networks on image classification tasks.","score":0.5934925675392151,"polarity":"negative","source":"semantic","contexts":null,"background":"Given samples of a continuous object (e.g. a function), HDFE produces an explicit vector representation of the given object, invariant to the sample distribution and density. Sample distribution and density invariance enables HDFE to consistently encode continuous objects regardless of their sampling, and therefore allows neural networks to receive continuous objects as inputs for machine learning tasks, such as classification and regression. Besides, HDFE does not require any training and is proved to map the object into an organized embedding space, which facilitates the training of the downstream tasks. In addition, the encoding is decodable, which enables neural networks to regress continuous objects by regressing their encodings.","target":null},{"summary":"The Related Paper supports the Main Paper by highlighting the advantages of using advanced neural network architectures, such as sinusoidal representation networks (Sirens), which can effectively model complex signals and their derivatives. This aligns with the Main Paper's focus on Hyper-Dimensional Function Encoding (HDFE) for continuous object representation, emphasizing the importance of encoding techniques that maintain sample invariance. Both papers advocate for innovative approaches to enhance the representation and processing of continuous objects, suggesting that HDFE could benefit from the insights gained from the use of periodic activation functions in Sirens.","paper_id":"43b1e34451f783fed053c1d539d7560dc4ec16a9","title":"Implicit Neural Representations with Periodic Activation Functions","abstract":"Implicitly defined, continuous, differentiable signal representations parameterized by neural networks have emerged as a powerful paradigm, offering many possible benefits over conventional representations. However, current network architectures for such implicit neural representations are incapable of modeling signals with fine detail, and fail to represent a signal's spatial and temporal derivatives, despite the fact that these are essential to many physical signals defined implicitly as the solution to partial differential equations. We propose to leverage periodic activation functions for implicit neural representations and demonstrate that these networks, dubbed sinusoidal representation networks or Sirens, are ideally suited for representing complex natural signals and their derivatives. We analyze Siren activation statistics to propose a principled initialization scheme and demonstrate the representation of images, wavefields, video, sound, and their derivatives. Further, we show how Sirens can be leveraged to solve challenging boundary value problems, such as particular Eikonal equations (yielding signed distance functions), the Poisson equation, and the Helmholtz and wave equations. Lastly, we combine Sirens with hypernetworks to learn priors over the space of Siren functions.","score":0.35312163829803467,"polarity":"positive","source":"citations","contexts":[{"sentence":"FT is also incorporated into deep learning architectures \\citep{fan2019bcr, sitzmann2020implicit}.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper on event-based vision supports the Main Paper by highlighting the need for novel methods to process unconventional data outputs, such as those from event cameras. This aligns with the Main Paper's focus on Hyper-Dimensional Function Encoding (HDFE) as a method for encoding continuous objects in a sample-invariant manner. Both papers emphasize the importance of efficient data representation for advanced machine learning tasks, suggesting that HDFE could be beneficial in processing the high temporal resolution and dynamic range data from event cameras, thereby enhancing applications in robotics and computer vision.","paper_id":"dd971c07879e1ce12b06991319528c06280eeb9b","title":"Event-Based Vision: A Survey","abstract":"Event cameras are bio-inspired sensors that differ from conventional frame cameras: Instead of capturing images at a fixed rate, they asynchronously measure per-pixel brightness changes, and output a stream of events that encode the time, location and sign of the brightness changes. Event cameras offer attractive properties compared to traditional cameras: high temporal resolution (in the order of $\\mu$μs), very high dynamic range (140 dB versus 60 dB), low power consumption, and high pixel bandwidth (on the order of kHz) resulting in reduced motion blur. Hence, event cameras have a large potential for robotics and computer vision in challenging scenarios for traditional cameras, such as low-latency, high speed, and high dynamic range. However, novel methods are required to process the unconventional output of these sensors in order to unlock their potential. This paper provides a comprehensive overview of the emerging field of event-based vision, with a focus on the applications and the algorithms developed to unlock the outstanding properties of event cameras. We present event cameras from their working principle, the actual sensors that are available and the tasks that they have been used for, from low-level vision (feature detection and tracking, optic flow, etc.) to high-level vision (reconstruction, segmentation, recognition). We also discuss the techniques developed to process events, including learning-based techniques, as well as specialized processors for these novel sensors, such as spiking neural networks. Additionally, we highlight the challenges that remain to be tackled and the opportunities that lie ahead in the search for a more efficient, bio-inspired way for machines to perceive and interact with the world.","score":0.33826765418052673,"polarity":"positive","source":"citations","contexts":[{"sentence":"Examples include point clouds \\citep{guo2020deep}, event-based vision data \\citep{gallego2020event}, and sparse meteorological data \\citep{lu2021impacts}.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper, PCPNet, supports the Main Paper's claims by demonstrating the effectiveness of local shape property estimation in point clouds, which aligns with the Main Paper's focus on improving point cloud surface normal estimation using HDFE. Both papers emphasize the importance of handling noise and multi-scale features in point cloud data, with PCPNet providing a patch-based learning method that complements HDFE's sample distribution invariance. Additionally, the success of HDFE in reducing error rates in point cloud tasks further validates the approaches proposed in the Related Paper.","paper_id":"55de5d37a78a560f99bdc7ba8ced5393b700ee96","title":"PCPNet Learning Local Shape Properties from Raw Point Clouds","abstract":"In this paper, we propose PCPNET, a deep‐learning based approach for estimating local 3D shape properties in point clouds. In contrast to the majority of prior techniques that concentrate on global or mid‐level attributes, e.g., for shape classification or semantic labeling, we suggest a patch‐based learning method, in which a series of local patches at multiple scales around each point is encoded in a structured manner. Our approach is especially well‐adapted for estimating local shape properties such as normals (both unoriented and oriented) and curvature from raw point clouds in the presence of strong noise and multi‐scale features. Our main contributions include both a novel multi‐scale variant of the recently proposed PointNet architecture with emphasis on local shape information, and a series of novel applications in which we demonstrate how learning from training data arising from well‐structured triangle meshes, and applying the trained model to noisy point clouds can produce superior results compared to specialized state‐of‐the‐art techniques. Finally, we demonstrate the utility of our approach in the context of shape reconstruction, by showing how it can be used to extract normal orientation information from point clouds.","score":0.31769442558288574,"polarity":"positive","source":"citations","contexts":[{"sentence":"In the first baseline, we compare the vanilla HDFE with the PCPNet \\citep{guerrero2018pcpnet}, which is a vanilla PointNet \\citep{qi2017pointnet} architecture.","polarity":"positive"},{"sentence":"~ We use the root mean squared angle error (RMSE) as the metrics, evaluated on the PCPNet \\citep{guerrero2018pcpnet} and FamousShape \\citep{li2023shs} datasets.","polarity":"positive"},{"sentence":"}{% {l|ccccccc|ccccccc} & {c|}{ { MATH_PLACEHOLDER } means improvement)}} & {c}{ { MATH_PLACEHOLDER } means improvement)}} \\\\ & {c|}{Noise} & {c|}{Density} & & {c|}{Noise} & {c|}{Density} & \\\\ & None & Low & Med & {c|}{High} & Stripe & {c|}{Gradient} & {*}","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper, 3DSSD, supports the Main Paper's claims by demonstrating the effectiveness of point-based methods in 3D object detection, which aligns with the Main Paper's focus on encoding continuous objects for machine learning tasks. Both papers emphasize the importance of efficiency and accuracy in processing point cloud data, with the Main Paper's HDFE providing a robust encoding method that enhances performance in tasks like surface normal estimation. The advancements in point-based techniques presented in the Related Paper further validate the Main Paper's approach to utilizing continuous object representations in neural networks.","paper_id":"c31c55db4d962527fd2e1366d173ba3f9a5fb0ed","title":"3DSSD: Point-Based 3D Single Stage Object Detector","abstract":"Prevalence of voxel-based 3D single-stage detectors contrast with underexplored point-based methods. In this paper, we present a lightweight point-based 3D single stage object detector 3DSSD to achieve decent balance of accuracy and efficiency. In this paradigm, all upsampling layers and the refinement stage, which are indispensable in all existing point-based methods, are abandoned. We instead propose a fusion sampling strategy in downsampling process to make detection on less representative points feasible. A delicate box prediction network, including a candidate generation layer and an anchor-free regression head with a 3D center-ness assignment strategy, is developed to meet the demand of high accuracy and speed. Our 3DSSD paradigm is an elegant single-stage anchor-free one. We evaluate it on widely used KITTI dataset and more challenging nuScenes dataset. Our method outperforms all state-of-the-art voxel-based single-stage methods by a large margin, and even yields comparable performance with two-stage point-based methods, with amazing inference speed of 25+ FPS, 2x faster than former state-of-the-art point-based methods.","score":0.31428390741348267,"polarity":"positive","source":"citations","contexts":[{"sentence":"PointNet and its variation \\citep{zaheer2017deep, qi2017pointnet++, joseph2019momen, yang2019modeling, zhao2019pointweb, duan2019structural, yan2020pointasnl} have been widely applied to sparse data processing, for example, for object classification \\citep","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper supports the Main Paper by demonstrating advanced techniques in processing point clouds, which aligns with the Main Paper's focus on encoding continuous objects. Both papers emphasize the importance of efficient representation and processing of variable input sizes, with the Related Paper introducing Gumbel Subset Sampling to enhance point cloud representation. This complements the Main Paper's Hyper-Dimensional Function Encoding (HDFE) by providing a method to select representative subsets of input data, thereby potentially improving the performance of HDFE in practical applications.","paper_id":"c256c0fca1f0f6de240743164ae729da3a29fc81","title":"Modeling Point Clouds With Self-Attention and Gumbel Subset Sampling","abstract":"Geometric deep learning is increasingly important thanks to the popularity of 3D sensors. Inspired by the recent advances in NLP domain, the self-attention transformer is introduced to consume the point clouds. We develop Point Attention Transformers (PATs), using a parameter-efficient Group Shuffle Attention (GSA) to replace the costly Multi-Head Attention. We demonstrate its ability to process size-varying inputs, and prove its permutation equivariance. Besides, prior work uses heuristics dependence on the input data (e.g., Furthest Point Sampling) to hierarchically select subsets of input points. Thereby, we for the first time propose an end-to-end learnable and task-agnostic sampling operation, named Gumbel Subset Sampling (GSS), to select a representative subset of input points. Equipped with Gumbel-Softmax, it produces a \"soft\" continuous subset in training phase, and a \"hard\" discrete subset in test phase. By selecting representative subsets in a hierarchical fashion, the networks learn a stronger representation of the input sets with lower computation cost. Experiments on classification and segmentation benchmarks show the effectiveness and efficiency of our methods. Furthermore, we propose a novel application, to process event camera stream as point clouds, and achieve a state-of-the-art performance on DVS128 Gesture Dataset.","score":0.29832690954208374,"polarity":"positive","source":"citations","contexts":[{"sentence":"PointNet and its variation \\citep{zaheer2017deep, qi2017pointnet++, joseph2019momen, yang2019modeling, zhao2019pointweb, duan2019structural, yan2020pointasnl} have been widely applied to sparse data processing, for example, for object classification \\citep","polarity":"positive"}],"background":null,"target":null}],"paper":{"title":"Decodable and Sample Invariant Continuous Object Encoder","abstract":"We propose Hyper-Dimensional Function Encoding (HDFE). Given samples of a continuous object (e.g. a function), HDFE produces an explicit vector representation of the given object, invariant to the sample distribution and density. Sample distribution and density invariance enables HDFE to consistently encode continuous objects regardless of their sampling, and therefore allows neural networks to receive continuous objects as inputs for machine learning tasks, such as classification and regression. Besides, HDFE does not require any training and is proved to map the object into an organized embedding space, which facilitates the training of the downstream tasks.  In addition, the encoding is decodable, which enables neural networks to regress continuous objects \nby regressing their encodings.  Therefore, HDFE serves as an interface for processing continuous objects. \n\nWe apply HDFE to function-to-function mapping, where vanilla HDFE achieves competitive performance with the state-of-the-art algorithm. We apply HDFE to point cloud surface normal estimation, where a simple replacement from PointNet to HDFE leads to  12\\% and 15\\% error reductions in two benchmarks. \nIn addition, by integrating HDFE into the PointNet-based SOTA network, we improve the SOTA baseline by 2.5\\% and 1.7\\% on the same benchmarks.","authors":["Dehao Yuan","Furong Huang","Cornelia Fermuller","Yiannis Aloimonos"],"sections":[{"heading":"Introduction","text":"# Introduction\n\nContinuous objects are objects that can be sampled with arbitrary distribution and density. Examples include point clouds [@guo2020deep], event-based vision data [@gallego2020event], and sparse meteorological data [@lu2021impacts]. A crucial characteristic of continuous objects, which poses a challenge for learning, is that their sample distribution and size varies between training and test sets. For example, point cloud data in the testing phase may be sparser or denser than that in the training phase. A framework that handles this inconsistency is essential for continuous object learning.\n\nWhen designing the framework, four properties are desirable: (1) *Sample distribution invariance*: the framework is not affected by the distribution from which the samples are collected. (2) *Sample size invariance*: the framework is not affected by the number of samples. (3) *Explicit representation*: the framework generates outputs with fixed dimensions, such as fixed-length vectors. (4) *Decodability*: the continuous object can be reconstructed at arbitrary resolution from the representation.\n\nSample invariance (properties 1 and 2) ensures that differently sampled instances of the same continuous objects are treated consistently, thereby eliminating the ambiguity caused by variations in sampling. An explicit representation (property 3) enables a neural network to receive continuous objects as inputs, by consuming the encodings of the objects. Decodability (property 4) enables a neural network to predict a continuous object, by first predicting the representation and then decoding it back to the continuous object. Fig. [1](#fig:teasor){reference-type=\"ref\" reference=\"fig:teasor\"} illustrates the properties and their motivations.\n\nHowever, existing methodologies, which we divide into three categories, are limited when incorporating the four properties. (1) *Discrete framework*. The methods discretize continuous objects and process them with neural networks. For example, @liu2019point uses a 3D-CNN to process voxelized point clouds, @kim2017probabilistic uses an RNN to predict particle trajectories. These methods are not sample invariant -- the spatial and temporal resolution must be consistent across the training and testing phases. (2) *Mesh-grid-based framework*. They operate on continuous objects defined on mesh grids and achieve discretization invariance (the framework is not affected by the resolution of the grids). Examples include the Fourier transform [@salih2012fourier] and the neural operator [@li2020fourier]. But they do not apply to sparse data like point clouds. (3) *Sparse framework*. They operate on sparse samples drawn from the continuous object. Kernel methods [@hofmann2008kernel] work for non-linear regression, classification, etc. But they do not provide an explicit representation of the function. PointNet [@qi2017pointnet] receives sparse point cloud input and produces an explicit representation, but the representation is not decodable (see Appendix [8](#sec:app_pointnet){reference-type=\"ref\" reference=\"sec:app_pointnet\"}). In addition, all the frameworks require extra training of the encoder, which is undesired in some scarce data scenarios.\n\n[Currently, only the vector function architecture (VFA) [@frady2021computing] can encode an explicit function into a vector through sparse samples, while preserving all four properties. However, VFA is limited by its strong assumption of the functional form. VFA requires the input function to conform to $f(x)=\\sum_k\\alpha_k\\cdot K(x,x_k)$, where $K:X\\times X\\rightarrow \\mathbb{R}$ is a kernel defined on $X$. If the input function does not conform to the form, VFA cannot apply or induces large errors. In practice, such requirement is rarely satisfied. For example, $f(x)$ cannot even approximate a constant function $g(x)=1$: to approximate the constant function, the kernel $K$ must be constant. But with the constant kernel, $f(x)$ cannot approximate other non-constant functions. Such limitation greatly hinders the application of VFA. Kindly refer to Appendix [9](#sec:app_VFA){reference-type=\"ref\" reference=\"sec:app_VFA\"} for failure cases and detailed discussions.]{style=\"color: black\"}\n\nWe propose hyper-dimensional function encoding (HDFE), which does not assume any explicit form of input functions but only requires Lipschitz continuity (Appendix [10](#sec:app6_input_types){reference-type=\"ref\" reference=\"sec:app6_input_types\"} illustrates some suitable input types). Consequently, HDFE can encode *a much larger class of functions*, while holding all four properties without any training. Thanks to the relaxation, HDFE can be applied to multiple real-world applications that VFA fails, which will be elaborated on in the experiment section. HDFE maps the samples to a high-dimensional space and computes weighted averages of the samples in that space to capture collective information of all the samples. A challenge in HDFE design is maintaining sample invariance, for which we propose a novel iterative refinement process to decide the weight of each sample. The contributions of our paper can be summarized as follows:\\\n\n-   We present HDFE, an encoder for continuous objects without any training that exhibits sample invariance, decodability, and distance-preservation. [To the best of our knowledge, HDFE is the only algorithm that can encode Lipschitz functions while upholding all the four properties.]{style=\"color: black\"}\n\n-   We provide extensive theoretical foundation for HDFE. We prove that HDFE is equipped with all the desirable properties. We also verify them with empirical experiments.\n\n-   [We evaluate HDFE on mesh-grid data and sparse data. In the mesh-grid data domain, HDFE achieves competitive performance as the specialized state-of-the-art (SOTA) in function-to-function mapping tasks. In the sparse data domain, replacing PointNet with HDFE leads to average error decreases of 12% and 15% in two benchmarks, and incorporating HDFE into the PointNet-based SOTA architecture leads to average error decreases of 2.5% and 1.7%.]{style=\"color: black\"}\n\n![**Left**: HDFE encodes continuous objects into fixed-length vectors without any training. The encoding is not affected by the distribution and size with which the object is sampled. The encoding can be decoded to reconstruct the continuous object. **Right**: Applications of HDFE. HDFE can be used to perform machine learning tasks (e.g. classification, regression) on continuous objects. HDFE also enables neural networks to regress continuous objects by predicting their encodings.](figs/teasor.drawio.pdf){#fig:teasor width=\"95%\"}"},{"heading":"Problem Definition and Methodology","text":"# Problem Definition and Methodology\n\nLet $\\mathit{F}$ be the family of $c$-Lipschitz continuous functions defined on a compact domain $X$ with a compact range $Y$. In other words, $\\forall f\\in\\mathit{F}$, $f:X\\rightarrow Y$ and $d_Y\\big(f(x_1), f(x_2)\\big) \\leq c\\cdot d_X\\big(x_1, x_2\\big)$, where $(X, d_X)$ and $(Y, d_Y)$ are metric spaces, and $c$ is the Lipschitz constant. Our goal is to find a representation algorithm that can encode a function $f\\in\\mathit{F}$ into a vector representation $\\mathbf{F}\\in\\mathbb{C}^N$. To construct it, we will feed samples of the function mapping $\\big\\{\\big(x_i,f(x_i)\\big)\\big\\}$ to the representation algorithm, which will generate the vector representation based on these samples.\n\nWe require the function representation to satisfy the following: (1) Sample distribution invariance: the function representation is \"not affected\\\" by the distribution from which the samples are collected. (2) Sample size invariance: the function representation is \"not affected\\\" by the number of samples. (3) Fixed-length representation: all functions are represented by fixed-length vectors. (4) Decodability: as new inputs query the function representation, it can reconstruct the function values.\n\nTo better formalize the heuristic expression of \"not affected\\\" in Properties 1 and 2, we introduce the definition of asymptotic sample invariance to formulate an exact mathematical expression:\n\n::: {#def:1 .definition}\n**Definition 1** (Asymptotic Sample Invariance). *Let $f:X\\rightarrow Y$ be the function to be encoded, $p:X\\rightarrow (0,1)$ be a probability density function (pdf) on $X$, $\\{x_i\\}_{i=1}^n \\sim p(X)$ be $n$ independent samples of $X$. Let $\\mathbf{F}_n$ be the representation computed from the samples $\\{x_i, f(x_i)\\}^n_{i=1}$, asymptotic sample invariance implies $\\mathbf{F}_n$ converges to a limit $\\mathbf{F}_\\infty$ independent of the pdf $p$. *\n:::\n\nIn this definition, sample size invariance is reflected because the distance between $\\mathbf{F}_m$ and $\\mathbf{F}_n$ can be arbitrarily small as $m,n$ become large. Sample distribution invariance is reflected because the limit $\\mathbf{F}_\\infty$ does not depend on the pdf $p$, as long as $p$ is supported on the whole input space $X$.\n\nWith the problem definition above, we present our hyper-dimensional function encoding (HDFE) approach. Sec. [\\[sec:explicit\\]](#sec:explicit){reference-type=\"ref\" reference=\"sec:explicit\"} introduces how HDFE encodes explicit functions. Sec. [\\[sec:implicit\\]](#sec:implicit){reference-type=\"ref\" reference=\"sec:implicit\"} generalizes HDFE to implicit function encoding. Sec. [\\[sec:vector_valued\\]](#sec:vector_valued){reference-type=\"ref\" reference=\"sec:vector_valued\"} realizes HDFE for vector-valued function encoding. Finally, Sec. [\\[sec:properties\\]](#sec:properties){reference-type=\"ref\" reference=\"sec:properties\"} establishes the theorems that HDFE is asymptotic sample invariant and distance-preserving. Throughout the section, we assume the functions are $c$-Lipschitz continuous. The assumption will also be explained in Section [\\[sec:properties\\]](#sec:properties){reference-type=\"ref\" reference=\"sec:properties\"}. Kindly refer to Appendix [7](#sec:app_notation){reference-type=\"ref\" reference=\"sec:app_notation\"} for the table of notations.\n\n## Explicit Function Encoding\n\n**Encoding**  HDFE is inspired by the methodology of hyper-dimensional computing (HDC) [@kleyko2023survey], where one encodes an indefinite number of data points into a fixed-length vector. The common practice is to first map the data points to a high-dimensional space and then average the data point representations in that space. The resulting superposed vector can represent the distribution of the data. Following the idea, we represent an explicit function as the superposition of its samples: $$\\mathbf{F}= \\sum_i w_i\\cdot E(x_i, y_i)\n    \\label{eqn:main}$$ where $E$ maps function samples to a high-dimensional space $\\mathbb{C}^N$. The question remains (a) how to design the mapping to make the vector decodable; (b) how to determine the weight of each sample $w_i$ so that the representation is sample invariant. We will answer question (a) first and leave question (b) to the iterative refinement section.\n\nRegarding the selection of $E(x,y)$, a counter-example is a linear mapping, where the average of the function samples in the high-dimensional space will degenerate to the average of the function samples, which does not represent the function. To avoid degeneration, the encodings of the samples should not interfere with each other if they are far from each other. Specifically, if $d_X(x_1, x_2)$ is larger than a threshold $\\epsilon_0$, their function values $f(x_1), f(x_2)$ may be significantly different. In this case, we want $E(x_1,y_1)$ to be orthogonal to $E(x_2, y_2)$ to avoid interference. On the other hand, if $d_X(x_1, x_2)$ is smaller than the threshold $\\epsilon_0$, by the Lipschitz continuity, the distance between their function values $d_Y(f(x_1), f(x_2))$ is bounded by $c\\epsilon_0$. In this case, we want $E(x_1, y_1)$ to be similar to $E(x_2, y_2)$. We call the tunable threshold $\\epsilon_0$ the *receptive field* of HDFE, which will be discussed in Sec. [\\[sec:properties\\]](#sec:properties){reference-type=\"ref\" reference=\"sec:properties\"}. Denoting the similarity between vectors as $\\langle \\cdot, \\cdot \\rangle$, the requirement can be formulated as: $$\\langle E(x, y), E(x', y')\\rangle\n    \\begin{cases}\n    \\approx 1 & d_X(x, x') < \\epsilon_0 \\\\\n    \\text{decays to 0 quickly} & d_X(x, x') > \\epsilon_0\n    \\end{cases}\n    \\label{eqn:requirement}$$ In addition to avoiding degeneration, we also require the encoding to be decodable. This can be achieved by factorizing $E(x,y)$ into two components: We first map $x_i$ and $y_i$ to the high-dimensional space $\\mathbb{C}^N$ through two different mappings $E_X$ and $E_Y$. To ensure equation [\\[eqn:requirement\\]](#eqn:requirement){reference-type=\"ref\" reference=\"eqn:requirement\"} is satisfied, we require $\\langle E_X(x), E_X(x')\\rangle\\approx 1$ when $d_X(x,x')<\\epsilon_0$ and that it decays to $0$ otherwise. The property of $E_Y$ will be mentioned later in the discussion of decoding. Finally, we compute the joint embedding of $x_i$ and $y_i$ through a *binding* operation $\\otimes$: $E(x_i, y_i)=E_X(x_i)\\otimes E_Y(y_i)$.\n\nWe will show that the representation is decodable if the binding operation satisfies these properties:\n\n1.  commutative: $x \\otimes y = y \\otimes x$\n\n2.  distributive: $x\\otimes(y+z)=x\\otimes y + x\\otimes z$\n\n3.  similarity preserving: $\\langle x\\otimes y, x\\otimes z\\rangle = \\langle  y, z\\rangle$.\n\n4.  invertible: there exists an associative, distributive, similarity preserving operator that undoes the binding, called *unbinding* $\\oslash$, satisfying $(x\\otimes y)\\oslash z=(x\\oslash z)\\otimes y$ and $(x\\otimes y)\\oslash x=y$.\n\nThe binding and unbinding operations can be analogous to multiplication and division, where the difference is that binding and unbinding operate on vectors and are similarity preserving.\n\n**Decoding**    With the properties of the two operations, the decoding of the function representation can be performed by a similarity search. Given the function representation $\\mathbf{F}\\in\\mathbb{C}^N$, and a query input $x_0\\in X$, the estimated function value $\\hat{y_0}$ is computed by: $$\\hat{y_0}=\\mathrm{argmax}_{y\\in Y} \\langle \\mathbf{F}\\oslash E_X(x_0), E_Y(y)\\rangle\n \\label{eqn:decoding}$$ The distributive property allows the unbinding operation to be performed sample-by-sample. The invertible property allows the unbinding operation to recover the encoding of the function values: $E_X(x_i) \\otimes E_Y\\big(f(x_i)\\big)\\oslash E_X(x_0)\\approx E_Y\\big(f(x_i)\\big)\\approx E_Y\\big(f(x_0)\\big)$ when $d_X(x_0, x_i)$ is small. The similarity preserving property ensures that $[E_X(x_i)\\oslash E_X(x_0)]\\otimes E_Y(f(x_i))$ produces a vector orthogonal to $E_Y(f(x_0))$ when the distance between two samples is large, resulting in a summation of noise. The following formula illustrates the idea and Appendix [11](#sec:app_decoding_proof){reference-type=\"ref\" reference=\"sec:app_decoding_proof\"} details the derivation. $$\\begin{aligned}\n    \\mathbf{F}\\oslash E_X(x_0)&=\\sum_i w_i\\cdot \\big[E_X(x_i) \\otimes E_Y\\big(f(x_i)\\big)\\oslash E_X(x_0)\\big] \\\\\n    &=\\underbrace{\\sum_{d(x_0, x_i)<\\epsilon_0} w_i\\cdot E_Y\\big(f(x_i)\\big)}_{\\approx E_Y(f(x_0))} \\quad + \\underbrace{\\sum_{d(x_0, x_i)>\\epsilon_0} w_i \\cdot [E_X(x_i)\\oslash E_X(x_0)]\\otimes E_Y(f(x_i))}_{\\text{noise, since orthogonal to $E_Y(f(x_0))$}}\n\\end{aligned}$$ After computing $\\mathbf{F}\\oslash E_X(x_0)$, we search for $y\\in Y$ such that the cosine similarity between $E_Y(y)$ and $\\mathbf{F}\\oslash E_X(x_0)$ is maximized. We desire that $\\frac{\\partial}{\\partial y}\\langle E_Y(y), E_Y(y')\\rangle > 0$ for all $y$ and $y'$ so that the optimization can be solved by gradient descent. See Appendix [12](#sec:app_decoding){reference-type=\"ref\" reference=\"sec:app_decoding\"} for detailed formulation.\n\nSince the decoding only involves measuring cosine similarity, in the last step, we normalize the function representation to achieve sample size invariance without inducing any loss: $$\\mathbf{F}= normalize\\Big(\\sum_i w_i\\cdot \\big[E_X\\big(x_i\\big)\\otimes E_Y\\big(f(x_i)\\big)\\big]\\Big)\n    \\label{eqn:final}$$\n\n:::::: wrapfigure\nR0.4\n\n::::: minipage\n:::: algorithm\n::: algorithmic\n$z_i \\gets E_X(x_i)\\otimes E_Y(f(x_i))$ for all $i$. $\\mathbf{F}=\\sum_i z_i$ $j = \\mathrm{argmin}_i \\langle \\mathbf{F}, z_i \\rangle$ $\\mathbf{F}\\gets \\mathbf{F}+ z_j$\n:::\n::::\n:::::\n::::::\n\n**Iterative refinement for sample distribution invariance**   In equation [\\[eqn:final\\]](#eqn:final){reference-type=\"ref\" reference=\"eqn:final\"}, we are left to determine the weight of each sample so that the representation is sample invariant. To address this, we propose an iterative refinement process to make the encoding invariant to the sample distribution. We initialize $w_i=1$ and compute the initial function vector. Then we compute the similarity between the function vector and the encoding of each sample. We then add the sample encoding with the lowest similarity to the function vector and repeat this process until the lowest similarity no longer increases. By doing so, the output will be *the center of the smallest ball containing all the sample encodings*. Such output is asymptotic sample invariant because the ball converges to the smallest ball containing $\\cup_{x\\in X} [E_X(x)\\otimes E_Y(f(x))]$ as the sample size goes large, where the limit ball only depends on the function. We left the formal proof to the Appendix [14.1](#sec:app_proof_sample_invariance){reference-type=\"ref\" reference=\"sec:app_proof_sample_invariance\"}. In Appendix [15.3](#sec:app_experiment_cost){reference-type=\"ref\" reference=\"sec:app_experiment_cost\"}, we introduce a practical implementation of the iterative refinement for saving computational cost. []{#sec:explicit label=\"sec:explicit\"}\n\n## Implicit Function Encoding\n\nGeneralizing HDFE to implicit functions is fairly straightforward. Without loss of generality, we assume an implicit function is represented as $f(x)=0$. Then it can be encoded using equation [\\[eqn:implicit\\]](#eqn:implicit){reference-type=\"ref\" reference=\"eqn:implicit\"}, where the weights $w_x$ are determined by the iterative refinement: $$\\mathbf{F}_{f=0} = normalize\\Big(\\sum_{x:f(x)=0} w_x\\cdot E_X(x)\\Big)\n    \\label{eqn:implicit}$$ The formula can be understood as encoding an explicit function $g$, where $g(x)=1$ if $f(x)=0$ and $g(x)=0$ if $f(x)\\neq 0$. Then by choosing $E_Y(1)=1$ and $E_Y(0)=0$ in equation [\\[eqn:final\\]](#eqn:final){reference-type=\"ref\" reference=\"eqn:final\"}, we can obtain equation [\\[eqn:implicit\\]](#eqn:implicit){reference-type=\"ref\" reference=\"eqn:implicit\"}. The formula can be interpreted in a simple way: a continuous object can be represented as the summation of its samples in a high-dimensional space. []{#sec:implicit label=\"sec:implicit\"}\n\n## Vector-Valued Function Encoding\n\nIn the previous sections, we established a theoretical framework for encoding $c$-Lipschitz continuous functions. In this section, we put this framework into practice by carefully choosing appropriate input and output mappings $E_X$, $E_Y$, the binding operator $\\otimes$, and the unbinding operator $\\oslash$ in equation [\\[eqn:final\\]](#eqn:final){reference-type=\"ref\" reference=\"eqn:final\"}. We will first state our choice and then explain the motivation behind it.\n\n**Formulation**   Let $(\\textbf{x}, y)$ be one of the function samples, where $\\textbf{x}\\in\\mathbb{R}^m$ and $y\\in\\mathbb{R}$, the mapping $E_X:X\\rightarrow\\mathbb{C}^N$, $E_Y:\\mathbb{R}\\rightarrow \\mathbb{C}^N$ and the operations $\\otimes$ and $\\oslash$ are chosen as: $$E_X(\\textbf{x}):=\\exp\\big(i\\cdot\\alpha\\frac{\\Phi\\textbf{x}}{m}\\big)\\qquad  E_Y(y):=\\exp\\big(i\\beta\\Psi y\\big)\n\\label{eqn:FPE}$$ $$\\begin{aligned}\n        E_X(\\textbf{x})\\otimes E_Y(y) &:=\\exp\\big(i\\cdot\\alpha\\frac{\\Phi\\textbf{x}}{m} + i\\beta\\Psi y\\big)\\\\\n    E_X(\\textbf{x})\\oslash E_Y(y) &:=\\exp\\big(i\\cdot\\alpha\\frac{\\Phi\\textbf{x}}{m} - i\\beta\\Psi y\\big)\n\\end{aligned}$$\n\nwhere $i$ is the imaginary unit, $\\Phi\\in\\mathbb{R}^{N\\times m}$ and $\\Psi\\in\\mathbb{R}^{N}$ are random fixed matrices where all elements are drawn from the standard normal distribution. $\\alpha$ and $\\beta$ are hyper-parameters controlling the properties of the mappings.\n\n**Motivation**  The above way of mapping real vectors to high-dimensional spaces is modified from @komer2020efficient, known as fractional power encoding (FPE). We introduce the motivation for adopting this technique heuristically. In Appendix [13](#sec:app_FPE_RBF){reference-type=\"ref\" reference=\"sec:app_FPE_RBF\"}, we elaborate on the relation between FPE and radial basis function (RBF) kernels, which gives a rigorous reason for adopting this technique.\n\nFirst, the mappings are continuous, which can avoid losses when mapping samples to the embedding space. Second, the receptive field of the input mapping $E_X$ (the $\\epsilon_0$ in equation [\\[eqn:requirement\\]](#eqn:requirement){reference-type=\"ref\" reference=\"eqn:requirement\"}) can be adjusted easily through manipulating $\\alpha$. Fig. [2](#fig:fig2a){reference-type=\"ref\" reference=\"fig:fig2a\"} demonstrates how manipulating $\\alpha$ can alter the behavior of $E_X$. Typically, $\\alpha$ has a magnitude of $10$ for capturing the high-frequency component of the function. Thirdly, the decodability of the output mapping $E_Y$ can easily be achieved by selecting appropriate $\\beta$ values. We select $\\beta$ such that $\\langle E_Y(0), E_Y(1)\\rangle$ is equal to 0 to utilize the space $\\mathbb{C}^N$ maximally while keeping the gradient of $\\langle E_Y(y_1), E_Y(y_2)\\rangle$ non-zero for all $y_1$ and $y_2$. Per the illustration in Fig. [2](#fig:fig2a){reference-type=\"ref\" reference=\"fig:fig2a\"}, the optimal choice for $\\beta$ is 2.5. Finally, the binding and unbinding operators are defined as the element-wise multiplication and division of complex vectors, which satisfy the required properties. []{#sec:vector_valued label=\"sec:vector_valued\"}\n\n## Properties of HDFE\n\nHDFE produces an explicit decodable representation of functions. In this section, we state a theorem on the asymptotic sample invariance, completing the claim that HDFE satisfies all four desirable properties. We study the effect of the receptive field on the behavior of HDFE. We also state that HDFE is distance-preserving and discuss the potential of scaling HDFE to high-dimensional data. We leave the proofs to Appendix [14](#sec:app_properties){reference-type=\"ref\" reference=\"sec:app_properties\"} and verify the claims with empirical experiments in Appendix [15](#sec:app_empirical){reference-type=\"ref\" reference=\"sec:app_empirical\"}. We include several empirical experiments of HDFE in Appendix [15](#sec:app_empirical){reference-type=\"ref\" reference=\"sec:app_empirical\"}, including the cost of the iterative refinement and its practical implementation, the effectiveness of sample invariance in a synthetic regression problem, and the analysis of information loss when encoding continuous objects.\n\n::: theorem\n**Theorem 1** (Sample Invariance). *HDFE is asymptotic sample invariant (defined at **Definition** [1](#def:1){reference-type=\"ref\" reference=\"def:1\"}).*\n:::\n\nHDFE being sample invariant ensures functions realized with different sampling schemes are treated invariantly. Kindly refer to Appendix [14.1](#sec:app_proof_sample_invariance){reference-type=\"ref\" reference=\"sec:app_proof_sample_invariance\"} and [15.1](#sec:app_experiment_sample_invariance){reference-type=\"ref\" reference=\"sec:app_experiment_sample_invariance\"} for the proof and empirical experiments.\n\n::: {#thm:isometry .theorem}\n**Theorem 2** (Distance Preserving). *Let $f, g:X\\rightarrow Y$ be both $c$-Lipschitz continuous, then their L2-distance is preserved in the encoding. In other words, HDFE is an isometry: $$||f-g||_{L_2}=\\int_{x\\in X} \\big|f(x)-g(x)\\big|^2dx \\approx b-a\\langle \\mathbf{F}, \\mathbf{G}\\rangle$$*\n:::\n\nHDFE being isometric indicates that HDFE encodes functions into a organized embedding space, which can reduce the complexity of the machine learning architecture when training downstream tasks on the functions. Kindly refer to Appendix [14.2](#sec:app_isometry){reference-type=\"ref\" reference=\"sec:app_isometry\"} and [15.2](#sec:app_experiment_isometry){reference-type=\"ref\" reference=\"sec:app_experiment_isometry\"} for the proof and empirical experiment.\n\n**Effect of receptive field**    Fig. [6](#fig:fig2){reference-type=\"ref\" reference=\"fig:fig2\"} shows the reconstruction results of a 1d function $f:\\mathbb{R}\\rightarrow\\mathbb{R}$, which demonstrates that HDFE can reconstruct the original functions given a suitable receptive field and a sufficiently large embedding space. When using a large receptive field (Fig. [3](#fig:fig2b){reference-type=\"ref\" reference=\"fig:fig2b\"}), the high-frequency components will be missed by HDFE. When using a small receptive field (Fig. [4](#fig:fig2c){reference-type=\"ref\" reference=\"fig:fig2c\"}), the high-frequency components can be captured, but it may cause incorrect reconstruction if the dimension of the embedding space is not large enough. Fortunately, reconstruction failures can be eliminated by increasing the dimension of the embedding space (Fig. [5](#fig:fig2d){reference-type=\"ref\" reference=\"fig:fig2d\"}).\n\n<figure id=\"fig:fig2\">\n<figure id=\"fig:fig2a\">\n<img src=\"figs/receptive_field/hi.jpg\" style=\"height:3cm\" />\n<figcaption>Similarity between <span class=\"math inline\"><em>E</em><sub><em>X</em></sub>(<em>x</em>)</span> and <span class=\"math inline\"><em>E</em><sub><em>X</em></sub>(0)</span>.</figcaption>\n</figure>\n<figure id=\"fig:fig2b\">\n<img src=\"figs/receptive_field/low_10.jpg\" style=\"height:3cm\" />\n<figcaption>Large recept. field.<br />\nDimension <span class=\"math inline\">=</span> 1000.</figcaption>\n</figure>\n<figure id=\"fig:fig2c\">\n<img src=\"figs/receptive_field/low_50.jpg\" style=\"height:3cm\" />\n<figcaption>Small recept. field.<br />\nDimension <span class=\"math inline\">=</span> 1000.</figcaption>\n</figure>\n<figure id=\"fig:fig2d\">\n<img src=\"figs/receptive_field/high_50.jpg\" style=\"height:3cm\" />\n<figcaption>Small recept. field.<br />\nDimension <span class=\"math inline\">=</span> 2000.</figcaption>\n</figure>\n<figcaption>(a): How <span class=\"math inline\"><em>α</em></span> and <span class=\"math inline\"><em>β</em></span> in equation <a href=\"#eqn:FPE\" data-reference-type=\"ref\" data-reference=\"eqn:FPE\">[eqn:FPE]</a> affects the receptive field of HDFE. (b)-(d): Functions can be reconstructed accurately given a suitable receptive field and encoding dimension. To capture the high-frequency component of the function, a small receptive field and a high dimension are required. </figcaption>\n</figure>\n\n**Scale to high-dimensional input**   HDFE produces the function encoding based on the sparsely collected samples. Unlike mesh-grid based methods, which require a mesh-grid domain and suffer from an exponential increase in memory and computational cost as the data dimension increases, HDFE uses superposition to encode all the samples defined in the support of the function. This means the required dimensionality only depends on the size of the support, not on the data dimensionality. Even if the data dimensionality is high, HDFE can mitigate this issue as long as the data reside in a low-rank subspace. Appendix [15.6](#sec:app_experiment_high_dimension){reference-type=\"ref\" reference=\"sec:app_experiment_high_dimension\"} gives an empirical experiment of high-dimensional input to show the potential of HDFE to work in low-rank high-dimensional scenarios.\n\n[]{#sec:properties label=\"sec:properties\"}"},{"heading":"Experiment","text":"# Experiment\n\nIn this section, we present two applications of HDFE. Sec. [3.1](#sec:PDE_solver){reference-type=\"ref\" reference=\"sec:PDE_solver\"} showcases how HDFE can be leveraged for solving partial differential equations (PDE). This exemplifies how HDFE can enhance neural networks to receive function inputs and produce function outputs. In Sec. [3.2](#sec:normal_estimation){reference-type=\"ref\" reference=\"sec:normal_estimation\"}, we apply HDFE to predict the surface normal of point clouds. This demonstrates how HDFE can enhance neural networks to process implicit functions and extract relevant attributes.\n\n## PDE Solver {#sec:PDE_solver}\n\nSeveral neural networks have been developed to solve partial differential equations (PDE), such as the Fourier neural operator [@li2020fourier]. In this section, we compare our approach using HDFE against the current approaches and show that we achieve on-par performance. VFA does not apply to the problem since the input and output functions do not conform to the form that VFA requires.\n\n**Architecture**   To solve PDEs using neural networks, we first encode the PDE and its solution into their vector embeddings using HDFE. Then, we train a multi-layer perceptron to map the embedding of the PDE to the embedding of its solution. The optimization target is the cosine similarity between the predicted embedding and the true embedding. Since the embeddings are complex vectors, we adopt a Deep Complex Network [@trabelsi2017deep] as the architecture of the multi-layer perceptron. The details are presented in Appendix [16.1](#sec:app_PDE_solver_details){reference-type=\"ref\" reference=\"sec:app_PDE_solver_details\"}. Once the model is trained, we use it to predict the embedding of the solution, which is then decoded to obtain the actual solution.\n\n**Dataset**   We use 1d Burgers' Equation [@su1969korteweg] and 2d Darcy Flow [@tek1957development] for evaluating our method. The error is measured by the absolute distance between the predicted solution and the ground-truth solution. The benchmark [@li2020multipole] has been used to evaluate neural operators widely. For the 1d Burgers' Equation, it provides 2048 PDEs and their solutions, sampled at a 1d mesh grid at a resolution of $8192$. For the 2d Darcy Flow, it provides 2048 PDEs and their solutions, sampled at a 2d mesh grid at a resolution of $241\\times 241$.\n\n**Baselines**  We evaluate our HDFE against other neural network PDE-solving methods. These include: [PCANN]{.underline} [@bhattacharya2021model]; [MGKN]{.underline}: Multipole Graph Neural Operator [@li2020multipole]; [FNO]{.underline}: Fourier Neural Operator [@li2020fourier].\n\n<figure id=\"fig:fig4\">\n<figure>\n<img src=\"figs/PDE_error/burger.jpeg\" />\n</figure>\n<figure>\n<img src=\"figs/PDE_error/err_dim.jpeg\" />\n</figure>\n<figure>\n<img src=\"figs/PDE_error/darcy.jpeg\" />\n</figure>\n<figcaption>HDFE solves a PDE by predicting the encoding of its solution and then reconstructing at points, so the error consists of a function encoding prediction error and a reconstruction error. <strong>Left</strong>: Prediction error of different methods under different testing resolutions, evaluated on the 1d Burgers’ equation. <strong>Mid</strong>: The reconstruction error (in HDFE) dominates the function encoding prediction error, while the reconstruction error can be reduced by increasing the dimensionality of the embedding. <strong>Right</strong>: Prediction error of different methods evaluated on 2d Darcy Flow.</figcaption>\n</figure>\n\n*When decoding is required*, **our approach achieves $\\sim 55\\%$ lower prediction error than MGKN and PCANN and competitive performance to FNO**. The error of HDFE consists of two components. The first is the error arising from predicting the solution embedding, and the second is the reconstruction error arising when decoding the solution from the predicted embedding. In contrast, FNO directly predicts the solution, and hence, does not suffer from reconstruction error. If we consider both errors, HDFE achieves comparable performance to FNO. Fig. [7](#fig:fig4){reference-type=\"ref\" reference=\"fig:fig4\"} shows the comparison.\n\nOn the other hand, *when decoding is not required*, **our approach achieves lower error than FNO**. Such scenarios happen frequently when we use functions only as input, for example, the local geometry prediction problem in Experiment [3.2](#sec:normal_estimation){reference-type=\"ref\" reference=\"sec:normal_estimation\"}. Despite the presence of reconstruction error, **the reconstruction error can be reduced by increasing the embedding dimension**, as shown in Figure [7](#fig:fig4){reference-type=\"ref\" reference=\"fig:fig4\"} (Mid). Increasing the embedding dimension may slightly increase the function prediction error, possibly because the network is not adequately trained due to limited training data and some overfitting. We conjecture that this prediction error can be reduced with more training data.\n\nIn addition to comparable performance, **HDFE overcomes two limitations of FNO**. First, HDFE provides an explicit function representation, resolving the restriction of FNO, which only models the mappings between functions without extracting attributes from them. Second, HDFE not only works for grid-sampled functions but also for sparsely sampled functions.\n\n## Unoriented Surface Normal Estimation {#sec:normal_estimation}\n\nNext, we apply HDFE to extract attributes of functions, a setting where neither neural operators nor VFA applies, because neural operators do not consume sparse samples and VFA does not encode implicit functions. We predict the unoriented surface normal from 3d point cloud input.\n\n**Baselines**   We compare our HDFE with two baselines. In the first baseline, we compare the vanilla HDFE with the PCPNet [@guerrero2018pcpnet], which is a vanilla PointNet [@qi2017pointnet] architecture. We replace the PointNet with our HDFE appended with a deep complex network [@trabelsi2017deep]. In the second baseline, we incorporate HDFE into HSurf-Net [@li2022hsurf], which is the state-of-the-art PointNet-based normal estimator. In both settings, we compare the effect of data augmentation in the HDFE module, where we add noise to the weight of each sample when generating the patch encoding by HDFE. Kindly refer to Appendix [16.2](#sec:app_normal_estimation_details){reference-type=\"ref\" reference=\"sec:app_normal_estimation_details\"} [16.3](#sec:app_hsurfnet_details){reference-type=\"ref\" reference=\"sec:app_hsurfnet_details\"} for details.\n\n**Dataset and metrics**   We use the root mean squared angle error (RMSE) as the metrics, evaluated on the PCPNet [@guerrero2018pcpnet] and FamousShape [@li2023shs] datasets. We compare the robustness for two types of data corruption: (1) point density: sampling subsets of points with two regimes, where *gradient* simulates the effects of distance from the sensor, and *strips* simulates local occlusions. (2) point perturbations: adding Gaussian noise to the point coordinates. Table [\\[tab:normal_estimation_error\\]](#tab:normal_estimation_error){reference-type=\"ref\" reference=\"tab:normal_estimation_error\"} reports normal angle RMSE comparison with the baselines on PCPNet and FamousShape. Appendix [17](#sec:app_ablation){reference-type=\"ref\" reference=\"sec:app_ablation\"} reports the ablation studies examining the effect of the receptive field size and the dimensionality.\n\n[]{#tab:normal_estimation_error label=\"tab:normal_estimation_error\"}\n\n**HDFE significantly outperforms the PointNet baseline.** When processing the local patches, we replace PointNet with HDFE followed by a neural network. This replacement leads to an average reduction in error of 1.70 and 3.79 on each dataset. This is possibly because HDFE encodes the distribution of the local patch, which is guaranteed by the decodability property of HDFE. PointNet, on the other hand, does not have such guarantee. Specifically, PointNet aggregates point cloud features through a max-pooling operation, which may omit points within the point cloud and fail to adequately capture the patch's distribution. Consequently, in tasks where modeling the point cloud distribution is crucial, such as normal estimation, PointNet exhibits higher error compared to HDFE.\n\n**HDFE, as a plug-in module, improves the SOTA baseline significantly**. HSurf-Net [@li2022hsurf], the SOTA method in surface normal estimation, introduces many features, such as local aggregation layers, and global shift layers specifically for the task. Notably, HDFE does not compel such features. We incorporate HDFE into HSurf-Net (See Appendix [16.3](#sec:app_hsurfnet_details){reference-type=\"ref\" reference=\"sec:app_hsurfnet_details\"} for details), where it leads to average error reductions of 0.25/0.30 on each dataset. Notably, such incorporation can be performed on any PointNet-based architecture across various tasks. Incorporating HDFE to other PointNet-based architectures for performance and robustness gain can be a future research direction.\n\n**HDFE promotes stronger robustness to point density variance.** In both comparisons and both benchmarks, HDFE exhibits stronger robustness to point density variation than its PointNet counterpart, especially in the Density-Gradient setting (error reduction of 4.79/7.37/0.52/0.46). This shows the effectiveness of the HDFE's sample invariance property and the embedding augmentation. Sample invariance ensures a stable encoding of local patches when the point density changes. The embedding augmentation is a second assurance to make the system more robust to density variation."},{"heading":"Related Work","text":"# Related Work {#sec:related_work}\n\n## Mesh-grid-based framework\n\nThese methods operate on continuous objects (functions) defined on mesh grids with arbitrary resolution. They enjoy discretization invariance, but they do not receive sparse samples as input.\n\n**Fourier transform** (FT) can map functions from their time domains to their frequency domains. By keeping a finite number of frequencies, FT can provide a vector representation of functions. 1D-FT has been a standard technique for signal processing [@salih2012fourier] and 2D-FT has been used for image processing [@jain1989fundamentals]. FT is also incorporated into deep learning architectures [@fan2019bcr; @sitzmann2020implicit]. However, FT is not scalable since the $n$-dimensional Fourier transform returns an $n$-dimensional matrix, which is hard to process when $n$ gets large.\n\n**Neural operator** is a set of toolkits to model the mapping between function spaces. The technique was pioneered in DeepONet [@lu2019deeponet] and a series of tools were developed [@li2021physics; @li2020neural; @li2020multipole; @guibas2021adaptive; @kovachki2021neural] for studying the problem. The most well-known work is the Fourier Neural Operator (FNO) [@li2020fourier]. The approach showed promising accuracy and computational efficiency. Though proposed in 2020, FNO is still the first choice when mapping between function spaces [@wen2023real; @renn2023forecasting; @gopakumar2023fourier]. Despite their success, neural operators lack explicit function representations and their application is limited to mappings between function spaces.\n\n## Sparse framework {#sec:sparse_framework}\n\nThese methods, including HDFE, work with sparse samples from continuous objects.\n\n**PointNet** [@qi2017pointnet] is a neural network architecture for processing point cloud data. It uses multi-layer perceptrons to capture local features of every point and then aggregates them into a global feature vector that's invariant to the order of the input points. PointNet and its variation [@zaheer2017deep; @{qi2017pointnet++}; @joseph2019momen; @yang2019modeling; @zhao2019pointweb; @duan2019structural; @yan2020pointasnl] have been widely applied to sparse data processing, for example, for object classification [@yan2020pointasnl; @lin2019justlookup], semantic segmentation [@ma2020global; @li2019mvp], and object detection [@qi2020imvotenet; @yang20203dssd] with point cloud input. However, PointNet does not produce a decodable representation. Specifically, after encoding a point cloud with PointNet, it is difficult to decide whether a point is drawn from the point cloud distribution. Besides, PointNet is also sensitive to perturbations in the input point cloud.\n\n**Kernel methods** [@hofmann2008kernel] are a type of machine learning algorithm that transforms data into a higher-dimensional feature space via a kernel function, such as the radial basis function (RBF) [@cortes1995support], which can capture nonlinear relationships. Though kernel methods can predict function values at any query input (i.e. decodable) and the prediction is invariant to the size and distribution of the training data, kernel methods do not produce an explicit representation of functions, so they are only used for fitting functions but not processing or predicting functions.\n\n**Vector function architecture** VFA [@frady2021computing] encodes a function of the form $f(x)=\\sum_k \\alpha_k\\cdot K(x,x_k)$ into a vector, where $K:X\\times X\\rightarrow \\mathbb{R}$ is a kernel defined on the input space. VFA and HDFE share a similar high-level idea. They both map the samples to high-dimensional space and compute the weighted average in that space. However VFA determines the weight by relying on the assumption of the functional form. HDFE, on the other hand, uses iterative refinement to solve the weights. The iterative refinement coupled with the binding operation relaxes the assumption required by VFA and enables encoding functions across a larger class of inputs. In addition, VFA is limited to empirical experiments such as non-linear regression and density estimation, without practical applications. In comparison, HDFE is demonstrated to be applicable to real-world problems."},{"heading":"Conclusion","text":"# Conclusion {#sec:conclusion}\n\n[We introduced Hyper-Dimensional Function Encoding (HDFE), which constructs vector representations for continuous objects. The representation, without any training, is sample invariant, decodable, and isometric. These properties position HDFE as an interface for the processing of continuous objects by neural networks. Our study demonstrates that the HDFE-based architecture attains significantly reduced errors compared to PointNet-based counterparts, especially in the presence of density perturbations. This reveals that HDFE presents a promising complement to PointNet and its variations for processing point cloud data. Adapting HDFE (e.g. imposing rotational invariance to HDFE) to tasks like point cloud classification and segmentation offers promising avenues for exploration.]{style=\"color: black\"} [Still, HDFE does possess limitations in encoding capacity. For functions defined over large domains or highly non-linear functions, HDFE can experience underfitting. The exploration of techniques to enhance HDFE's capacity remains promising research. Regardless, HDFE already shows strong applicability in low-dimensional (1D, 2D, 3D) inputs.]{style=\"color: black\"}"},{"heading":"Acknowledgement","text":"# Acknowledgement\n\nThe support of NSF under awards OISE 2020624 and BCS 2318255, and ARL under the Army Cooperative Agreement W911NF2120076 is greatly acknowledged. The in-depth discussions with Denis Kleyko, Paxon Frady, Bruno Olshausen, Christopher Kymn, Friedrich Sommer, Pentti Kanerva significantly improved the manuscript and we are grateful.\n\n::: center\n[Appendix]{.smallcaps}\n:::"},{"heading":"Notation Table","text":"# Notation Table {#sec:app_notation}\n\n:::: center\n::: {#tab:TableOfNotationForMyResearch}\n  ------------------------------------------------- -------------- --------------------------------------------------------------------------------\n                                                                   \n    [Notations of Continuous Functions]{.underline}                \n                                                                   \n                                                $F$  $\\triangleq$  family of $c$-Lipschitz continuous functions\n                                                $c$  $\\triangleq$  Lipschitz constant of the continuous function\n                                                $X$  $\\triangleq$  input space, a bounded domain of the function\n                                                $Y$  $\\triangleq$  output space, a bounded range of the function\n                                              $d_X$  $\\triangleq$  distance metrics in the input space $X$\n                                              $d_Y$  $\\triangleq$  distance metrics in the output space $Y$\n                                 $\\{(x_i, f(x_i)\\}$  $\\triangleq$  collection of function samples.\n                                                $m$  $\\triangleq$  dimensionality of the input space $X$.\n                                                                   \n                    [Notations of HDFE]{.underline}                \n                                                                   \n                                       $\\epsilon_0$  $\\triangleq$  receptive field of HDFE.\n                                       $\\mathbf{F}$  $\\triangleq$  $N$-dimensional complex vector. Encoding of the explicit function $f$.\n                                 $\\mathbf{F}_{f=0}$  $\\triangleq$  $N$-dimensional complex vector. Encoding of the implicit function $f(x)=0$.\n                                                $N$  $\\triangleq$  dimensionality of the function encoding.\n                                         $E_X, E_Y$  $\\triangleq$  the input and output mapping from $X, Y$ to the encoding space $\\mathbb{C}^N$.\n                                          $\\otimes$  $\\triangleq$  binding operation.\n                                          $\\oslash$  $\\triangleq$  unbinding operation.\n                     $\\langle \\cdot, \\cdot \\rangle$  $\\triangleq$  cosine similarity between two complex vectors.\n  ------------------------------------------------- -------------- --------------------------------------------------------------------------------\n\n  : Table of Notation\n:::\n::::\n\n[]{#tab:TableOfNotationForMyResearch label=\"tab:TableOfNotationForMyResearch\"}"},{"heading":"PointNet as Function Encoder","text":"# PointNet as Function Encoder {#sec:app_pointnet}\n\nIn this section, we present empirical evidence highlighting PointNet's limitations in generating decodable function encodings. Our designed pipeline, following the popular style of training reconstruction networks, demonstrates PointNet's inability to produce even reasonable reconstructions. Consequently, we infer that without substantial modifications, PointNet is unlikely to acquire the necessary capability for effective function encoding.\n\nSpecifically, we generate random functions by $$f(x)=\\frac{1}{2}+\\frac{1}{8}\\sum_{k=1}^4 a_k\\sin(2\\pi kx)$$ where $a_k\\sim Uniform(0,1)$ are the parameters controlling the generation and $f(x)\\in(0,1)$. We randomly sample $\\{x_i, y_i\\}_{i=1}^{5000}$ where $y_i=f(x_i)+\\epsilon_i$, $x_i\\sim Uniform(0,1)$ and $\\epsilon_i$ is white noise with variance 1e-4. Then we stack $x_i$ and $y_i$ into a $(5000, 2)$ matrix and feed it to a standard PointNet to generate a $1024$-dimensional vector. After encoding the function samples, we introduce a decoder that retrieves the function values from the encoding when receiving function inputs. We optimize the PointNet encoder and the decoder by minimizing the reconstruction loss. The procedure can be summarized as: $$\\mathbf{F}= \\text{\\texttt{PointNet}}\\big(\\{(x_i, y_i)\\}_{i=1}^n\\big),\\quad \\hat{y_i} = \\text{\\texttt{Decoder}}(\\mathbf{F}, x_i),\\quad \\mathcal{L}=\\sum_{i=1}^n |y_i-\\hat{y}_i|^2$$ The decoder is designed as followed: $x_i$ is lifted to a $1024$-dimensional vector $\\tilde{\\mathbf{x}}_i$ through sequential layers of `Linear(1,64)`, `Linear(64,128)`, `Linear(128,1024)` with `BatchNorm` and `ReLU` inserted between the linear layers. The retrieved function value $\\hat{y}_i$ is computed by the dot product between $\\mathbf{F}$ and $\\tilde{\\mathbf{x}}_i$. Figure [8](#fig:app_ptn_recon){reference-type=\"ref\" reference=\"fig:app_ptn_recon\"} (**Left**) plots the training curve and Figure [8](#fig:app_ptn_recon){reference-type=\"ref\" reference=\"fig:app_ptn_recon\"} (**Right**) visualizes the reconstruction, which shows PointNet fails to learn a decodable representation.\n\n<figure id=\"fig:app_ptn_recon\">\n<figure>\n<img src=\"figs/app_pointnet_encoder/loss.jpg\" />\n</figure>\n<figure>\n<img src=\"figs/app_pointnet_encoder/ptn_recon.jpg\" />\n</figure>\n<figcaption>PointNet fails to learn an effective function encoder. <strong>Left</strong>: Training curve of the PointNet function encoder. The error is still significantly higher than HDFE though training for 700 epochs. <strong>Right</strong>: The PointNet function encoder does not produce a reasonable reconstruction.</figcaption>\n</figure>"},{"heading":"Vector Function Architecture","text":"# Vector Function Architecture {#sec:app_VFA}\n\nIn this section, we will give a brief introduction of VFA and its relation and comparison with HDFE.\n\n**Vector Function Architecture (VFA)** A function of the form $$f(x)=\\sum_{k}\\alpha_k\\cdot K(x,x_k)\\label{eqn:VFA}$$ is represented by $\\mathbf{F}=\\sum_k \\alpha_k\\cdot E(x_k)$, where the kernel $K(\\cdot,\\cdot)$ and the encoder $E(\\cdot)$ satisfy $K(x,y)=\\langle E(x), E(y) \\rangle$. Given the function encoding $\\mathbf{F}$, the function value at a query point $x_0$ can be retrieved by $\\hat{f}(x_0)=\\langle \\mathbf{F}, E(x_0)\\rangle$.\n\nVFA satisfies the four desired properties: VFA can encode an explicit function into a fixed-length vector, where the encoding is sample invariant and decodable. Besides, the function encoding will preserve the overall similarity of the functions: $\\langle \\mathbf{F}, \\mathbf{G}\\rangle=\\int_x f(x)g(x)dx$. Note that when encoding multiple functions, the kernel $K(\\cdot,\\cdot)$ and the encoder $E(\\cdot)$ must be the same. Otherwise, the function encoding generated by VFA will be meaningless.\n\n:::: wrapfigure\nR0.4\n\n::: minipage\n![image](figs/VFA_fail.jpg){width=\"\\\\textwidth\"}\n:::\n::::\n\nHowever, it is a strong assumption that a function can be approximated by equation [\\[eqn:VFA\\]](#eqn:VFA){reference-type=\"ref\" reference=\"eqn:VFA\"}. In other words, under a fixed selection of $K(\\cdot,\\cdot)$ and $E(\\cdot)$, equation [\\[eqn:VFA\\]](#eqn:VFA){reference-type=\"ref\" reference=\"eqn:VFA\"} can only approximate a small set of functions. There are a large set of functions that cannot be approximated by equation [\\[eqn:VFA\\]](#eqn:VFA){reference-type=\"ref\" reference=\"eqn:VFA\"}. In Fig. [\\[fig:VFA_fail\\]](#fig:VFA_fail){reference-type=\"ref\" reference=\"fig:VFA_fail\"}, we show a failure case of VFA. We generate a function $f(x)=0.1+\\sum_{k=1}^{10}\\alpha_k\\cdot K(x,x_k)$, where $x_k\\sim N(0,1)$, $\\alpha_k\\sim Uniform(0,1)$. $K(x,y)=\\exp[-20(x-y)^2]$ is an RBF kernel. We generate 1000 function samples and add white noise to the output values to form the training set. The experiment shows that VFA fails to reconstruct the function but HDFE succeeds.\n\nIn this paper, HDFE is applicable for all $c$-Lipchitz function, without compromising the four desired properties. Thanks to the improvement, we can apply function encoding to real-world applications. The first application, PDE solving, cannot be solved by VFA because the input and output functions cannot be approximated by equation [\\[eqn:VFA\\]](#eqn:VFA){reference-type=\"ref\" reference=\"eqn:VFA\"}. The second application, local geometry prediction, has to deal with implicit function encoding, which cannot be solved by VFA either because VFA only encodes explicit functions."},{"heading":"Suitable Input Types for HDFE","text":"# Suitable Input Types for HDFE {#sec:app6_input_types}\n\nWe mentioned HDFE can encode Lipschitz functions. In this section, we will discuss several data types that exhibits Lipschitz continuity, making them well-suited as inputs for HDFE. This enumeration is not exhaustive of all potential suitable inputs for HDFE. Our objective is to furnish a conceptual understanding of the characteristics that define a suitable input, thereby guiding future considerations in this domain.\n\n**Point Cloud Local Geometry** In many 3D vision problems, point cloud local features are important, such as point cloud registration [@huang2021comprehensive], scene matching [@han20233d]. The local geometry around a point in a point cloud is usually a continuous surface, which inherently exhibits Lipschitz continuity. This characteristic makes HDFE suitable for encoding this type of data.\n\n**Meteorological Measurements** In the field of meteorology, machine learning plays a pivotal role in various applications, including pollutant estimation [@lu2020estimations] and weather forecasting [@chen2022estimation]. A standard practice in these applications involves inputting meteorological measurements from neighboring areas (for instance, windows of 100 km$^2$) into machine learning models. HDFE is a suitable tool for encoding these neighboring meteorological measurements, primarily due to the inherent physical constraints that ensure these measurements do not rapidly change over time and space.\n\n**Time Series Data**: Some time series data, especially in fields like event logging [@chen2021experience] or network traffic [@abbasi2021deep], are sparse in nature. Such sparse events can be treated as implicit functions and therefore HDFE is well-suited for it."},{"heading":"Derivation of Decoding","text":"# Derivation of Decoding {#sec:app_decoding_proof}\n\nIn this section, we complete the details why $\\mathbf{F}\\oslash E_X(x_0)$ can be decomposed into the summation of $E_Y(f(x_0))$ and noises. This is an immediate outcome from the similarity preserving property. When $d_X(x_0, x_i)$ is large, $\\langle E_X(x_0)\\otimes E_Y(f(x_0)), E_X(x_i)\\otimes E_Y(f(x_i)) \\rangle\\approx 0$. Since the unbinding operation is similarity preserving, we have $\\langle E_Y(f(x_0)), E_X(x_i)\\otimes E_Y(f(x_i)) \\oslash E_X(x_0)\\rangle\\approx 0$. Therefore, $\\mathbf{F}\\oslash E_X(x_0)$ can be decomposed into $E_Y(f(x_0))$ and the sum of vectors that are orthogonal to it. Consequently, when we search for the $y$ to maximize the $\\langle \\mathbf{F}\\oslash E_X(x_0), E_Y(y) \\rangle$, those orthogonal vectors will not bias the optimization."},{"heading":"Gradient Descent for Decoding Function Encoding","text":"# Gradient Descent for Decoding Function Encoding {#sec:app_decoding}\n\nIn equation [\\[eqn:decoding\\]](#eqn:decoding){reference-type=\"ref\" reference=\"eqn:decoding\"}, HDFE decodes the function encoding by a similarity maximization. Given the function encoding $\\mathbf{F}\\in\\mathbb{C}^N$, and a query point $x_0\\in X$, the function value $\\hat{y}_0$ is reconstructed by: $$\\hat{y_0}=\\mathrm{argmax}_{y\\in Y} \\langle \\mathbf{F}\\oslash E_X(x_0), E_Y(y)\\rangle$$ When $E_X$ and $E_Y$ are chosen as the fractional power encoding (equation [\\[eqn:FPE\\]](#eqn:FPE){reference-type=\"ref\" reference=\"eqn:FPE\"}), the optimization can be solved by gradient descent. In this section, we detail the gradient descent formulation. We assume the output space $Y=\\mathbb{R}$.\n\nBy setting $E_Y$ as the fractional power encoding, the optimization can be rewritten as: $$\\hat{y}_0=\\mathrm{argmax}_{y\\in(0,1)}\\langle\\mathbf{F}\\oslash E_X(x_0),\\exp(i\\Psi y)\\rangle\\text{\\footnotemark}$$ where $\\Psi\\in\\mathbb{R}^N$ is a random fixed vector where all elements are drawn from the normal distribution. Since $\\mathbf{F}\\oslash E_X(x_0)$ is a constant vector, the optimization can be further simplified as: $$\\hat{y}_0=\\mathrm{argmax}_{y\\in(0,1)}\\langle\\textbf{z},\\exp(i\\Psi y) \\rangle\\label{eqn:app_decoding}$$\n\nwhere $\\textbf{z}=\\mathbf{F}\\oslash E_X(x_0)\\in\\mathbb{C}^N$. We write $\\textbf{z}$ into its polar form: $$\\textbf{z}=\\left[a_1 e^{i\\theta_1}, a_2 e^{i\\theta_2}, \\cdots, a_N e^{i\\theta_N}\\right]$$ where $a_k\\in[0,+\\infty)$ and $\\theta_k\\in[0,2\\pi)$. We first simplify equation [\\[eqn:app_decoding\\]](#eqn:app_decoding){reference-type=\"ref\" reference=\"eqn:app_decoding\"} and then compute its gradient with respect to $y$. $$\\begin{aligned}\n    \\langle\\textbf{z},\\exp(i\\Psi y) \\rangle &= \\frac{1}{N^2}||\\bar{\\textbf{z}}\\cdot \\exp(i\\Psi y)||^2 \\\\\n    &=\\frac{1}{N^2}\\big|\\big|\\sum_{k=1}^N a_k e^{i\\theta_k} e^{-i\\Psi_k y} \\big|\\big|^2 \\\\\n    &=\\frac{1}{N^2}\\sum_{p=1}^N\\sum_{q=1}^N a_p a_q  e^{i\\big[(\\theta_p-\\theta_q)-(\\Psi_p-\\Psi_q)y\\big]} \\\\\n    &=\\frac{1}{N^2}\\sum_{p=1}^N\\sum_{q=1}^N a_pa_q\\cos\\big[(\\theta_p-\\theta_q)-(\\Psi_p-\\Psi_q)y\\big]\n\\end{aligned}$$ The gradient can be computed easily by taking the derivative: $$\\frac{d}{dy}\\langle\\textbf{z},\\exp(i\\Psi y) \\rangle = \\frac{1}{N^2}\\sum_{p=1}^N\\sum_{q=1}^N a_pa_q(\\Psi_p-\\Psi_q)\\sin\\big[(\\theta_p-\\theta_q)-(\\Psi_p-\\Psi_q)y\\big]\\label{eqn:app_decoding_final}$$\n\nIn practice, $N$ can be a large number like 8000. Computing the gradient by equation [\\[eqn:app_decoding_final\\]](#eqn:app_decoding_final){reference-type=\"ref\" reference=\"eqn:app_decoding_final\"} can be expensive. Fortunately, since $\\Psi$ is a random fixed vector, where all elements are independent of each other, we can unbiasedly estimate the gradient by sampling a small number of entries in the vector. The decoding can be summarized by the pseudo-code below.\n\n:::: algorithm\n::: algorithmic\nInput: $\\mathbf{F}$, $x_0$, $E_X$, $\\Psi$ $\\textbf{z}=\\mathbf{F}\\oslash E_X(x_0)$ $\\textbf{z}=\\left[a_1 e^{i\\theta_1}, a_2 e^{i\\theta_2}, \\cdots, a_N e^{i\\theta_N}\\right]$ Randomly select a subset of $[0,N)\\cap\\mathbb{Z}$. Denote as $S$. $g=|S|^{-2}\\cdot\\sum_{p,q\\in S} a_pa_q(\\Psi_p-\\Psi_q)\\sin\\big[(\\theta_p-\\theta_q)-(\\Psi_p-\\Psi_q)y\\big]$ $y \\leftarrow y-\\alpha \\cdot g$\n:::\n::::"},{"heading":"Relation between FPE and RBF Kernel","text":"# Relation between FPE and RBF Kernel {#sec:app_FPE_RBF}\n\nIn the main paper, we mention that we adopt fractional power encoding (FPE) as the mapping for the input and output space. In this section, we explain the rational behind our choice by revealing its close relationship between the radial basis function (RBF) kernel. For explanation purpose, we discuss the single-variable case. It is straight-forward to generalize to multi-variable scenarios.\n\nRBF kernel is a similarity measure defined as $K(x,y)=\\exp\\big(-\\gamma(x-y)^2\\big)$. The feature space of the kernel has an infinite number of dimensions: $$\\exp\\big(-\\gamma(x-y)^2\\big)=\\sum_{k=0}^\\infty \\frac{(-1)^k}{(2k)!}\\gamma^{2k}(x-y)^{2k}=\\langle \\phi(x), \\phi(y)\\rangle$$ where $\\phi(x)=e^{-\\gamma x^2}\\left[1,\\sqrt{\\frac{\\gamma}{1!}}x, \\sqrt{\\frac{\\gamma^2}{2!}}x^2, \\sqrt{\\frac{\\gamma^3}{3!}}x^3, \\cdots \\right]$.\n\nWe will then show a theorem that tells that FPE maps real numbers into finite complex vectors, where the similarity between the vectors can approximate a heavy-tailed RBF kernel. However, the feature space of the heavy-tailed RBF kernel still has an infinite number of dimensions and therefore inherits all the blessings of the RBF kernel. Notably, FPE provides a finite encoding, while approximating an infinite dimensional feature space.\n\n::: {#thm:FPE .theorem}\n**Theorem 3**. *Let $x, y\\in\\mathbb{R}$, $E(x)=e^{i\\gamma\\Theta x}$, where $\\Theta\\in\\mathbb{R}^N$ and $\\forall \\theta \\in\\Theta, \\theta\\sim \\mathcal{N}(0,\\frac{1}{2})$, then as $N\\to\\infty$, $$\\langle E(x), E(y)\\rangle=\\langle e^{i\\gamma\\Theta x}, e^{i\\gamma\\Theta y}\\rangle\\rightarrow\\sum_{k=0}^\\infty \\frac{(-1)^k}{(2k)!!}\\gamma^{2k}(x-y)^{2k}=\\langle \\phi(x),\\phi(y)\\rangle$$ where $\\phi(x)=e^{-\\gamma x^2}\\left[1,\\sqrt{\\frac{\\gamma}{1!!}}x, \\sqrt{\\frac{\\gamma^2}{2!!}}x^2, \\sqrt{\\frac{\\gamma^3}{3!!}}x^3, \\cdots \\right]$. *\n:::\n\n::: proof\n*Proof.* $$\\begin{aligned}\n        \\langle e^{i\\gamma\\Theta x}, e^{i\\gamma\\Theta y}\\rangle &= \\frac{1}{N^2}||\\exp(i\\gamma\\Theta x)\\cdot \\exp(-i\\gamma\\Theta y)||^2 \\\\\n        &=\\frac{1}{N^2}\\big|\\big| \\sum_{k=1}^N e^{i\\gamma\\theta_k (x-y)} \\big|\\big|^2 \\\\\n        &=\\frac{1}{N^2}\\Big[\\sum_{p=1}^N 1 + \\sum_{p\\neq q}e^{i\\gamma(\\theta_p-\\theta_q)(x-y)}\\Big] \\\\\n        &=\\frac{1}{N}+\\frac{1}{N^2}\\sum_{p\\neq q} \\cos\\big[\\gamma(\\theta_p-\\theta_q)(x-y)\\big] \\\\\n        &=\\frac{1}{N}+\\frac{1}{N^2}\\sum_{p\\neq q}\\sum_{k=0}^\\infty(-1)^k \\frac{\\big[\\gamma(\\theta_p-\\theta_q)(x-y)\\big]^{2k}}{(2k)!} \\\\\n        &=\\frac{1}{N}+\\sum_{k=0}^{\\infty} (-1)^k \\big[\\sum_{p\\neq q}\\frac{(\\theta_p-\\theta_q)^{2k}}{N^2}\\big] \\frac{\\gamma^{2k}(x-y)^{2k}}{(2k)!} \\\\\n        &\\rightarrow \\sum_{k=0}^{\\infty} (-1)^k (2k-1)!! \\frac{\\gamma^{2k}(x-y)^{2k}}{(2k)!} \\\\\n        &=\\sum_{k=0}^\\infty \\frac{(-1)^k}{(2k)!!}\\gamma^{2k}(x-y)^{2k}\n    \n\\end{aligned}$$ Since $\\theta_p, \\theta_q\\sim\\mathcal{N}(0,\\frac{1}{2})$, $\\theta_p-\\theta_q\\sim\\mathcal{N}(0,1)$, and therefore, $\\mathbb{E}[(\\theta_p-\\theta_q)^{2n}]=(2n-1)!!$. So $\\sum_{p\\neq q}\\frac{(\\theta_p-\\theta_q)^{2n}}{N^2}$ converges to $(2n-1)!!$. ◻\n:::"},{"heading":"Proof of the HDFE's Properties","text":"# Proof of the HDFE's Properties {#sec:app_properties}\n\n## Asymptotic Sample Invariance {#sec:app_proof_sample_invariance}\n\nIn the main paper, we claim that the iterative refinement (Algorithm [\\[alg:1\\]](#alg:1){reference-type=\"ref\" reference=\"alg:1\"}) will converge to *the center of the smallest ball containing all the sample encodings* and therefore, HDFE leads to an asymptotic sample invariant representation. In this section, we detail the proof of the argument. To facilitate the understanding, Figure [9](#fig:app_graph_proof){reference-type=\"ref\" reference=\"fig:app_graph_proof\"} sketches the proof from a high-level viewpoint. Recall the definition of asymptotic sample invariance (definition [1](#def:1){reference-type=\"ref\" reference=\"def:1\"}):\n\n::: definition*\n**Definition 1** (Asymptotic Sample Invariance). *Let $f:X\\rightarrow Y$ be the function to be encoded, $p:X\\rightarrow (0,1)$ be a probability density function (pdf) on $X$, $\\{x_i\\}_{i=1}^n \\sim p(X)$ be $n$ independent samples of $X$. Let $\\mathbf{F}_n$ be the representation computed from the samples $\\{x_i, f(x_i)\\}^n_{i=1}$, asymptotic sample invariance implies $\\mathbf{F}_n$ converges to a limit $\\mathbf{F}_\\infty$ independent of the pdf $p$.*\n:::\n\n::::: proof\n*Proof.* We begin by showing the iterative refinement converges to $$\\mathbf{F}_n=\\mathrm{argmax}_{||z||=1}\\min _{i=1}^n \\langle z, E(x_i,f(x_i))\\rangle\n    \\label{eqn:app_sample_invariance_final}$$ where $E(x, f(x))$ is defined at equation [\\[eqn:FPE\\]](#eqn:FPE){reference-type=\"ref\" reference=\"eqn:FPE\"} in the original paper. It maps a function sample to a high-dimensional space $\\mathbb{C}^N$.\n\nTo show the convergence of the iterative refinement, it follows from the gradient descent: since $\\nabla [-\\min_i \\langle z, E(x_i, f(x_i)\\rangle]=-\\mathrm{argmin}_i \\langle z, E(x_i, f(x_i)\\rangle$, the gradient descent is formulated as $z\\leftarrow z+\\alpha \\cdot \\mathrm{argmin_i}\\langle z, E(x_i, f(x_i))\\rangle$, which aligns with the iterative refinement in the paper.\n\nThen we will prove equation [\\[eqn:app_sample_invariance_final\\]](#eqn:app_sample_invariance_final){reference-type=\"ref\" reference=\"eqn:app_sample_invariance_final\"} produces a sample invariant encoding by proving $\\mathbf{F}_n$ converges to $$\\mathbf{F}_\\infty=\\mathrm{argmax}_{||z||=1}\\min _{x\\in X} \\langle z, E(x,f(x))\\rangle$$\n\nThroughout the proof, we use the following definitions:\n\n:::: center\n::: {#tab:app_sample_invariance_table}\n  -------------------------- -------------- --------------------------------------------------------------------------------------------------------------------\n      $S\\subset\\mathbb{C}^N$  $\\triangleq$  $\\bigcup_{x\\in X}E(x, f(x))$\n    $S_n\\subset\\mathbb{C}^N$  $\\triangleq$  $\\bigcup_{i=1}^n E(x_i, f(x_i))$\n                 $||\\cdot||$  $\\triangleq$  L2-norm of a complex vector.\n                       $d_H$  $\\triangleq$  $\\max_{q\\in Q}\\min_{p\\in P}||p-q||$. Hausdorff distance between two compact sets $P\\subset Q\\subset \\mathbb{C}^N$.\n                   $Ball(P)$  $\\triangleq$  the smallest solid ball that contains the compact set $P$.\n       $center(Ball(\\cdot))$  $\\triangleq$  center of the ball.\n  -------------------------- -------------- --------------------------------------------------------------------------------------------------------------------\n:::\n::::\n\n[]{#tab:app_sample_invariance_table label=\"tab:app_sample_invariance_table\"}\n\nRecall from equation [\\[eqn:FPE\\]](#eqn:FPE){reference-type=\"ref\" reference=\"eqn:FPE\"}, $E(x,y)=\\mathcal{F}^{-1}(e^{i(\\Phi x+\\Psi y)})$, so $||E(x,y)||=1$ for all $x$ and $y$. Since $||z_1-z_2||^2=||z_1||^2+||z_2||^2-2\\langle z_1, z_2\\rangle$, we have $\\langle z, E(x,y)\\rangle = 1-\\frac{1}{2}||z-E(x,y)||^2$ if $||z||^2=1$. Therefore, equation [\\[eqn:app_sample_invariance_final\\]](#eqn:app_sample_invariance_final){reference-type=\"ref\" reference=\"eqn:app_sample_invariance_final\"} is equivalent to $$\\mathbf{F}_n=\\mathrm{argmin}_{||z||=1} \\max_{i=1}^n ||z-E(x_i, f(x_i))||\\label{eqn:app_sample_invariance_euclead}$$\n\nNote that equation [\\[eqn:app_sample_invariance_euclead\\]](#eqn:app_sample_invariance_euclead){reference-type=\"ref\" reference=\"eqn:app_sample_invariance_euclead\"} implies **$\\mathbf{F}_n$ is the center of the smallest ball containing $S_n$**: $$\\mathbf{F}_n=center(Ball(S_n))\\label{eqn:app_sample_invariance_ball}$$ $$$$ because if we were to construct balls containing $S_n$ with a center $\\mathbf{F}'\\neq \\mathbf{F}_n$, the radius of the ball must be larger than the radius of $Ball(S_n)$.\n\n**When $n\\to\\infty$, the Hausdorff distance between $Ball(S_n)$ and $Ball(S)$ goes to 0 with probability one.** First, it is easy to see that $d_H(Ball(S_n), Ball(S))$ is a decreasing sequence and is positive, so the limit exists. Assume the limit is strictly positive, then there exists a point $p'\\in S$ such that $\\min_{q\\in S_n}||p'-q|| >c$ for some constant $c>0$ as $n\\to\\infty$. This means no sample is drawn from the ball $B_c(p')$. This is contradictory to the definition of $p:X\\rightarrow (0,1)$: $p$ is positive over the input space $X$.\n\nFinally, we conclude by $||\\mathbf{F}_n-\\mathbf{F}_\\infty||\\leq d_H(Ball(S_n), Ball(S))$. Since $Ball(S_n)\\subset Ball(S)$, from elementary geometry, if $A\\subset B$ are two balls, then $||center(B)-center(A)||\\leq radius(B)-radius(A)\\leq d_H(B,A)$. Therefore, we have $||center(Ball(S_n))-center(Ball(S))||\\leq d_H(Ball(S_n), Ball(S))$. Therefore, $||\\mathbf{F}_n-\\mathbf{F}_\\infty||\\leq d_H(Ball(S_n), Ball(S))$, which decays to 0 as $n\\to\\infty$. ◻\n:::::\n\n![Proof of asymptotic sample invariance (overview). $Ball(S)$ and $Ball(S_n)$ are the smallest ball containing $S$ and $S_n$. As $n\\to\\infty$, the Hausdorff distance between the two balls goes to zero with probability one. From elementary geometry, $||center(Ball(S_n))-center(Ball(S))||\\leq d_H(Ball(S_n), Ball(S))$. So the distance between the centers of the two balls goes to 0.](figs/proof.drawio.pdf){#fig:app_graph_proof width=\"50%\"}\n\n## Isometry {#sec:app_isometry}\n\nIn this section, we complete the proof that HDFE is an isometry.\n\n::: theorem*\n**Theorem 1**. *Let $f, g:X\\rightarrow Y$ be both $c$-Lipschitz continuous, then their L2-distance is preserved in the encoding. In other words, HDFE is an isometry: $$||f-g||_{L_2}=\\int_{x\\in X} \\big|f(x) - g(x)\\big|^2dx\\approx b -a\\langle \\mathbf{F}, \\mathbf{G}\\rangle$$*\n:::\n\n::: {#thm:lemma .lemma}\n**Lemma 4**. *$\\langle x\\otimes y, x\\otimes z\\rangle=\\langle y,z \\rangle$. *\n:::\n\n::: proof\n*Proof.* Let $x=e^{i\\mathbf{x}}$, $y=e^{i\\mathbf{y}}$, $z=e^{i\\mathbf{z}}$, $$\\begin{aligned}\n        \\langle x\\otimes y, x\\otimes z\\rangle &=\\langle e^{i(\\mathbf{x}+\\mathbf{y}))}, e^{i(\\mathbf{x}+\\mathbf{z})}\\rangle \\\\\n        &=e^{i(\\textbf{x}+ \\textbf{y})} \\cdot e^{-i(\\textbf{x}+ \\textbf{z})}\\\\\n        &=\\langle e^{i\\mathbf{y}}, e^{i\\mathbf{z}}\\rangle \\\\\n        &=\\langle y, z\\rangle\n    \n\\end{aligned}$$ ◻\n:::\n\n::: proof\n*Proof.* $$\\begin{aligned}\n    \\langle \\mathbf{F}, \\mathbf{G}\\rangle &= \\int_x \\int_{x'} \\langle E_X(x)\\otimes E_Y(f(x)), E_X(x')\\otimes E_Y(g(x')) \\rangle dx' dx \\\\\n    &= \\int_{|x-x'|<\\epsilon} \\langle E_X(x)\\otimes E_Y(f(x)), E_X(x')\\otimes E_Y(g(x'))\\rangle dx'dx\\\\\n    &\\qquad\\qquad+\\int_{|x-x'|>\\epsilon} \\langle E_X(x)\\otimes E_Y(f(x)), E_X(x')\\otimes E_Y(g(x'))\\rangle dx'dx\\\\\n    &= \\int_{x} \\langle E_X(x)\\otimes E_Y(f(x)), E_X(x)\\otimes E_Y(g(x))\\rangle dx + noise\\\\\n    &\\approx \\int_x \\langle E_Y(f(x)), E_Y(g(x))\\rangle dx \\qquad \\text{by Lemma \\ref{thm:lemma}.}\\\\\n    &=\\int_x\\sum_{k=0}^\\infty \\frac{(-1)^k}{(2k)!!}\\beta^{2k}(f(x)-g(x))^{2k}dx \\qquad\\text{by Theorem \\ref{thm:FPE}} \\\\\n    &\\approx b-a\\int_x |f(x)-g(x)|^2 dx \\qquad\\text{by taking the first and second order terms}\n\\end{aligned}$$ The second line holds because when $d_X(x,x')$ is larger than the receptive field $\\epsilon_0$, $E_X(x)$ and $E_X(x')$ will be orthogonal, so the similarity between $E_X(x)\\otimes E_Y(f(y))$ and $E_X(x')\\otimes E_Y(g(y))$ will be close to zero and they will be summed as noise. ◻\n:::"},{"heading":"Empirical Experiment of HDFE","text":"# Empirical Experiment of HDFE {#sec:app_empirical}\n\nIn this section, we verify the properties claimed in Sec. [\\[sec:properties\\]](#sec:properties){reference-type=\"ref\" reference=\"sec:properties\"} with empirical experiments.\n\n## Sample Invariance {#sec:app_experiment_sample_invariance}\n\nIn Fig. [10](#fig:fig3){reference-type=\"ref\" reference=\"fig:fig3\"}, we demonstrate that the function encoding produced by HDFE remains invariant of both the sample distribution and sample density. Specifically, we sample function values from three distinct input space distributions, namely left-skewed, right-skewed, and uniform distribution, each with sample sizes of either 5000 or 1000. We then calculate the similarity between the function vectors generated from these six sets of function samples. Before tuning the function vectors, the representation is influenced by the sample distributions (Fig. [10](#fig:fig3){reference-type=\"ref\" reference=\"fig:fig3\"} Mid). However, after the tuning process, the function vector becomes immune to the sample distribution (Fig. [10](#fig:fig3){reference-type=\"ref\" reference=\"fig:fig3\"} Right).\n\n<figure id=\"fig:fig3\">\n<figure>\n<img src=\"figs/app_sample_invariance/sample_distribution.jpeg\" />\n</figure>\n<figure>\n<img src=\"figs/app_sample_invariance/similarity_before.jpg\" />\n</figure>\n<figure>\n<img src=\"figs/app_sample_invariance/similarity_after.jpg\" />\n</figure>\n<figcaption>HDFE is invariant of sample distribution and sample size. <strong>Left</strong>: Three distributions where the function samples are drawn from. For each distribution, the sample size is either 5000 or 1000. <strong>Mid, Right</strong>: Similarity among the function vectors generated by the six sets of function samples, before and after the function vector tuning process, respectively.</figcaption>\n</figure>\n\n## Isometry {#sec:app_experiment_isometry}\n\nIn Fig. [11](#fig:isometry){reference-type=\"ref\" reference=\"fig:isometry\"}, we generate pairs of random functions and compute their function encodings through HDFE. We plot the L2-distance between the functions and the similarity between their encodings. We discover a strong correlation between them. This coincides the isometric property claimed in Theorem [2](#thm:isometry){reference-type=\"ref\" reference=\"thm:isometry\"}.\n\n![HDFE is a distance preserving transformation. The L2-distance between functions is proportional to the negative similarity between their encodings.](figs/isometry.jpeg){#fig:isometry width=\"40%\"}\n\n## Practical Consideration of Iterative Refinement {#sec:app_experiment_cost}\n\nIn Algorithm [\\[alg:1\\]](#alg:1){reference-type=\"ref\" reference=\"alg:1\"}, we propose one implementation of iterative refinement, which iteratively adds the sample encoding that has the minimum similarity with the function encoding. This implementation is a conservative implementation that guarantees asymptotic sample invariance. However, in practical applications, strict sample invariance may not be necessary. For example, achieving a similarity threshold of 0.99 when constructing with different samples might not be required. This relaxation is viable because the downstream neural network possesses an inherent ability to handle some level of inconsistency. Therefore, we consider a practical adaptation of Algorithm [\\[alg:1\\]](#alg:1){reference-type=\"ref\" reference=\"alg:1\"} by introducing slight modifications to accommodate these real-world considerations.\n\n**One-Shot Refinement** In Algorithm [\\[alg:1\\]](#alg:1){reference-type=\"ref\" reference=\"alg:1\"}, the motivation of the iterative refinement is to balance the weights between dense and sparse samples. By iterative refinement, we adjust the function encoding so that the sparse samples also contribute to the encoding. Such motivation can be achieved by another cheaper one-shot refinement. After obtaining the initial function encoding by averaging the sample encoding, we compute the similarity between this initial encoding and all the sample encodings. The similarity can serve as a rough estimation of the sample density at a particular point. Therefore, if we were to balance the weights between dense and sparse samples, we can simply recompute the weights by the inverse estimated density. Algorithm [\\[alg:app_oneshot_refinement\\]](#alg:app_oneshot_refinement){reference-type=\"ref\" reference=\"alg:app_oneshot_refinement\"} illustrates the procedure.\n\n:::: algorithm\n::: algorithmic\n$z_i \\gets E_X(x_i)\\otimes E_Y(f(x_i))$ for all $i$. $\\mathbf{F}=\\sum_i z_i$ $w_i = \\langle \\mathbf{F}, z_i\\rangle$ $w_i=\\max(\\epsilon, w_i)$ $w_i = w_i^{-1} / \\sum_{j=1}^n w_j^{-1}$ $\\mathbf{F}= \\sum_i w_i\\cdot z_i$\n:::\n::::\n\n**Although one-shot refinement is not strictly sample distribution invariant, it is a quite good approximation of the sample invariant function encoding and is very cheap to compute.** We perform a comparison among no refinement, one-shot refinement and iterative refinement with synthetic data, where we encode the same function sampled with two different distributions and compute the similarity between the two encodings. Specifically, we generate a random function by $$f(x)=\\frac{1}{2}+\\frac{1}{8}\\sum_{k=1}^4 a_k\\sin(2\\pi kx)\\label{eqn:app_random_function}$$ where $a_k\\sim Uniform(0, 1)$ are the parameters controlling the generation and $f(x)\\in(0,1)$. We construct the encoding of the function by samples from two different sample distributions. The first distribution is computed by $x_i\\sim Uniform(0,1)$ and $x_i\\leftarrow x_i^2$. The second distribution is computed by $x_i\\sim Uniform(0, 1)$ and $x_i\\leftarrow 1-x_i^2$. Consequently, the first distribution is left-tailed, and the second distribution is right-tailed. Then we compare the similarity of function encodings generated by no iterative refinement, one-shot refinement, and iterative refinement. Figure [12](#fig:app_refinement_comparison){reference-type=\"ref\" reference=\"fig:app_refinement_comparison\"} shows the comparison, which demonstrates that one-shot refinement is a quite good approximation of the sample invariant function encoding (the similarity increases from $\\sim$ 0.5 to 0.98 after one-shot refinement). In Appendix [15.4](#sec:app_efficacy_sample_invariance){reference-type=\"ref\" reference=\"sec:app_efficacy_sample_invariance\"}, Table [2](#tab:app_sample_invariance_table){reference-type=\"ref\" reference=\"tab:app_sample_invariance_table\"}, we also compare the effectiveness of the three refinement schemes in a synthetic regression problem.\n\n![When encoding the same function under two different sample distributions, one-shot refinement can approximate the sample invariant function encoding well. It takes 75/90/1500 ms to encode 5000 samples on a CPU, and 7.5/8.0/250 ms on an NVIDIA Titan-X GPU when performing no refinement/one-shot refinement/200-step iterative refinement.](figs/comparison_refinement.jpg){#fig:app_refinement_comparison width=\"45%\"}\n\n## Effectiveness of Sample Invariance {#sec:app_efficacy_sample_invariance}\n\nIn this section, we examine the effectiveness of HDFE's sample invariance property through an synthetic function regression problem. We first generate random functions by equation [\\[eqn:app_random_function\\]](#eqn:app_random_function){reference-type=\"ref\" reference=\"eqn:app_random_function\"}, where $a_k\\sim Uniform(0,1)$ are the parameters controlling the generation. The task is to regress the coefficients $\\left[a_1, a_2, a_3, a_4\\right]$ from the function samples $\\{x_i, f(x_i)\\}$. Regarding the sample size, the number of function samples is 5000 in the training phase and 2500 in the testing phase. Regarding sample distribution, we consider two different settings:\n\n**Setting 1 (No Sample Distribution Variation)**: The sample distribution is consistent between training phase and testing phase. We let $x_i\\sim Uniform(0, 1)$ in both training phase and testing phase.\n\n**Setting 2 (Sample Distribution Variation)**: The sample distribution is different between the training phase and testing phase. Specifically, in the training phase, we let $x_i\\sim Uniform(0, 1)$ and $x_i \\leftarrow x_i ^2$. In the testing phase, we let $x_i\\sim Uniform(0, 1)$ and $x_i\\leftarrow 1-x_i^2$. Consequently, the sample distribution in the training phase is left-tailed, while in the testing phase is right-tailed.\n\nWe compare our HDFE with PointNet in terms of mean squared error (MSE) and the R-squared ($R^2$) metrics. For HDFE, we compare the performance among no refinement, one-shot refinement (introduced in Appendix [15.3](#sec:app_experiment_cost){reference-type=\"ref\" reference=\"sec:app_experiment_cost\"}), and 200-step iterative refinement. Table [2](#tab:app_sample_invariance_table){reference-type=\"ref\" reference=\"tab:app_sample_invariance_table\"} shows the comparison.\n\nIn Setting 1, when there is no distribution variation, HDFE achieves significantly lower error than PointNet. This is because HDFE is capable of capturing the entire distribution of functions, while PointNet seems to struggle on that.\n\nIn Setting 2, when there is distribution variation, PointNet fails miserably, while HDFE, even without iterative refinement, already achieves fairly good estimation, and even better than the PointNet in Setting 1. In addition, the experiment also shows that both the one-shot refinement and the iterative refinement are effective techniques to improve the robustness to distribution variation.\n\n[]{#tab:app_sample_invariance_table label=\"tab:app_sample_invariance_table\"}\n\n## Information Loss of HDFE {#sec:app_information_loss}\n\nIn this section, we analyze the information loss when encoding continuous objects with HDFE. It is intuitive that a larger encoding dimensionality induces smaller information loss, and encoding a function changing more rapidly induces larger information loss. We attempt to quantify the relation through empirical experiments. We generate random functions and we measure the \"function complexity\\\" by the integral of the absolute gradient: $\\mathrm{complexity}(f)=\\int_0^1 |f'(x)|dx$. Consequently, functions changing more rapidly yield a higher $\\mathrm{complexity}(f)$.\n\nWe study the relation between the reconstruction mean absolute error (MAE) / R-squared ($R^2$) and the function complexity under different encoding dimensions. Figure [13](#fig:app_info_loss){reference-type=\"ref\" reference=\"fig:app_info_loss\"} reveals the MAE exhibits a linear relation with the input function complexity, while the R-squared seems not to be affected by the function complexity when the dimension is large enough.\n\n<figure id=\"fig:app_info_loss\">\n<figure>\n<img src=\"figs/app_info_loss/info_loss_err.jpg\" />\n</figure>\n<figure>\n<img src=\"figs/app_info_loss/info_loss_r2.jpg\" />\n</figure>\n<figcaption>Empirical information loss when encoding functions of different complexities.</figcaption>\n</figure>\n\n## Low-Rank High-Dimensional Scenarios {#sec:app_experiment_high_dimension}\n\nWe generate random functions by first randomizing $x_k\\in\\mathbb{R}^d$ and $\\alpha_k\\in\\mathbb{R}$, the random function is constructed by: $$f(x)=\\sum_{k=1}^n \\alpha_k\\cdot K(x,x_k)$$ where $n$ can measure the complexity of the function, and $d$ is the dimension of the function input. The testing samples are generated by $x_k+noise$ for all $k\\in[n]$.\n\nIn Fig. [14](#fig:high_dimension){reference-type=\"ref\" reference=\"fig:high_dimension\"}, the reconstruction error increases as $n$ increases, which indicates the encoding quality is negatively correlated to the complexity of the function. However, the reconstruction error does not change as $d$ increases, which indicates that the encoding quality does not depend on the explicit dimension of the function input.\n\nThis empirical experiment shows that HDFE has the potential to operate on high-dimensional data, because the encoding quality of HDFE does not depend on the dimension of the function input, but only depends on the complexity of the function.\n\n![The reconstruction error of HDFE is negatively correlated to the complexity of the function, but does not depend on the dimension of the function input.](figs/high_dimension.jpg){#fig:high_dimension width=\"40%\"}"},{"heading":"Experiment Details","text":"# Experiment Details {#sec:app_experiment_details}\n\n## PDE Solver {#sec:app_PDE_solver_details}\n\nThe PDE and the solution are encoded into two embedding vectors with length $N$. A deep complex network is trained to learn the mapping between two vectors. The architecture is a sequence of layers: `[ComplexLinear(N,256), ComplexReLU(), ComplexLinear(256,256), ComplexReLU(), ComplexLinear(256,256), ComplexReLU(), ComplexLinear(256,N)]`. The network is trained with Adam optimizer with a learning rate of 0.001 for 20,000 iterations. The $\\alpha$ value in equation [\\[eqn:FPE\\]](#eqn:FPE){reference-type=\"ref\" reference=\"eqn:FPE\"} is 15, 25, 42, 45 for $N=4000,8000,16000,24000$ and the $\\beta$ value is 2.5.\n\n## Surface Normal Estimation {#sec:app_normal_estimation_details}\n\nThe architecture is a sequence of layers: `[ComplexLinear(N,256), ComplexBatchNorm() ComplexReLU(), ComplexLinear(256,256), ComplexBatchNorm(), ComplexReLU(), ComplexLinear(256,128), ComplexBatchNorm(), ComplexReLU()]`. After the sequence of layers, it will produce a 128-dimensional complex vector `z`. Since we desire a 3-dimensional real vector output (normal vector in $\\mathbb{R}^3$), we use two `RealLinear(128,3)` layers `L_real` and `L_imag`. The final output normal vector is `L_real(z.real) + L_imag(z.imag)`. The network is trained with Adam optimizer with learning rate 0.001 for 270 epochs. The $\\alpha$ is chosen as 20 and the dimensionality is chosen as 4096.\n\n## Adding HDFE Module to HSurf-Net {#sec:app_hsurfnet_details}\n\nDenote the input local patch as $P$ with shape $(B, N, 3)$, where $B$ is the batch size, $N$ is the number of points in a local patch. HSurf-Net uses their novel space transformation module to extract $n$ keypoints and their $K$ nearest neighbors. The resulting data is denoted as $P\\_sub$ with shape $(B, n, K, 3)$. HSurf-Net uses a PointNet to process $P\\_sub$, by first lifting the dimension to $(B,n,K,C)$ and then doing a maxpooling to shape the data into $(B,n,C)$. We add our HDFE module here: we use HDFE to shape the data from $(B,n,K,3)$ to $(B,n,C)$, by first lifting the dimension from $(B,n,K,3)$ to $(B,n,K,512)$ using equation [\\[eqn:FPE\\]](#eqn:FPE){reference-type=\"ref\" reference=\"eqn:FPE\"} and then average the embedding across the neighbors to shape it into $(B, n, 512)$. Then we use a fully-connected layer to map the data into $(B, n, C)$, which becomes the HDFE feature. Then we sum the features generated by HSurf-Net and HDFE into a $(B,n,C)$ matrix and pass to the output layer as HSurf-Net does."},{"heading":"Ablation Studies of Surface Normal Estimation","text":"# Ablation Studies of Surface Normal Estimation {#sec:app_ablation}\n\nIn general, when the dimensionality is higher, the error is lower. When the receptive field is large ($\\alpha$ is small), HDFE performs better when the noise level is high. When the receptive field is small ($\\alpha$ is large), HDFE performs better when the noise level is low. This coincides with the analysis in Fig. [6](#fig:fig2){reference-type=\"ref\" reference=\"fig:fig2\"}. A large receptive field tends to filter out the perturbations and therefore is more robust to noise. A small receptive field can capture the high-frequency details and therefore is more accurate."},{"heading":"Noise Robustness","text":"# Noise Robustness {#sec:app_noise_robustness}\n\nIn this section, we further analyze why HDFE is robust to point perturbations. For visualization purposes, we perform the analysis on 2d data, while the analysis generalizes well to higher dimensions. We randomly sample 1000 points from the unit circle $x^2 + y^2 = 1$ and add Gaussian noises to the samples. Then we encode the points into vectors using HDFE with different receptive fields ($\\alpha=10, 15, 20, 25$) and reconstruct the implicit function. The pseudo-color plot in Fig. [15](#fig:app_noise){reference-type=\"ref\" reference=\"fig:app_noise\"} visualizes the likelihood that a point lies on the unit circle.\n\nWhen $\\alpha$ is small, the visualization shows that the reconstructions under different noise levels are similar, which tells that the encodings under different noise levels are similar. So it demonstrates a robustness to point perturbations. On the other hand, when $\\alpha$ is large, the reconstruction is more refined and captures the high-frequency details, but as a price, it is more sensitive to the point perturbations.\n\n![Reconstruction of implicit functions sampled with noisy inputs under different choices of receptive field.](figs/noise_robust.drawio.pdf){#fig:app_noise width=\"80%\"}"}],"approval":true,"conference":"iclr","rating":3,"year":2024,"id":"364820bed45b054e4ab112ecba6c7c614fdfe12faef0d2ec2fb3742d6ef4c658","y_true":1,"y_pred":1,"rationale_true":"Summary: This paper proposes Hyper-Dimensional Function Encoding (HDFE), which encodes a continuous object (eg, functions) into a fixed-size explicit vector representation without requiring training. While it maintains the benefits of vector function architecture (VFA), satisfying sample invariance and decodability, it relaxes the strict assumption on the function form in VFA into Lipschitz functions by introducing a novel iterative refinement process. While HDFE serves as a general interface for a continuous object encoder without training, substituting HDFE for domain-specific algorithms in experiments on mesh-grid data and sparse data shows comparable performance. \nThe main contributions of the papers are: \n\n(1) The authors propose a novel function encoding method that satisfies key properties of VFA while relaxing the strict assumption on function space to  Lipschitz continuity. \n\n(2) Theoretical foundations and empirical analysis support the validity of HDFE on key properties. \n\n(3) Experimental results confirm that replacing domain-specific algorithms with HDFE maintains competitive performance and robustness to the noise perturbation.\n\nStrengths: - The paper is well written and easy to follow. \n\n- The formulation of the decodable encoder and iterative refinement process for sample invariance seems interesting and convincing. Also, theoretical analysis on each component is clear and supports the claims.\n\n- Despite the general and straightforward formulation, empirical results demonstrate the effectiveness of HDFE.\n\nWeaknesses: Method\n\n- One concern is the computational cost of HDFE induced by the iterative refinement process. In order to employ function representation for the downstream tasks, computational costs of HDFE is important. it may hinder application to large-scale tasks. \n\nExperiment\n\n- Overall, it’s convincing that HDFE is a reasonable and general interface for processing continuous objects, supported by the experiments. However, it’s less convincing why we should use HDFE instead of other domain-specific encoding methods. The authors claim that sample invariance is a crucial property for the machine learning tasks throughout the paper, but it lacks the supporting experiment revealing HDFE’s efficacy in those scenarios (i.e., sample distributions are different in training and test dataset). It would make the paper stronger if it presents the experiments with scenarios having disparate sample distributions between training and test datasets and compares the performance of HDFE compared to the baselines. \n\n- In the experiment section, it lacks the analysis why HDFE is more beneficial than the counterparts (e.g., PointNet) in terms of the performance. It would improve the understanding of HDFE if analysis on which component leads to the performance gap even when the noise is absent is provided.\n\nQuestions: - How long does the HDFE take compared to the baselines (eg, pointNet in Experiment 3.2)? Is the iterative refinement process applicable to a large number of samples? How long does it take for convergence in the process? \n\n- In the formulation on decoding, (i.e., equation between eq. (2) and eq.(3)), can you please clarify on why orthogonality property ensures that $E_X(x_i) ⊘ E_X(x_0) $ will produce a vector orthogonal to $E_X(x_0)$ when the distance between two samples is large? Also what does the noise mean? Does it mean that it’s near zero so that it is a negligible component?\n\n- In the formulation on decoding, (i.e., equation between eq. (2) and eq.(3)), it seems it misses $w_i$. \n\n- For an unbinding operation, element-wise division of complex vectors is used. But I don't think this operation is commutative, which violates the assumption. Can you please clarify on this? \n\n- In experiment 3.1, how does the function prediction error is measured? Is it measured in embedding space? And the paper states that “when decoding is not required, our approach achieves lower error than FNO”, but how can we compare to FNO, which directly predicts the solution? \n\n- While the authors claim that HDFE is robust to point perturbation, the experiments on  [PCPNet - PointNet + HDFE] in Table 1 shows that the performance boost becomes much less as the noise level increases. Can you please elaborate on this?\n\n- [Possible Typo] In the last sentence in section 2.1, “appendix F.1” should be “appendix E.1”.","rationale_pred":"Paper Summary: The paper introduces Hyper-Dimensional Function Encoding (HDFE), a novel method for generating vector representations of continuous objects. HDFE is sample distribution and density invariant, decodable, and doesn't require training. It's applied to function-to-function mapping and point cloud surface normal estimation, showing competitive or improved performance compared to existing methods like PointNet.\n\nSupporting Evidence:\n- PointNet with KAN versus PointNet with MLP supports the idea of improving neural network performance on continuous objects through innovative architectures.\n- Geometry and Learning Co-Supported Normal Estimation highlights the importance of effective feature preservation and accuracy in normal estimation, aligning with HDFE's application in point cloud surface normal estimation.\n- Rethinking Network Design and Local Geometry in Point Cloud highlights the potential for innovative methods in point cloud processing.\n- SSRNet supports the claims by addressing the challenges of scalability and detail preservation in surface reconstruction from point clouds.\n- RISurConv supports the claims by addressing the challenge of rotation invariance in 3D point cloud analysis.\n- Implicit Neural Representations with Periodic Activation Functions supports the claims by highlighting the advantages of using advanced neural network architectures.\n- Event-Based Vision supports the claims by highlighting the need for novel methods to process unconventional data outputs.\n- PCPNet Learning Local Shape Properties from Raw Point Clouds supports the claims by demonstrating the effectiveness of local shape property estimation in point clouds.\n- 3DSSD: Point-Based 3D Single Stage Object Detector supports the claims by demonstrating the effectiveness of point-based methods in 3D object detection.\n- Modeling Point Clouds With Self-Attention and Gumbel Subset Sampling supports the claims by demonstrating advanced techniques in processing point clouds.\n\nContradictory Evidence:\n- Copula Density Neural Estimation contrasts by focusing on probability density estimation rather than encoding continuous objects.\n- Enhancing 3D implicit shape representation by leveraging periodic activation functions contrasts by focusing on the enhancement of 3D implicit shape representations through periodic activation functions, rather than the sample invariant encoding proposed by HDFE.\n- Relative representations enable zero-shot latent space communication contrasts by emphasizing the challenges of achieving coherent latent spaces in neural networks.\n- Analyzing the Dynamics of Gated Auto-encoders contrasts by focusing on gated auto-encoders (GAEs) as a representation learning method.\n- Spectral Graph Theory and Deep Learning on Graphs contrasts by emphasizing the importance of learning representations that capture both individual sample characteristics and their relationships within a dataset, using graph convolution methods.\n\nConclusion: The paper introduces a novel approach (HDFE) for encoding continuous objects with properties like sample invariance and decodability. While related works explore alternative encoding methods and improvements in point cloud processing, HDFE's specific combination of properties and its training-free nature appear to be unique. The contrasting papers highlight different approaches to representation learning, further suggesting that HDFE offers a distinct contribution. Therefore, the paper demonstrates novelty.","structured_evaluation":{"paper_summary":"The paper introduces Hyper-Dimensional Function Encoding (HDFE), a novel method for generating vector representations of continuous objects. HDFE is sample distribution and density invariant, decodable, and doesn't require training. It's applied to function-to-function mapping and point cloud surface normal estimation, showing competitive or improved performance compared to existing methods like PointNet.","supporting_evidence":["PointNet with KAN versus PointNet with MLP supports the idea of improving neural network performance on continuous objects through innovative architectures.","Geometry and Learning Co-Supported Normal Estimation highlights the importance of effective feature preservation and accuracy in normal estimation, aligning with HDFE's application in point cloud surface normal estimation.","Rethinking Network Design and Local Geometry in Point Cloud highlights the potential for innovative methods in point cloud processing.","SSRNet supports the claims by addressing the challenges of scalability and detail preservation in surface reconstruction from point clouds.","RISurConv supports the claims by addressing the challenge of rotation invariance in 3D point cloud analysis.","Implicit Neural Representations with Periodic Activation Functions supports the claims by highlighting the advantages of using advanced neural network architectures.","Event-Based Vision supports the claims by highlighting the need for novel methods to process unconventional data outputs.","PCPNet Learning Local Shape Properties from Raw Point Clouds supports the claims by demonstrating the effectiveness of local shape property estimation in point clouds.","3DSSD: Point-Based 3D Single Stage Object Detector supports the claims by demonstrating the effectiveness of point-based methods in 3D object detection.","Modeling Point Clouds With Self-Attention and Gumbel Subset Sampling supports the claims by demonstrating advanced techniques in processing point clouds."],"contradictory_evidence":["Copula Density Neural Estimation contrasts by focusing on probability density estimation rather than encoding continuous objects.","Enhancing 3D implicit shape representation by leveraging periodic activation functions contrasts by focusing on the enhancement of 3D implicit shape representations through periodic activation functions, rather than the sample invariant encoding proposed by HDFE.","Relative representations enable zero-shot latent space communication contrasts by emphasizing the challenges of achieving coherent latent spaces in neural networks.","Analyzing the Dynamics of Gated Auto-encoders contrasts by focusing on gated auto-encoders (GAEs) as a representation learning method.","Spectral Graph Theory and Deep Learning on Graphs contrasts by emphasizing the importance of learning representations that capture both individual sample characteristics and their relationships within a dataset, using graph convolution methods."],"conclusion":"The paper introduces a novel approach (HDFE) for encoding continuous objects with properties like sample invariance and decodability. While related works explore alternative encoding methods and improvements in point cloud processing, HDFE's specific combination of properties and its training-free nature appear to be unique. The contrasting papers highlight different approaches to representation learning, further suggesting that HDFE offers a distinct contribution. Therefore, the paper demonstrates novelty.","label":1,"rationale":"Paper Summary: The paper introduces Hyper-Dimensional Function Encoding (HDFE), a novel method for generating vector representations of continuous objects. HDFE is sample distribution and density invariant, decodable, and doesn't require training. It's applied to function-to-function mapping and point cloud surface normal estimation, showing competitive or improved performance compared to existing methods like PointNet.\n\nSupporting Evidence:\n- PointNet with KAN versus PointNet with MLP supports the idea of improving neural network performance on continuous objects through innovative architectures.\n- Geometry and Learning Co-Supported Normal Estimation highlights the importance of effective feature preservation and accuracy in normal estimation, aligning with HDFE's application in point cloud surface normal estimation.\n- Rethinking Network Design and Local Geometry in Point Cloud highlights the potential for innovative methods in point cloud processing.\n- SSRNet supports the claims by addressing the challenges of scalability and detail preservation in surface reconstruction from point clouds.\n- RISurConv supports the claims by addressing the challenge of rotation invariance in 3D point cloud analysis.\n- Implicit Neural Representations with Periodic Activation Functions supports the claims by highlighting the advantages of using advanced neural network architectures.\n- Event-Based Vision supports the claims by highlighting the need for novel methods to process unconventional data outputs.\n- PCPNet Learning Local Shape Properties from Raw Point Clouds supports the claims by demonstrating the effectiveness of local shape property estimation in point clouds.\n- 3DSSD: Point-Based 3D Single Stage Object Detector supports the claims by demonstrating the effectiveness of point-based methods in 3D object detection.\n- Modeling Point Clouds With Self-Attention and Gumbel Subset Sampling supports the claims by demonstrating advanced techniques in processing point clouds.\n\nContradictory Evidence:\n- Copula Density Neural Estimation contrasts by focusing on probability density estimation rather than encoding continuous objects.\n- Enhancing 3D implicit shape representation by leveraging periodic activation functions contrasts by focusing on the enhancement of 3D implicit shape representations through periodic activation functions, rather than the sample invariant encoding proposed by HDFE.\n- Relative representations enable zero-shot latent space communication contrasts by emphasizing the challenges of achieving coherent latent spaces in neural networks.\n- Analyzing the Dynamics of Gated Auto-encoders contrasts by focusing on gated auto-encoders (GAEs) as a representation learning method.\n- Spectral Graph Theory and Deep Learning on Graphs contrasts by emphasizing the importance of learning representations that capture both individual sample characteristics and their relationships within a dataset, using graph convolution methods.\n\nConclusion: The paper introduces a novel approach (HDFE) for encoding continuous objects with properties like sample invariance and decodability. While related works explore alternative encoding methods and improvements in point cloud processing, HDFE's specific combination of properties and its training-free nature appear to be unique. The contrasting papers highlight different approaches to representation learning, further suggesting that HDFE offers a distinct contribution. Therefore, the paper demonstrates novelty."},"arxiv_id":"2311.00187"},"terms":{"tasks":["classification","regression","function-to-function mapping","point cloud surface normal estimation"],"methods":["Hyper-Dimensional Function Encoding"],"metrics":["error reductions"],"resources":["PointNet"],"relations":[{"head":"Hyper-Dimensional Function Encoding","tail":"classification"},{"head":"Hyper-Dimensional Function Encoding","tail":"regression"},{"head":"Hyper-Dimensional Function Encoding","tail":"function-to-function mapping"},{"head":"Hyper-Dimensional Function Encoding","tail":"point cloud surface normal estimation"},{"head":"error reductions","tail":"function-to-function mapping"},{"head":"error reductions","tail":"point cloud surface normal estimation"},{"head":"PointNet","tail":"function-to-function mapping"},{"head":"PointNet","tail":"point cloud surface normal estimation"}]},"background":"Given samples of a continuous object (e.g. a function), HDFE produces an explicit vector representation of the given object, invariant to the sample distribution and density. Sample distribution and density invariance enables HDFE to consistently encode continuous objects regardless of their sampling, and therefore allows neural networks to receive continuous objects as inputs for machine learning tasks, such as classification and regression. Besides, HDFE does not require any training and is proved to map the object into an organized embedding space, which facilitates the training of the downstream tasks. In addition, the encoding is decodable, which enables neural networks to regress continuous objects by regressing their encodings.","target":"We propose Hyper-Dimensional Function Encoding (HDFE). Therefore, HDFE serves as an interface for processing continuous objects. We apply HDFE to function-to-function mapping, where vanilla HDFE achieves competitive performance with the state-of-the-art algorithm. We apply HDFE to point cloud surface normal estimation, where a simple replacement from PointNet to HDFE leads to 12% and 15% error reductions in two benchmarks. In addition, by integrating HDFE into the PointNet-based SOTA network, we improve the SOTA baseline by 2.5% and 1.7% on the same benchmarks."},{"graph":{"title":"JPEG Inspired Deep Learning","abstract":"Although it is traditionally believed that lossy image compression, such as JPEG compression, has a negative impact on the performance of deep neural networks (DNNs), it is shown by recent works that well-crafted JPEG compression can actually improve the performance of deep learning (DL). Inspired by this, we propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer. To make the quantization operation in JPEG compression trainable, a new differentiable soft quantizer is employed at the JPEG layer, and then the quantization operation and underlying DNN are jointly trained. Extensive experiments show that in comparison with the standard DL,  JPEG-DL delivers significant accuracy improvements across various datasets and model architectures while enhancing robustness against adversarial attacks. Particularly, on some fine-grained image classification datasets, JPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is available on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git.","entities":[{"label":"JPEG Inspired Deep Learning","type":"title","detail":null,"excerpts":null},{"label":"general machine learning (i.e., none of the above)","type":"primary_area","detail":null,"excerpts":null},{"label":"JPEG compression","type":"keyword","detail":null,"excerpts":null},{"label":"deep learning","type":"keyword","detail":null,"excerpts":null},{"label":"trainable JPEG compression layer","type":"keyword","detail":null,"excerpts":null},{"label":"differentiable soft quantizer","type":"keyword","detail":null,"excerpts":null},{"label":"adversarial robustness","type":"keyword","detail":null,"excerpts":null},{"label":"We propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer, employing a new differentiable soft quantizer at the JPEG layer, and jointly training the quantization operation and underlying DNN.","type":"tldr","detail":null,"excerpts":null},{"label":"Introduction of a trainable JPEG layer","type":"claim","detail":"The paper introduces a novel trainable JPEG layer that leverages differentiable soft quantizers with analytical formulas, enabling gradient-based optimization for quantization parameters.","excerpts":[{"section":"Introduction","text":"We introduce a novel trainable JPEG layer leveraging differentiable soft quantizers with nice analytical formulas."}]},{"label":"JPEG-DL framework proposal","type":"claim","detail":"The paper proposes a new DL framework called JPEG-DL, which jointly optimizes the JPEG layer and the DNN model during training, integrating the JPEG layer directly after the original input layer of any underlying DNN architecture.","excerpts":[{"section":"Introduction","text":"Based on the new JPEG layer, we propose a new DL framework dubbed JPEG-DL, which jointly optimizes the JPEG layer and the DNN model during training."},{"section":"Introduction","text":"We then present JPEG-DL, a novel deep learning (DL) framework that introduces a new DNN architecture by inserting a JPEG layer directly after the original input layer of any underlying DNN architecture."}]},{"label":"Superior performance of JPEG-DL","type":"claim","detail":"The paper claims that JPEG-DL outperforms standard DL, verified by comprehensive experimental results on various image classification datasets across multiple DNN architectures, demonstrating significant gains in accuracy and enhanced adversarial robustness.","excerpts":[{"section":"Introduction","text":"The outstanding performance of JPEG-DL over the standard DL is verified by comprehensive experimental results on various image classification datasets across multiple DNN architectures and for a variety of tasks including adversarial defense."},{"section":"Abstract","text":"Extensive experiments show that in comparison with the standard DL,  JPEG-DL delivers significant accuracy improvements across various datasets and model architectures while enhancing robustness against adversarial attacks."}]},{"label":"JPEG-DL improves adversarial robustness","type":"claim","detail":"JPEG-DL improves the adversarial robustness of the learned model.","excerpts":[{"section":"Conclusion","text":"Additionally, we demonstrate that JPEG-DL improves the adversarial robustness of the learned model."}]},{"label":"Trainable JPEG Layer with Differentiable Soft Quantizers","type":"method","detail":"The method involves creating a trainable JPEG layer by replacing the hard quantization step with a differentiable soft quantizer ($Q_d$) defined by an analytical formula. This allows for gradient-based optimization of quantization parameters and introduces additional trainable non-linearity.","excerpts":[{"section":"Introduction","text":"To this end, we first introduce a trainable JPEG compression layer, the structure of which is illustrated in Fig. [\\[fig:jpeg_dl_a\\]](#fig:jpeg_dl_a){reference-type=\"ref\" reference=\"fig:jpeg_dl_a\"}."},{"section":"Introduction","text":"A novel differentiable soft quantizer ($Q_d$) is then applied to quantize the DCT coefficients at each frequency position, followed by the standard JPEG inverse process to reconstruct the RGB image."},{"section":"Introduction","text":"The core of JPEG-DL is $Q_d$ as it substitutes the non-differentiable, hard quantization in JPEG with a differentiable, soft quantization operation defined by a neat analytical formula, which not only facilitates gradient-based optimization for quantization parameters but also introduces additional trainable non-linearity to the overall image understanding pipeline."},{"section":"JPEG-DL: JPEG Inspired DL","text":"Substituting $Q_u$ in $\\mathcal{J}$ with $Q_d$, we get a differentiable JPEG layer $\\hat{\\mathcal{J}}$ parameterized by $Q$ and $\\boldsymbol{\\alpha}$, where $\\boldsymbol{\\alpha}=(\\boldsymbol{\\alpha}_Y, \\boldsymbol{\\alpha}_C)$."}]},{"label":"JPEG-DL Framework","type":"method","detail":"The JPEG-DL framework prepends a trainable JPEG compression layer to any underlying DNN architecture. The JPEG layer and the DNN model weights are jointly optimized during training. The framework uses a differentiable soft quantizer to facilitate gradient-based optimization.","excerpts":[{"section":"Introduction","text":"We then present JPEG-DL, a novel deep learning (DL) framework that introduces a new DNN architecture by inserting a JPEG layer directly after the original input layer of any underlying DNN architecture."},{"section":"Introduction","text":"This layer can be considered an integral part of any underlying DNN architecture, forming a new unified DNN architecture, whose parameters get optimized jointly with DNN model weights during training."},{"section":"JPEG-DL: JPEG Inspired DL","text":"Overall, for an input image $x$, we have $\\hat{x}=\\hat{\\mathcal{J}}(x;Q,\\boldsymbol{\\alpha})$. Therefore, we can rewrite ([\\[eq:jpeg-dl\\]](#eq:jpeg-dl){reference-type=\"ref\" reference=\"eq:jpeg-dl\"}), the JPEG-DL formulation, as $$\\label{eq:diff-jpeg-dl}\n\\min_{\\theta, Q, \\boldsymbol{\\alpha}}~\\mathbb{E}[\\mathcal{L}( f_{\\theta}(\\hat{\\mathcal{J}}(x;Q,\\boldsymbol{\\alpha})), y)],$$ where the expectation can be approximated by the empirical mean over a mini-batch in actual training."}]},{"label":"CIFAR-100 Experiments","type":"experiment","detail":"The method was evaluated on CIFAR-100 using EfficientFormer-L1, ResNet (ResNet32, ResNet56, ResNet110), VGG (VGG8, VGG13), MobileNet, and ShuffleNet architectures, following the training recipe from CRD for CNNs and the setup proposed by @xu2023initializing for EfficientFormer-L1.","excerpts":[{"section":"Experiments","text":"We evaluate our proposed method using a transformer-based architecture and four state-of-the-art convolutional neural networks (CNNs): EfficientFormer-L1 [@li2022efficientformer], ResNet [@he2016deep], VGG [@simonyan2014very], MobileNet [@sandler2018mobilenetv2], and ShuffleNet [@ma2018shufflenet]."},{"section":"Experiments","text":"For ResNet, we employ CIFAR-specific versions: ResNet32, ResNet56, and ResNet110. For VGG, we utilize VGG8 and VGG13."},{"section":"Experiments","text":"All CNN architectures follow the training recipe from CRD [@tian2019crd] (see Appendix [7.3](#app:cnn_settings){reference-type=\"ref\" reference=\"app:cnn_settings\"}), while for the transformer-based architecture, EfficientFormer-L1, we adhere to the setup proposed by @xu2023initializing (see Appendix [7.5](#app:transformer-based_settings){reference-type=\"ref\" reference=\"app:transformer-based_settings\"})."}]},{"label":"Fine-grained Tasks Experiments","type":"experiment","detail":"The method was evaluated on CUB-200-2011, Stanford Dogs, Flowers, and Pets datasets using PreAct ResNet-18 and DenseNet-BC for CNN architectures, and EfficientFormer-L1 for the transformer-based architecture, following the experimental setup and architecture modifications of @zhang2017mixup and the setup outlined by @xu2023initializing.","excerpts":[{"section":"Experiments","text":"We evaluate our method on four datasets: CUB-200-2011 [@wah2011caltech], Stanford Dogs [@khosla2011novel], Flowers [@nilsback2008automated], and Pets [@parkhi2012cats]."},{"section":"Experiments","text":"For CNN architectures, we employ PreAct ResNet-18 [@he2016deep] and DenseNet-BC [@huang2017densely], following the experimental setup and architecture modifications of @zhang2017mixup."},{"section":"Experiments","text":"For the transformer-based architecture, we use EfficientFormer-L1, adopting the setup outlined by @xu2023initializing (see Appendices [7.4](#app:fine_grained){reference-type=\"ref\" reference=\"app:fine_grained\"} and [7.5](#app:transformer-based_settings){reference-type=\"ref\" reference=\"app:transformer-based_settings\"})."}]},{"label":"ImageNet-1K Experiments","type":"experiment","detail":"The method was evaluated on ImageNet-1K using SqueezeNet, ResNet-18, and ResNet-34, utilizing the standard training recipes without any modifications.","excerpts":[{"section":"Experiments","text":"For all experiments on this dataset, we utilize the standard training recipes shown by @paszke2019pytorch without any modifications."},{"section":"Experiments","text":"We use SqueezeNet [@iandola2016squeezenet], ResNet-18 and ResNet-34 as our testing underlying models."}]}],"relationships":[{"source":"JPEG Inspired Deep Learning","target":"general machine learning (i.e., none of the above)"},{"source":"JPEG Inspired Deep Learning","target":"JPEG compression"},{"source":"JPEG Inspired Deep Learning","target":"deep learning"},{"source":"JPEG Inspired Deep Learning","target":"trainable JPEG compression layer"},{"source":"JPEG Inspired Deep Learning","target":"differentiable soft quantizer"},{"source":"JPEG Inspired Deep Learning","target":"adversarial robustness"},{"source":"JPEG Inspired Deep Learning","target":"We propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer, employing a new differentiable soft quantizer at the JPEG layer, and jointly training the quantization operation and underlying DNN."},{"source":"We propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer, employing a new differentiable soft quantizer at the JPEG layer, and jointly training the quantization operation and underlying DNN.","target":"Introduction of a trainable JPEG layer"},{"source":"We propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer, employing a new differentiable soft quantizer at the JPEG layer, and jointly training the quantization operation and underlying DNN.","target":"JPEG-DL framework proposal"},{"source":"We propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer, employing a new differentiable soft quantizer at the JPEG layer, and jointly training the quantization operation and underlying DNN.","target":"Superior performance of JPEG-DL"},{"source":"We propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer, employing a new differentiable soft quantizer at the JPEG layer, and jointly training the quantization operation and underlying DNN.","target":"JPEG-DL improves adversarial robustness"},{"source":"Introduction of a trainable JPEG layer","target":"Trainable JPEG Layer with Differentiable Soft Quantizers"},{"source":"JPEG-DL framework proposal","target":"JPEG-DL Framework"},{"source":"Superior performance of JPEG-DL","target":"JPEG-DL Framework"},{"source":"JPEG-DL improves adversarial robustness","target":"JPEG-DL Framework"},{"source":"Trainable JPEG Layer with Differentiable Soft Quantizers","target":"CIFAR-100 Experiments"},{"source":"Trainable JPEG Layer with Differentiable Soft Quantizers","target":"Fine-grained Tasks Experiments"},{"source":"Trainable JPEG Layer with Differentiable Soft Quantizers","target":"ImageNet-1K Experiments"},{"source":"JPEG-DL Framework","target":"CIFAR-100 Experiments"},{"source":"JPEG-DL Framework","target":"Fine-grained Tasks Experiments"},{"source":"JPEG-DL Framework","target":"ImageNet-1K Experiments"}],"valid_status":"Valid","valid_status_all":["Valid"]},"related":[{"summary":"The Related Paper, 'Sharpness-aware Quantization for Deep Neural Networks', supports the Main Paper by providing insights into the challenges of quantization in deep learning models, which is a key aspect of the JPEG-DL framework. Both papers emphasize the importance of improving model performance through innovative quantization techniques. While the Main Paper introduces a trainable JPEG compression layer to enhance accuracy and robustness, the Related Paper's Sharpness-Aware Quantization (SAQ) method addresses the stability of quantized models during training, thereby complementing the Main Paper's findings on the benefits of quantization in deep learning.","paper_id":"440a9a4e8571441da570c15ef3c30d19937dfd10","title":"Sharpness-aware Quantization for Deep Neural Networks","abstract":"Network quantization is a dominant paradigm of model compression. However, the abrupt changes in quantized weights during training often lead to severe loss fluctuations and result in a sharp loss landscape, making the gradients unstable and thus degrading the performance. Recently, Sharpness-Aware Minimization (SAM) has been proposed to smooth the loss landscape and improve the generalization performance of the models. Nevertheless, directly applying SAM to the quantized models can lead to perturbation mismatch or diminishment issues, resulting in suboptimal performance. In this paper, we propose a novel method, dubbed Sharpness-Aware Quantization (SAQ), to explore the effect of SAM in model compression, particularly quantization for the first time. Specifically, we first provide a unified view of quantization and SAM by treating them as introducing quantization noises and adversarial perturbations to the model weights, respectively. According to whether the noise and perturbation terms depend on each other, SAQ can be formulated into three cases, which are analyzed and compared comprehensively. Furthermore, by introducing an efficient training strategy, SAQ only incurs a little additional training overhead compared with the default optimizer (e.g., SGD or AdamW). Extensive experiments on both convolutional neural networks and Transformers across various datasets (i.e., ImageNet, CIFAR-10/100, Oxford Flowers-102, Oxford-IIIT Pets) show that SAQ improves the generalization performance of the quantized models, yielding the SOTA results in uniform quantization. For example, on ImageNet, SAQ outperforms AdamW by 1.2% on the Top-1 accuracy for 4-bit ViT-B/16. Our 4-bit ResNet-50 surpasses the previous SOTA method by 0.9% on the Top-1 accuracy.","score":0.7430941462516785,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"Inspired by this, we propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer. To make the quantization operation in JPEG compression trainable, a new differentiable soft quantizer is employed at the JPEG layer, and then the quantization operation and underlying DNN are jointly trained. Extensive experiments show that in comparison with the standard DL, JPEG-DL delivers significant accuracy improvements across various datasets and model architectures while enhancing robustness against adversarial attacks. Particularly, on some fine-grained image classification datasets, JPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is available on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git."},{"summary":"The Related Paper, FxP-QNet, supports the Main Paper by emphasizing the importance of quantization in deep neural networks (DNNs) and its impact on model efficiency and accuracy. While the Main Paper introduces a novel JPEG-DL framework that incorporates a trainable JPEG compression layer to enhance DNN performance, the Related Paper focuses on a post-training quantization method that optimizes low-precision representations for DNNs. Both papers highlight the trade-offs between compression and accuracy, with the Related Paper providing empirical evidence of effective quantization strategies that align with the Main Paper's claims of improved performance through innovative compression techniques.","paper_id":"d419b3ebe1fd5cf6c20e55bd3eb693d9460d162f","title":"FxP-QNet: A Post-Training Quantizer for the Design of Mixed Low-Precision DNNs with Dynamic Fixed-Point Representation","abstract":"Deep neural networks (DNNs) have demonstrated their effectiveness in a wide range of computer vision tasks, with the state-of-the-art results obtained through complex and deep structures that require intensive computation and memory. In the past, graphic processing units enabled these breakthroughs because of their greater computational speed. Now-a-days, efficient model inference is crucial for consumer applications on resource-constrained platforms. As a result, there is much interest in the research and development of dedicated deep learning (DL) hardware to improve the throughput and energy efficiency of DNNs. Low-precision representation of DNN data-structures through quantization would bring great benefits to specialized DL hardware especially when expensive floating-point operations can be avoided and replaced by more efficient fixed-point operations. However, the rigorous quantization leads to a severe accuracy drop. As such, quantization opens a large hyper-parameter space at bit-precision levels, the exploration of which is a major challenge. In this paper, we propose a novel framework referred to as the Fixed-Point Quantizer of deep neural Networks (FxP-QNet) that flexibly designs a mixed low-precision DNN for integer-arithmetic-only deployment. Specifically, the FxP-QNet gradually adapts the quantization level for each data-structure of each layer based on the trade-off between the network accuracy and the low-precision requirements. Additionally, it employs post-training self-distillation and network prediction error statistics to optimize the quantization of floating-point values into fixed-point numbers. Examining FxP-QNet1 on state-of-the-art architectures and the benchmark ImageNet dataset, we empirically demonstrate the effectiveness of FxP-QNet in achieving the accuracy-compression trade-off without the need for training. The results show that FxP-QNet-quantized AlexNet, VGG-16, and ResNet-18 reduce the overall memory requirements of their full-precision counterparts by 7.16×, 10.36×, and 6.44× with less than 0.95%, 0.95%, and 1.99% accuracy drop, respectively.","score":0.7328503727912903,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"Inspired by this, we propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer. To make the quantization operation in JPEG compression trainable, a new differentiable soft quantizer is employed at the JPEG layer, and then the quantization operation and underlying DNN are jointly trained. Extensive experiments show that in comparison with the standard DL, JPEG-DL delivers significant accuracy improvements across various datasets and model architectures while enhancing robustness against adversarial attacks. Particularly, on some fine-grained image classification datasets, JPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is available on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git."},{"summary":"The Related Paper supports the Main Paper by providing insights into quantization techniques that enhance the training of deep neural networks. While the Main Paper introduces a novel JPEG-DL framework that incorporates a trainable JPEG compression layer to improve accuracy and robustness, the Related Paper discusses a layer-wise precision-adaptive quantization method that stabilizes data distribution during training. This complementary approach reinforces the Main Paper's claims by demonstrating that effective quantization strategies can lead to significant performance improvements in deep learning, thus validating the potential benefits of the JPEG-inspired method proposed.","paper_id":"b174629cf0677c22841cf6da462c515b50ab1d22","title":"Fixed-Point Back-Propagation Training","abstract":"Recent emerged quantization technique (i.e., using low bit-width fixed-point data instead of high bit-width floating-point data) has been applied to inference of deep neural networks for fast and efficient execution. However, directly applying quantization in training can cause significant accuracy loss, thus remaining an open challenge. In this paper, we propose a novel training approach, which applies a layer-wise precision-adaptive quantization in deep neural networks. The new training approach leverages our key insight that the degradation of training accuracy is attributed to the dramatic change of data distribution. Therefore, by keeping the data distribution stable through a layer-wise precision-adaptive quantization, we are able to directly train deep neural networks using low bit-width fixed-point data and achieve guaranteed accuracy, without changing hyper parameters. Experimental results on a wide variety of network architectures (e.g., convolution and recurrent networks) and applications (e.g., image classification, object detection, segmentation and machine translation) show that the proposed approach can train these neural networks with negligible accuracy losses (-1.40%-1.3%, 0.02% on average), and speed up training by 252% on a state-of-the-art Intel CPU.","score":0.7270384430885315,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"Inspired by this, we propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer. To make the quantization operation in JPEG compression trainable, a new differentiable soft quantizer is employed at the JPEG layer, and then the quantization operation and underlying DNN are jointly trained. Extensive experiments show that in comparison with the standard DL, JPEG-DL delivers significant accuracy improvements across various datasets and model architectures while enhancing robustness against adversarial attacks. Particularly, on some fine-grained image classification datasets, JPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is available on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git."},{"summary":"The Related Paper discusses advancements in quantization techniques for deep learning models, particularly focusing on MobileNets. It supports the Main Paper's claims by emphasizing the importance of quantization-friendly architectures, which aligns with the Main Paper's innovative approach of integrating a trainable JPEG compression layer in deep learning frameworks. Both papers highlight the potential for improved performance and efficiency in deep learning through effective quantization strategies, reinforcing the Main Paper's findings on accuracy enhancements and robustness.","paper_id":"c9b61aab2ce451612b1df245af80efd480dd3468","title":"A Quantization-Friendly Separable Convolution for MobileNets","abstract":"As deep learning (DL) is being rapidly pushed to edge computing, researchers invented various ways to make inference computation more efficient on mobile/IoT devices, such as network pruning, parameter compression, and etc. Quantization, as one of the key approaches, can effectively offload GPU, and make it possible to deploy DL on fixed-point pipeline. Unfortunately, not all existing networks design are friendly to quantization. For example, the popular lightweight MobileNetV1, while it successfully reduces parameter size and computation latency with separable convolution, our experiment shows its quantized models have large performance gap against its float point models. To resolve this, we analyzed the root cause of quantization loss and proposed a quantization-friendly separable convolution architecture. By evaluating the image classification task on ImageNet2012 dataset, our modified MobileNetV1 model can archive 8-bit inference top-1 accuracy in 68.03%, almost closed the gap to the float pipeline.","score":0.7231389880180359,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"Inspired by this, we propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer. To make the quantization operation in JPEG compression trainable, a new differentiable soft quantizer is employed at the JPEG layer, and then the quantization operation and underlying DNN are jointly trained. Extensive experiments show that in comparison with the standard DL, JPEG-DL delivers significant accuracy improvements across various datasets and model architectures while enhancing robustness against adversarial attacks. Particularly, on some fine-grained image classification datasets, JPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is available on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git."},{"summary":"The Related Paper supports the Main Paper by demonstrating that JPEG compression can effectively mitigate adversarial attacks on deep neural networks (DNNs), aligning with the Main Paper's claim that JPEG-inspired techniques can enhance DNN performance. Both papers highlight the benefits of JPEG compression in improving robustness against adversarial samples, with the Related Paper providing empirical evidence of JPEG's effectiveness as a pre-processing step to reduce the impact of adversarial perturbations, thereby reinforcing the Main Paper's findings on accuracy improvements and robustness.","paper_id":"8ab5d59c6534039e6854cdb60a8519e0e96bde03","title":"Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression","abstract":"Deep neural networks (DNNs) have achieved great success in solving a variety of machine learning (ML) problems, especially in the domain of image recognition. However, recent research showed that DNNs can be highly vulnerable to adversarially generated instances, which look seemingly normal to human observers, but completely confuse DNNs. These adversarial samples are crafted by adding small perturbations to normal, benign images. Such perturbations, while imperceptible to the human eye, are picked up by DNNs and cause them to misclassify the manipulated instances with high confidence. In this work, we explore and demonstrate how systematic JPEG compression can work as an effective pre-processing step in the classification pipeline to counter adversarial attacks and dramatically reduce their effects (e.g., Fast Gradient Sign Method, DeepFool). An important component of JPEG compression is its ability to remove high frequency signal components, inside square blocks of an image. Such an operation is equivalent to selective blurring of the image, helping remove additive perturbations. Further, we propose an ensemble-based technique that can be constructed quickly from a given well-performing DNN, and empirically show how such an ensemble that leverages JPEG compression can protect a model from multiple types of adversarial attacks, without requiring knowledge about the model.","score":0.7225937247276306,"polarity":"positive","source":"semantic","contexts":null,"background":null,"target":"Inspired by this, we propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer. To make the quantization operation in JPEG compression trainable, a new differentiable soft quantizer is employed at the JPEG layer, and then the quantization operation and underlying DNN are jointly trained. Extensive experiments show that in comparison with the standard DL, JPEG-DL delivers significant accuracy improvements across various datasets and model architectures while enhancing robustness against adversarial attacks. Particularly, on some fine-grained image classification datasets, JPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is available on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git."},{"summary":"The Related Paper contrasts the Main Paper by emphasizing the negative impact of JPEG compression on deep learning performance, highlighting that high levels of compression can significantly degrade accuracy on common tasks. While the Main Paper proposes a novel framework that claims to enhance performance through a trainable JPEG compression layer, the Related Paper presents evidence of performance penalties associated with lossy compression, suggesting that the benefits claimed in the Main Paper may not hold under all conditions.","paper_id":"2cd03a0b34d4a300e3e1123f336b04708ffd1d8e","title":"Analyzing and Mitigating Compression Defects in Deep Learning","abstract":"With the proliferation of deep learning methods, many computer vision problems which were considered academic are now viable in the consumer setting. One drawback of consumer applications is lossy compression, which is necessary from an engineering standpoint to efficiently and cheaply store and transmit user images. Despite this, there has been little study of the effect of compression on deep neural networks and benchmark datasets are often losslessly compressed or compressed at high quality. Here we present a unified study of the effects of JPEG compression on a range of common tasks and datasets. We show that there is a significant penalty on common performance metrics for high compression. We test several methods for mitigating this penalty, including a novel method based on artifact correction which requires no labels to train.","score":0.8055890202522278,"polarity":"negative","source":"semantic","contexts":null,"background":"Although it is traditionally believed that lossy image compression, such as JPEG compression, has a negative impact on the performance of deep neural networks (DNNs), it is shown by recent works that well-crafted JPEG compression can actually improve the performance of deep learning (DL).","target":null},{"summary":"The Related Paper contrasts the Main Paper by emphasizing that while the Main Paper claims that JPEG compression can enhance deep learning performance, the Related Paper argues that deep learning image compression methods outperform traditional JPEG in terms of visual quality and efficiency. It highlights the limitations of JPEG-inspired approaches in capturing broader context, suggesting that advanced convolutional modules and attention mechanisms in deep learning models provide superior feature extraction and performance optimization, albeit with a trade-off in rate-distortion performance.","paper_id":"07f85260ca028f06bbee632473afd8bd20fcc24c","title":"Improved deep learning image compression model: performance optimization based on convolutional modules and local attention mechanism","abstract":"Deep learning image compression, using neural networks, improves compression over traditional methods like JPEG. These methods enhance visual quality at lower bit rates by learning better image representations. However, they struggle with capturing broad context compared to local features. To address this, we propose enhancements: a new convolutional module with stacked layers and advanced operations, and a spatial attention block (\"Shuffle attention\") for better feature extraction. These boost performance. Our method is faster and requires fewer parameters than state-of-the-art techniques on Kodak and CLIC datasets. Despite slightly lower rate-distortion performance, our Composite Conv module and spatial attention block effectively extract global features and reduce encoding time. In conclusion, our work advances deep learning image compression by mitigating convolutional network limitations, enhancing compression efficiency while preserving quality.","score":0.7875392436981201,"polarity":"negative","source":"semantic","contexts":null,"background":"Although it is traditionally believed that lossy image compression, such as JPEG compression, has a negative impact on the performance of deep neural networks (DNNs), it is shown by recent works that well-crafted JPEG compression can actually improve the performance of deep learning (DL).","target":null},{"summary":"The Related Paper contrasts the Main Paper by arguing that while the Main Paper promotes the idea that JPEG compression can enhance deep learning performance, the Related Paper emphasizes the entrenched nature of classical compression methods like JPEG and MPEG, which limits the adoption of deep learning solutions for multimedia compression. It suggests that leveraging deep learning to improve classical algorithms is more effective than creating entirely new methods, highlighting a preference for approaches grounded in established engineering principles over novel, less proven techniques.","paper_id":"48861e711dbbe5f0e430171791629d513e0e672c","title":"The First Principles of Deep Learning and Compression","abstract":"The deep learning revolution incited by the 2012 Alexnet paper has been transformative for the field of computer vision. Many problems which were severely limited using classical solutions are now seeing unprecedented success. The rapid proliferation of deep learning methods has led to a sharp increase in their use in consumer and embedded applications. One consequence of consumer and embedded applications is lossy multimedia compression which is required to engineer the efficient storage and transmission of data in these real-world scenarios. As such, there has been increased interest in a deep learning solution for multimedia compression which would allow for higher compression ratios and increased visual quality. The deep learning approach to multimedia compression, so called Learned Multimedia Compression, involves computing a compressed representation of an image or video using a deep network for the encoder and the decoder. While these techniques have enjoyed impressive academic success, their industry adoption has been essentially non-existent. Classical compression techniques like JPEG and MPEG are too entrenched in modern computing to be easily replaced. This dissertation takes an orthogonal approach and leverages deep learning to improve the compression fidelity of these classical algorithms. This allows the incredible advances in deep learning to be used for multimedia compression without threatening the ubiquity of the classical methods. The key insight of this work is that methods which are motivated by first principles, i.e., the underlying engineering decisions that were made when the compression algorithms were developed, are more effective than general methods. By encoding prior knowledge into the design of the algorithm, the flexibility, performance, and/or accuracy are improved at the cost of generality...","score":0.7751079201698303,"polarity":"negative","source":"semantic","contexts":null,"background":"Although it is traditionally believed that lossy image compression, such as JPEG compression, has a negative impact on the performance of deep neural networks (DNNs), it is shown by recent works that well-crafted JPEG compression can actually improve the performance of deep learning (DL).","target":null},{"summary":"The Related Paper contrasts the Main Paper by emphasizing that traditional DNN model compression techniques focus on reducing model size without compromising accuracy, often through elimination of components or complexity penalties. In contrast, the Main Paper argues that JPEG compression can enhance DNN performance, suggesting that compression can be beneficial rather than detrimental. While the Main Paper promotes a novel framework that integrates JPEG compression to improve accuracy and robustness, the Related Paper highlights the risks of unpredictable outcomes in compression methods that do not consider loss function changes.","paper_id":"f2cf9f651a7546d4670e15e8e504572c635c0059","title":"DNN Model Compression Under Accuracy Constraints","abstract":"The growing interest to implement Deep Neural Networks (DNNs) on resource-bound hardware has motivated innovation of compression algorithms. Using these algorithms, DNN model sizes can be substantially reduced, with little to no accuracy degradation. This is achieved by either eliminating components from the model, or penalizing complexity during training. While both approaches demonstrate considerable compressions, the former often ignores the loss function during compression while the later produces unpredictable compressions. In this paper, we propose a technique that directly minimizes both the model complexity and the changes in the loss function. In this technique, we formulate compression as a constrained optimization problem, and then present a solution for it. We will show that using this technique, we can achieve competitive results.","score":0.7724272012710571,"polarity":"negative","source":"semantic","contexts":null,"background":"Although it is traditionally believed that lossy image compression, such as JPEG compression, has a negative impact on the performance of deep neural networks (DNNs), it is shown by recent works that well-crafted JPEG compression can actually improve the performance of deep learning (DL).","target":null},{"summary":"The Related Paper contrasts the Main Paper by arguing that while the Main Paper claims that JPEG compression can enhance deep learning performance, the Related Paper finds that existing compression artifact reduction methods often yield limited improvements or even negative effects on high-level vision tasks. The Related Paper emphasizes a different approach, proposing a compression artifacts reduction framework that focuses on restoring images for DNNs, suggesting that the benefits of compression may not be as straightforward as presented in the Main Paper.","paper_id":"85087eb08e3194ea7ba9c37139e999497ba02357","title":"Reducing Image Compression Artifacts for Deep Neural Networks","abstract":"Existing compression artifacts reduction methods aim to restore images on pixel-level, which can improve the human visual experience. However, in many applications, large-scale images are collected not for visual examination by humans. Instead, they are used for many high-level vision tasks usually by Deep Neural Networks (DNN). In this paper, we find that these methods have limited performance improvements to high-level tasks, even bring negative effects. Therefore, inspired by the teacher-student network framework, we propose a compression artifacts reduction framework (ARF) for DNN. In addition, we generalize our method to the unsupervised setting (U-ARF) where the corresponding original images are unavailable in training. Extensive experiments indicate the proposed methods can help DNNs improve performance on the highly compressed images significantly.","score":0.7672973871231079,"polarity":"negative","source":"semantic","contexts":null,"background":"Although it is traditionally believed that lossy image compression, such as JPEG compression, has a negative impact on the performance of deep neural networks (DNNs), it is shown by recent works that well-crafted JPEG compression can actually improve the performance of deep learning (DL).","target":null},{"summary":"The Related Paper provides a comprehensive overview of JPEG compression techniques, including the Discrete Cosine Transform and various coding models, which underpins the Main Paper's innovative approach of integrating a trainable JPEG compression layer into deep learning frameworks. By detailing the performance and applications of JPEG, the Related Paper supports the Main Paper's claims of improved accuracy and robustness in deep learning models when utilizing JPEG-inspired methods.","paper_id":"a9c521df97e54ffa1c597915e808e7f67bb7cc54","title":"JPEG: Still Image Data Compression Standard","abstract":"Foreword. Acknowledgments. Trademarks. Introduction. Image Concepts and Vocabulary. Aspects of the Human Visual Systems. The Discrete Cosine Transform (DCT). Image Compression Systems. JPEG Modes of Operation. JPEG Syntax and Data Organization. Entropy Coding Concepts. JPEG Binary Arithmetic Coding. JPEG Coding Models. JPEG Huffman Entropy Coding. Arithmetic Coding Statistical. More on Arithmetic Coding. Probability Estimation. Compression Performance. JPEG Enhancements. JPEG Applications and Vendors. Overview of CCITT, ISO, and IEC. History of JPEG. Other Image Compression Standards. Possible Future JPEG Directions. Appendix A. Appendix B. References. Index.","score":0.41476261615753174,"polarity":"positive","source":"citations","contexts":[{"sentence":"JPEG compression \\citep{wallace1992jpeg} is the lossy image compression technique with ubiquitous presence in real-world applications.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper, while not directly focused on deep learning or JPEG compression, supports the Main Paper by emphasizing the importance of open access to scientific research, which includes advancements in deep learning methodologies. The availability of research findings on platforms like arXiv allows for rapid dissemination and collaboration, potentially leading to innovations such as the JPEG-DL framework proposed in the Main Paper. This environment fosters the exploration of novel ideas, like the integration of JPEG compression in deep learning, which can enhance model performance and robustness.","paper_id":"f4327b978dec52f16b089c222c43543f8ecf4717","title":"arXiv","abstract":"The innovative preprint repository, arXiv, was created in the early 1990s to improve access to scientific research. arXiv contains millions of Open Access articles in physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering\n and systems science, and economics. All articles are available for free download on the open web. Often research findings are available on arXiv before they are published in a peer-reviewed journal. arXiv relies on a collaborative support business model where institutions that most heavily\n utilize arXiv contribute financially. Support also comes from Cornell University and the Simons Foundation.","score":0.183680921792984,"polarity":"positive","source":"citations","contexts":[{"sentence":"Beyond its traditional use, JPEG has found numerous applications in deep learning: (1) it has been utilized as a data augmentation technique to improve robustness of DNNs against image compression \\citep{benbarrad2022compression}; (2) it has been employed ","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper supports the Main Paper by demonstrating the importance of robust algorithms in computer vision, which aligns with the Main Paper's findings on enhancing deep learning performance through innovative techniques like JPEG compression. Both papers emphasize the significance of improving accuracy and robustness in their respective domains, with the Related Paper's focus on tracking dynamics complementing the Main Paper's advancements in image classification accuracy through the JPEG-DL framework.","paper_id":"527bcde38f5598553953217eef344b85cfb7fd2d","title":"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","abstract":"We describe a tracking algorithm to address the interactions among objects, and to track them individually and confidently via a static camera. It is achieved by constructing an invariant bipartite graph to model the dynamics of the tracking process, of which the nodes are classified into objects and profiles. The best match of the graph corresponds to an optimal assignment for resolving the identities of the detected objects. Since objects may enter/exit the scene indefinitely, or when interactions occur/conclude they could form/leave a group, the number of nodes in the graph changes dynamically. Therefore it is critical to maintain an invariant property to assure that the numbers of nodes of both types are kept the same so that the matching problem is manageable. In addition, several important issues are also discussed, including reducing the effect of shadows, extracting objects’ shapes, and adapting large abrupt changes in the scene background. Finally, experimental results are provided to illustrate the efficiency of our approach.","score":0.15457914769649506,"polarity":"positive","source":"citations","contexts":[{"sentence":"This experimental setup is also outlined by \\citet{yun2020regularizing}.","polarity":"positive"}],"background":null,"target":null},{"summary":"The Related Paper provides supporting evidence for the Main Paper's claims by demonstrating the effectiveness of incorporating additional components in a system, akin to how the JPEG-DL framework enhances deep learning performance through a trainable JPEG compression layer. While the Related Paper focuses on the formulation of tablets, it parallels the Main Paper's innovative approach to improving DNNs by suggesting that well-designed components can lead to significant performance gains.","paper_id":"a6d27e9e5598780cd9e2bb865f3d5455b333297d","title":"Unknown Title.","abstract":"The tablets contain the following inactive ingredients: corn starch; lactose monohydrate; microcrystalline cellulose; silicon dioxide; sodium starch glycolate; and stearic acid. The 10 mg tablet also contains D&C Red No. 27 aluminum lake. The 15 mg tablet also contains D&C Yellow No. 10 aluminum lake and FD&C Blue No. 2 aluminum lake. The 20 mg tablet also contains FD&C Blue No. 2 aluminum lake; FD&C Red No. 40 aluminum lake; and FD&C Yellow No. 6 aluminum lake. The 30 mg tablet also contains FD&C Blue No. 2 aluminum lake.","score":0.09965136647224426,"polarity":"positive","source":"citations","contexts":[{"sentence":"To validate the effectiveness of JPEG-DL, we conducted extensive experiments for image classification on six datasets including four fine-grained classification datasets \\citep{wah2011caltech,khosla2011novel,nilsback2008automated,parkhi2012cats}, CIFAR-100","polarity":"positive"}],"background":null,"target":null}],"paper":{"title":"JPEG Inspired Deep Learning","abstract":"Although it is traditionally believed that lossy image compression, such as JPEG compression, has a negative impact on the performance of deep neural networks (DNNs), it is shown by recent works that well-crafted JPEG compression can actually improve the performance of deep learning (DL). Inspired by this, we propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer. To make the quantization operation in JPEG compression trainable, a new differentiable soft quantizer is employed at the JPEG layer, and then the quantization operation and underlying DNN are jointly trained. Extensive experiments show that in comparison with the standard DL,  JPEG-DL delivers significant accuracy improvements across various datasets and model architectures while enhancing robustness against adversarial attacks. Particularly, on some fine-grained image classification datasets, JPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is available on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git.","authors":["Ahmed H. Salamah","Kaixiang Zheng","Yiwen Liu","EN-HUI YANG"],"sections":[{"heading":"Introduction","text":"# Introduction\n\nJPEG compression [@wallace1992jpeg] is the *defacto* lossy image compression technique with ubiquitous presence in real-world applications. With the development of deep learning, more and more images, potentially compressed by JPEG, are consumed by deep neural networks (DNNs). Naturally, it's of interest to study how JPEG compression will impact DNN performance for computer vision tasks, and extensive research has been conducted along this line such as @dodge2016understanding [@liu2018deepn] and @xie2019source. These initial explorations establish a widely accepted view that the information loss caused by JPEG obscures important features in the input image, thereby negatively impacting DNN performance.\n\nHowever, it was shown by @yang2021compression that the above conventional wisdom does not hold anymore if JPEG compression is applied intelligently and adaptively on a per-image basis. Indeed, @yang2021compression showed that if applied appropriately, JPEG compression can actually improve DNN performance, at least in theory. They further proposed to train a DNN based on images with various JPEG quality levels. While they managed to demonstrate improved performance with a specially designed DNN topology, the model is too cumbersome to be fully trained, leading to suboptimal performance. Moreover, the adherence to the default JPEG quantization also limits the effectiveness of this method. On the other hand, given a fixed DNN model, @JPEG_Compliant and @salamah2024jpeg found that its performance could be slightly improved if the input images got compressed by JPEG with optimized quantization parameters. However, the performance gain is not significant due to the frozen DNN model. Although these existing works provide promising insights to improve DNN performance with JPEG compression, a solid solution that can fully unleash the potential of this idea has yet to be found.\n\n<figure id=\"fig:jpeg_DL_diagram\">\n\n<figcaption>(a) The JPEG-DL framework is illustrated, with both standard DNN’s operations and the forward/ inverse processes of the standard JPEG pipeline are shown in white boxes as non-trainable components. The JPEG pipeline receives a conventionally preprocessed input image <span class=\"math inline\"><em>x</em> ∈ ℝ<sup>3 × <em>W</em> × <em>H</em></sup></span> sampled from the underlying task’s dataset. The differentiable soft quantizer (<span class=\"math inline\"><em>Q</em><sub><em>d</em></sub></span>) and the underlying DNN architecture (<span class=\"math inline\"><em>f</em><sub><em>θ</em></sub></span>), shown in blue, formed a unified new architecture <span class=\"math inline\"><em>f̂</em>(<em>x</em>; <em>θ</em>, <em>Q</em>, <strong>α</strong>)</span> parametrized with these being the only trainable components. (b) As an example, we show <span class=\"math inline\"><strong>z</strong><sub>1, :,:</sub></span>, i.e., the DCT representation of the Y channel of an image, by a tensor consisting of <span class=\"math inline\"><em>B</em></span> blocks of DCT coefficients. Each 8<span class=\"math inline\">×</span>8 block contains <span class=\"math inline\"><em>M</em> = 64</span> DCT frequencies, ordered from low to high in a zigzag manner. Then, we show how <span class=\"math inline\"><strong>z</strong><sub>1, 1, :</sub></span> and <span class=\"math inline\"><strong>z</strong><sub>1, <em>M</em>, :</sub></span> are quantized by <span class=\"math inline\"><em>Q</em><sub><em>d</em></sub>(⋅ ; <em>q</em> = 1, <em>α</em> = 10)</span> and <span class=\"math inline\"><em>Q</em><sub><em>d</em></sub>(⋅ ; <em>q</em> = 0.5, <em>α</em> = 16)</span>, respectively.</figcaption>\n</figure>\n\nTo address the above issue, in this paper, we propose jointly optimizing both JPEG quantization operation and a DNN to achieve greater effectiveness. To this end, we first introduce a trainable JPEG compression layer, the structure of which is illustrated in Fig. [\\[fig:jpeg_dl_a\\]](#fig:jpeg_dl_a){reference-type=\"ref\" reference=\"fig:jpeg_dl_a\"}. This layer follows the standard JPEG pipeline to convert a preprocessed input image, after passing through the input layer, into blockwise Discrete Cosine Transform (DCT) coefficients in the YCbCr color space. A novel differentiable soft quantizer ($Q_d$) is then applied to quantize the DCT coefficients at each frequency position, followed by the standard JPEG inverse process to reconstruct the RGB image. We then present JPEG-DL, a novel deep learning (DL) framework that introduces a new DNN architecture by inserting a JPEG layer directly after the original input layer of any underlying DNN architecture. This layer can be considered an integral part of any underlying DNN architecture, forming a new unified DNN architecture, whose parameters get optimized jointly with DNN model weights during training. The core of JPEG-DL is $Q_d$ as it substitutes the non-differentiable, hard quantization in JPEG with a differentiable, soft quantization operation defined by a neat analytical formula, which not only facilitates gradient-based optimization for quantization parameters but also introduces additional trainable non-linearity to the overall image understanding pipeline. To validate the effectiveness of JPEG-DL, we conducted extensive experiments for image classification on six datasets including four fine-grained classification datasets [@wah2011caltech; @khosla2011novel; @nilsback2008automated; @parkhi2012cats], CIFAR-100 [@krizhevsky2009learning] and ImageNet [@deng2009imagenet]. Results show that JPEG-DL significantly and consistently outperforms the standard DL across various DNN architectures, with a negligible increase in model complexity. Specifically, JPEG-DL improves classification accuracy by up to 20.9% on some fine-grained classification dataset, while adding only 128 trainable parameters to the DL pipeline. Moreover, the superiority of JPEG-DL over the standard DL is further demonstrated by the enhanced adversarial robustness of the learned unified architecture.\n\nThe main contributions of this paper can be summarized as follows:\n\n-   We introduce a novel trainable JPEG layer leveraging differentiable soft quantizers with nice analytical formulas.\n\n-   Based on the new JPEG layer, we propose a new DL framework dubbed JPEG-DL, which jointly optimizes the JPEG layer and the DNN model during training.\n\n-   The outstanding performance of JPEG-DL over the standard DL is verified by comprehensive experimental results on various image classification datasets across multiple DNN architectures and for a variety of tasks including adversarial defense."},{"heading":"Background and Related Work","text":"# Background and Related Work {#sec:backgorund}\n\n**JPEG applications.** JPEG was originally developed as a lossy image compression technique based on transform coding, which reduces image file sizes by generating their compact representations. Beyond its traditional use, JPEG has found numerous applications in deep learning: (1) it has been utilized as a data augmentation technique to improve robustness of DNNs against image compression [@benbarrad2022compression]; (2) it has been employed as an empirical defense method against adversarial attacks, effectively reducing adversarial perturbations and enhancing the adversarial robustness of DNNs [@DziugaiteGR16; @Das2017KeepingTB; @guo2018countering]; and (3) it has been integrated into the knowledge distillation [@hinton2015distilling] framework by @salamah2024coded, where it helps the teacher model transfer knowledge to the student model in a more effective way. In contrast, this paper focuses on leveraging JPEG to enhance the natural performance, instead of the robust performance, of DNNs without relying on any teacher model.\n\n**Optimizing JPEG Compression for DNN vision.** As a lossy image compression technique, JPEG is developed specifically for the human visual system. As a result, while the information loss introduced by JPEG is often imperceptible to humans, it can significantly degrade the performance of DNNs. This issue gives rise to a line of research which optimizes JPEG compression based on DNN perception. For instance, given a pretrained DNN, @xie2019source, @JPEG_Compliant and @salamah2024jpeg first derive its sensitivity to different DCT frequencies, based on which they customize JPEG quantization tables for this DNN to reach the optimal rate-accuracy tradeoff. Another popular direction is to make JPEG trainable, which integrates the JPEG encoder and DNN into an end-to-end differentiable training framework [@luo2020rate; @xie2022bandwidth]. These methods create differentiable proxies for image quantization and bitrate calculation, so that JPEG compression can be optimized via backpropagation in order to minimize a total loss considering both DNN performance and bitrate. However, all the above works focus on mitigating DNN performance degradation in the presence of JPEG compressed images, but offer little to no improvement on DNN performance when raw images are given as input. On the contrary, this paper leverages JPEG purely as a tool to improve DNN performance on raw images, regardless of its compression capability.\n\n**Improving DNN performance with JPEG.** Due to the aforementioned reason, JPEG compression generally hurts DNN performance. However, it's recently demonstrated by @yang2021compression that, with an oracle guiding the compression process, one can select an optimal quality level to compress each image, enabling the DNN to make its best possible prediction for it. By applying this adaptive JPEG compression across a set of images, one can actually improve the DNN prediction accuracy considerably. This phenomenon, termed \"compression helps\\\" in the original paper, is justified by the fact that compression can remove noise and disturbing background features, thereby highlighting the main object in an image, which helps DNNs make better prediction. Due to the need of ground truth labels in the compression stage, the above adaptive compression scheme is not realizable in most real world applications; however, the discovery of \"compression helps\\\" at least show the potential of using JPEG to improve DNN performance. Thus motivated, the authors in turn proposed an implementable way to improve DNN performance with JPEG. They built a new DNN topology that incorporates 11 parallel branches of an underlying pretrained model, with each branch obtaining as input either the raw image or its compressed version at a varying quality level. The penultimate layer representations from all branches are concatenated and fed into a classification head, which is then trained together with those 11 model backbones as a unified DNN structure. This new DNN topology is clearly too complex to train, so the authors opted for partial training to mitigate the training complexity, therefore resulting in a suboptimal performance. In contrast, our proposed method introduces only 128 additional trainable parameters to the existing DL pipeline, causing negligible complexity increase. Moreover, it's noteworthy that our method is orthogonal to theirs, as our trainable JPEG quantization tables can be embedded into their framework to replace the default JPEG quantization tables, thereby further improving the performance.\n\n**Trainable Activation Functions.** Relentless efforts have been made to search for activation functions that can improve DNN performance. Among all the directions, trainable activation functions have gained particular interest for their flexibility, expressive power, and adaptability during training. @chen1996feedforward propose the adjustable generalized hyperbolic tangent function, which extends the classic hyperbolic tangent function by introducing parameters to control the saturation level and slope of the function. @he2015delving introduce the parametric ReLU (PReLU), a variant of ReLU with a trainable parameter that adjusts the negative part of ReLU. More recently, Kolmogorov-Arnold Networks (KANs) [@liu2024kan] employ trainable activation functions on edges, with nodes simply summing all the incoming activations. Interestingly, the differentiable soft quantizers in our JPEG layer can be interpreted as trainable activation functions whose input is the DCT representations of images. These trainable soft quantizers effectively introduce additional nonlinearity to DNN models, thus improving their expressive power."},{"heading":"JPEG-DL: JPEG Inspired DL","text":"# JPEG-DL: JPEG Inspired DL\n\n## Problem Formulation\n\nIn the JPEG pipeline, an RGB image $x \\in \\mathbb{R}^{3 \\times W \\times H}$ is first converted to the YCbCr color space and then partitioned into $B$ non-overlapping $8 \\times 8$ blocks, where DCT is applied to each of these blocks to obtain the corresponding DCT coefficients. For each color channel, the DCT coefficients in each block are then flattened following the zigzag order, resulting in $M=64$ frequency positions ordered from low frequency to high frequency. Therefore, we denote the DCT coefficients of the image $x$ as ${\\bm{z}}=[z_{l,m,n}]$, where $l=1,2,3$ corresponds to the color channel Y, Cb and Cr respectively, $1 \\leq m \\leq M$ is the index for frequency position, and $1 \\leq n \\leq B$ is the index for block. Up to this point, all operations involved are differentiable. Next, quantization tables $Q_Y = [q_1, q_2, \\dots, q_M]$ and $Q_C = [q_{M+1}, q_{M+2}, \\dots, q_{2M}]$ are used for the luminance (Y) and chrominance (CbCr) channels respectively to quantize their DCT coefficients. Following uniform quantization, we obtain quantized DCT coefficients $\\hat{z}_{l,m,n}=\\round{z_{l,m,n}/q_m} \\cdot q_m$ for $l=1$, and $\\hat{z}_{l,m,n}=\\round{z_{l,m,n}/q_{M+m}} \\cdot q_{M+m}$ for $l=2, 3$. Note that quantization is non-differentiable due to the use of the rounding operation. Finally, inverse operations including blockwise inverse DCT (IDCT) transform, blocks merging and YCbCr-to-RGB color space conversion are conducted over $\\hat{{\\bm{z}}}$ sequentially to obtain the reconstructed RGB image $\\hat{x}$. Similar to their forward counterparts, all these inverse operations are differentiable. Denoting the composition of all the above operations as $\\mathcal{J}$, we then have $\\hat{x}=\\mathcal{J}(x;Q)$, where $Q=(Q_Y, Q_C)$. Hereafter, the mapping $\\mathcal{J}$ stands for the JPEG encoding-decoding operation.\n\nIn supervised learning, each $x \\in \\mathcal{X}$ corresponds to a ground truth label $y \\in \\mathcal{Y}$. Let $f_{\\theta}$ represent a DNN model with trainable weights $\\theta$, and let $\\mathcal{L}$ denote the loss function used to train this DNN. In standard DL, the primary objective is to solve the following minimization problem: $$\\label{eq:general}\n\\min_{\\theta }~\\mathbb{E}[\\mathcal{L}(f_{\\theta}(x), y)].$$ In contrast, JPEG-DL tries to improve the performance of DNN by jointly training it with the JPEG operation. As a result, the formulation should be instead: $$\\label{eq:jpeg-dl}\n\\min_{\\theta,Q}~\\mathbb{E}[\\mathcal{L}(f_{\\theta}(\\mathcal{J}(x;Q)), y)].$$ However, in order to solve ([\\[eq:jpeg-dl\\]](#eq:jpeg-dl){reference-type=\"ref\" reference=\"eq:jpeg-dl\"}) with gradient descent, the key challenge is caused by the non-differentiable quantization operation, which makes the gradients w.r.t. $Q$ almost zero everywhere. To address this issue, we will introduce a *differentiable soft quantizer* ($Q_d$) in the next subsection, replacing the uniform quantizer ($Q_u$) used in $\\mathcal{J}$.\n\n## Differentiable Soft Quantizer\n\nDenote the index set of uniform quantization as $$\\begin{aligned}\n \\label{eq:reconstruction_space}\n\\mathcal{A}&= \\{ -L, -L+1, \\dots, 0, \\dots, L-1, L \\}.   \n\\end{aligned}$$ For convenience, $\\mathcal{A}$ is also regarded as a vector of length $2L+1$. Multiplying $\\mathcal{A}$ with a quantization step size $q$, we get the corresponding reconstruction space $$\\begin{aligned}\n  \\hat{\\mathcal{A}} = q \\times [-L, -L+1, \\dots, 0, \\dots , L-1, L].    \n\\end{aligned}$$ Again, we will regard $\\hat{\\mathcal{A}}$ as both a vector and a set.\n\nTo randomly quantize a DCT coefficient $z$ to an element in $\\hat{\\mathcal{A}}$, we invoke from @yang_patent a trainable conditional probability mass function (CPMF) ${P_{\\alpha}(\\cdot | z) }$ over the reconstruction space $\\hat{\\mathcal{A}}$ or equivalently the index set $\\mathcal{A}$ given $z$, where $\\alpha > 0$ is a trainable parameter: $$\\label{eq:CPMF}\n     P_{\\alpha}(iq | z) = \\frac{e^{-\\alpha (z - iq)^2}}{\\sum_{j \\in \\mathcal{A}} e^{-\\alpha (z - jq)^2 }}, ~\\forall i \\in \\mathcal{A}.$$\n\nExtend $z$ to a vector of length ${2L+1}$, i.e., $[z]_{2L+1} = [\\overbrace{z, \\dots, z}^{\\text{$2L+1$ times}}]$. Then, the CPMF ${ P_{\\alpha}(\\cdot | z) }$, regarded as a vector of length ${2L+1}$, can be easily computed via the softmax operation $\\sigma(\\cdot)$: $$\\begin{aligned}\n \\label{eq:PMF}\n \\big[P_{\\alpha}(\\cdot | z) \\big]_{2L+1} &= \\sigma \\Big(- \\alpha \\times \\left(  \\big[ z \\big]_{2L+1} -   \\hat{\\mathcal{A}} \\right)^2 \\Big).\n\\end{aligned}$$\n\nWith the CPMF ${ P_{\\alpha}(\\cdot | z)  }$, $z$ is now quantized to each $iq \\in \\hat{\\mathcal{A}}$ with probability ${P_{\\alpha}(iq | z)}$. Note that as $\\alpha \\rightarrow \\infty$, ${ P_{\\alpha}(\\cdot | z) }$ approaches an one-hot vector with probability 1 at the nearest point to $z$ in $\\hat{\\mathcal{A}}$ and 0 elsewhere. Therefore, the resulting random quantizer effectively functions as the deterministic uniform quantizer $Q_u(z)=\\round{z/q} \\cdot q$.\n\nBased on the CPMF ${ P_{\\alpha}(\\cdot | z)  }$, we can now define a differentiable soft quantizer $Q_d$ as the conditional expectation of $iq$ given $z$, i.e., $$\\begin{aligned}\n \\label{eq:softQ}\nQ_d(z) = \\mathbb{E}[iq|z]  = \\sum_{i \\in {\\mathcal{A}}} P_{\\alpha}(iq|z) \\cdot iq.    \n\\end{aligned}$$ Similarly, as $\\alpha \\rightarrow \\infty$, $Q_d$ also goes to $Q_u$. Fig. [2](#fig:Qd_shape){reference-type=\"ref\" reference=\"fig:Qd_shape\"} shows how the shape of $Q_d$ varies w.r.t $\\alpha$, given a fixed $q$.\n\n<figure id=\"fig:Qd_shape\">\n\n<figcaption>Illustration of <span class=\"math inline\"><em>Q</em><sub><em>u</em></sub></span> vs. <span class=\"math inline\"><em>Q</em><sub><em>d</em></sub></span> with <span class=\"math inline\"><em>α</em> = 1, 3, 5, 10</span>, where <span class=\"math inline\"><em>L</em></span> and <span class=\"math inline\"><em>q</em></span> are set to 3 and 1, respectively.</figcaption>\n</figure>\n\nThis soft quantizer $Q_d$ serves as an analytical proxy for $Q_u$. It's differentiable everywhere, allowing gradients to flow through it smoothly. More importantly, compared to $Q_u$, $Q_d$ involves a trainable parameter $\\alpha$ which can adjust the softness of the quantizer, thereby introducing more flexibility. In view of these nice properties, $Q_d$ is the ideal candidate in place of $Q_u$ used in $\\mathcal{J}$.\n\nAs a side note, for the reader who is not familiar with quantization, but familiar with the attention operation used in transformer models [@vaswani2017attention], $Q_d$ can be regarded as an attention operation in broad sense, with the query being $z$, the key and value being $\\hat{\\mathcal{A}}$, and the similarity metric between the query and key being negative squared distance instead of dot product.\n\n## Overall Framework of JPEG-DL {#sec:JPEG_framework}\n\nSubstituting $Q_u$ in $\\mathcal{J}$ with $Q_d$, we get a differentiable JPEG layer $\\hat{\\mathcal{J}}$ parameterized by $Q$ and $\\boldsymbol{\\alpha}$, where $\\boldsymbol{\\alpha}=(\\boldsymbol{\\alpha}_Y, \\boldsymbol{\\alpha}_C)$. $\\boldsymbol{\\alpha}_Y = [\\alpha_1, \\alpha_2, \\dots, \\alpha_M]$ and $\\boldsymbol{\\alpha}_C = [\\alpha_{M+1}, \\alpha_{M+2}, \\dots, \\alpha_{2M}]$ are $\\alpha$ tables for the luminance and chrominance channels respectively, used in conjunction with $Q_Y$ and $Q_C$ to quantize DCT coefficients. Following the proposed soft quantization, we obtain quantized DCT coefficients $\\hat{z}_{l,m,n}=Q_d(z_{l,m,n}; q_m, \\alpha_m)$ for $l=1$, and $\\hat{z}_{l,m,n}=Q_d(z_{l,m,n}; q_{M+m}, \\alpha_{M+m})$ for $l=2, 3$, where $Q_d(z; q, \\alpha)$ denotes a differentiable soft quantizer defined in ([\\[eq:softQ\\]](#eq:softQ){reference-type=\"ref\" reference=\"eq:softQ\"}) parameterized by a quantization step $q$ and a scaling factor $\\alpha$. Overall, for an input image $x$, we have $\\hat{x}=\\hat{\\mathcal{J}}(x;Q,\\boldsymbol{\\alpha})$. Therefore, we can rewrite ([\\[eq:jpeg-dl\\]](#eq:jpeg-dl){reference-type=\"ref\" reference=\"eq:jpeg-dl\"}), the JPEG-DL formulation, as $$\\label{eq:diff-jpeg-dl}\n\\min_{\\theta, Q, \\boldsymbol{\\alpha}}~\\mathbb{E}[\\mathcal{L}( f_{\\theta}(\\hat{\\mathcal{J}}(x;Q,\\boldsymbol{\\alpha})), y)],$$ where the expectation can be approximated by the empirical mean over a mini-batch in actual training. Thanks to the use of $Q_d$, ([\\[eq:diff-jpeg-dl\\]](#eq:diff-jpeg-dl){reference-type=\"ref\" reference=\"eq:diff-jpeg-dl\"}) can now be solved by gradient descent with ease (see Appendix [7.1](#app:Partial_Derivatives){reference-type=\"ref\" reference=\"app:Partial_Derivatives\"} for the derivative analytical formulas).\n\nAfter training with JPEG-DL, we get the optimized parameters $\\theta^*$, $Q^*$ and $\\boldsymbol{\\alpha}^*$. Then, we consider the composition of the JPEG layer and the underlying DNN as a unified DNN model $\\hat{f}(x;\\theta^*, Q^*,\\boldsymbol{\\alpha}^*)=f_{{\\theta}^*}(\\hat{\\mathcal{J}}(x;Q^*,\\boldsymbol{\\alpha}^*))$ to do validation. Concretely, any raw input $x$ should be fed into $\\hat{\\mathcal{J}}$, instead of directly to $f_{{\\theta}^*}$, thus allowing the reconstructed image $\\hat{x}$ to be fed into the underlying DNN $f_{{\\theta}^*}$. In other words, the JPEG layer is prepended as the first layer of any underlying DNN.\n\nTo conclude this section, we refer readers to Fig. [\\[fig:jpeg_dl_a\\]](#fig:jpeg_dl_a){reference-type=\"ref\" reference=\"fig:jpeg_dl_a\"} and Fig. [\\[fig:jpeg_dl_b\\]](#fig:jpeg_dl_b){reference-type=\"ref\" reference=\"fig:jpeg_dl_b\"} for an illustration of the inner workings of the JPEG-DL framework."},{"heading":"Experiments","text":"# Experiments {#sec:Experiments}\n\n**CIFAR-100.** We evaluate our proposed method using a transformer-based architecture and four state-of-the-art convolutional neural networks (CNNs): EfficientFormer-L1 [@li2022efficientformer], ResNet [@he2016deep], VGG [@simonyan2014very], MobileNet [@sandler2018mobilenetv2], and ShuffleNet [@ma2018shufflenet]. For ResNet, we employ CIFAR-specific versions: ResNet32, ResNet56, and ResNet110. For VGG, we utilize VGG8 and VGG13. All CNN architectures follow the training recipe from CRD [@tian2019crd] (see Appendix [7.3](#app:cnn_settings){reference-type=\"ref\" reference=\"app:cnn_settings\"}), while for the transformer-based architecture, EfficientFormer-L1, we adhere to the setup proposed by @xu2023initializing (see Appendix [7.5](#app:transformer-based_settings){reference-type=\"ref\" reference=\"app:transformer-based_settings\"}).\n\n**Fine-grained Tasks.** These tasks involve visually similar classes and typically feature fewer training samples per class compared to conventional classification tasks. We evaluate our method on four datasets: CUB-200-2011 [@wah2011caltech], Stanford Dogs [@khosla2011novel], Flowers [@nilsback2008automated], and Pets [@parkhi2012cats]. For CNN architectures, we employ PreAct ResNet-18 [@he2016deep] and DenseNet-BC [@huang2017densely], following the experimental setup and architecture modifications of @zhang2017mixup. For the transformer-based architecture, we use EfficientFormer-L1, adopting the setup outlined by @xu2023initializing (see Appendices [7.4](#app:fine_grained){reference-type=\"ref\" reference=\"app:fine_grained\"} and [7.5](#app:transformer-based_settings){reference-type=\"ref\" reference=\"app:transformer-based_settings\"}).\n\n**JPEG-layer settings** for [CIFAR-100 and fine-grained tasks]{.underline}. To train our JPEG layer, we first study the gradient nature of $Q_d$ with respect to $q$ and $\\alpha$ in ([\\[eq:CPMF\\]](#eq:CPMF){reference-type=\"ref\" reference=\"eq:CPMF\"}) by changing one parameter and fixing the other. Both $q$ and $\\alpha$ are sharable parameters among different numbers of blocks per image. During the calculation of the gradient of $Q_d$ with respect to $\\alpha$, our analysis shows that when $\\alpha$ is sufficiently large, such that $Q_d$ is not too far from $Q_u$, the gradient magnitude for $\\alpha$ is almost zero, as shown in Appendix [7.1](#app:Partial_Derivatives){reference-type=\"ref\" reference=\"app:Partial_Derivatives\"}. This indicates that $\\boldsymbol{\\alpha}$ will not be updated effectively if initialized within a reasonable range. Experiments also confirmed that making $\\boldsymbol{\\alpha}$ trainable does not significantly impact model performance. As a result, we choose not to train $\\boldsymbol{\\alpha}$ in our framework. However, when we explore the calculation of the gradient of $Q_d$ with respect to $q$, the accumulated gradient received from different blocks per image during backpropagation results in unstable gradient magnitudes at a fixed value of $\\alpha$, as shown in our analysis in Appendix [7.1](#app:Partial_Derivatives){reference-type=\"ref\" reference=\"app:Partial_Derivatives\"}. To address this, we use the ADAM optimizer, which adapts the learning rate for each trainable parameter $q$ in our JPEG layer, enabling more efficient training and better convergence. For CIFAR-100, we set the learning rate to 0.003 across all tested models. For the fine-grained datasets, we set the JPEG learning rate to 0.005. Across these datasets, we fix $\\alpha_m = 5$ for all $1 \\leq m \\leq 2M$, and set $L = 2^{b-1}$ in ([\\[eq:reconstruction_space\\]](#eq:reconstruction_space){reference-type=\"ref\" reference=\"eq:reconstruction_space\"}), where $b$ is a tunable hyperparameter set to 8.\n\n**ImageNet-1K.** For all experiments on this dataset, we utilize the standard training recipes shown by @paszke2019pytorch without any modifications. We use SqueezeNet [@iandola2016squeezenet], ResNet-18 and ResNet-34 as our testing underlying models.\n\n**JPEG-layer settings** for [ImageNet-1K]{.underline}. We will utilize specific settings to control the gradient magnitude to ensure more stable updates for $Q$. We define the Gradient Scaling Constants $\\hslash_m=\\alpha_m q_m^2$, $1 \\leq m \\leq 2M$, which allows us to control the magnitude of gradients w.r.t $Q$. Specifically, we fix $\\hslash_m = 0.7$ for all $1 \\leq m \\leq 2M$ . During training, we update the value of $\\alpha_m$ to be ${\\hslash_m}/{q_m^2}$ before calculating the gradients w.r.t $Q$. As a result of controlling the maximum gradient magnitude, we can optimize $Q$ using an SGD optimizer with 0.5 learning rate, instead of an ADAM optimizer. This approach ensures stable and efficient training for quantization table updates (see Appendix [7.2](#app:Gradient_Scaling){reference-type=\"ref\" reference=\"app:Gradient_Scaling\"} for more details). For this dataset, $b$ is equal to 11 across all tested models.\n\n**Quantization Table Initialization.** For [CIFAR-100 and fine-grained tasks]{.underline}, we initialize the quantization table $Q$ based on the reciprocal of sensitivity for each DCT frequency, given a pre-trained model of the underlying DNN architecture, following the approach described by @JPEG_Compliant [@salamah2024jpeg]. Broadly speaking, the sensitivity of a frequency indicates the rate of change of the loss function w.r.t. the perturbation on this frequency, so we favor a smaller quantization step for a more sensitive frequency to limit the distortion amount on it. For [ImageNet-1K]{.underline}, we adopt the strategy from @esser2019learned, where the initialization of $q_m$ is based on the average of absolute values of DCT coefficients across all blocks in all training images that will be quantized by $q_m$. Specifically, $q_m = 2\\sum_{k=1}^N\\sum_{n=1}^B|z_{1,m,n}^{(k)}| / (NB \\sqrt{2^{b-1}})$ for $1 \\leq m\\leq M$, i.e. $Q_Y$, and $q_m = \\sum_{k=1}^N\\sum_{l=2}^3\\sum_{n=1}^B|z_{l,m,n}^{(k)}| / (NB\\sqrt{2^{b-1}})$ for $M+1 \\leq m \\leq 2M$, i.e., $Q_C$, where $k$ is the index for image and $N$ is the number of training images.\n\n::: center\n:::\n\n[]{#table:cifar100 label=\"table:cifar100\"}\n\n::: center\n:::\n\n[]{#table:fine_grained label=\"table:fine_grained\"}\n\n::: center\n:::\n\n[]{#tbl:imagenet label=\"tbl:imagenet\"}\n\n**CIFAR-100 and Fine-grained tasks Results.** The performance of JPEG-DL is shown in Tables [\\[table:cifar100\\]](#table:cifar100){reference-type=\"ref\" reference=\"table:cifar100\"} and [\\[table:fine_grained\\]](#table:fine_grained){reference-type=\"ref\" reference=\"table:fine_grained\"}. Across all seven tested models for CIFAR-100, JPEG-DL consistently provides improvements, with gains of up to 1.53% in top-1 accuracy. In the fine-grained tasks, JPEG-DL offers a substantial performance increase, with improvements of up to 20.90% across all datasets using two different models. Additional results for CIFAR-100 and fine-grained tasks using a transformer-based model are shown in Appendices [7.5](#app:transformer-based_settings){reference-type=\"ref\" reference=\"app:transformer-based_settings\"}. We further extend our results on fine-grained tasks to include a comparison with additional baselines that address the non-differentiability and zero derivative problems of JPEG quantization (see Appendix [7.6](#app:more_baselines){reference-type=\"ref\" reference=\"app:more_baselines\"}). After demonstrating the nonlinearity introduced by inserting the JPEG layer after the input layer, we extend our evaluation to include the replacement of the ReLU activation function with our JPEG layer, which highlights the potential of new forms of nonlinear operations in DNN architectures (see Appendix [7.7](#app:layer_replacement){reference-type=\"ref\" reference=\"app:layer_replacement\"}). Furthermore, we provide comprehensive experiments on the impact of chrominance subsampling on JPEG-DL, as well as a comparison with both non-learnable and learnable preprocessing methods (see Appendix [7.8](#app:Prepossessing){reference-type=\"ref\" reference=\"app:Prepossessing\"}).\n\n**ImageNet-1K Results.** The performance of JPEG-DL is shown in Table [\\[tbl:imagenet\\]](#tbl:imagenet){reference-type=\"ref\" reference=\"tbl:imagenet\"}. With a trivial increase in complexity (adding 128 parameters), JPEG-DL achieves a gain of 0.31% in top-1 accuracy for SqueezeNetV1.1 compared to the baseline using a single round of $Q_d$ quantization operation. By increasing the number of quantization rounds to five, we observe an additional improvement of 0.20%, leading to a total gain of 0.51% over the baseline. The best results are indicated in bold, and values in parentheses indicate relative accuracy gains over the baseline."},{"heading":"Analysis and Discussion","text":"# Analysis and Discussion\n\n**Robustness.** JPEG has generally been used as an empirical defense mechanism against adversarial attacks by mitigating adversarial perturbations and enhancing the robustness of DNNs, as discussed in Section [2](#sec:backgorund){reference-type=\"ref\" reference=\"sec:backgorund\"}. To evaluate the adversarial robustness of JPEG-DL models in comparison to standard DNN, we conduct experiments using two attack methods, FGSM and PGD, on CIFAR-100 with two different models from Table [\\[table:cifar100\\]](#table:cifar100){reference-type=\"ref\" reference=\"table:cifar100\"}. The perturbation budget, Epsilon, ranged from 1 to 4 for both attack methods. For PGD, we applied 5 steps with a perturbation step size of $(2.5 \\times \\text{Epsilon})/\\text{steps}$, following the setup used by @madry2017towards. As shown in Fig. [3](#fig:fgsm_pgd_cifar100){reference-type=\"ref\" reference=\"fig:fgsm_pgd_cifar100\"}, the JPEG-DL models significantly improve the adversarial robustness compared to the standard DNN models, with improvements of up to 15% for FGSM and 6% for PGD. We will show some examples of the quantization tables used in this study in the next subsection.\n\n<figure id=\"fig:fgsm_pgd_cifar100\">\n\n<figcaption>Evaluate the adversarial robustness of JPEG-DL models in comparison to standard DNN on VGG13 and Res56 for CIFAR-100 against FGSM and PGD attacks.</figcaption>\n</figure>\n\n**Designed Quantization Tables.** Fig. [4](#fig:q_table_cifar_fine_grained){reference-type=\"ref\" reference=\"fig:q_table_cifar_fine_grained\"} presents the Y and CbCr quantization tables, both at initialization and after convergence, for VGG13 trained on CIFAR-100 and ResNet-18 trained on the CUB200 dataset. The estimated sensitivity values used to initialize these quantization tables are provided in Appendix [7.10](#app:sensitivity_q_table){reference-type=\"ref\" reference=\"app:sensitivity_q_table\"}.\n\n<figure id=\"fig:q_table_cifar_fine_grained\">\n\n<figcaption>Initial and final quantization tables for VGG13 trained on CIFAR-100 and ResNet18 trained on CUB200, with frequency indices arranged in the default zigzag order.</figcaption>\n</figure>\n\n**Feature maps visualization.** Fig. [5](#fig:feature_Map_1){reference-type=\"ref\" reference=\"fig:feature_Map_1\"} presents the feature maps extracted after the first dense block in DenseNet-121 for both the JPEG-DL model and the baseline model, trained on the CUB200 dataset using the model from Table [\\[table:fine_grained\\]](#table:fine_grained){reference-type=\"ref\" reference=\"table:fine_grained\"}. The output of the feature maps at this stage is of size 56$\\times$`<!-- -->`{=html}56, and both sets are shown in the same sequence using the same original image. The shown example was incorrectly classified by the baseline model, while the JPEG-DL model correctly classified it. In this figure, it is evident that the feature maps from the JPEG-DL model show significantly better contrast between the foreground information (the bird) and the background compared to the feature maps generated by the baseline model. Specifically, the foreground object in the JPEG-DL feature maps is enclosed within a well-defined contour, making it visually distinguishable from the background. In contrast, the baseline model's feature maps show a more blended structure, where the foreground contains higher energy in low frequencies, causing it to blend more smoothly with the background. Additionally, another example in Appendix [7.11](#app:feature_maps){reference-type=\"ref\" reference=\"app:feature_maps\"} shows a similar phenomenon in addition to background information being more effectively removed, following the same setup as the first example. These discrepancies in feature map clarity and contrast are propagated through subsequent blocks of DenseNet-121, eventually contributing to the misclassification problem observed in the baseline model.\n\n**Interpretability using CAM.** Fig. [6](#fig:grad_cam){reference-type=\"ref\" reference=\"fig:grad_cam\"} illustrates GradCAM++ visualizations [@chattopadhay2018grad] for two examples from the CUB-200 dataset, comparing the baseline model with JPEG-DL using ResNet-18 as our underlying model. In both instances, the baseline model incorrectly classifies the input, while the JPEG-DL model correctly classifies it. The visualizations highlight how JPEG-DL focuses more precisely on the main object in the image, demonstrating the model's improved attention to key regions that contribute to correct classification. This highlights the effectiveness of JPEG-DL in enhancing model interpretability and performance, and it also supports the case for background removal discussed in the previous subsection.\n\n<figure id=\"fig:feature_Map_1\">\n\n<figcaption>Feature maps of size 56×56 are shown after the first dense block in DenseNet-121 for both JPEG-DL and baseline models Figs. in <a href=\"#fig:baseline_feature_map\" data-reference-type=\"ref\" data-reference=\"fig:baseline_feature_map\">[fig:baseline_feature_map]</a> and <a href=\"#fig:jpeg_feature_map\" data-reference-type=\"ref\" data-reference=\"fig:jpeg_feature_map\">[fig:jpeg_feature_map]</a>, respectively, using an original input shown in Fig.<a href=\"#fig:original_feature_map\" data-reference-type=\"ref\" data-reference=\"fig:original_feature_map\">[fig:original_feature_map]</a>. The JPEG-DL model highlights the foreground (bird) more distinctly, while the baseline model shows less contrast, contributing to its misclassification.</figcaption>\n</figure>\n\n<figure id=\"fig:grad_cam\">\n\n<figcaption>GradCAM++ visualization for baseline and JPEG-DL models on CUB200 using two examples, where the baseline model incorrectly classified them and the JPEG-DL model correctly classified them.</figcaption>\n</figure>"},{"heading":"Conclusion","text":"# Conclusion\n\nIn contrast to the conventional understanding that JPEG compression negatively impacts the DL performance, this paper introduces a novel trainable JPEG compression layer into the DL pipeline to improve DL performance, termed JPEG-DL. This layer enables gradient-based optimization for quantization parameters and can be integrated seamlessly with any underlying DNN to be trained jointly. To validate the effectiveness of JPEG-DL, we conduct extensive experiments on six image classification datasets and show significant gains over the standard DL. Additionally, we demonstrate that JPEG-DL improves the adversarial robustness of the learned model.\n\n::: thebibliography\n45 urlstyle\n\nJohannes Ballé, Valero Laparra, and Eero P Simoncelli. End-to-end optimized image compression. *arXiv preprint arXiv:1611.01704*, 2016.\n\nTajeddine Benbarrad, Salaheddine Kably, Mounir Arioua, and Nabih Alaoui. Compression-based data augmentation for cnn generalization. In *International Conference on Cybersecurity, Cybercrimes, and Smart Emerging Technologies*, pp. 235--244. Springer, 2022.\n\nYoshua Bengio, Nicholas Léonard, and Aaron Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. *arXiv preprint arXiv:1308.3432*, 2013.\n\nAditya Chattopadhay, Anirban Sarkar, Prantik Howlader, and Vineeth N Balasubramanian. Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks. In *2018 IEEE winter conference on applications of computer vision (WACV)*, pp. 839--847. IEEE, 2018.\n\nChyi-Tsong Chen and Wei-Der Chang. A feedforward neural network with function shape autotuning. *Neural networks*, 9 (4): 627--641, 1996.\n\nNilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Fred Hohman, Li Chen, Michael E. Kounavis, and Duen Horng Chau. Keeping the bad guys out: Protecting and vaccinating deep learning with jpeg compression. *ArXiv*, abs/1705.02900, 2017.\n\nJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. ImageNet: A large-scale hierarchical image database. In *2009 IEEE conference on computer vision and pattern recognition*, pp. 248--255. Ieee, 2009.\n\nSamuel Dodge and Lina Karam. Understanding how image quality affects deep neural networks. In *2016 eighth international conference on quality of multimedia experience (QoMEX)*, pp. 1--6. IEEE, 2016.\n\nGintare Karolina Dziugaite, Zoubin Ghahramani, and Daniel M. Roy. A study of the effect of JPG compression on adversarial images. *CoRR*, abs/1608.00853, 2016.\n\nSteven K Esser, Jeffrey L McKinstry, Deepika Bablani, Rathinakumar Appuswamy, and Dharmendra S Modha. Learned step size quantization. *arXiv preprint arXiv:1902.08153*, 2019.\n\nChuan Guo, Mayank Rana, Moustapha Cisse, and Laurens van der Maaten. Countering adversarial images using input transformations. In *International Conference on Learning Representations*, 2018.\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In *Proceedings of the IEEE international conference on computer vision*, pp. 1026--1034, 2015.\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In *Proceedings of the IEEE conference on computer vision and pattern recognition*, pp. 770--778, 2016.\n\nGeoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distilling the knowledge in a neural network. *arXiv preprint arXiv:1503.02531*, 2 (7), 2015.\n\nGao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected convolutional networks. In *Proceedings of the IEEE conference on computer vision and pattern recognition*, pp. 4700--4708, 2017.\n\nForrest N Iandola. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\\< 0.5 mb model size. *arXiv preprint arXiv:1602.07360*, 2016.\n\nAditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, and Fei-Fei Li. Novel dataset for fine-grained image categorization: Stanford dogs. In *Proc. CVPR workshop on fine-grained visual categorization (FGVC)*, volume 2. Citeseer, 2011.\n\nAlex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. .\n\nYanyu Li, Geng Yuan, Yang Wen, Eric Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, and Jian Ren. Efficientformer: Vision transformers at mobilenet speed. *arXiv preprint arXiv:2206.01191*, 2022.\n\nZihao Liu, Tao Liu, Wujie Wen, Lei Jiang, Jie Xu, Yanzhi Wang, and Gang Quan. DeepN-JPEG: A deep neural network favorable JPEG-based image compression framework. In *Proceedings of the 55th Annual Design Automation Conference*, pp.  18. ACM, 2018.\n\nZiming Liu, Yixuan Wang, Sachin Vaidya, Fabian Ruehle, James Halverson, Marin Soljačić, Thomas Y Hou, and Max Tegmark. Kan: Kolmogorov-arnold networks. *arXiv preprint arXiv:2404.19756*, 2024.\n\nXiyang Luo, Hossein Talebi, Feng Yang, Michael Elad, and Peyman Milanfar. The rate-distortion-accuracy tradeoff: Jpeg case study. *arXiv preprint arXiv:2008.00605*, 2020.\n\nNingning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun. Shufflenet v2: Practical guidelines for efficient cnn architecture design. In *Proceedings of the European conference on computer vision (ECCV)*, pp. 116--131, 2018.\n\nAleksander Madry. Towards deep learning models resistant to adversarial attacks. *arXiv preprint arXiv:1706.06083*, 2017.\n\nMaria-Elena Nilsback and Andrew Zisserman. Automated flower classification over a large number of classes. In *2008 Sixth Indian conference on computer vision, graphics & image processing*, pp. 722--729. IEEE, 2008.\n\nOmkar M Parkhi, Andrea Vedaldi, Andrew Zisserman, and CV Jawahar. Cats and dogs. In *2012 IEEE conference on computer vision and pattern recognition*, pp. 3498--3505. IEEE, 2012.\n\nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. *Advances in neural information processing systems*, 32, 2019.\n\nWilliam B. Pennebaker and Joan L. Mitchell. *JPEG Still Image Data Compression Standard*. Kluwer Academic Publishers, Norwell, MA, United States, 1992. ISBN 0442012721.\n\nAhmed H Salamah, Shayan Mohajer Hamidi, and En-Hui Yang. A coded knowledge distillation framework for image classification based on adaptive jpeg encoding. *Pattern Recognition*, pp. 110966, 2024a.\n\nAhmed H Salamah, Kaixiang Zheng, Linfeng Ye, and En-Hui Yang. Jpeg compliant compression for dnn vision. *IEEE Journal on Selected Areas in Information Theory*, 2024b.\n\nMark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. In *Proceedings of the IEEE conference on computer vision and pattern recognition*, pp. 4510--4520, 2018.\n\nRichard Shin and Dawn Song. Jpeg-resistant adversarial images. In *NIPS 2017 workshop on machine learning and computer security*, volume 1, pp.  8, 2017.\n\nKaren Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. *arXiv preprint arXiv:1409.1556*, 2014.\n\nYonglong Tian, Dilip Krishnan, and Phillip Isola. Contrastive representation distillation. In *International Conference on Learning Representations*, 2020.\n\nZhengzhong Tu, Peyman Milanfar, and Hossein Talebi. Muller: Multilayer laplacian resizer for vision. In *Proceedings of the IEEE/CVF International Conference on Computer Vision*, pp. 6877--6887, 2023.\n\nA Vaswani. Attention is all you need. *Advances in Neural Information Processing Systems*, 2017.\n\nCatherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. The caltech-ucsd birds-200-2011 dataset. .\n\nXiufeng Xie and Kyu-Han Kim. Source compression with bounded dnn perception loss for iot edge computer vision. In *The 25th Annual International Conference on Mobile Computing and Networking*, pp. 1--16, 2019.\n\nXiufeng Xie, Ning Zhou, Wentao Zhu, and Ji Liu. Bandwidth-aware adaptive codec for dnn inference offloading in iot. In *European Conference on Computer Vision*, pp. 88--104. Springer, 2022.\n\nZhiqiu Xu, Yanjie Chen, Kirill Vishniakov, Yida Yin, Zhiqiang Shen, Trevor Darrell, Lingjie Liu, and Zhuang Liu. Initializing models with larger ones. In *The Twelfth International Conference on Learning Representations*, 2023.\n\nEn-Hui Yang and Shayan Mohajer Hamidi. Systems and methods for training deep learning models. .\n\nEn-Hui Yang, Hossam Amer, and Yanbing Jiang. Compression helps deep learning in image classification. *Entropy*, 23 (7): 881, 2021.\n\nSukmin Yun, Jongjin Park, Kimin Lee, and Jinwoo Shin. Regularizing class-wise predictions via self-knowledge distillation. In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition*, pp. 13876--13885, 2020.\n\nHongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. *arXiv preprint arXiv:1710.09412*, 2017.\n\nKaixiang Zheng, Ahmed H. Salamah, Linfeng Ye, and En-Hui Yang. Jpeg compliant compression for dnn vision. In *2023 IEEE International Conference on Image Processing (ICIP)*, pp. 1875--1879, 2023. doi: 10.1109/ICIP49359.2023.10221982.\n:::"},{"heading":"Appendix","text":"# Appendix\n\n## Partial Derivatives of $Q_d$ {#app:Partial_Derivatives}\n\nWith the CPMF ${ P_{\\alpha}(\\cdot | z)  }$ shown in ([\\[eq:PMF\\]](#eq:PMF){reference-type=\"ref\" reference=\"eq:PMF\"}), $z$ is now quantized to each ${\\hat{z} \\in \\hat{\\mathcal{A}} }$ with probability ${P_{\\alpha}(\\hat{z} | z)}$. Denote this random mapping by $$\\begin{aligned}\n \\label{eq:Qprob}\n\\hat{z} =  {Q}_{\\rm p}(z).   \n\\end{aligned}$$ Note that given $z$, ${\\hat{z}}$ is a random variable taking values in ${\\hat{\\mathcal{A}}}$ with distribution ${ P_{\\alpha}(\\cdot | z)}$.\n\n### Quantization Step and Input {#app:Partial_Derivatives_Q_input}\n\nThe partial derivatives of $Q_{d}(z)$ w.r.t. $q$ and $z$ are obtained as $$\\label{eq:partial}\n\\begin{align} \\label{eq:partialW}\n\\frac{\\partial Q_{d}(z)}{\\partial z} &=  2\\alpha \\text{Var}  \\big\\{ Q_{p}(z) \\big\\}, \\\\\n\\frac{\\partial Q_{d}(z)}{\\partial q} &= \\frac{1}{q} \\Big( \\mathbb{E} \\big\\{ Q_{p}(z) \\big\\} + (2\\alpha  z) \\text{Var}  \\big\\{ Q_{p}(z) \\big\\} \\nonumber \\\\ \\label{eq:partialQ}\n& \\qquad -(2\\alpha ) \\text{Skew}_{\\rm u} \\big\\{ Q_{p}(z) \\big\\} \\Big),\n\\end{align}$$ where for any random variable $V$, $$\\text{Skew}_{\\rm u} (V) \\defeq \\sum_{v} v^3 {{\\mathbb{P}}}_V(v) -\\Big(\\sum_{v} v {{\\mathbb{P}}}_V(v) \\Big) \\Big( \\sum_{v} v^2 {{\\mathbb{P}}}_V(v)\\Big).$$\n\n### Scaling Factor $\\alpha$ {#app:Partial_Derivatives_Alpha}\n\nThe partial derivatives of $Q_{d}(Z)$ w.r.t. $\\alpha$ obtained as\n\n$$\\begin{aligned}\n    \\frac{\\partial Q_d(z)}{\\partial \\alpha} &= \\frac{\\partial \\sum_{i \\in \\mathcal{A}} iqP_{\\alpha}(iq|z)}{\\partial \\alpha} \\nonumber \\\\ \n    &=  \\sum_{i \\in \\mathcal{A}} iq\\frac{\\partial P_{\\alpha}(iq|z)}{\\partial \\alpha}\n\\end{aligned}$$ $$\\begin{aligned}\n    \\frac{\\partial P_{\\alpha}(iq|z)}{\\partial \\alpha} &= \\frac{-(z-iq)^2 e^{-\\alpha (z-iq)^2}}{\\sum_{j \\in \\mathcal{A}} e^{-\\alpha (z-jq)^2}} + \\frac{e^{-\\alpha (z-iq)^2 \\sum_{j \\in \\mathcal{A}} (z-jq)^2 e^{-\\alpha (z-jq)^2}}}{(\\sum_{j \\in \\mathcal{A}} e^{-\\alpha (z-jq)^2})^2} \\nonumber \\\\\n    &= P_{\\alpha}(iq|z)\\sum_{j \\in \\mathcal{A}} (z-jq)^2 P_{\\alpha}(jq|z) - (z-iq)^2 P_{\\alpha}(iq|z)\n\\end{aligned}$$ Plugging (2) in (1) yields $$\\begin{aligned}\n    \\frac{\\partial Q_d(z)}{\\partial \\alpha} &=  \\sum_{i \\in \\mathcal{A}} iqP_{\\alpha}(iq|z)\\sum_{j \\in \\mathcal{A}} (z-jq)^2 P_{\\alpha}(jq|z) - \\sum_{i \\in \\mathcal{A}} iq(z-iq)^2 P_{\\alpha}(iq|z) \\nonumber \\\\\n    &= \\mathbb{E}\\{Q_p(z)\\}\\mathbb{E}\\{(z-Q_p(z))^2\\}-\\mathbb{E}\\{Q_p(z)(z-Q_p(z))^2\\} \\nonumber \\\\\n    &= -Cov\\{Q_p(z), (z-Q_p(z))^2\\}\n\\end{aligned}$$\n\nTo gain a better understanding, we fix $q$ and $b$, and analyzed how $\\frac{\\partial Q_d(z)}{\\partial \\alpha}$ behaves for different values of $\\alpha$. From Fig. [7](#fig:partial_derivatives_alpha){reference-type=\"ref\" reference=\"fig:partial_derivatives_alpha\"}, it is evident that the gradient magnitude decreases as $\\alpha$ increases. This indicates that $Q_d$ approaches the shape of the uniform quantizer $Q_u$, as shown previously in Fig. [2](#fig:Qd_shape){reference-type=\"ref\" reference=\"fig:Qd_shape\"}, leading to a reduction in the gradient magnitude for ${\\alpha}$. As a result, when $\\alpha$ becomes sufficiently large, the gradient approaches zero, effectively preventing further updates to $\\alpha$, making it act as a non-trainable parameter at a certain point of the training process. Based on this observation and verified experimental results, we opt not to train $\\alpha$ for simple image classification tasks like CIFAR-100 and fine-grained datasets, as it does not impact the overall performance.\n\n![This Figure illustrates the partial derivatives of $Q_d(z)$ w.r.t. the scaling factor $\\alpha$, where $b=3$ and $q=1$.](gradient_analysis/partial_Q_d_x_partial_alpha_1.pdf){#fig:partial_derivatives_alpha width=\"50%\"}\n\n## Gradient Scaling {#app:Gradient_Scaling}\n\nFigures [\\[fig:partial Q_d(x)\\_q_vary_q\\]](#fig:partial Q_d(x)_q_vary_q){reference-type=\"ref\" reference=\"fig:partial Q_d(x)_q_vary_q\"} and [\\[fig:partial Q_d(x)\\_q_vary_alpha\\]](#fig:partial Q_d(x)_q_vary_alpha){reference-type=\"ref\" reference=\"fig:partial Q_d(x)_q_vary_alpha\"} demonstrate the impact of varying $\\alpha$ and $q$ on the gradient magnitude of $Q_d(z)$ with respect to $q$. As observed, decreasing the value of $q$ while keeping $\\alpha$ constant leads to a decrease in the gradient magnitude. Similarly, decreasing the value of $\\alpha$ while maintaining a fixed $q$ also results in a reduction of the gradient magnitude. To address the instability in updating the trainable parameters $Q$, we propose utilizing $\\alpha$ to regulate the magnitude of $\\frac{\\partial Q_d(z)}{\\partial q}$, as illustrated in Figure [\\[fig:partial Q_d(x)\\_q_vary_alpha\\]](#fig:partial Q_d(x)_q_vary_alpha){reference-type=\"ref\" reference=\"fig:partial Q_d(x)_q_vary_alpha\"}. By leveraging this control mechanism of adjusting $\\alpha$, we can stabilize the magnitude of the gradients that update $q$. This behavior suggests a relationship between $q$ and $\\alpha$ in controlling the gradient magnitude of $Q_d(z)$.\n\nTo explore the relationship between $\\alpha$ and $q$, we refer to the exponent in ([\\[eq:CPMF\\]](#eq:CPMF){reference-type=\"ref\" reference=\"eq:CPMF\"}), $\\alpha(z - i q)^2$, which can be rewritten by expressing $z = c q$, resulting in the form $\\alpha q^2(c - i)^2$. From this, we define a new term, $\\hslash = {\\alpha} q^2$, referred to as the *Gradient Scaling Constant*. To further illustrate this relationship, in Fig. [9](#fig:partial Q_d(x)_q_hardness){reference-type=\"ref\" reference=\"fig:partial Q_d(x)_q_hardness\"}, we set $\\hslash = 2$, and by selecting different pairs of $\\alpha$ and $q$ values, we demonstrate that the maximum magnitude of $\\frac{\\partial Q_d(z)}{\\partial q}$ remains invariant. This confirms that the gradient magnitude can be effectively controlled by adjusting $\\alpha$ based on the last updated value of $q$, according to the specified $\\hslash$ value. This adjustment allows for controlled quantization updates, reducing the potential instability during training. Moreover, by controlling the gradient magnitude, we simplify the optimization process, enabling the use of a single learning rate for all $q$ values by using the SGD optimizer, instead of the ADAM optimizer. This gradient scaling mechanism is analogous to the ADAM optimizer, which adapts different learning rates for individual trainable parameters based on momentum and recent gradient magnitudes.\n\n<figure id=\"fig:partial Q_d(x)_q\">\n\n<figcaption>Figures <a href=\"#fig:partial Q_d(x)_q_vary_q\" data-reference-type=\"ref\" data-reference=\"fig:partial Q_d(x)_q_vary_q\">[fig:partial Q_d(x)_q_vary_q]</a> and <a href=\"#fig:partial_Q_d_x_q_vary_alpha\" data-reference-type=\"ref\" data-reference=\"fig:partial_Q_d_x_q_vary_alpha\">[fig:partial_Q_d_x_q_vary_alpha]</a> illustrate the partial derivatives of <span class=\"math inline\"><em>Q</em><sub><em>d</em></sub>(<em>z</em>)</span> w.r.t. the parameter <span class=\"math inline\"><em>q</em></span> for cases where <span class=\"math inline\"><em>α</em> = 8</span> and <span class=\"math inline\"><em>q</em></span> varies, and <span class=\"math inline\"><em>α</em></span> varies and <span class=\"math inline\"><em>q</em> = 2</span>, respectively. For both figures, we set <span class=\"math inline\"><em>b</em> = 6</span>.</figcaption>\n</figure>\n\n![Demonstrating impact of $\\hslash$ on gradient magnitude for various combinations of $q$ and $\\alpha$. We fixed $\\hslash$=2 and $b$=6.](gradient_analysis/partial_Q_d_x_partial_q_hardness.pdf){#fig:partial Q_d(x)_q_hardness width=\"60%\"}\n\n## CNN-based Architectures Setting {#app:cnn_settings}\n\nFor CIFAR100, we deploy a stochastic gradient descent (SGD) optimizer with a momentum of 0.9, a weight decay of 0.0005, and a batch size of 64. We initialize the learning rate as 0.05, and decay it by 0.1 every 30 epochs after the first 150 epochs until the last 240 epoch. For MobileNetV2, ShuffleNetV1 and ShuffleNetV2, we use a learning rate of 0.01 as this learning rate is optimal for these models in a grid search, while 0.05 is optimal for other models.\n\nFor fine-grained classification tasks, all networks are trained from scratch and optimized by SGD with a momentum of 0.9, weight decay of 0.0001, and an initial learning rate of 0.1,. The learning rate is divided by 10 after epochs 100 and 150 for all datasets, and the total epochs are 200. We set batch size 32 for these fine-grained classification tasks. We use the standard data augmentation technique for ImageNet [@deng2009imagenet], *i.e.*, flipping and random cropping. This experimental setup is also outlined by @yun2020regularizing.\n\n## Fine-grained Model Architectures {#app:fine_grained}\n\nWe use standard ResNet-18 with 64 filters and DenseNet-121 with a growth rate of 32 for image size $224 \\times 224$. For fine-grained classification tasks, we use PreAct ResNet-18 [@he2016deep], which modifies the first convolutional layer with kernel size $3 \\times 3$, strides 1 and padding 1, instead of the kernel size $7 \\times 7$, strides 2 and padding 3, for image size $32 \\times 32$ by following @zhang2017mixup. We use DenseNet-BC structure [@huang2017densely], and the first convolution layer of the network is also modified in the same way as in PreAct ResNet-18 for image size $32 \\times 32$.\n\n## Transformer-based Settings and Results {#app:transformer-based_settings}\n\nIn this section, we compare the performance of JPEG-DL compared to its baseline using the EfficientFormer-L1 model [@li2022efficientformer] on CIFAR-100, as well as two fine-grained datasets, Flowers and Pets. We followed the experimental setup described by @xu2023initializing, adhering to the same configurations mentioned in Table [\\[tab:transformer_settings\\]](#tab:transformer_settings){reference-type=\"ref\" reference=\"tab:transformer_settings\"}. The learning rate was set to 0.003 for CIFAR-100 and 0.005 for the fine-grained tasks, aligning with our standard settings in Section [4](#sec:Experiments){reference-type=\"ref\" reference=\"sec:Experiments\"}.\n\nInterestingly, we found that the best performance for transformer-based architectures was achieved when the quantization tables were initialized with all ones, effectively representing the highest quality factor quantization table for JPEG. The top-1 validation accuracy performance is presented in Table [\\[tbl:transformer-based\\]](#tbl:transformer-based){reference-type=\"ref\" reference=\"tbl:transformer-based\"}, demonstrating the significant improvements achieved by JPEG-DL over the baseline.\n\n[]{#tab:transformer_settings label=\"tab:transformer_settings\"}\n\n::: center\n:::\n\n[]{#tbl:transformer-based label=\"tbl:transformer-based\"}\n\n## Comparison with more Baselines {#app:more_baselines}\n\nIn Table [\\[table:fine_grained_baseline\\]](#table:fine_grained_baseline){reference-type=\"ref\" reference=\"table:fine_grained_baseline\"}, we have included comparisons against other baselines that employed JPEG quantization in the pipeline, but with heuristic approaches to handle the non-differentiability and zero derivative problems of JPEG quantization. For example, @balle2016end allow optimization via stochastic gradient descent by replacing the quantizer with an additive i.i.d. uniform noise, which has the same width as the quantization bins, where $\\hat{z} = z + q * U(-0.5, 0.5)$. However, during validation, they employed $Q_u$ using the trained quantization tables. @shin2017jpeg employ a third-order polynomial approximation of the rounding function to make JPEG differentiable. The gradient approximation through the round function is a key aspect of certain neural network approaches. @esser2019learned[^2] employ a straight-through estimator, originally proposed by @bengio2013estimating, to achieve this approximation. This method treats the round function as a pass-through operation during backpropagation, allowing for effective gradient estimation. Our experimental results demonstrate that we consistently outperform all tested baselines. Even though these methods find a way to make the quantization differentiable, they still hurt the performance. This is consistent with the well-known wisdom in the literature, which also shows that they did not take advantage of the higher level of non-linearity introduced into DNN architectures, as proposed by our JPEG-DL framework.\n\n::: center\n:::\n\n[]{#table:fine_grained_baseline label=\"table:fine_grained_baseline\"}\n\n## Layer Replacement {#app:layer_replacement}\n\nWe extend our evaluation of the JPEG-DL framework to include layer replacement, where we substitute the ReLU activation function with our JPEG layer in ResNet-18. This replacement is implemented directly after the first convolution layer, which has 64 kernels and outputs a feature map of 112x112. For this layer replacement, we did not perform any color space conversion and added a quantization table with a size of 8x8 for each kernel output. We follow the experimental setup mentioned in Section [4](#sec:Experiments){reference-type=\"ref\" reference=\"sec:Experiments\"}, except we use a learning rate of 0.001, $\\alpha$ equal to 2, and $b$ equal to 6 bits. The performance of this approach is shown in the last row of the following table and is compared to the performance of JPEG-DL when the JPEG layer is placed directly after the input layer shown in Fig. [1](#fig:jpeg_DL_diagram){reference-type=\"ref\" reference=\"fig:jpeg_DL_diagram\"}. The results shown in Table [\\[table:layer_replacement\\]](#table:layer_replacement){reference-type=\"ref\" reference=\"table:layer_replacement\"} confirm that this new architecture, resulting from layer replacement with the JPEG layer or inserting the JPEG layer directly after the Input Layer, indeed improves deep learning performance by a significant margin, thereby showing the potential of new forms of nonlinear operation in DNN architectures.\n\n::: center\n:::\n\n[]{#table:layer_replacement label=\"table:layer_replacement\"}\n\n## Comparison with JPEG-based Data Augmentation and Other Preprocessing Methods {#app:Prepossessing}\n\n::: center\n:::\n\n[]{#table:fine_grained_all label=\"table:fine_grained_all\"}\n\n**JPEG-based Data Augmentation.** We have compared and implemented JPEG-based data augmentation across three different sets, each with varying ranges of quantity factor (QF). For each tested range, we randomly select a QF for each image within the mini-batch. These sets have been tested on fine-grained datasets for all the models evaluated. Table [\\[table:fine_grained_all\\]](#table:fine_grained_all){reference-type=\"ref\" reference=\"table:fine_grained_all\"} shows corresponding results for these tested sets. Consistent with the common knowledge in the literature, JPEG-based data augmentation in general degrades the accuracy performance.\n\n**Non-Learnable and Learnable Preprocessing Methods.** We have tested the performance of non-learnable and learnable preprocessing methods during training and validation across all tested models on all tested fine-grained datasets, as demonstrated in Table [\\[table:fine_grained_all\\]](#table:fine_grained_all){reference-type=\"ref\" reference=\"table:fine_grained_all\"}. For non-learnable preprocessing, we have considered applying denoising using a Gaussian kernel and histogram equalization for each image within a mini-batch. As for the learnable one, we have compared it with @tu2023muller as a learnable resize module, which has a bandpass nature in that it learns to boost details in certain frequency subbands that benefit the downstream recognition models. We have applied the same setup mentioned in their paper, in which they fine-tuned the model to achieve some improvement [^3].\n\n**Impact of chrominance subsampling on JPEG-DL.** In Table [\\[table:fine_grained_all\\]](#table:fine_grained_all){reference-type=\"ref\" reference=\"table:fine_grained_all\"}, we evaluate various subsampling schemes for all tested models across all tested fine-grained datasets. Notably, although there is no clear winner among different chroma subsampling methods, DNNs indeed respond to color information differently from human; color information is more important to DNNs than human since chroma subsampling formats 4:4:4 and 4:2:2, in general, give rise to better accuracy performance than the 4:2:0 subsampling format which is adopted predominantly in the image and video coding.\n\n## Fixing Hyperparamters across different datasets\n\nIn Table [\\[table:fine_grained_fixed_hyperparameters\\]](#table:fine_grained_fixed_hyperparameters){reference-type=\"ref\" reference=\"table:fine_grained_fixed_hyperparameters\"}, we evaluate the difference between the hyperparameters used for CIFAR-100 and the fine-grained task, where the only difference lies in the learning rate. In the following setup, we present the results when a learning rate of 0.003 is applied to the fine-grained dataset. We observe that the performance difference is marginal, and in some cases, we can even achieve higher gains in model performance. This suggests that the choice of learning rate can have a significant impact on the effectiveness of the model.\n\n::: center\n:::\n\n[]{#table:fine_grained_fixed_hyperparameters label=\"table:fine_grained_fixed_hyperparameters\"}\n\n## Sensitivity and Q Table Initialization {#app:sensitivity_q_table}\n\nFigure [10](#fig:sensitivity_all){reference-type=\"ref\" reference=\"fig:sensitivity_all\"} presents the estimated sensitivity values for all models considered in the CUB200 dataset and a subset of models used for CIFAR-100, as proposed by [@salamah2024jpeg; @JPEG_Compliant]. These estimated sensitivity values are used to initialize the quantization table for JPEG-DL. Figure [11](#fig:q_tables_app){reference-type=\"ref\" reference=\"fig:q_tables_app\"} illustrates the initial and converged values of the quantization table at the end of training.\n\n<figure id=\"fig:sensitivity_all\">\n<p><br />\n</p>\n<figcaption>The estimated sensitivity is shown for two pre-trained models on the CUB200 (first row) and three pre-trained models on the CIFAR-100 (second row), with sensitivity indices arranged in the default zigzag order.</figcaption>\n</figure>\n\n<figure id=\"fig:q_tables_app\">\n<p><br />\n<br />\n</p>\n<figcaption>Initial and final quantization tables for Res56 trained on CIFAR-100 and DenseNet-121 trained on CUB200.</figcaption>\n</figure>\n\n## Feature maps visualization {#app:feature_maps}\n\nFigure [12](#fig:feature_Map_2){reference-type=\"ref\" reference=\"fig:feature_Map_2\"} presents the feature maps extracted after the first dense block in DenseNet-121 for both the JPEG-DL and the baseline models, trained on the Flowers dataset using the model from Table [\\[table:fine_grained\\]](#table:fine_grained){reference-type=\"ref\" reference=\"table:fine_grained\"}. The shown example was incorrectly classified by the baseline model, while the JPEG-DL model correctly classified it.\n\n<figure id=\"fig:feature_Map_2\">\n<p><br />\n</p>\n<figcaption>Feature maps of size 56×56 are shown after the first dense block in DenseNet-121 for both JPEG-DL and baseline models in Figs. <a href=\"#fig:baseline_feature_map_2\" data-reference-type=\"ref\" data-reference=\"fig:baseline_feature_map_2\">[fig:baseline_feature_map_2]</a> and <a href=\"#fig:jpeg_feature_map_2\" data-reference-type=\"ref\" data-reference=\"fig:jpeg_feature_map_2\">[fig:jpeg_feature_map_2]</a>, respectively, using an original input shown in Fig. <a href=\"#fig:original_feature_map_2\" data-reference-type=\"ref\" data-reference=\"fig:original_feature_map_2\">[fig:original_feature_map_2]</a>. The JPEG-DL model highlights the foreground (flower) more distinctly, while the baseline model shows less contrast, contributing to its misclassification.</figcaption>\n</figure>\n\n## Mitigating the Inference Overhead of Differentiable Soft Quantizers {#app:latency}\n\nThe reconstruction space $\\mathcal{\\hat{A}}$ is configured with a specific size, determined by the parameter $L$, which is set to $2^{b-1}$, as mentioned in Section [4](#sec:Experiments){reference-type=\"ref\" reference=\"sec:Experiments\"}. For CIFAR-100 and Fine-grained datasets, $b$ is set to 8 bits, resulting in a reconstruction space length of 513. For ImageNet-1K, $b$ is set to 11 bits, resulting in a length of 2047. This high dimensionality of the reconstruction space poses a computational challenge during inference when calculating the conditional probability mass function (CPMF) $P_{\\alpha}(\\cdot|z)$. To address this, the support of each CPMF is restricted to the five closest points in $\\mathcal{\\hat{A}}$ to the coefficient $z$ being quantized. This simplification, referred to as the masked CPMF, significantly reduces computational complexity without compromising the effectiveness of the quantization scheme $\\mathcal{Q}_d$.\n\n<figure id=\"fig:CPMF_1\">\n<p><br />\n</p>\n<figcaption>Partial visualization of CPMFs <span class=\"math inline\"><em>P</em><sub><em>α</em></sub>(⋅|<em>z</em> = 0.5)</span> computed using (<a href=\"#eq:PMF\" data-reference-type=\"ref\" data-reference=\"eq:PMF\">[eq:PMF]</a>), with <span class=\"math inline\"><em>L</em> = 1023</span>, <span class=\"math inline\"><em>q</em> = 1</span>, and <span class=\"math inline\"><em>α</em></span> values of (a) 1, (b) 3, (c) 5, and (d) 10. The reconstruction levels between two red dashed lines represent <span class=\"math inline\">ℳ</span>.</figcaption>\n</figure>\n\nFigure [13](#fig:CPMF_1){reference-type=\"ref\" reference=\"fig:CPMF_1\"} demonstrates the rapid decay of probability mass in CPMFs as the reconstruction level $\\hat{z}$ deviates from the quantized value the uniform quantizer $\\mathcal{Q}_u(z)$. The set $\\mathcal{M}$, consisting of five reconstruction levels centered around $\\mathcal{Q}_u(z)$, captures a significant portion of the total probability mass, even in extreme cases where the quantization step $q$ and the parameter $\\alpha$ are very small. This observation suggests that restricting the CPMF support to $\\mathcal{M}$ (masked CPMF) is a valid simplification. Instead of computing the full-space CPMF with length $2L+1$, we can efficiently calculate the masked CPMF with length 5 using softmax on $\\mathcal{M}$. The impact of this simplification on the quantization scheme $\\mathcal{Q}_d$ is negligible, particularly for high values of $\\alpha$, as shown in Table [\\[tab:CPMF\\]](#tab:CPMF){reference-type=\"ref\" reference=\"tab:CPMF\"}. Therefore, using the masked CPMF in our implementation is a justified simplification that significantly reduces computational complexity without compromising accuracy.\n\nSpecifically, Fig. [13](#fig:CPMF_1){reference-type=\"ref\" reference=\"fig:CPMF_1\"} illustrates how fast the probability mass of a reconstruction level $\\hat{z}$ decays in CPMFs as $\\hat{z}$ deviates from the uniform quantizer $\\mathcal{Q}_u(z)$. It's clear that the set $\\mathcal{M}=\\{\\mathcal{Q}_u(z)-2q, \\mathcal{Q}_u(z)-q, \\mathcal{Q}_u(z), \\mathcal{Q}_u(z)+q, \\mathcal{Q}_u(z)+2q\\}$ of reconstruction levels retain a total probability mass close to 1, even in an adversarially chosen scenario where both $q$ and $\\alpha$ are extremely small[^4] (i.e., 1) and the coefficient $C$ being quantized lies exactly at a quantization threshold. Therefore, instead of computing the full-space CPMF with length $2L+1$ following ([\\[eq:PMF\\]](#eq:PMF){reference-type=\"ref\" reference=\"eq:PMF\"}), we only conduct softmax on $\\mathcal{M}$ to get the masked CPMF with length 5. The error in $\\mathcal{Q}_d$ caused by this masking is negligible as shown in Table [\\[tab:CPMF\\]](#tab:CPMF){reference-type=\"ref\" reference=\"tab:CPMF\"}, especially in the high $\\alpha$ case. Therefore, it's totally justified to simplify the full-space CPMF to the masked CPMF in our implementation.\n\nTable [\\[tab:Time_Memory\\]](#tab:Time_Memory){reference-type=\"ref\" reference=\"tab:Time_Memory\"} presents a comparison of inference time and throughput between the standard model and our unified model, which incorporates the JPEG layer with the underlying model. The inference times for both the full-space CPMF and the masked CPMF are measured. The reported inference time is averaged across the entire validation set of ImageNet using Resnet18 from Table [\\[tbl:imagenet\\]](#tbl:imagenet){reference-type=\"ref\" reference=\"tbl:imagenet\"}. These results demonstrate the effectiveness of the proposed approach in addressing the computational complexity of the JPEG-DL framework.\n\n[^1]: Authors contributed equally.\n\n[^2]: We followed the experimental setup defined by @esser2019learned using Stochastic Gradient Descent (SGD) with an initial learning rate of 0.01, adhering to the same learning rate decay schedule as the underlying model. Additionally, we initialized $Q$ by setting it to $2|Q|/ \\sqrt{2^b - 1}$ and implemented gradient scaling during training mentioned in their paper. We also maintained consistency by using the same number of bits used by JPEG-DL.\n\n[^3]: We have verified the correctness of our PyTorch implementation with the authors' TensorFlow implementation provided in <https://colab.research.google.com/github/google-research/google-research/blob/master/muller/muller_demo.ipynb>.\n\n[^4]: As $q$ and $\\alpha$ increase, the CPMF becomes even sharper, and as a result, $\\mathcal{M}$ will capture increasingly higher probability mass."}],"approval":true,"conference":"iclr","rating":3,"year":2025,"id":"c7c7b9b9fdafacf30aecd2dcef1acf425eeaa3aa12912112a83ad5d0ff7ccb79","y_true":1,"y_pred":1,"rationale_true":"Summary: The paper introduces a trainable JPEG inspired layer to neural networks. The new layer performs the linear JPEG steps of RGB to YCbCr and DCT with the non-differentiable quantization step replaced with a learnable quantization proxy finishing with the linear IDCT and YCbCr to RGB.  The learnable quantization proxy uses a soft-max with a tunable parameter which controls how close the proxy matches true quantization. The quantization step size is a learnable parameter in this layer. The paper shows how including this layer as the first layer of neural network architectures can improve their accuracy on different tasks.\n\nStrengths: Overall this is a very interesting paper with an unintuitive result. As the authors point out (ln 30) the conventional wisdom is that JPEG compression removes information from an image and should only hurt neural network accuracy. However as this paper, and some prior works, show that is not necessarily the case. This paper builds significantly on prior works by showing not only that JPEG compression can be mitigated, but that it can actually be a large component of a neural networks success and proposing a method for achieving this. The differential soft quantizer is something which may be useful in many different applications, potentially being a better option that the addition of noise or a straight-through gradient as it more accurately models the information loss. Finally, the results show a clear improvement when incorporating the method.\n\nWeaknesses: While the appendix was fairly comprehensive with additional results there are a few additional things that I would have liked to see. The first is that the paper only tests the JPEG layer as the first layer of the architecture, there could have been more experiments in layer placement that would have been really interesting to see. It also wasn't immediately clear to me how $\\alpha$ was being set in experiments, I understand that there is a derivation of $\\frac{\\partial}{\\partial\\alpha}$ but is that parameter actually trained and if so how was the gradient magnitude controlled? There is some discussion of this from ln 689 but it was a little unclear if $\\alpha$ was fixed or not. One thing missing from the JPEG step was chroma subsampling: another non-linearity. Was this considered? It would be fascinating to see if neural networks respond to missing color information similarly to humans.\n\nLastly, and maybe most importantly, there was little discussion of *why this couterintuitive results holds*. While many view JPEG as something incidental the core idea of JPEG to isolate important information based on frequency bands. My take on the results presented here is that the learnable layer is essentially filtering out information which is irrelevant for the networks task, but I would love to hear the authors take on it. Perhaps such analysis could lead to a more direct approach? (For example: a layer which only filters frequencies or which alters the color channels, etc.)\n\nQuestions: * Could we see even better results if the JPEG layer was included periodically? \n    * What if *all* nonlinearity was replaced with the JPEG layer?\n* Please clarify how $\\alpha$ was used in experiments\n* What about chroma subsampling?\n* Why do the authors think this layer helps?\n\n## Update After Discussion\n\nAfter discussion with the authors I am raising my rating\n\nThe authors did a great job responding to the concerns of myself and fellow reviews and went above and beyond on additional experiments which strengthen the case for this paper quite a bit. I specifically have to call out the layer 1 non-linearity experiments that the authors conducted on a very short turnaround that shows additional gains for the JPEG layer. Given the impact of this result I have to conclude that there is indeed something fundamental about using a JPEG inspired layer as a non-linearity which could have repercussions on the broader field. As I stated in a comment, many view JPEG as something incidental; a specific way of storing images. But the core idea of JPEG is to re-weight frequency bands based on their importance. We know from several studies (Maiya et al. [1] for example) that such re-weighting affects neural networks much as it does humans and this paper gives an actionable method for capturing this phenomenon.\n\n1. Maiya, Shishira R., et al. \"Unifying the Harmonic Analysis of Adversarial Attacks and Robustness.\" BMVC. 2023.","rationale_pred":"Paper Summary: The paper introduces JPEG-DL, a novel deep learning framework that incorporates a trainable JPEG compression layer into DNNs. This layer uses a differentiable soft quantizer, allowing joint training of the JPEG layer and the DNN. The paper claims and demonstrates improved accuracy and adversarial robustness across various datasets and model architectures.\n\nSupporting Evidence:\n- Sharpness-aware Quantization provides insights into quantization challenges, complementing JPEG-DL's quantization techniques.\n- FxP-QNet emphasizes the importance of quantization for model efficiency and accuracy, aligning with JPEG-DL's approach.\n- Fixed-Point Back-Propagation Training demonstrates that effective quantization strategies can lead to significant performance improvements, validating the potential benefits of JPEG-DL.\n- A Quantization-Friendly Separable Convolution for MobileNets highlights the potential for improved performance and efficiency through effective quantization strategies, reinforcing JPEG-DL's findings.\n- Keeping the Bad Guys Out demonstrates that JPEG compression can effectively mitigate adversarial attacks, aligning with JPEG-DL's claim of enhanced adversarial robustness.\n- JPEG: Still Image Data Compression Standard provides a comprehensive overview of JPEG compression techniques, which underpins the Main Paper's innovative approach of integrating a trainable JPEG compression layer into deep learning frameworks.\n\nContradictory Evidence:\n- Analyzing and Mitigating Compression Defects in Deep Learning emphasizes the negative impact of JPEG compression on deep learning performance, contrasting JPEG-DL's claims.\n- Improved deep learning image compression model argues that deep learning image compression methods outperform traditional JPEG, suggesting that JPEG-inspired approaches may not be optimal.\n- The First Principles of Deep Learning and Compression emphasizes the entrenched nature of classical compression methods like JPEG, suggesting that improving classical algorithms is more effective than creating entirely new methods.\n- DNN Model Compression Under Accuracy Constraints highlights that traditional DNN model compression techniques focus on reducing model size without compromising accuracy, contrasting JPEG-DL's claim that compression can enhance performance.\n- Reducing Image Compression Artifacts for Deep Neural Networks finds that existing compression artifact reduction methods often yield limited improvements, suggesting that the benefits of compression may not be as straightforward as presented in JPEG-DL.\n\nConclusion: While the paper presents a novel approach and demonstrates promising results, several contrasting papers highlight the potential drawbacks and limitations of using JPEG compression in deep learning. However, the supporting papers suggest that the specific implementation of a trainable JPEG layer with a differentiable soft quantizer could offer unique advantages. Given the conflicting evidence, the novelty is debatable, but the specific approach appears sufficiently unique to warrant a 'novel' label.","structured_evaluation":{"paper_summary":"The paper introduces JPEG-DL, a novel deep learning framework that incorporates a trainable JPEG compression layer into DNNs. This layer uses a differentiable soft quantizer, allowing joint training of the JPEG layer and the DNN. The paper claims and demonstrates improved accuracy and adversarial robustness across various datasets and model architectures.","supporting_evidence":["Sharpness-aware Quantization provides insights into quantization challenges, complementing JPEG-DL's quantization techniques.","FxP-QNet emphasizes the importance of quantization for model efficiency and accuracy, aligning with JPEG-DL's approach.","Fixed-Point Back-Propagation Training demonstrates that effective quantization strategies can lead to significant performance improvements, validating the potential benefits of JPEG-DL.","A Quantization-Friendly Separable Convolution for MobileNets highlights the potential for improved performance and efficiency through effective quantization strategies, reinforcing JPEG-DL's findings.","Keeping the Bad Guys Out demonstrates that JPEG compression can effectively mitigate adversarial attacks, aligning with JPEG-DL's claim of enhanced adversarial robustness.","JPEG: Still Image Data Compression Standard provides a comprehensive overview of JPEG compression techniques, which underpins the Main Paper's innovative approach of integrating a trainable JPEG compression layer into deep learning frameworks."],"contradictory_evidence":["Analyzing and Mitigating Compression Defects in Deep Learning emphasizes the negative impact of JPEG compression on deep learning performance, contrasting JPEG-DL's claims.","Improved deep learning image compression model argues that deep learning image compression methods outperform traditional JPEG, suggesting that JPEG-inspired approaches may not be optimal.","The First Principles of Deep Learning and Compression emphasizes the entrenched nature of classical compression methods like JPEG, suggesting that improving classical algorithms is more effective than creating entirely new methods.","DNN Model Compression Under Accuracy Constraints highlights that traditional DNN model compression techniques focus on reducing model size without compromising accuracy, contrasting JPEG-DL's claim that compression can enhance performance.","Reducing Image Compression Artifacts for Deep Neural Networks finds that existing compression artifact reduction methods often yield limited improvements, suggesting that the benefits of compression may not be as straightforward as presented in JPEG-DL."],"conclusion":"While the paper presents a novel approach and demonstrates promising results, several contrasting papers highlight the potential drawbacks and limitations of using JPEG compression in deep learning. However, the supporting papers suggest that the specific implementation of a trainable JPEG layer with a differentiable soft quantizer could offer unique advantages. Given the conflicting evidence, the novelty is debatable, but the specific approach appears sufficiently unique to warrant a 'novel' label.","label":1,"rationale":"Paper Summary: The paper introduces JPEG-DL, a novel deep learning framework that incorporates a trainable JPEG compression layer into DNNs. This layer uses a differentiable soft quantizer, allowing joint training of the JPEG layer and the DNN. The paper claims and demonstrates improved accuracy and adversarial robustness across various datasets and model architectures.\n\nSupporting Evidence:\n- Sharpness-aware Quantization provides insights into quantization challenges, complementing JPEG-DL's quantization techniques.\n- FxP-QNet emphasizes the importance of quantization for model efficiency and accuracy, aligning with JPEG-DL's approach.\n- Fixed-Point Back-Propagation Training demonstrates that effective quantization strategies can lead to significant performance improvements, validating the potential benefits of JPEG-DL.\n- A Quantization-Friendly Separable Convolution for MobileNets highlights the potential for improved performance and efficiency through effective quantization strategies, reinforcing JPEG-DL's findings.\n- Keeping the Bad Guys Out demonstrates that JPEG compression can effectively mitigate adversarial attacks, aligning with JPEG-DL's claim of enhanced adversarial robustness.\n- JPEG: Still Image Data Compression Standard provides a comprehensive overview of JPEG compression techniques, which underpins the Main Paper's innovative approach of integrating a trainable JPEG compression layer into deep learning frameworks.\n\nContradictory Evidence:\n- Analyzing and Mitigating Compression Defects in Deep Learning emphasizes the negative impact of JPEG compression on deep learning performance, contrasting JPEG-DL's claims.\n- Improved deep learning image compression model argues that deep learning image compression methods outperform traditional JPEG, suggesting that JPEG-inspired approaches may not be optimal.\n- The First Principles of Deep Learning and Compression emphasizes the entrenched nature of classical compression methods like JPEG, suggesting that improving classical algorithms is more effective than creating entirely new methods.\n- DNN Model Compression Under Accuracy Constraints highlights that traditional DNN model compression techniques focus on reducing model size without compromising accuracy, contrasting JPEG-DL's claim that compression can enhance performance.\n- Reducing Image Compression Artifacts for Deep Neural Networks finds that existing compression artifact reduction methods often yield limited improvements, suggesting that the benefits of compression may not be as straightforward as presented in JPEG-DL.\n\nConclusion: While the paper presents a novel approach and demonstrates promising results, several contrasting papers highlight the potential drawbacks and limitations of using JPEG compression in deep learning. However, the supporting papers suggest that the specific implementation of a trainable JPEG layer with a differentiable soft quantizer could offer unique advantages. Given the conflicting evidence, the novelty is debatable, but the specific approach appears sufficiently unique to warrant a 'novel' label."},"arxiv_id":"2410.07081"},"terms":{"tasks":["improve the performance of deep learning","increase prediction accuracy","enhance robustness against adversarial attacks"],"methods":["JPEG-DL","differentiable soft quantizer"],"metrics":["accuracy"],"resources":["JPEG compression","datasets","code"],"relations":[{"head":"JPEG-DL","tail":"improve the performance of deep learning"},{"head":"JPEG-DL","tail":"increase prediction accuracy"},{"head":"JPEG-DL","tail":"enhance robustness against adversarial attacks"},{"head":"differentiable soft quantizer","tail":"trainable JPEG compression layer"},{"head":"accuracy","tail":"increase prediction accuracy"},{"head":"JPEG compression","tail":"improve the performance of deep learning"},{"head":"datasets","tail":"increase prediction accuracy"},{"head":"code","tail":"improve the performance of deep learning"}]},"background":"Although it is traditionally believed that lossy image compression, such as JPEG compression, has a negative impact on the performance of deep neural networks (DNNs), it is shown by recent works that well-crafted JPEG compression can actually improve the performance of deep learning (DL).","target":"Inspired by this, we propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer. To make the quantization operation in JPEG compression trainable, a new differentiable soft quantizer is employed at the JPEG layer, and then the quantization operation and underlying DNN are jointly trained. Extensive experiments show that in comparison with the standard DL, JPEG-DL delivers significant accuracy improvements across various datasets and model architectures while enhancing robustness against adversarial attacks. Particularly, on some fine-grained image classification datasets, JPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is available on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git."}]
