root := `git rev-parse --show-toplevel`
eval_cmd := "uv run gpt eval"

# Configuration selector
demos := env("DEMOS", "eval_4")
model := env("MODEL", "4o-mini")
data := env("DATA", "subset")

# Number of items
n := if data == "full" {
    "125"
} else {
    "0"
}

# Sans data paths
data_sans := if data == "full" {
    root + "/output/output_new/subset/peerread_with_s2_references.json"
} else {
    root + "/output/subset/peerread_with_s2_references.json"
}

# Full data paths
data_full := if data == "full" {
    root + "/output/output_new/peter_summarised/result.json"
} else {
    root + "/output/peter_c2_s2_sum/result.json"
}

eval_flags := "--demos " + demos + " -n " + n + " -m " + model
eval_sans := eval_flags + " --peerread " + data_sans
eval_full := eval_flags + " --papers " + data_full
output := root+"/output/eval/graph/"+data+"/"+model+"/"+demos

_default:
    @echo "Environment variables:"
    @echo "    MODEL: '4o' or '4o-mini' (default)"
    @echo "    DATA: 'full' or 'subset' (default)"
    @echo "    DEMOS: see 'gpt demos'. Default: eval_4."
    @echo
    @just --list --unsorted

_t msg:
    @echo '{{ style("warning") }}>>> {{msg}}{{ NORMAL }}'

# Graph evaluation
_graph prompt:
    {{eval_cmd}} graph run {{eval_full}} --output {{output}}/graph/{{prompt}} --eval-prompt {{prompt}}

# Graph-eval with abstract-only prompt
[group: 'graph']
graph-sans: (_t "Running graph evaluation - sans mode")
    @just _graph sans

# Graph-eval with PETER prompt
[group: 'graph']
graph-related: (_t "Running graph evaluation - PETER (related) mode")
    @just _graph related

# Graph-eval with full graph prompt
[group: 'graph']
graph-all: (_t "Running graph evaluation - main graph mode")
    @just _graph full-graph

# Graph-eval with title and graph prompt
[group: 'graph']
graph-title: (_t "Running graph evaluation - title-only graph")
    @just _graph title-graph

# Graph-eval with only graphs prompt
[group: 'graph']
graph-only: (_t "Running graph evaluation - graphs only")
    @just _graph only-graph

# PETER evaluation
_peter prompt:
    {{eval_cmd}} peter run {{eval_full}} --output {{output}}/peter/{{prompt}} --user-prompt {{prompt}}

# PETER-eval with abstract-only prompt
[group: 'peter']
peter-sans: (_t "Running PETER evaluation - sans mode")
    @just _peter sans

# PETER-eval with full PETER prompt
[group: 'peter']
peter-related: (_t "Running graph evaluation - PETER (related) mode")
    @just _peter simple

# Full evaluation
[group: 'sans']
sans: (_t "Running sans evaluation")
    {{eval_cmd}} sans run {{eval_sans}} --output {{output}}/sans --user-prompt simple-abs

# Compare all implementations of sans evaluation
cmp-sans: (_t "Comparing sans evaluation")
    @just sans
    @just peter-sans
    @just graph-sans

# Compare all implementations of PETER (related) evaluation
cmp-related: (_t "Comparing PETER (related) evaluation")
    @just peter-related
    @just graph-related

# Run all unique experiments (sans/PETER/graph)
all: (_t "Comparing sans/PETER/graph variants")
    @just sans
    @just peter-related
    @just graph-all

# Run all graph versions
all-graphs: (_t "Run all main graph versions and show metrics")
    @just graph-only
    @just graph-title
    @just graph-all
    @just metrics

# Show metrics for all available runs
metrics:
    #!/usr/bin/env fish
    echo "Metrics for model: {{model}}, data: {{data}}, demos: {{demos}}"
    {{root}}/scripts/experiments/show_eval_results.fish {{output}}/**/metrics.json
